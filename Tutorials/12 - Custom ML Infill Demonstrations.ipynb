{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom ML Infill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a companion to the essay [Custom ML Infill with Automunge](https://medium.com/automunge/custom-ml-infill-with-automunge-5b31d7cfd4d2), and demonstrates user-defined machine learning training and inference operations for integration into Automunge's ML infill.\n",
    "\n",
    "We recommend reading the essay prior to this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data is kind of a fundamental obstacle for machine learning, as backpropagation requires all valid entries. ML infill is a more sophisticated convention than often common practices like mean imputation to numeric sets or constant imputation to categoric. By feature set specific partitioning of the training data, feature set specific machine learning models are trained to impute missing data based on properties of the surrounding features. Sounds simple, doesn’t it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial demonstrates a new convention allowing users to define custom machine learning algorithms for integration into Automunge’s ML infill. These custom learning algorithms could be built around gradient boosting, neural networks, or even quantum machine learning, whatever you want. All you have to do is define a wrapper function for your model tuning / training and a wrapper function for inference. You pass those functions as part of the automunge(.) call, and we do all the rest. Sounds simple, doesn’t it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can either define separate wrapper functions for classification and regression, or you can define a single wrapper function and use the received labels column header to distinguish between whether a received label set is a target for classification (1) or regression (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full templates provided in essay appendices and read me\n",
    "def customML_train_classifier(labels, features, columntype_report, commands, randomseed):\n",
    "  ...\n",
    "  return model\n",
    "def customML_train_regressor(labels, features, columntype_report, commands, randomseed):\n",
    "  ...\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convention is really simple, your wrapper function receives as input a dataframe of labels, a dataframe of features, a report of feature properties, any commands that you passed as part of the automunge(.) call for the operation, and a unique sampled randomseed. You then tune and train a model however you want and return the trained model from the function and let us handle the rest (basically that means we’ll store the model in the returned dictionary that is used as key to prepare additional data).\n",
    "\n",
    "The features will be received as a numerically encoded dataframe consistent with form returned from automunge(.), excluding any features from transforms that may return non-numeric entries or otherwise identified as a channel for data leakage. Any missing data will have received an initial imputation applied as part of the transformation functions, which initial imputation may be replaced when that feature has already been targeted with ML infill. Categoric features will be integer encoded, which could include ordinal integers, one hot encodings, or binarizations. The columntype_report can be used to access feature properties, and will include a list of all categoric features, a list of all numeric features, or more granular details such as listed categoric features of a certain type and groupings (the form will be similar to the final version returned as postprocess_dict['columtype_report']).\n",
    "\n",
    "The labels for a classification target will be received as a single column pandas series with header as the integer 1, and entries in the form of str(int), which basically means entries will be integers that have been converted to strings. The str(int) convention we believe is a neat concept since some libraries like their classification targets as strings and some prefer integers, so this way if you library is integer based classification you can just convert the labels with labels.astype(int) and you’re off to the races. The labels for a regression target will also be a single column pandas series, but this time with column header as the integer 0 and entries as floats. (Received continuous integer types for regression targets can be treated as floats since we’ll round them back to integers after inference.)\n",
    "\n",
    "Any imports needed, such as for learning libraries and stuff, can either be performed external to the automunge(.) call or included as an import operation within the wrapper functions. Pandas is available as pd, Numpy as np, spicy.stats as stats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes time to use that model for inference, we’ll access the appropriate model and pass it to your corresponding custom inference function along with the correspondingly partitioned features dataframe serving as basis and any commands a user passed as part of the automunge(.) call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full templates provided in essay appendices and read me\n",
    "def customML_predict_classifier(features, model, commands):\n",
    "  ...\n",
    "  return infill\n",
    "def customML_predict_regressor(features, model, commands):\n",
    "  ...\n",
    "  return infill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So then you just use the predict wrapper function to run your inference and return the resulting derived infill. The form of the returned infill is user choice, you can provide the derivations as a single column array, single column dataframe, or as a series. Regression output is expected as floats. Classification output types can be returned as int or as str(int). Up to you. Once we access the infill we’ll convert it back to whatever form is needed. We’ll take it from there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined our custom ML wrapper functions, now all it takes to integrate into an automunge call is passing them through the ML_cmnd parameter. Here we demonstration choosing customML as the autoML_type (meaning we apply your defined functions instead of the default random forest), passing any desired parameters to your functions (which may differ between automunge(.) calls), and passing the functions themselves. This also demonstrates passing parameters to the customML functions which are received as the input \"commands\" - in this example classification training and inference would receive the diciontary commands = {'parameter1' : 'value1'}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_cmnd = {'autoML_type' : 'customML',\n",
    "           'MLinfill_cmnd' : {'customML_Classifier':{'parameter1' : 'value1'},\n",
    "                              'customML_Regressor' :{'parameter2' : 'value2'}},\n",
    "           'customML' : {'customML_Classifier_train'  : customML_train_classifier, \n",
    "                         'customML_Classifier_predict': customML_predict_classifier, \n",
    "                         'customML_Regressor_train'   : customML_train_regressor, \n",
    "                         'customML_Regressor_predict' : customML_predict_regressor}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the library has an internal suite of inference functions for different ML libraries that can optionally be used in place of a user defined customML inference function. These can be activated by passing a string to entries for ‘customML_Classifier_predict’ or ‘customML_Regressor_predict’ as one of `{‘tensorflow’, ‘xgboost’, ‘catboost’, ‘flaml’, ‘autogluon’, ‘randomforest’}`. Use of the internally defined inference functions allows a user to upload a postprocess_dict in a separate notebook without needing to first reinitialize the customML inference functions. For example, to apply a default inference function for the XGBoost library could apply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this demonstrates applying a default inference function for xgboost\n",
    "#by way of string  'xgboost' specification\n",
    "#to ML_cmnd['customML']['customML_Classifier_predict']\n",
    "#and ML_cmnd['customML']['customML_Regressor_predict']\n",
    "\n",
    "#customML_train_classifier and customML_train_regressor\n",
    "#should be user defined training functions built around xgboost library\n",
    "#per the templates in Appendix A\n",
    "\n",
    "ML_cmnd = {'autoML_type' : 'customML',\n",
    "           'customML' : {'customML_Classifier_train'  : customML_train_classifier, \n",
    "                         'customML_Classifier_predict': 'xgboost', \n",
    "                         'customML_Regressor_train'   : customML_train_regressor, \n",
    "                         'customML_Regressor_predict' : 'xgboost'}}\n",
    "                         \n",
    "#default inference functions currently available for following libraries\n",
    "#{'tensorflow', 'xgboost', 'catboost', 'flaml', 'autogluon', 'randomforest'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined the customML training functions and populated a ML_cmnd specificaiton, they can they be passed to an automunge(.) call as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Automunge import *\n",
    "am = AutoMunge()\n",
    "\n",
    "train, train_ID, labels, \\\n",
    "val, val_ID, val_labels, \\\n",
    "test, test_ID, test_labels, \\\n",
    "postprocess_dict = \\\n",
    "am.automunge(df_train,\n",
    "            labels_column = labels_column,\n",
    "            ML_cmnd = ML_cmnd,\n",
    "            printstatus=True)\n",
    "\n",
    "#download postprocess_dict for use in another notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use that postprocess_dict to prepare additional corresponding data in a separate notebook. Because we used the default inference functions instead of user defined inference functions, we won't need to re-initialize the inference function definitions prior to uploading postprocess_dict in another notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, test_ID, test_labels, \\\n",
    "postreports_dict = \\\n",
    "am.postmunge(postprocess_dict, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the essay we gave examples of defined training and corresponding inference functions built around random forest. Here we'll demonstrate defining training functions for each of these libraries that can make use of the internally defined inference functions. A user could use any of these functions as a starting point for building a training loop incorporating hyperparameter tuning or whatever bells and whistles they prefer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following demonstrated customML training pipelines are compatible with the internally defined inference options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customML_train_classifier(labels, features, columntype_report, commands, randomseed):\n",
    "  \n",
    "  #note that RandomForestClassifier already imported in Automunge\n",
    "  model = RandomForestClassifier(**commands)\n",
    "\n",
    "  #labels are received as str(int), for this demonstration will convert to integer\n",
    "  labels = labels.astype(int)\n",
    "\n",
    "  model.fit(features, labels)\n",
    "\n",
    "  return model\n",
    "\n",
    "#___________________________________________________\n",
    "\n",
    "def customML_train_regressor(labels, features, columntype_report, commands, randomseed):\n",
    "  \n",
    "  #note that RandomForestRegressor already imported in Automunge\n",
    "  model = RandomForestRegressor(**commands)\n",
    "\n",
    "  model.fit(features, labels)\n",
    "\n",
    "  return model\n",
    "\n",
    "#___________________________________________________\n",
    "\n",
    "ML_cmnd = {'autoML_type' : 'customML',\n",
    "           'customML' : {'customML_Classifier_train'  : customML_train_classifier, \n",
    "                         'customML_Classifier_predict': 'randomforest', \n",
    "                         'customML_Regressor_train'   : customML_train_regressor, \n",
    "                         'customML_Regressor_predict' : 'randomforest'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customML_train_classifier(labels, features, columntype_report, commands, randomseed):\n",
    "  \n",
    "  from autogluon import TabularPrediction as task\n",
    "  \n",
    "  #autogluon accepts labels as part of training set\n",
    "  features = pd.concat([features, labels], axis=1)\n",
    "  \n",
    "  label = labels.name\n",
    "  \n",
    "  model = task.fit(train_data=features, label=label, **commands, random_seed=randomseed)\n",
    "\n",
    "  return model\n",
    "\n",
    "#___________________________________________________\n",
    "\n",
    "def customML_train_regressor(labels, features, columntype_report, commands, randomseed):\n",
    "  \n",
    "  from autogluon import TabularPrediction as task\n",
    "  \n",
    "  #autogluon accepts labels as part of training set\n",
    "  features = pd.concat([features, labels], axis=1)\n",
    "  \n",
    "  label = labels.name\n",
    "  \n",
    "  model = task.fit(train_data=features, label=label, **commands, random_seed=randomseed)\n",
    "\n",
    "  return model\n",
    "\n",
    "#___________________________________________________\n",
    "\n",
    "ML_cmnd = {'autoML_type' : 'customML',\n",
    "           'customML' : {'customML_Classifier_train'  : customML_train_classifier, \n",
    "                         'customML_Classifier_predict': 'autogluon', \n",
    "                         'customML_Regressor_train'   : customML_train_regressor, \n",
    "                         'customML_Regressor_predict' : 'autogluon'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customML_train_classifier(labels, features, columntype_report, commands, randomseed):\n",
    "  \n",
    "  from flaml import AutoML\n",
    "  \n",
    "  #flaml takes numeric classificaiton targets\n",
    "  labels = labels.astype(int)\n",
    "  \n",
    "  commands.update({'task' : 'classification'})\n",
    "  \n",
    "  model = AutoML()\n",
    "\n",
    "  #train the model without validation set\n",
    "  model.fit(\n",
    "    features, labels, **commands\n",
    "  )\n",
    "\n",
    "  return model\n",
    "\n",
    "#___________________________________________________\n",
    "\n",
    "def customML_train_regressor(labels, features, columntype_report, commands, randomseed):\n",
    "  \n",
    "  from flaml import AutoML\n",
    "  \n",
    "  commands.update({'task' : 'regression'})\n",
    "  \n",
    "  model = AutoML()\n",
    "\n",
    "  #train the model without validation set\n",
    "  model.fit(\n",
    "    features, labels, **commands\n",
    "  )\n",
    "\n",
    "  return model\n",
    "\n",
    "#___________________________________________________\n",
    "\n",
    "ML_cmnd = {'autoML_type' : 'customML',\n",
    "           'customML' : {'customML_Classifier_train'  : customML_train_classifier, \n",
    "                         'customML_Classifier_predict': 'flaml', \n",
    "                         'customML_Regressor_train'   : customML_train_regressor, \n",
    "                         'customML_Regressor_predict' : 'flaml'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customML_train_classifier(labels, features, columntype_report, commands, randomseed):\n",
    "  \n",
    "  from catboost import CatBoostClassifier\n",
    "#   from catboost import CatBoostRegressor\n",
    "  \n",
    "  categorical_features_indices = columntype_report['all_categoric']\n",
    "  \n",
    "  model = CatBoostClassifier()\n",
    "\n",
    "  #train the model without validation set\n",
    "  model.fit(\n",
    "    features, labels, **commands\n",
    "  )\n",
    "\n",
    "  return model\n",
    "\n",
    "#___________________________________________________\n",
    "\n",
    "def customML_train_regressor(labels, features, columntype_report, commands, randomseed):\n",
    "  \n",
    "#   from catboost import CatBoostClassifier\n",
    "  from catboost import CatBoostRegressor\n",
    "  \n",
    "  categorical_features_indices = columntype_report['all_categoric']\n",
    "  \n",
    "  model = CatBoostRegressor()\n",
    "\n",
    "  #train the model without validation set\n",
    "  model.fit(\n",
    "    features, labels, **commands\n",
    "  )\n",
    "\n",
    "  return model\n",
    "\n",
    "#___________________________________________________\n",
    "\n",
    "ML_cmnd = {'autoML_type' : 'customML',\n",
    "           'customML' : {'customML_Classifier_train'  : customML_train_classifier, \n",
    "                         'customML_Classifier_predict': 'catboost', \n",
    "                         'customML_Regressor_train'   : customML_train_regressor, \n",
    "                         'customML_Regressor_predict' : 'catboost'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customML_train_classifier(labels, features, columntype_report, commands, randomseed):\n",
    "  \n",
    "  from xgboost import XGBClassifier\n",
    "#   from xgboost import XGBRegressor\n",
    "\n",
    "  labels = labels.astype(int)\n",
    "  \n",
    "  default_model_params = {'verbosity' : 1,\n",
    "                           'use_label_encoder' : False}\n",
    "  \n",
    "  model = XGBClassifier(**default_model_params)\n",
    "\n",
    "  #train the model without validation set\n",
    "  model.fit(\n",
    "    features, labels, **commands\n",
    "  )\n",
    "\n",
    "  return model\n",
    "\n",
    "#___________________________________________________\n",
    "\n",
    "def customML_train_regressor(labels, features, columntype_report, commands, randomseed):\n",
    "  \n",
    "#   from xgboost import XGBClassifier\n",
    "  from xgboost import XGBRegressor\n",
    "\n",
    "  default_model_params = {'verbosity' : 1}\n",
    "  \n",
    "  model = XGBRegressor(**default_model_params)\n",
    "\n",
    "  #train the model without validation set\n",
    "  model.fit(\n",
    "    features, labels, **commands\n",
    "  )\n",
    "\n",
    "  return model\n",
    "\n",
    "#___________________________________________________\n",
    "\n",
    "ML_cmnd = {'autoML_type' : 'customML',\n",
    "           'customML' : {'customML_Classifier_train'  : customML_train_classifier, \n",
    "                         'customML_Classifier_predict': 'xgboost', \n",
    "                         'customML_Regressor_train'   : customML_train_regressor, \n",
    "                         'customML_Regressor_predict' : 'xgboost'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customML_train_classifier(labels, features, columntype_report, commands, randomseed):\n",
    "  \n",
    "  import tensorflow as tf\n",
    "\n",
    "  from tensorflow.keras.models import Sequential\n",
    "  from tensorflow.keras.layers import Dense\n",
    "  from tensorflow.keras.layers import Dropout\n",
    "\n",
    "  labels = labels.astype(int)\n",
    "  \n",
    "  #will implement tf classification with one hot labels\n",
    "  #with unique sigmoid activation per column\n",
    "  \n",
    "  maxlabel = labels.max()\n",
    "  nunique = maxlabel+1\n",
    "  \n",
    "  labels_onehot = pd.DataFrame()\n",
    "  \n",
    "  for entry in range(nunique):\n",
    "    labels_onehot[entry] = np.where(labels==entry, 1, 0)\n",
    "    \n",
    "  featurecount = len(list(features))\n",
    "\n",
    "  def create_model():\n",
    "\n",
    "    #create model with keras\n",
    "    model = Sequential()\n",
    "    #layer widths are kind of arbitrarily populated\n",
    "    model.add(Dropout(0.1, input_shape=(featurecount,)))\n",
    "    model.add(Dense(int(featurecount/2), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(int(featurecount/4), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(int(featurecount/6), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(nunique, activation='sigmoid'))\n",
    "\n",
    "    #compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "  \n",
    "  model = create_model()\n",
    "  \n",
    "  features = features.to_numpy()\n",
    "  labels_onehot = labels_onehot.to_numpy()\n",
    "  \n",
    "  train = tf.convert_to_tensor(features)\n",
    "  labels = tf.convert_to_tensor(labels_onehot)\n",
    "  \n",
    "  model.fit(train, labels, epochs=5, verbose=1)\n",
    "\n",
    "  return model\n",
    "\n",
    "#___________________________________________________\n",
    "\n",
    "def customML_train_regressor(labels, features, columntype_report, commands, randomseed):\n",
    "  \n",
    "  import tensorflow as tf\n",
    "\n",
    "  from tensorflow.keras.models import Sequential\n",
    "  from tensorflow.keras.layers import Dense\n",
    "  from tensorflow.keras.layers import Dropout\n",
    "  \n",
    "  featurecount = len(list(features))\n",
    "  \n",
    "  def create_model():\n",
    "    \n",
    "    #this config has edge case when less than 3 features\n",
    "    #create model with keras\n",
    "    model = Sequential()\n",
    "    #layer widths are kind of arbitrarily populated\n",
    "    model.add(Dropout(0.1, input_shape=(featurecount,)))\n",
    "    model.add(Dense(int(featurecount/2), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(int(featurecount/4), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(int(featurecount/6), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    #compile model\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "\n",
    "    return model\n",
    "  \n",
    "  model = create_model()\n",
    "  \n",
    "  features = features.to_numpy()\n",
    "  labels = labels.to_numpy()\n",
    "  \n",
    "  train = tf.convert_to_tensor(features)\n",
    "  labels = tf.convert_to_tensor(labels)\n",
    "  \n",
    "  model.fit(train, labels, epochs=5, verbose=1)\n",
    "\n",
    "  return model\n",
    "\n",
    "#___________________________________________________\n",
    "\n",
    "ML_cmnd = {'autoML_type' : 'customML',\n",
    "           'customML' : {'customML_Classifier_train'  : customML_train_classifier, \n",
    "                         'customML_Classifier_predict': 'tensorflow', \n",
    "                         'customML_Regressor_train'   : customML_train_regressor, \n",
    "                         'customML_Regressor_predict' : 'tensorflow'}}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
