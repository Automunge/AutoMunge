{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML infill demonstrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automunge is available now for pip install:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Automunge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or to upgrade (we currently roll out upgrades pretty frequently):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Automunge --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once installed, run this in a local session to initialize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Automunge import *\n",
    "am = AutoMunge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML infill is a push button method for missing data inputation, utilizing auto ML models trained on partitions of the training set for each feature. These models trained on the designated training set and saved in the returned postprocess_dict dictionary can then be applied to infer infill to training and test data passed to the automunge(.) function as well as to subsequent test data passed to the postmunge(.) function.\n",
    "\n",
    "ML infill need not only be applied in scenarios with missing data present. It can also be applied to fully represented data sets to serve as a precaution against imperfections in subsequent data streams.\n",
    "\n",
    "ML infill is turned on by default with the automunge(.) parameter setting `MLinfill=True`. It can be deactivate by passing `MLinfill=False`, in which case assigning to distinct columns can take place in `assigninfill` parameter.\n",
    "\n",
    "The default architecture is Random Forest for simplicity, although other auto ML architectures like AutoGluon and Catboost are also available which may make use of ensembles and train on GPU's for more accurate and quickly trained models.\n",
    "\n",
    "In this notebook we'll demonstrate how simple applying ML infill is in context of an automunge(.) call, as well as demonstrate passing parameters to the model training and selecting alternate architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate, let's encode the [Ames Housing set](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data), a well known tabular benchmark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#housing set\n",
    "df_train = pd.read_csv('housing_train.csv')\n",
    "df_test = pd.read_csv('housing_test.csv')\n",
    "\n",
    "labels_column = 'SalePrice'\n",
    "trainID_column = 'Id'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what the data looks like in a raw form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Exterior2nd</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>Heating</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>196.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>706</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>856</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>8</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>978</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>1262</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>162.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Mn</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>486</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>434</td>\n",
       "      <td>920</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>1786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>Wd Shng</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>BrkTil</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>216</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>756</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>1717</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>7</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NoRidge</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>350.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Av</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>655</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "      <td>1145</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>2198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>9</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>3</td>\n",
       "      <td>836</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities LotConfig LandSlope Neighborhood Condition1  \\\n",
       "0         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
       "1         Lvl    AllPub       FR2       Gtl      Veenker      Feedr   \n",
       "2         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
       "3         Lvl    AllPub    Corner       Gtl      Crawfor       Norm   \n",
       "4         Lvl    AllPub       FR2       Gtl      NoRidge       Norm   \n",
       "\n",
       "  Condition2 BldgType HouseStyle  OverallQual  OverallCond  YearBuilt  \\\n",
       "0       Norm     1Fam     2Story            7            5       2003   \n",
       "1       Norm     1Fam     1Story            6            8       1976   \n",
       "2       Norm     1Fam     2Story            7            5       2001   \n",
       "3       Norm     1Fam     2Story            7            5       1915   \n",
       "4       Norm     1Fam     2Story            8            5       2000   \n",
       "\n",
       "   YearRemodAdd RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType  \\\n",
       "0          2003     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "1          1976     Gable  CompShg     MetalSd     MetalSd       None   \n",
       "2          2002     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "3          1970     Gable  CompShg     Wd Sdng     Wd Shng       None   \n",
       "4          2000     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "\n",
       "   MasVnrArea ExterQual ExterCond Foundation BsmtQual BsmtCond BsmtExposure  \\\n",
       "0       196.0        Gd        TA      PConc       Gd       TA           No   \n",
       "1         0.0        TA        TA     CBlock       Gd       TA           Gd   \n",
       "2       162.0        Gd        TA      PConc       Gd       TA           Mn   \n",
       "3         0.0        TA        TA     BrkTil       TA       Gd           No   \n",
       "4       350.0        Gd        TA      PConc       Gd       TA           Av   \n",
       "\n",
       "  BsmtFinType1  BsmtFinSF1 BsmtFinType2  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  \\\n",
       "0          GLQ         706          Unf           0        150          856   \n",
       "1          ALQ         978          Unf           0        284         1262   \n",
       "2          GLQ         486          Unf           0        434          920   \n",
       "3          ALQ         216          Unf           0        540          756   \n",
       "4          GLQ         655          Unf           0        490         1145   \n",
       "\n",
       "  Heating HeatingQC CentralAir Electrical  1stFlrSF  2ndFlrSF  LowQualFinSF  \\\n",
       "0    GasA        Ex          Y      SBrkr       856       854             0   \n",
       "1    GasA        Ex          Y      SBrkr      1262         0             0   \n",
       "2    GasA        Ex          Y      SBrkr       920       866             0   \n",
       "3    GasA        Gd          Y      SBrkr       961       756             0   \n",
       "4    GasA        Ex          Y      SBrkr      1145      1053             0   \n",
       "\n",
       "   GrLivArea  BsmtFullBath  BsmtHalfBath  FullBath  HalfBath  BedroomAbvGr  \\\n",
       "0       1710             1             0         2         1             3   \n",
       "1       1262             0             1         2         0             3   \n",
       "2       1786             1             0         2         1             3   \n",
       "3       1717             1             0         1         0             3   \n",
       "4       2198             1             0         2         1             4   \n",
       "\n",
       "   KitchenAbvGr KitchenQual  TotRmsAbvGrd Functional  Fireplaces FireplaceQu  \\\n",
       "0             1          Gd             8        Typ           0         NaN   \n",
       "1             1          TA             6        Typ           1          TA   \n",
       "2             1          Gd             6        Typ           1          TA   \n",
       "3             1          Gd             7        Typ           1          Gd   \n",
       "4             1          Gd             9        Typ           1          TA   \n",
       "\n",
       "  GarageType  GarageYrBlt GarageFinish  GarageCars  GarageArea GarageQual  \\\n",
       "0     Attchd       2003.0          RFn           2         548         TA   \n",
       "1     Attchd       1976.0          RFn           2         460         TA   \n",
       "2     Attchd       2001.0          RFn           2         608         TA   \n",
       "3     Detchd       1998.0          Unf           3         642         TA   \n",
       "4     Attchd       2000.0          RFn           3         836         TA   \n",
       "\n",
       "  GarageCond PavedDrive  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  \\\n",
       "0         TA          Y           0           61              0          0   \n",
       "1         TA          Y         298            0              0          0   \n",
       "2         TA          Y           0           42              0          0   \n",
       "3         TA          Y           0           35            272          0   \n",
       "4         TA          Y         192           84              0          0   \n",
       "\n",
       "   ScreenPorch  PoolArea PoolQC Fence MiscFeature  MiscVal  MoSold  YrSold  \\\n",
       "0            0         0    NaN   NaN         NaN        0       2    2008   \n",
       "1            0         0    NaN   NaN         NaN        0       5    2007   \n",
       "2            0         0    NaN   NaN         NaN        0       9    2008   \n",
       "3            0         0    NaN   NaN         NaN        0       2    2006   \n",
       "4            0         0    NaN   NaN         NaN        0      12    2008   \n",
       "\n",
       "  SaleType SaleCondition  SalePrice  \n",
       "0       WD        Normal     208500  \n",
       "1       WD        Normal     181500  \n",
       "2       WD        Normal     223500  \n",
       "3       WD       Abnorml     140000  \n",
       "4       WD        Normal     250000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 300)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in missing data theory, there is a fundamental distinction between values that are missing at random and values that are not missing at random. For example, in this set, the 'Alley' column appears to contain NaN values associated with houses that are not located on an alley, so this might not be as good of a target for ML infill, amd may be better suited for a distinct value as infill. In order to signal to training the presence of cells that were subject to infill, we'll activate the NArw_marker parameter, which will assemble a column for each feature set containing boolean integer markers signalling presence of entries that were subject to infill. (This parameter is activated by default).\n",
    "\n",
    "This data set does not have a very high prevelance of missing at random data, so to improve visibility we'll apply an automunge(.) parameter that can inject missing data into a training set. Let's arbitrarily select for injection the columns 'LotArea' and 'Neighborhood'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is to inject some missing at random entries into the selected columns\n",
    "#for demonstration of ML infill\n",
    "#we'll inject missing data into 50% of entries in each target column\n",
    "\n",
    "assignnan = {}\n",
    "\n",
    "assignnan.update({'injections' : {'LotArea'      : {'inject_ratio' : .5},\n",
    "                                  'Neighborhood' : {'inject_ratio' : .5}}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's go ahead and run ML infill using just defaults on this set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, train_ID, labels, \\\n",
    "val, val_ID, val_labels, \\\n",
    "test, test_ID, test_labels, \\\n",
    "postprocess_dict \\\n",
    "= am.automunge(df_train,\n",
    "               labels_column = labels_column,\n",
    "               trainID_column = trainID_column,\n",
    "               assignnan = assignnan,\n",
    "               NArw_marker = True,\n",
    "               shuffletrain = False, \n",
    "               MLinfill = True,\n",
    "               printstatus = False\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned data looks like following, note the NArw columns signalling presence of infill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass_nmbr</th>\n",
       "      <th>LotFrontage_nmbr</th>\n",
       "      <th>LotArea_nmbr</th>\n",
       "      <th>Street_bnry</th>\n",
       "      <th>Alley_bnry</th>\n",
       "      <th>Utilities_bnry</th>\n",
       "      <th>OverallQual_nmbr</th>\n",
       "      <th>OverallCond_nmbr</th>\n",
       "      <th>YearBuilt_nmbr</th>\n",
       "      <th>YearRemodAdd_nmbr</th>\n",
       "      <th>MasVnrArea_nmbr</th>\n",
       "      <th>BsmtFinSF1_nmbr</th>\n",
       "      <th>BsmtFinSF2_nmbr</th>\n",
       "      <th>BsmtUnfSF_nmbr</th>\n",
       "      <th>TotalBsmtSF_nmbr</th>\n",
       "      <th>CentralAir_bnry</th>\n",
       "      <th>1stFlrSF_nmbr</th>\n",
       "      <th>2ndFlrSF_nmbr</th>\n",
       "      <th>LowQualFinSF_nmbr</th>\n",
       "      <th>GrLivArea_nmbr</th>\n",
       "      <th>BsmtFullBath_nmbr</th>\n",
       "      <th>FullBath_nmbr</th>\n",
       "      <th>BedroomAbvGr_nmbr</th>\n",
       "      <th>KitchenAbvGr_nmbr</th>\n",
       "      <th>TotRmsAbvGrd_nmbr</th>\n",
       "      <th>Fireplaces_nmbr</th>\n",
       "      <th>GarageYrBlt_nmbr</th>\n",
       "      <th>GarageCars_nmbr</th>\n",
       "      <th>GarageArea_nmbr</th>\n",
       "      <th>WoodDeckSF_nmbr</th>\n",
       "      <th>OpenPorchSF_nmbr</th>\n",
       "      <th>EnclosedPorch_nmbr</th>\n",
       "      <th>3SsnPorch_nmbr</th>\n",
       "      <th>ScreenPorch_nmbr</th>\n",
       "      <th>PoolArea_nmbr</th>\n",
       "      <th>MiscVal_nmbr</th>\n",
       "      <th>MoSold_nmbr</th>\n",
       "      <th>YrSold_nmbr</th>\n",
       "      <th>MSSubClass_NArw</th>\n",
       "      <th>MSZoning_NArw</th>\n",
       "      <th>MSZoning_1010_0</th>\n",
       "      <th>MSZoning_1010_1</th>\n",
       "      <th>MSZoning_1010_2</th>\n",
       "      <th>LotFrontage_NArw</th>\n",
       "      <th>LotArea_NArw</th>\n",
       "      <th>Street_NArw</th>\n",
       "      <th>Alley_NArw</th>\n",
       "      <th>LotShape_NArw</th>\n",
       "      <th>LotShape_1010_0</th>\n",
       "      <th>LotShape_1010_1</th>\n",
       "      <th>LotShape_1010_2</th>\n",
       "      <th>LandContour_NArw</th>\n",
       "      <th>LandContour_1010_0</th>\n",
       "      <th>LandContour_1010_1</th>\n",
       "      <th>LandContour_1010_2</th>\n",
       "      <th>Utilities_NArw</th>\n",
       "      <th>LotConfig_NArw</th>\n",
       "      <th>LotConfig_1010_0</th>\n",
       "      <th>LotConfig_1010_1</th>\n",
       "      <th>LotConfig_1010_2</th>\n",
       "      <th>LandSlope_NArw</th>\n",
       "      <th>LandSlope_1010_0</th>\n",
       "      <th>LandSlope_1010_1</th>\n",
       "      <th>Neighborhood_NArw</th>\n",
       "      <th>Neighborhood_1010_0</th>\n",
       "      <th>Neighborhood_1010_1</th>\n",
       "      <th>Neighborhood_1010_2</th>\n",
       "      <th>Neighborhood_1010_3</th>\n",
       "      <th>Neighborhood_1010_4</th>\n",
       "      <th>Condition1_NArw</th>\n",
       "      <th>Condition1_1010_0</th>\n",
       "      <th>Condition1_1010_1</th>\n",
       "      <th>Condition1_1010_2</th>\n",
       "      <th>Condition1_1010_3</th>\n",
       "      <th>Condition2_NArw</th>\n",
       "      <th>Condition2_1010_0</th>\n",
       "      <th>Condition2_1010_1</th>\n",
       "      <th>Condition2_1010_2</th>\n",
       "      <th>Condition2_1010_3</th>\n",
       "      <th>BldgType_NArw</th>\n",
       "      <th>BldgType_1010_0</th>\n",
       "      <th>BldgType_1010_1</th>\n",
       "      <th>BldgType_1010_2</th>\n",
       "      <th>HouseStyle_NArw</th>\n",
       "      <th>HouseStyle_1010_0</th>\n",
       "      <th>HouseStyle_1010_1</th>\n",
       "      <th>HouseStyle_1010_2</th>\n",
       "      <th>HouseStyle_1010_3</th>\n",
       "      <th>OverallQual_NArw</th>\n",
       "      <th>OverallCond_NArw</th>\n",
       "      <th>YearBuilt_NArw</th>\n",
       "      <th>YearRemodAdd_NArw</th>\n",
       "      <th>RoofStyle_NArw</th>\n",
       "      <th>RoofStyle_1010_0</th>\n",
       "      <th>RoofStyle_1010_1</th>\n",
       "      <th>RoofStyle_1010_2</th>\n",
       "      <th>RoofMatl_NArw</th>\n",
       "      <th>RoofMatl_1010_0</th>\n",
       "      <th>RoofMatl_1010_1</th>\n",
       "      <th>RoofMatl_1010_2</th>\n",
       "      <th>RoofMatl_1010_3</th>\n",
       "      <th>Exterior1st_NArw</th>\n",
       "      <th>Exterior1st_1010_0</th>\n",
       "      <th>Exterior1st_1010_1</th>\n",
       "      <th>Exterior1st_1010_2</th>\n",
       "      <th>Exterior1st_1010_3</th>\n",
       "      <th>Exterior2nd_NArw</th>\n",
       "      <th>Exterior2nd_1010_0</th>\n",
       "      <th>Exterior2nd_1010_1</th>\n",
       "      <th>Exterior2nd_1010_2</th>\n",
       "      <th>Exterior2nd_1010_3</th>\n",
       "      <th>Exterior2nd_1010_4</th>\n",
       "      <th>MasVnrType_NArw</th>\n",
       "      <th>MasVnrType_1010_0</th>\n",
       "      <th>MasVnrType_1010_1</th>\n",
       "      <th>MasVnrType_1010_2</th>\n",
       "      <th>MasVnrArea_NArw</th>\n",
       "      <th>ExterQual_NArw</th>\n",
       "      <th>ExterQual_1010_0</th>\n",
       "      <th>ExterQual_1010_1</th>\n",
       "      <th>ExterQual_1010_2</th>\n",
       "      <th>ExterCond_NArw</th>\n",
       "      <th>ExterCond_1010_0</th>\n",
       "      <th>ExterCond_1010_1</th>\n",
       "      <th>ExterCond_1010_2</th>\n",
       "      <th>Foundation_NArw</th>\n",
       "      <th>Foundation_1010_0</th>\n",
       "      <th>Foundation_1010_1</th>\n",
       "      <th>Foundation_1010_2</th>\n",
       "      <th>BsmtQual_NArw</th>\n",
       "      <th>BsmtQual_1010_0</th>\n",
       "      <th>BsmtQual_1010_1</th>\n",
       "      <th>BsmtQual_1010_2</th>\n",
       "      <th>BsmtCond_NArw</th>\n",
       "      <th>BsmtCond_1010_0</th>\n",
       "      <th>BsmtCond_1010_1</th>\n",
       "      <th>BsmtCond_1010_2</th>\n",
       "      <th>BsmtExposure_NArw</th>\n",
       "      <th>BsmtExposure_1010_0</th>\n",
       "      <th>BsmtExposure_1010_1</th>\n",
       "      <th>BsmtExposure_1010_2</th>\n",
       "      <th>BsmtFinType1_NArw</th>\n",
       "      <th>BsmtFinType1_1010_0</th>\n",
       "      <th>BsmtFinType1_1010_1</th>\n",
       "      <th>BsmtFinType1_1010_2</th>\n",
       "      <th>BsmtFinSF1_NArw</th>\n",
       "      <th>BsmtFinType2_NArw</th>\n",
       "      <th>BsmtFinType2_1010_0</th>\n",
       "      <th>BsmtFinType2_1010_1</th>\n",
       "      <th>BsmtFinType2_1010_2</th>\n",
       "      <th>BsmtFinSF2_NArw</th>\n",
       "      <th>BsmtUnfSF_NArw</th>\n",
       "      <th>TotalBsmtSF_NArw</th>\n",
       "      <th>Heating_NArw</th>\n",
       "      <th>Heating_1010_0</th>\n",
       "      <th>Heating_1010_1</th>\n",
       "      <th>Heating_1010_2</th>\n",
       "      <th>HeatingQC_NArw</th>\n",
       "      <th>HeatingQC_1010_0</th>\n",
       "      <th>HeatingQC_1010_1</th>\n",
       "      <th>HeatingQC_1010_2</th>\n",
       "      <th>CentralAir_NArw</th>\n",
       "      <th>Electrical_NArw</th>\n",
       "      <th>Electrical_1010_0</th>\n",
       "      <th>Electrical_1010_1</th>\n",
       "      <th>Electrical_1010_2</th>\n",
       "      <th>1stFlrSF_NArw</th>\n",
       "      <th>2ndFlrSF_NArw</th>\n",
       "      <th>LowQualFinSF_NArw</th>\n",
       "      <th>GrLivArea_NArw</th>\n",
       "      <th>BsmtFullBath_NArw</th>\n",
       "      <th>BsmtHalfBath_NArw</th>\n",
       "      <th>BsmtHalfBath_1010_0</th>\n",
       "      <th>BsmtHalfBath_1010_1</th>\n",
       "      <th>FullBath_NArw</th>\n",
       "      <th>HalfBath_NArw</th>\n",
       "      <th>HalfBath_1010_0</th>\n",
       "      <th>HalfBath_1010_1</th>\n",
       "      <th>BedroomAbvGr_NArw</th>\n",
       "      <th>KitchenAbvGr_NArw</th>\n",
       "      <th>KitchenQual_NArw</th>\n",
       "      <th>KitchenQual_1010_0</th>\n",
       "      <th>KitchenQual_1010_1</th>\n",
       "      <th>KitchenQual_1010_2</th>\n",
       "      <th>TotRmsAbvGrd_NArw</th>\n",
       "      <th>Functional_NArw</th>\n",
       "      <th>Functional_1010_0</th>\n",
       "      <th>Functional_1010_1</th>\n",
       "      <th>Functional_1010_2</th>\n",
       "      <th>Fireplaces_NArw</th>\n",
       "      <th>FireplaceQu_NArw</th>\n",
       "      <th>FireplaceQu_1010_0</th>\n",
       "      <th>FireplaceQu_1010_1</th>\n",
       "      <th>FireplaceQu_1010_2</th>\n",
       "      <th>GarageType_NArw</th>\n",
       "      <th>GarageType_1010_0</th>\n",
       "      <th>GarageType_1010_1</th>\n",
       "      <th>GarageType_1010_2</th>\n",
       "      <th>GarageYrBlt_NArw</th>\n",
       "      <th>GarageFinish_NArw</th>\n",
       "      <th>GarageFinish_1010_0</th>\n",
       "      <th>GarageFinish_1010_1</th>\n",
       "      <th>GarageCars_NArw</th>\n",
       "      <th>GarageArea_NArw</th>\n",
       "      <th>GarageQual_NArw</th>\n",
       "      <th>GarageQual_1010_0</th>\n",
       "      <th>GarageQual_1010_1</th>\n",
       "      <th>GarageQual_1010_2</th>\n",
       "      <th>GarageCond_NArw</th>\n",
       "      <th>GarageCond_1010_0</th>\n",
       "      <th>GarageCond_1010_1</th>\n",
       "      <th>GarageCond_1010_2</th>\n",
       "      <th>PavedDrive_NArw</th>\n",
       "      <th>PavedDrive_1010_0</th>\n",
       "      <th>PavedDrive_1010_1</th>\n",
       "      <th>WoodDeckSF_NArw</th>\n",
       "      <th>OpenPorchSF_NArw</th>\n",
       "      <th>EnclosedPorch_NArw</th>\n",
       "      <th>3SsnPorch_NArw</th>\n",
       "      <th>ScreenPorch_NArw</th>\n",
       "      <th>PoolArea_NArw</th>\n",
       "      <th>PoolQC_NArw</th>\n",
       "      <th>PoolQC_1010_0</th>\n",
       "      <th>PoolQC_1010_1</th>\n",
       "      <th>Fence_NArw</th>\n",
       "      <th>Fence_1010_0</th>\n",
       "      <th>Fence_1010_1</th>\n",
       "      <th>Fence_1010_2</th>\n",
       "      <th>MiscFeature_NArw</th>\n",
       "      <th>MiscFeature_1010_0</th>\n",
       "      <th>MiscFeature_1010_1</th>\n",
       "      <th>MiscFeature_1010_2</th>\n",
       "      <th>MiscVal_NArw</th>\n",
       "      <th>MoSold_NArw</th>\n",
       "      <th>YrSold_NArw</th>\n",
       "      <th>SaleType_NArw</th>\n",
       "      <th>SaleType_1010_0</th>\n",
       "      <th>SaleType_1010_1</th>\n",
       "      <th>SaleType_1010_2</th>\n",
       "      <th>SaleType_1010_3</th>\n",
       "      <th>SaleCondition_NArw</th>\n",
       "      <th>SaleCondition_1010_0</th>\n",
       "      <th>SaleCondition_1010_1</th>\n",
       "      <th>SaleCondition_1010_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.073350</td>\n",
       "      <td>-0.229293</td>\n",
       "      <td>-0.241283</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.651256</td>\n",
       "      <td>-0.517023</td>\n",
       "      <td>1.050634</td>\n",
       "      <td>0.878367</td>\n",
       "      <td>0.511243</td>\n",
       "      <td>0.575228</td>\n",
       "      <td>-0.288554</td>\n",
       "      <td>-0.944267</td>\n",
       "      <td>-0.459145</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.793162</td>\n",
       "      <td>1.161454</td>\n",
       "      <td>-0.120201</td>\n",
       "      <td>0.370207</td>\n",
       "      <td>1.107431</td>\n",
       "      <td>0.789470</td>\n",
       "      <td>0.163723</td>\n",
       "      <td>-0.211381</td>\n",
       "      <td>0.911897</td>\n",
       "      <td>-0.950901</td>\n",
       "      <td>1.020807</td>\n",
       "      <td>0.311618</td>\n",
       "      <td>0.350880</td>\n",
       "      <td>-0.751918</td>\n",
       "      <td>0.216429</td>\n",
       "      <td>-0.359202</td>\n",
       "      <td>-0.116299</td>\n",
       "      <td>-0.270116</td>\n",
       "      <td>-0.068668</td>\n",
       "      <td>-0.087658</td>\n",
       "      <td>-1.598563</td>\n",
       "      <td>0.138730</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.872264</td>\n",
       "      <td>0.451781</td>\n",
       "      <td>0.058864</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.071812</td>\n",
       "      <td>2.178881</td>\n",
       "      <td>0.156680</td>\n",
       "      <td>-0.429430</td>\n",
       "      <td>-0.574214</td>\n",
       "      <td>1.171591</td>\n",
       "      <td>-0.288554</td>\n",
       "      <td>-0.641008</td>\n",
       "      <td>0.466305</td>\n",
       "      <td>1</td>\n",
       "      <td>0.257052</td>\n",
       "      <td>-0.794891</td>\n",
       "      <td>-0.120201</td>\n",
       "      <td>-0.482347</td>\n",
       "      <td>-0.819683</td>\n",
       "      <td>0.789470</td>\n",
       "      <td>0.163723</td>\n",
       "      <td>-0.211381</td>\n",
       "      <td>-0.318574</td>\n",
       "      <td>0.600289</td>\n",
       "      <td>-0.104447</td>\n",
       "      <td>0.311618</td>\n",
       "      <td>-0.060710</td>\n",
       "      <td>1.625638</td>\n",
       "      <td>-0.704242</td>\n",
       "      <td>-0.359202</td>\n",
       "      <td>-0.116299</td>\n",
       "      <td>-0.270116</td>\n",
       "      <td>-0.068668</td>\n",
       "      <td>-0.087658</td>\n",
       "      <td>-0.488943</td>\n",
       "      <td>-0.614228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073350</td>\n",
       "      <td>-0.093078</td>\n",
       "      <td>-0.097692</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.651256</td>\n",
       "      <td>-0.517023</td>\n",
       "      <td>0.984415</td>\n",
       "      <td>0.829930</td>\n",
       "      <td>0.322950</td>\n",
       "      <td>0.092875</td>\n",
       "      <td>-0.288554</td>\n",
       "      <td>-0.301540</td>\n",
       "      <td>-0.313261</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.627611</td>\n",
       "      <td>1.188943</td>\n",
       "      <td>-0.120201</td>\n",
       "      <td>0.514836</td>\n",
       "      <td>1.107431</td>\n",
       "      <td>0.789470</td>\n",
       "      <td>0.163723</td>\n",
       "      <td>-0.211381</td>\n",
       "      <td>-0.318574</td>\n",
       "      <td>0.600289</td>\n",
       "      <td>0.937455</td>\n",
       "      <td>0.311618</td>\n",
       "      <td>0.631510</td>\n",
       "      <td>-0.751918</td>\n",
       "      <td>-0.070337</td>\n",
       "      <td>-0.359202</td>\n",
       "      <td>-0.116299</td>\n",
       "      <td>-0.270116</td>\n",
       "      <td>-0.068668</td>\n",
       "      <td>-0.087658</td>\n",
       "      <td>0.990552</td>\n",
       "      <td>0.138730</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.309753</td>\n",
       "      <td>-0.456318</td>\n",
       "      <td>-0.093364</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.651256</td>\n",
       "      <td>-0.517023</td>\n",
       "      <td>-1.862993</td>\n",
       "      <td>-0.720051</td>\n",
       "      <td>-0.574214</td>\n",
       "      <td>-0.499103</td>\n",
       "      <td>-0.288554</td>\n",
       "      <td>-0.061648</td>\n",
       "      <td>-0.687089</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.521555</td>\n",
       "      <td>0.936955</td>\n",
       "      <td>-0.120201</td>\n",
       "      <td>0.383528</td>\n",
       "      <td>1.107431</td>\n",
       "      <td>-1.025689</td>\n",
       "      <td>0.163723</td>\n",
       "      <td>-0.211381</td>\n",
       "      <td>0.296662</td>\n",
       "      <td>0.600289</td>\n",
       "      <td>0.812427</td>\n",
       "      <td>1.649742</td>\n",
       "      <td>0.790533</td>\n",
       "      <td>-0.751918</td>\n",
       "      <td>-0.175988</td>\n",
       "      <td>4.091122</td>\n",
       "      <td>-0.116299</td>\n",
       "      <td>-0.270116</td>\n",
       "      <td>-0.068668</td>\n",
       "      <td>-0.087658</td>\n",
       "      <td>-1.598563</td>\n",
       "      <td>-1.367186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.073350</td>\n",
       "      <td>0.633401</td>\n",
       "      <td>0.191731</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.374324</td>\n",
       "      <td>-0.517023</td>\n",
       "      <td>0.951306</td>\n",
       "      <td>0.733056</td>\n",
       "      <td>1.364102</td>\n",
       "      <td>0.463410</td>\n",
       "      <td>-0.288554</td>\n",
       "      <td>-0.174805</td>\n",
       "      <td>0.199611</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.045596</td>\n",
       "      <td>1.617323</td>\n",
       "      <td>-0.120201</td>\n",
       "      <td>1.298881</td>\n",
       "      <td>1.107431</td>\n",
       "      <td>0.789470</td>\n",
       "      <td>1.389547</td>\n",
       "      <td>-0.211381</td>\n",
       "      <td>1.527133</td>\n",
       "      <td>0.600289</td>\n",
       "      <td>0.895779</td>\n",
       "      <td>1.649742</td>\n",
       "      <td>1.697903</td>\n",
       "      <td>0.779930</td>\n",
       "      <td>0.563567</td>\n",
       "      <td>-0.359202</td>\n",
       "      <td>-0.116299</td>\n",
       "      <td>-0.270116</td>\n",
       "      <td>-0.068668</td>\n",
       "      <td>-0.087658</td>\n",
       "      <td>2.100173</td>\n",
       "      <td>0.138730</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass_nmbr  LotFrontage_nmbr  LotArea_nmbr  Street_bnry  Alley_bnry  \\\n",
       "0         0.073350         -0.229293     -0.241283            1           0   \n",
       "1        -0.872264          0.451781      0.058864            1           1   \n",
       "2         0.073350         -0.093078     -0.097692            1           0   \n",
       "3         0.309753         -0.456318     -0.093364            1           1   \n",
       "4         0.073350          0.633401      0.191731            1           0   \n",
       "\n",
       "   Utilities_bnry  OverallQual_nmbr  OverallCond_nmbr  YearBuilt_nmbr  \\\n",
       "0               1          0.651256         -0.517023        1.050634   \n",
       "1               1         -0.071812          2.178881        0.156680   \n",
       "2               1          0.651256         -0.517023        0.984415   \n",
       "3               1          0.651256         -0.517023       -1.862993   \n",
       "4               1          1.374324         -0.517023        0.951306   \n",
       "\n",
       "   YearRemodAdd_nmbr  MasVnrArea_nmbr  BsmtFinSF1_nmbr  BsmtFinSF2_nmbr  \\\n",
       "0           0.878367         0.511243         0.575228        -0.288554   \n",
       "1          -0.429430        -0.574214         1.171591        -0.288554   \n",
       "2           0.829930         0.322950         0.092875        -0.288554   \n",
       "3          -0.720051        -0.574214        -0.499103        -0.288554   \n",
       "4           0.733056         1.364102         0.463410        -0.288554   \n",
       "\n",
       "   BsmtUnfSF_nmbr  TotalBsmtSF_nmbr  CentralAir_bnry  1stFlrSF_nmbr  \\\n",
       "0       -0.944267         -0.459145                1      -0.793162   \n",
       "1       -0.641008          0.466305                1       0.257052   \n",
       "2       -0.301540         -0.313261                1      -0.627611   \n",
       "3       -0.061648         -0.687089                1      -0.521555   \n",
       "4       -0.174805          0.199611                1      -0.045596   \n",
       "\n",
       "   2ndFlrSF_nmbr  LowQualFinSF_nmbr  GrLivArea_nmbr  BsmtFullBath_nmbr  \\\n",
       "0       1.161454          -0.120201        0.370207           1.107431   \n",
       "1      -0.794891          -0.120201       -0.482347          -0.819683   \n",
       "2       1.188943          -0.120201        0.514836           1.107431   \n",
       "3       0.936955          -0.120201        0.383528           1.107431   \n",
       "4       1.617323          -0.120201        1.298881           1.107431   \n",
       "\n",
       "   FullBath_nmbr  BedroomAbvGr_nmbr  KitchenAbvGr_nmbr  TotRmsAbvGrd_nmbr  \\\n",
       "0       0.789470           0.163723          -0.211381           0.911897   \n",
       "1       0.789470           0.163723          -0.211381          -0.318574   \n",
       "2       0.789470           0.163723          -0.211381          -0.318574   \n",
       "3      -1.025689           0.163723          -0.211381           0.296662   \n",
       "4       0.789470           1.389547          -0.211381           1.527133   \n",
       "\n",
       "   Fireplaces_nmbr  GarageYrBlt_nmbr  GarageCars_nmbr  GarageArea_nmbr  \\\n",
       "0        -0.950901          1.020807         0.311618         0.350880   \n",
       "1         0.600289         -0.104447         0.311618        -0.060710   \n",
       "2         0.600289          0.937455         0.311618         0.631510   \n",
       "3         0.600289          0.812427         1.649742         0.790533   \n",
       "4         0.600289          0.895779         1.649742         1.697903   \n",
       "\n",
       "   WoodDeckSF_nmbr  OpenPorchSF_nmbr  EnclosedPorch_nmbr  3SsnPorch_nmbr  \\\n",
       "0        -0.751918          0.216429           -0.359202       -0.116299   \n",
       "1         1.625638         -0.704242           -0.359202       -0.116299   \n",
       "2        -0.751918         -0.070337           -0.359202       -0.116299   \n",
       "3        -0.751918         -0.175988            4.091122       -0.116299   \n",
       "4         0.779930          0.563567           -0.359202       -0.116299   \n",
       "\n",
       "   ScreenPorch_nmbr  PoolArea_nmbr  MiscVal_nmbr  MoSold_nmbr  YrSold_nmbr  \\\n",
       "0         -0.270116      -0.068668     -0.087658    -1.598563     0.138730   \n",
       "1         -0.270116      -0.068668     -0.087658    -0.488943    -0.614228   \n",
       "2         -0.270116      -0.068668     -0.087658     0.990552     0.138730   \n",
       "3         -0.270116      -0.068668     -0.087658    -1.598563    -1.367186   \n",
       "4         -0.270116      -0.068668     -0.087658     2.100173     0.138730   \n",
       "\n",
       "   MSSubClass_NArw  MSZoning_NArw  MSZoning_1010_0  MSZoning_1010_1  \\\n",
       "0                0              0                0                1   \n",
       "1                0              0                0                1   \n",
       "2                0              0                0                1   \n",
       "3                0              0                0                1   \n",
       "4                0              0                0                1   \n",
       "\n",
       "   MSZoning_1010_2  LotFrontage_NArw  LotArea_NArw  Street_NArw  Alley_NArw  \\\n",
       "0                1                 0             0            0           1   \n",
       "1                1                 0             1            0           1   \n",
       "2                1                 0             1            0           1   \n",
       "3                1                 0             0            0           1   \n",
       "4                1                 0             1            0           1   \n",
       "\n",
       "   LotShape_NArw  LotShape_1010_0  LotShape_1010_1  LotShape_1010_2  \\\n",
       "0              0                0                1                1   \n",
       "1              0                0                1                1   \n",
       "2              0                0                0                0   \n",
       "3              0                0                0                0   \n",
       "4              0                0                0                0   \n",
       "\n",
       "   LandContour_NArw  LandContour_1010_0  LandContour_1010_1  \\\n",
       "0                 0                   0                   1   \n",
       "1                 0                   0                   1   \n",
       "2                 0                   0                   1   \n",
       "3                 0                   0                   1   \n",
       "4                 0                   0                   1   \n",
       "\n",
       "   LandContour_1010_2  Utilities_NArw  LotConfig_NArw  LotConfig_1010_0  \\\n",
       "0                   1               0               0                 1   \n",
       "1                   1               0               0                 0   \n",
       "2                   1               0               0                 1   \n",
       "3                   1               0               0                 0   \n",
       "4                   1               0               0                 0   \n",
       "\n",
       "   LotConfig_1010_1  LotConfig_1010_2  LandSlope_NArw  LandSlope_1010_0  \\\n",
       "0                 0                 0               0                 0   \n",
       "1                 1                 0               0                 0   \n",
       "2                 0                 0               0                 0   \n",
       "3                 0                 0               0                 0   \n",
       "4                 1                 0               0                 0   \n",
       "\n",
       "   LandSlope_1010_1  Neighborhood_NArw  Neighborhood_1010_0  \\\n",
       "0                 0                  1                    0   \n",
       "1                 0                  0                    1   \n",
       "2                 0                  1                    0   \n",
       "3                 0                  0                    0   \n",
       "4                 0                  0                    0   \n",
       "\n",
       "   Neighborhood_1010_1  Neighborhood_1010_2  Neighborhood_1010_3  \\\n",
       "0                    0                    0                    0   \n",
       "1                    1                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    1                    1   \n",
       "4                    1                    1                    1   \n",
       "\n",
       "   Neighborhood_1010_4  Condition1_NArw  Condition1_1010_0  Condition1_1010_1  \\\n",
       "0                    0                0                  0                  0   \n",
       "1                    0                0                  0                  0   \n",
       "2                    0                0                  0                  0   \n",
       "3                    0                0                  0                  0   \n",
       "4                    1                0                  0                  0   \n",
       "\n",
       "   Condition1_1010_2  Condition1_1010_3  Condition2_NArw  Condition2_1010_0  \\\n",
       "0                  1                  0                0                  0   \n",
       "1                  0                  1                0                  0   \n",
       "2                  1                  0                0                  0   \n",
       "3                  1                  0                0                  0   \n",
       "4                  1                  0                0                  0   \n",
       "\n",
       "   Condition2_1010_1  Condition2_1010_2  Condition2_1010_3  BldgType_NArw  \\\n",
       "0                  0                  1                  0              0   \n",
       "1                  0                  1                  0              0   \n",
       "2                  0                  1                  0              0   \n",
       "3                  0                  1                  0              0   \n",
       "4                  0                  1                  0              0   \n",
       "\n",
       "   BldgType_1010_0  BldgType_1010_1  BldgType_1010_2  HouseStyle_NArw  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   HouseStyle_1010_0  HouseStyle_1010_1  HouseStyle_1010_2  HouseStyle_1010_3  \\\n",
       "0                  0                  1                  0                  1   \n",
       "1                  0                  0                  1                  0   \n",
       "2                  0                  1                  0                  1   \n",
       "3                  0                  1                  0                  1   \n",
       "4                  0                  1                  0                  1   \n",
       "\n",
       "   OverallQual_NArw  OverallCond_NArw  YearBuilt_NArw  YearRemodAdd_NArw  \\\n",
       "0                 0                 0               0                  0   \n",
       "1                 0                 0               0                  0   \n",
       "2                 0                 0               0                  0   \n",
       "3                 0                 0               0                  0   \n",
       "4                 0                 0               0                  0   \n",
       "\n",
       "   RoofStyle_NArw  RoofStyle_1010_0  RoofStyle_1010_1  RoofStyle_1010_2  \\\n",
       "0               0                 0                 0                 1   \n",
       "1               0                 0                 0                 1   \n",
       "2               0                 0                 0                 1   \n",
       "3               0                 0                 0                 1   \n",
       "4               0                 0                 0                 1   \n",
       "\n",
       "   RoofMatl_NArw  RoofMatl_1010_0  RoofMatl_1010_1  RoofMatl_1010_2  \\\n",
       "0              0                0                0                0   \n",
       "1              0                0                0                0   \n",
       "2              0                0                0                0   \n",
       "3              0                0                0                0   \n",
       "4              0                0                0                0   \n",
       "\n",
       "   RoofMatl_1010_3  Exterior1st_NArw  Exterior1st_1010_0  Exterior1st_1010_1  \\\n",
       "0                1                 0                   1                   1   \n",
       "1                1                 0                   1                   0   \n",
       "2                1                 0                   1                   1   \n",
       "3                1                 0                   1                   1   \n",
       "4                1                 0                   1                   1   \n",
       "\n",
       "   Exterior1st_1010_2  Exterior1st_1010_3  Exterior2nd_NArw  \\\n",
       "0                   0                   0                 0   \n",
       "1                   0                   0                 0   \n",
       "2                   0                   0                 0   \n",
       "3                   0                   1                 0   \n",
       "4                   0                   0                 0   \n",
       "\n",
       "   Exterior2nd_1010_0  Exterior2nd_1010_1  Exterior2nd_1010_2  \\\n",
       "0                   0                   1                   1   \n",
       "1                   0                   1                   0   \n",
       "2                   0                   1                   1   \n",
       "3                   0                   1                   1   \n",
       "4                   0                   1                   1   \n",
       "\n",
       "   Exterior2nd_1010_3  Exterior2nd_1010_4  MasVnrType_NArw  MasVnrType_1010_0  \\\n",
       "0                   0                   1                0                  0   \n",
       "1                   0                   0                0                  0   \n",
       "2                   0                   1                0                  0   \n",
       "3                   1                   1                0                  0   \n",
       "4                   0                   1                0                  0   \n",
       "\n",
       "   MasVnrType_1010_1  MasVnrType_1010_2  MasVnrArea_NArw  ExterQual_NArw  \\\n",
       "0                  0                  1                0               0   \n",
       "1                  1                  0                0               0   \n",
       "2                  0                  1                0               0   \n",
       "3                  1                  0                0               0   \n",
       "4                  0                  1                0               0   \n",
       "\n",
       "   ExterQual_1010_0  ExterQual_1010_1  ExterQual_1010_2  ExterCond_NArw  \\\n",
       "0                 0                 1                 0               0   \n",
       "1                 0                 1                 1               0   \n",
       "2                 0                 1                 0               0   \n",
       "3                 0                 1                 1               0   \n",
       "4                 0                 1                 0               0   \n",
       "\n",
       "   ExterCond_1010_0  ExterCond_1010_1  ExterCond_1010_2  Foundation_NArw  \\\n",
       "0                 1                 0                 0                0   \n",
       "1                 1                 0                 0                0   \n",
       "2                 1                 0                 0                0   \n",
       "3                 1                 0                 0                0   \n",
       "4                 1                 0                 0                0   \n",
       "\n",
       "   Foundation_1010_0  Foundation_1010_1  Foundation_1010_2  BsmtQual_NArw  \\\n",
       "0                  0                  1                  0              0   \n",
       "1                  0                  0                  1              0   \n",
       "2                  0                  1                  0              0   \n",
       "3                  0                  0                  0              0   \n",
       "4                  0                  1                  0              0   \n",
       "\n",
       "   BsmtQual_1010_0  BsmtQual_1010_1  BsmtQual_1010_2  BsmtCond_NArw  \\\n",
       "0                0                1                0              0   \n",
       "1                0                1                0              0   \n",
       "2                0                1                0              0   \n",
       "3                0                1                1              0   \n",
       "4                0                1                0              0   \n",
       "\n",
       "   BsmtCond_1010_0  BsmtCond_1010_1  BsmtCond_1010_2  BsmtExposure_NArw  \\\n",
       "0                0                1                1                  0   \n",
       "1                0                1                1                  0   \n",
       "2                0                1                1                  0   \n",
       "3                0                0                1                  0   \n",
       "4                0                1                1                  0   \n",
       "\n",
       "   BsmtExposure_1010_0  BsmtExposure_1010_1  BsmtExposure_1010_2  \\\n",
       "0                    0                    1                    1   \n",
       "1                    0                    0                    1   \n",
       "2                    0                    1                    0   \n",
       "3                    0                    1                    1   \n",
       "4                    0                    0                    0   \n",
       "\n",
       "   BsmtFinType1_NArw  BsmtFinType1_1010_0  BsmtFinType1_1010_1  \\\n",
       "0                  0                    0                    1   \n",
       "1                  0                    0                    0   \n",
       "2                  0                    0                    1   \n",
       "3                  0                    0                    0   \n",
       "4                  0                    0                    1   \n",
       "\n",
       "   BsmtFinType1_1010_2  BsmtFinSF1_NArw  BsmtFinType2_NArw  \\\n",
       "0                    0                0                  0   \n",
       "1                    0                0                  0   \n",
       "2                    0                0                  0   \n",
       "3                    0                0                  0   \n",
       "4                    0                0                  0   \n",
       "\n",
       "   BsmtFinType2_1010_0  BsmtFinType2_1010_1  BsmtFinType2_1010_2  \\\n",
       "0                    1                    0                    1   \n",
       "1                    1                    0                    1   \n",
       "2                    1                    0                    1   \n",
       "3                    1                    0                    1   \n",
       "4                    1                    0                    1   \n",
       "\n",
       "   BsmtFinSF2_NArw  BsmtUnfSF_NArw  TotalBsmtSF_NArw  Heating_NArw  \\\n",
       "0                0               0                 0             0   \n",
       "1                0               0                 0             0   \n",
       "2                0               0                 0             0   \n",
       "3                0               0                 0             0   \n",
       "4                0               0                 0             0   \n",
       "\n",
       "   Heating_1010_0  Heating_1010_1  Heating_1010_2  HeatingQC_NArw  \\\n",
       "0               0               0               1               0   \n",
       "1               0               0               1               0   \n",
       "2               0               0               1               0   \n",
       "3               0               0               1               0   \n",
       "4               0               0               1               0   \n",
       "\n",
       "   HeatingQC_1010_0  HeatingQC_1010_1  HeatingQC_1010_2  CentralAir_NArw  \\\n",
       "0                 0                 0                 0                0   \n",
       "1                 0                 0                 0                0   \n",
       "2                 0                 0                 0                0   \n",
       "3                 0                 1                 0                0   \n",
       "4                 0                 0                 0                0   \n",
       "\n",
       "   Electrical_NArw  Electrical_1010_0  Electrical_1010_1  Electrical_1010_2  \\\n",
       "0                0                  1                  0                  0   \n",
       "1                0                  1                  0                  0   \n",
       "2                0                  1                  0                  0   \n",
       "3                0                  1                  0                  0   \n",
       "4                0                  1                  0                  0   \n",
       "\n",
       "   1stFlrSF_NArw  2ndFlrSF_NArw  LowQualFinSF_NArw  GrLivArea_NArw  \\\n",
       "0              0              0                  0               0   \n",
       "1              0              0                  0               0   \n",
       "2              0              0                  0               0   \n",
       "3              0              0                  0               0   \n",
       "4              0              0                  0               0   \n",
       "\n",
       "   BsmtFullBath_NArw  BsmtHalfBath_NArw  BsmtHalfBath_1010_0  \\\n",
       "0                  0                  0                    0   \n",
       "1                  0                  0                    0   \n",
       "2                  0                  0                    0   \n",
       "3                  0                  0                    0   \n",
       "4                  0                  0                    0   \n",
       "\n",
       "   BsmtHalfBath_1010_1  FullBath_NArw  HalfBath_NArw  HalfBath_1010_0  \\\n",
       "0                    0              0              0                0   \n",
       "1                    1              0              0                0   \n",
       "2                    0              0              0                0   \n",
       "3                    0              0              0                0   \n",
       "4                    0              0              0                0   \n",
       "\n",
       "   HalfBath_1010_1  BedroomAbvGr_NArw  KitchenAbvGr_NArw  KitchenQual_NArw  \\\n",
       "0                1                  0                  0                 0   \n",
       "1                0                  0                  0                 0   \n",
       "2                1                  0                  0                 0   \n",
       "3                0                  0                  0                 0   \n",
       "4                1                  0                  0                 0   \n",
       "\n",
       "   KitchenQual_1010_0  KitchenQual_1010_1  KitchenQual_1010_2  \\\n",
       "0                   0                   1                   0   \n",
       "1                   0                   1                   1   \n",
       "2                   0                   1                   0   \n",
       "3                   0                   1                   0   \n",
       "4                   0                   1                   0   \n",
       "\n",
       "   TotRmsAbvGrd_NArw  Functional_NArw  Functional_1010_0  Functional_1010_1  \\\n",
       "0                  0                0                  1                  1   \n",
       "1                  0                0                  1                  1   \n",
       "2                  0                0                  1                  1   \n",
       "3                  0                0                  1                  1   \n",
       "4                  0                0                  1                  1   \n",
       "\n",
       "   Functional_1010_2  Fireplaces_NArw  FireplaceQu_NArw  FireplaceQu_1010_0  \\\n",
       "0                  0                0                 1                   0   \n",
       "1                  0                0                 0                   1   \n",
       "2                  0                0                 0                   1   \n",
       "3                  0                0                 0                   0   \n",
       "4                  0                0                 0                   1   \n",
       "\n",
       "   FireplaceQu_1010_1  FireplaceQu_1010_2  GarageType_NArw  GarageType_1010_0  \\\n",
       "0                   0                   0                0                  0   \n",
       "1                   0                   0                0                  0   \n",
       "2                   0                   0                0                  0   \n",
       "3                   1                   0                0                  1   \n",
       "4                   0                   0                0                  0   \n",
       "\n",
       "   GarageType_1010_1  GarageType_1010_2  GarageYrBlt_NArw  GarageFinish_NArw  \\\n",
       "0                  0                  1                 0                  0   \n",
       "1                  0                  1                 0                  0   \n",
       "2                  0                  1                 0                  0   \n",
       "3                  0                  1                 0                  0   \n",
       "4                  0                  1                 0                  0   \n",
       "\n",
       "   GarageFinish_1010_0  GarageFinish_1010_1  GarageCars_NArw  GarageArea_NArw  \\\n",
       "0                    0                    1                0                0   \n",
       "1                    0                    1                0                0   \n",
       "2                    0                    1                0                0   \n",
       "3                    1                    0                0                0   \n",
       "4                    0                    1                0                0   \n",
       "\n",
       "   GarageQual_NArw  GarageQual_1010_0  GarageQual_1010_1  GarageQual_1010_2  \\\n",
       "0                0                  1                  0                  0   \n",
       "1                0                  1                  0                  0   \n",
       "2                0                  1                  0                  0   \n",
       "3                0                  1                  0                  0   \n",
       "4                0                  1                  0                  0   \n",
       "\n",
       "   GarageCond_NArw  GarageCond_1010_0  GarageCond_1010_1  GarageCond_1010_2  \\\n",
       "0                0                  1                  0                  0   \n",
       "1                0                  1                  0                  0   \n",
       "2                0                  1                  0                  0   \n",
       "3                0                  1                  0                  0   \n",
       "4                0                  1                  0                  0   \n",
       "\n",
       "   PavedDrive_NArw  PavedDrive_1010_0  PavedDrive_1010_1  WoodDeckSF_NArw  \\\n",
       "0                0                  1                  0                0   \n",
       "1                0                  1                  0                0   \n",
       "2                0                  1                  0                0   \n",
       "3                0                  1                  0                0   \n",
       "4                0                  1                  0                0   \n",
       "\n",
       "   OpenPorchSF_NArw  EnclosedPorch_NArw  3SsnPorch_NArw  ScreenPorch_NArw  \\\n",
       "0                 0                   0               0                 0   \n",
       "1                 0                   0               0                 0   \n",
       "2                 0                   0               0                 0   \n",
       "3                 0                   0               0                 0   \n",
       "4                 0                   0               0                 0   \n",
       "\n",
       "   PoolArea_NArw  PoolQC_NArw  PoolQC_1010_0  PoolQC_1010_1  Fence_NArw  \\\n",
       "0              0            1              0              0           1   \n",
       "1              0            1              0              0           1   \n",
       "2              0            1              0              0           1   \n",
       "3              0            1              0              0           1   \n",
       "4              0            1              0              0           1   \n",
       "\n",
       "   Fence_1010_0  Fence_1010_1  Fence_1010_2  MiscFeature_NArw  \\\n",
       "0             0             0             0                 1   \n",
       "1             0             0             0                 1   \n",
       "2             0             0             0                 1   \n",
       "3             0             0             0                 1   \n",
       "4             0             0             0                 1   \n",
       "\n",
       "   MiscFeature_1010_0  MiscFeature_1010_1  MiscFeature_1010_2  MiscVal_NArw  \\\n",
       "0                   0                   0                   0             0   \n",
       "1                   0                   0                   0             0   \n",
       "2                   0                   0                   0             0   \n",
       "3                   0                   0                   0             0   \n",
       "4                   0                   0                   0             0   \n",
       "\n",
       "   MoSold_NArw  YrSold_NArw  SaleType_NArw  SaleType_1010_0  SaleType_1010_1  \\\n",
       "0            0            0              0                1                0   \n",
       "1            0            0              0                1                0   \n",
       "2            0            0              0                1                0   \n",
       "3            0            0              0                1                0   \n",
       "4            0            0              0                1                0   \n",
       "\n",
       "   SaleType_1010_2  SaleType_1010_3  SaleCondition_NArw  SaleCondition_1010_0  \\\n",
       "0                0                0                   0                     1   \n",
       "1                0                0                   0                     1   \n",
       "2                0                0                   0                     1   \n",
       "3                0                0                   0                     0   \n",
       "4                0                0                   0                     1   \n",
       "\n",
       "   SaleCondition_1010_1  SaleCondition_1010_2  \n",
       "0                     0                     0  \n",
       "1                     0                     0  \n",
       "2                     0                     0  \n",
       "3                     0                     0  \n",
       "4                     0                     0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned columns in some cases don't have grouping coherence for those derived from the same source feature. This was an intentional design decision for memory overhead, if grouping coherence is desired for the returned sets can activated by passing a parameter to assignparam as:\n",
    "```\n",
    "assignparam = {'global_assignparam' : {'inplace' : False}}\n",
    "```\n",
    "Since we are interested in viewing together columns originating from the same source column, we can do so with the column map saved in the returned postprocess_dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea_nmbr</th>\n",
       "      <th>LotArea_NArw</th>\n",
       "      <th>Neighborhood_NArw</th>\n",
       "      <th>Neighborhood_1010_0</th>\n",
       "      <th>Neighborhood_1010_1</th>\n",
       "      <th>Neighborhood_1010_2</th>\n",
       "      <th>Neighborhood_1010_3</th>\n",
       "      <th>Neighborhood_1010_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.241283</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.058864</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.097692</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.093364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.191731</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LotArea_nmbr  LotArea_NArw  Neighborhood_NArw  Neighborhood_1010_0  \\\n",
       "0     -0.241283             0                  1                    0   \n",
       "1      0.058864             1                  0                    1   \n",
       "2     -0.097692             1                  1                    0   \n",
       "3     -0.093364             0                  0                    0   \n",
       "4      0.191731             1                  0                    0   \n",
       "\n",
       "   Neighborhood_1010_1  Neighborhood_1010_2  Neighborhood_1010_3  \\\n",
       "0                    0                    0                    0   \n",
       "1                    1                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    1                    1   \n",
       "4                    1                    1                    1   \n",
       "\n",
       "   Neighborhood_1010_4  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[postprocess_dict['column_map']['LotArea'] + \\\n",
    "      postprocess_dict['column_map']['Neighborhood']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see inputation in a few rows, where 'LotArea_NArw' signals those entries of 'LotArea' that were subject to infill, and 'Neighborhood_NArw' signals those entries of 'Neighborhood' that were sunject to infill. (Again we injected a few nan points into the set for demonstration purposes.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same models from the train set basis are saved and returned in the postprocess_dict, allowing for a consistent inputation basis to subsequent data in the postmunge(.) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, test_ID, test_labels, \\\n",
    "postreports_dict \\\n",
    "= am.postmunge(postprocess_dict, \n",
    "               df_test,\n",
    "               printstatus = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea_nmbr</th>\n",
       "      <th>LotArea_NArw</th>\n",
       "      <th>Neighborhood_NArw</th>\n",
       "      <th>Neighborhood_1010_0</th>\n",
       "      <th>Neighborhood_1010_1</th>\n",
       "      <th>Neighborhood_1010_2</th>\n",
       "      <th>Neighborhood_1010_3</th>\n",
       "      <th>Neighborhood_1010_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.212333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.540939</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.023684</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.021091</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.704539</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LotArea_nmbr  LotArea_NArw  Neighborhood_NArw  Neighborhood_1010_0  \\\n",
       "0     -0.212333             1                  1                    0   \n",
       "1      0.540939             0                  1                    0   \n",
       "2      0.023684             1                  1                    0   \n",
       "3      0.021091             1                  1                    0   \n",
       "4     -0.704539             0                  1                    0   \n",
       "\n",
       "   Neighborhood_1010_1  Neighborhood_1010_2  Neighborhood_1010_3  \\\n",
       "0                    0                    0                    0   \n",
       "1                    0                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    0                    0   \n",
       "4                    0                    0                    0   \n",
       "\n",
       "   Neighborhood_1010_4  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[postprocess_dict['column_map']['LotArea'] + \\\n",
    "      postprocess_dict['column_map']['Neighborhood']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to apply ML infill only to select columns, we can deactivate the default with `MLinfill=False` and assign to distinct columns in `assigninfill` parameter. Note that column assignments can either be performed with source column headers or returned column headers which include suffix appenders.\n",
    "\n",
    "Here we'll demonstrate applying ML infill to a subset of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, train_ID, labels, \\\n",
    "val, val_ID, val_labels, \\\n",
    "test, test_ID, test_labels, \\\n",
    "postprocess_dict \\\n",
    "= am.automunge(df_train,\n",
    "               labels_column = labels_column,\n",
    "               trainID_column = trainID_column,\n",
    "               NArw_marker = True,\n",
    "               shuffletrain = False, \n",
    "               MLinfill = False,\n",
    "               assigninfill = {'MLinfill':['LotArea', 'Neighborhood']},\n",
    "               printstatus = False\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest ML infill can either be applied with defaults, or can also accept parameters passed to the training operation by way of the ML_cmnd parameter. Parameters are consistent with the Scikit Learn Random forest Classifier and Regressor that are the basis. Let's demonstrate here increasing the number of estimators (which will increase training time). Random Forest is pretty good for tendency not to overfit from what I understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we'll increase n_estimators from default of 100\n",
    "ML_cmnd = {'autoML_type'  :'randomforest', \\\n",
    "           'MLinfill_cmnd':{'RandomForestClassifier':{'n_estimators' : 1000}, \\\n",
    "                            'RandomForestRegressor' :{'n_estimators' : 1000}}\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea_nmbr</th>\n",
       "      <th>LotArea_NArw</th>\n",
       "      <th>Neighborhood_NArw</th>\n",
       "      <th>Neighborhood_1010_0</th>\n",
       "      <th>Neighborhood_1010_1</th>\n",
       "      <th>Neighborhood_1010_2</th>\n",
       "      <th>Neighborhood_1010_3</th>\n",
       "      <th>Neighborhood_1010_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.282955</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.011420</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.228283</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.026828</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.452619</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LotArea_nmbr  LotArea_NArw  Neighborhood_NArw  Neighborhood_1010_0  \\\n",
       "0     -0.282955             0                  0                    0   \n",
       "1     -0.011420             1                  0                    1   \n",
       "2     -0.228283             1                  0                    0   \n",
       "3     -0.026828             1                  1                    0   \n",
       "4      0.452619             0                  1                    0   \n",
       "\n",
       "   Neighborhood_1010_1  Neighborhood_1010_2  Neighborhood_1010_3  \\\n",
       "0                    0                    1                    0   \n",
       "1                    1                    0                    0   \n",
       "2                    0                    1                    0   \n",
       "3                    0                    0                    0   \n",
       "4                    0                    0                    0   \n",
       "\n",
       "   Neighborhood_1010_4  \n",
       "0                    1  \n",
       "1                    0  \n",
       "2                    1  \n",
       "3                    0  \n",
       "4                    0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, train_ID, labels, \\\n",
    "val, val_ID, val_labels, \\\n",
    "test, test_ID, test_labels, \\\n",
    "postprocess_dict \\\n",
    "= am.automunge(df_train,\n",
    "               labels_column = labels_column,\n",
    "               trainID_column = trainID_column,\n",
    "               assignnan = assignnan,\n",
    "               ML_cmnd = ML_cmnd,\n",
    "               NArw_marker = True,\n",
    "               shuffletrain = False, \n",
    "               MLinfill = True,\n",
    "               printstatus = False\n",
    "              )\n",
    "\n",
    "train[postprocess_dict['column_map']['LotArea'] + \\\n",
    "      postprocess_dict['column_map']['Neighborhood']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course there are tradeoffs associated with Random Forest, like the accuracy may not be as high as some other methods like gradient boosting and does not support GPU training which may be needed for larger training sets. Automunge doesn't currently include a gradient boosting option, partly because hyperparameter selection is a little more tricky and higher risk of overfitting, but we do have a few auto ML options that are expected to perform at comparable or better.\n",
    "\n",
    "Catboost: One way to think about Catboost is that it is an extension of gradient boosting, including support for GPU's, wrapped in an auto ML package.\n",
    "\n",
    "AutoGluon: Autogluon is another auto ML package that takes a different approach than catboost, relying on aggregation of ensembles (ensembles which include catboost within as a matter of fact).\n",
    "\n",
    "FLAML: FLAML is an auto ML library with some unique approaches for hyperparameter tuning. This library is expected to perform efficiently in inference. We'll demonstrate below designating a training time limit for each feature by parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can activate one of these other ML infill architectures in ML_Cmnd as well. (Note that you'll need to install them first, instructions are available on their respective websites)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea_nmbr</th>\n",
       "      <th>LotArea_NArw</th>\n",
       "      <th>Neighborhood_NArw</th>\n",
       "      <th>Neighborhood_1010_0</th>\n",
       "      <th>Neighborhood_1010_1</th>\n",
       "      <th>Neighborhood_1010_2</th>\n",
       "      <th>Neighborhood_1010_3</th>\n",
       "      <th>Neighborhood_1010_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.259700</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.120471</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077376</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.126466</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.118578</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LotArea_nmbr  LotArea_NArw  Neighborhood_NArw  Neighborhood_1010_0  \\\n",
       "0     -0.259700             1                  1                    1   \n",
       "1     -0.120471             0                  1                    1   \n",
       "2      0.077376             0                  1                    1   \n",
       "3     -0.126466             0                  0                    0   \n",
       "4      0.118578             1                  0                    0   \n",
       "\n",
       "   Neighborhood_1010_1  Neighborhood_1010_2  Neighborhood_1010_3  \\\n",
       "0                    1                    0                    0   \n",
       "1                    1                    0                    0   \n",
       "2                    1                    0                    0   \n",
       "3                    0                    1                    1   \n",
       "4                    1                    1                    1   \n",
       "\n",
       "   Neighborhood_1010_4  \n",
       "0                    1  \n",
       "1                    1  \n",
       "2                    1  \n",
       "3                    0  \n",
       "4                    1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#And here we demonstrate applying ML infill with CatBoost\n",
    "\n",
    "ML_cmnd = {'autoML_type':'catboost'}\n",
    "\n",
    "train, train_ID, labels, \\\n",
    "val, val_ID, val_labels, \\\n",
    "test, test_ID, test_labels, \\\n",
    "postprocess_dict \\\n",
    "= am.automunge(df_train,\n",
    "               labels_column = labels_column,\n",
    "               trainID_column = trainID_column,\n",
    "               assignnan = assignnan,\n",
    "               ML_cmnd = ML_cmnd,\n",
    "               NArw_marker = True,\n",
    "               shuffletrain = False, \n",
    "               MLinfill = True,\n",
    "               printstatus = False\n",
    "              )\n",
    "\n",
    "train[postprocess_dict['column_map']['LotArea'] + \\\n",
    "      postprocess_dict['column_map']['Neighborhood']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused KNeighborsClassifierUnif to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused KNeighborsClassifierDist to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused RandomForestClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierGini to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused ExtraTreesClassifierEntr to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 865, in _train_and_save\n",
      "    score = model.score(X=X_val, y=y_val)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 283, in score\n",
      "    y_pred = self.predict(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 244, in predict\n",
      "    y_pred_proba = self.predict_proba(X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 251, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, preprocess=preprocess)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 275, in _predict_proba\n",
      "    return y_pred_proba[:, 1]\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "Warning: Exception caused LightGBMClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused LightGBMClassifierXT to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused CatboostClassifier to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/catboost/catboost_model.py\", line 234, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 4302, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1806, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/catboost/core.py\", line 1258, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4156, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4205, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:376: Target contains only one unique value\n",
      "Warning: Exception caused LightGBMClassifierCustom to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 827, in _train_single\n",
      "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/lgb/lgb_model.py\", line 152, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1123, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 1165, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Number of classes should be specified and greater than 1 for multiclass training\n",
      "Warning: Exception caused weighted_ensemble_k0_l1 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 856, in _train_and_save\n",
      "    model = self._train_single(X_train, y_train, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\", line 825, in _train_single\n",
      "    model.fit(X=X_train, y=y_train, **model_fit_kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/weighted_ensemble_model.py\", line 23, in _fit\n",
      "    super()._fit(X, y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=compute_base_preds, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\", line 129, in _fit\n",
      "    super()._fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/bagged_ensemble_model.py\", line 127, in _fit\n",
      "    model_base.fit(X_train=X, y_train=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/abstract/abstract_model.py\", line 233, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/models/ensemble/greedy_weighted_ensemble_model.py\", line 37, in _fit\n",
      "    self.model = self.model.fit(X_train, y_train, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 48, in fit\n",
      "    self._fit(predictions=predictions, labels=labels, time_limit=time_limit)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/tuning/ensemble_selection.py\", line 94, in _fit\n",
      "    preds = get_pred_from_proba(y_pred_proba=fant_ensemble_prediction, problem_type=self.problem_type)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/autogluon/utils/tabular/ml/utils.py\", line 24, in get_pred_from_proba\n",
      "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in argmax\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 1188, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "numpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea_nmbr</th>\n",
       "      <th>LotArea_NArw</th>\n",
       "      <th>Neighborhood_NArw</th>\n",
       "      <th>Neighborhood_1010_0</th>\n",
       "      <th>Neighborhood_1010_1</th>\n",
       "      <th>Neighborhood_1010_2</th>\n",
       "      <th>Neighborhood_1010_3</th>\n",
       "      <th>Neighborhood_1010_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.213533</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.031697</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.108329</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.136284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.410957</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LotArea_nmbr  LotArea_NArw  Neighborhood_NArw  Neighborhood_1010_0  \\\n",
       "0     -0.213533             1                  1                    0   \n",
       "1     -0.031697             1                  0                    1   \n",
       "2     -0.108329             1                  0                    0   \n",
       "3     -0.136284             0                  0                    0   \n",
       "4      0.410957             0                  0                    0   \n",
       "\n",
       "   Neighborhood_1010_1  Neighborhood_1010_2  Neighborhood_1010_3  \\\n",
       "0                    0                    0                    0   \n",
       "1                    0                    1                    1   \n",
       "2                    0                    1                    0   \n",
       "3                    0                    1                    0   \n",
       "4                    1                    1                    1   \n",
       "\n",
       "   Neighborhood_1010_4  \n",
       "0                    0  \n",
       "1                    1  \n",
       "2                    0  \n",
       "3                    1  \n",
       "4                    0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we demonstrate applying ML infill with AutoGluon\n",
    "\n",
    "ML_cmnd = {'autoML_type':'autogluon', \\\n",
    "           'MLinfill_cmnd':{'AutoGluon'  : {'verbosity' : 0}}}\n",
    "\n",
    "train, train_ID, labels, \\\n",
    "val, val_ID, val_labels, \\\n",
    "test, test_ID, test_labels, \\\n",
    "postprocess_dict \\\n",
    "= am.automunge(df_train,\n",
    "               labels_column = labels_column,\n",
    "               trainID_column = trainID_column,\n",
    "               assignnan = assignnan,\n",
    "               ML_cmnd = ML_cmnd,\n",
    "               NArw_marker = True,\n",
    "               shuffletrain = False, \n",
    "               MLinfill = True,\n",
    "               printstatus = False\n",
    "              )\n",
    "\n",
    "train[postprocess_dict['column_map']['LotArea'] + \\\n",
    "      postprocess_dict['column_map']['Neighborhood']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "No init config given to FLOW2. Using random initial config.For cost-frugal search, consider providing init values for cost-related hps via 'init_config'.\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea_nmbr</th>\n",
       "      <th>LotArea_NArw</th>\n",
       "      <th>Neighborhood_NArw</th>\n",
       "      <th>Neighborhood_1010_0</th>\n",
       "      <th>Neighborhood_1010_1</th>\n",
       "      <th>Neighborhood_1010_2</th>\n",
       "      <th>Neighborhood_1010_3</th>\n",
       "      <th>Neighborhood_1010_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.400192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.172678</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.147621</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.340247</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.749245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LotArea_nmbr  LotArea_NArw  Neighborhood_NArw  Neighborhood_1010_0  \\\n",
       "0     -0.400192             0                  0                    0   \n",
       "1     -0.172678             0                  1                    0   \n",
       "2      0.147621             1                  0                    0   \n",
       "3     -0.340247             1                  0                    0   \n",
       "4      0.749245             0                  0                    0   \n",
       "\n",
       "   Neighborhood_1010_1  Neighborhood_1010_2  Neighborhood_1010_3  \\\n",
       "0                    0                    1                    0   \n",
       "1                    1                    1                    1   \n",
       "2                    0                    1                    0   \n",
       "3                    0                    1                    1   \n",
       "4                    1                    1                    1   \n",
       "\n",
       "   Neighborhood_1010_4  \n",
       "0                    1  \n",
       "1                    0  \n",
       "2                    1  \n",
       "3                    0  \n",
       "4                    1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#And here we demonstrate applying ML infill with FLAML\n",
    "\n",
    "ML_cmnd = {'autoML_type':'flaml'}\n",
    "\n",
    "#we can also pass parameters to designate a limit on training time for each feature (in seconds)\n",
    "ML_cmnd.update({'MLinfill_cmnd' : {'flaml_classifier_fit'   : {'time_budget' : 10 },\n",
    "                                   'flaml_regressor_fit'    : {'time_budget' : 10}}})\n",
    "\n",
    "train, train_ID, labels, \\\n",
    "val, val_ID, val_labels, \\\n",
    "test, test_ID, test_labels, \\\n",
    "postprocess_dict \\\n",
    "= am.automunge(df_train,\n",
    "               labels_column = labels_column,\n",
    "               trainID_column = trainID_column,\n",
    "               assignnan = assignnan,\n",
    "               ML_cmnd = ML_cmnd,\n",
    "               NArw_marker = True,\n",
    "               shuffletrain = False, \n",
    "               MLinfill = True,\n",
    "               printstatus = False\n",
    "              )\n",
    "\n",
    "train[postprocess_dict['column_map']['LotArea'] + \\\n",
    "      postprocess_dict['column_map']['Neighborhood']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 16:55:49,596]\u001b[0m A new study created in memory with name: no-name-2c729128-5c54-48df-8644-d809810ee40c\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:49,976]\u001b[0m Trial 0 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 0.5693802552648966, 'alpha': 9.647084502797554e-06, 'subsample': 0.33006496852390504, 'colsample_bytree': 0.6082716190524615, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.002005417051900534, 'gamma': 2.828414270871835e-05, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.0011243310818843852, 'skip_drop': 0.09227512813163202}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:50,218]\u001b[0m Trial 1 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 3.3815703958302712e-06, 'alpha': 3.0378433383345965e-06, 'subsample': 0.9269361276414925, 'colsample_bytree': 0.29663126939916895, 'max_depth': 9, 'min_child_weight': 5, 'eta': 6.420891887526793e-07, 'gamma': 0.002725487129380967, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.38910045089838863, 'skip_drop': 1.0448892278197508e-05}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:50,464]\u001b[0m Trial 2 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 5.922097011134004e-05, 'alpha': 1.0128847060519414e-08, 'subsample': 0.34799082584322905, 'colsample_bytree': 0.9692649887026235, 'max_depth': 9, 'min_child_weight': 10, 'eta': 3.997002962517214e-08, 'gamma': 2.035352621916822e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.03353854916945699, 'skip_drop': 0.000798118751724764}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:50,532]\u001b[0m Trial 3 finished with value: 0.0 and parameters: {'booster': 'gblinear', 'lambda': 6.767274753042792e-05, 'alpha': 6.186118158688231e-06, 'subsample': 0.7837319078845844, 'colsample_bytree': 0.3117523031934001}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:50,601]\u001b[0m Trial 4 finished with value: 0.0 and parameters: {'booster': 'gblinear', 'lambda': 3.0346162713754607e-05, 'alpha': 0.0002599045484244173, 'subsample': 0.32572114714665623, 'colsample_bytree': 0.6582957137200679}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:50,669]\u001b[0m Trial 5 finished with value: 0.0 and parameters: {'booster': 'gblinear', 'lambda': 6.099246061694379e-05, 'alpha': 0.003808481814524855, 'subsample': 0.24164098075992088, 'colsample_bytree': 0.5711162573265103}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:50,756]\u001b[0m Trial 6 finished with value: 0.0 and parameters: {'booster': 'gbtree', 'lambda': 5.080391634784647e-05, 'alpha': 0.00016113494872748715, 'subsample': 0.274229767705241, 'colsample_bytree': 0.9671087597058035, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.2319104940460761, 'gamma': 0.022970146161557473, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:51,002]\u001b[0m Trial 7 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 0.018518487380551903, 'alpha': 3.681146905042911e-08, 'subsample': 0.535829186947588, 'colsample_bytree': 0.9749123834128512, 'max_depth': 7, 'min_child_weight': 10, 'eta': 7.103933312615257e-08, 'gamma': 1.8918761044072492e-06, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 1.9458954568871293e-06, 'skip_drop': 9.64298172401456e-08}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:51,157]\u001b[0m Trial 8 finished with value: 0.0 and parameters: {'booster': 'gblinear', 'lambda': 2.313715043327859e-06, 'alpha': 0.04723350642460861, 'subsample': 0.9153149581209006, 'colsample_bytree': 0.24331240778840765}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:51,255]\u001b[0m Trial 9 finished with value: 0.0 and parameters: {'booster': 'gblinear', 'lambda': 0.08841893699254083, 'alpha': 0.003240120600808362, 'subsample': 0.5109800953775498, 'colsample_bytree': 0.6170701327804669}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:51,364]\u001b[0m Trial 10 finished with value: 0.0 and parameters: {'booster': 'gbtree', 'lambda': 3.7388613208201536e-08, 'alpha': 9.270100281345697e-07, 'subsample': 0.7025867386366134, 'colsample_bytree': 0.7805975781046781, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.004425662098395873, 'gamma': 2.6911171764069924e-05, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:51,605]\u001b[0m Trial 11 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 0.006170260143163808, 'alpha': 1.932684847936017e-06, 'subsample': 0.9857639367756487, 'colsample_bytree': 0.39838400425065723, 'max_depth': 5, 'min_child_weight': 6, 'eta': 2.921667053728454e-05, 'gamma': 0.009231735698852168, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.7072817460940841, 'skip_drop': 0.6544462414789247}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:51,875]\u001b[0m Trial 12 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 1.8409710726747442e-07, 'alpha': 1.2418483675044401e-05, 'subsample': 0.44917861254361835, 'colsample_bytree': 0.45095530509436954, 'max_depth': 5, 'min_child_weight': 3, 'eta': 2.1717230265046995e-05, 'gamma': 0.0008200486309465819, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.0002896518526890069, 'skip_drop': 5.217264970554617e-06}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:52,144]\u001b[0m Trial 13 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 0.8314320618256431, 'alpha': 1.716136506313483e-07, 'subsample': 0.6749521623924479, 'colsample_bytree': 0.7604299901858029, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.0012282647112986263, 'gamma': 0.966115072007458, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.0019399462115558426, 'skip_drop': 0.002578322420491738}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:52,426]\u001b[0m Trial 14 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 0.001743597930800244, 'alpha': 2.7622782930116383e-05, 'subsample': 0.8718137221085211, 'colsample_bytree': 0.48910554542454304, 'max_depth': 3, 'min_child_weight': 5, 'eta': 1.7678325431827095e-06, 'gamma': 1.044010463557373e-05, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.2187270678266849e-08, 'skip_drop': 0.6504856619895399}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:52,579]\u001b[0m Trial 15 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 2.157075121339685e-06, 'alpha': 0.6052228202376188, 'subsample': 0.6252058031041186, 'colsample_bytree': 0.20552749308767226, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.011219266154958102, 'gamma': 0.0009068995635881322, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.8942971993938027, 'skip_drop': 1.2201445558544033e-05}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:52,685]\u001b[0m Trial 16 finished with value: 0.0 and parameters: {'booster': 'gbtree', 'lambda': 0.0010471820594833063, 'alpha': 2.7340033972896917e-07, 'subsample': 0.4210442264341018, 'colsample_bytree': 0.35355651950482736, 'max_depth': 5, 'min_child_weight': 4, 'eta': 1.1896791716997013e-06, 'gamma': 2.970420355856324e-07, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:52,955]\u001b[0m Trial 17 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 0.7832597374910021, 'alpha': 2.113333612424007e-05, 'subsample': 0.7944899761803867, 'colsample_bytree': 0.5066195819611445, 'max_depth': 3, 'min_child_weight': 8, 'eta': 0.00019309230209218779, 'gamma': 1.6011957650601014e-05, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 5.321415869688735e-08, 'skip_drop': 0.8587311206935542}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:53,233]\u001b[0m Trial 18 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 1.788770492506001e-06, 'alpha': 0.8553139711026237, 'subsample': 0.6168917238053878, 'colsample_bytree': 0.7365376303263842, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.18478974974936777, 'gamma': 0.00022275949027364067, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 8.032276439195845e-06, 'skip_drop': 0.005536340360253288}. Best is trial 0 with value: 0.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 16:55:53,338]\u001b[0m Trial 19 finished with value: 0.0 and parameters: {'booster': 'gbtree', 'lambda': 0.0010099869966454364, 'alpha': 2.902279688983713e-07, 'subsample': 0.3727675984274071, 'colsample_bytree': 0.37000576871617075, 'max_depth': 5, 'min_child_weight': 2, 'eta': 1.2226339339823656e-06, 'gamma': 1.949054438159997e-07, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:53,604]\u001b[0m Trial 20 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 0.9417435394007607, 'alpha': 0.0014428141741633232, 'subsample': 0.7755955158917373, 'colsample_bytree': 0.5502415879259279, 'max_depth': 3, 'min_child_weight': 9, 'eta': 0.0005067965139363025, 'gamma': 8.340960365819165e-06, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 4.3988765573004586e-08, 'skip_drop': 0.053707332851612485}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:53,883]\u001b[0m Trial 21 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 0.14121227011248605, 'alpha': 0.9342880278022251, 'subsample': 0.5704236703910118, 'colsample_bytree': 0.7396599147939277, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.6864343876260517, 'gamma': 0.00017939504440864847, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 4.198922216139493e-06, 'skip_drop': 0.012719046328748826}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:53,988]\u001b[0m Trial 22 finished with value: 0.0 and parameters: {'booster': 'gbtree', 'lambda': 3.6138536539134955e-07, 'alpha': 0.043370961658344205, 'subsample': 0.4126356970969538, 'colsample_bytree': 0.8529290277167549, 'max_depth': 5, 'min_child_weight': 2, 'eta': 0.04567309407370545, 'gamma': 1.5193692189777834e-07, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:54,094]\u001b[0m Trial 23 finished with value: 0.0 and parameters: {'booster': 'gbtree', 'lambda': 0.09420588112951009, 'alpha': 0.0005351858592304342, 'subsample': 0.35061695783872593, 'colsample_bytree': 0.5489986414613014, 'max_depth': 3, 'min_child_weight': 10, 'eta': 0.0005040001392773128, 'gamma': 1.3211685998740972e-06, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:54,366]\u001b[0m Trial 24 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 0.10830798734422666, 'alpha': 0.07069517091510467, 'subsample': 0.760889314176271, 'colsample_bytree': 0.674265319748839, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.9926086997600113, 'gamma': 9.03187662492382e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 4.910806795163512e-07, 'skip_drop': 0.020938403596761426}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:54,478]\u001b[0m Trial 25 finished with value: 0.0 and parameters: {'booster': 'gbtree', 'lambda': 1.012074651653517e-08, 'alpha': 0.10207459382766992, 'subsample': 0.44221867600666326, 'colsample_bytree': 0.8578794372000673, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.03441064027114835, 'gamma': 1.663525274907743e-08, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:54,585]\u001b[0m Trial 26 finished with value: 0.0 and parameters: {'booster': 'gbtree', 'lambda': 0.013401051257610446, 'alpha': 0.0007120296270205767, 'subsample': 0.22371754422329804, 'colsample_bytree': 0.85907123970304, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.004078522871529304, 'gamma': 7.758409963905236e-07, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:54,691]\u001b[0m Trial 27 finished with value: 0.0 and parameters: {'booster': 'gbtree', 'lambda': 0.08572816004842053, 'alpha': 6.034728438526782e-05, 'subsample': 0.7150129897164511, 'colsample_bytree': 0.6345425189517061, 'max_depth': 7, 'min_child_weight': 10, 'eta': 6.652217993300365e-05, 'gamma': 5.509255472152881e-05, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:54,799]\u001b[0m Trial 28 finished with value: 0.0 and parameters: {'booster': 'gbtree', 'lambda': 1.5328545563033386e-08, 'alpha': 0.03722549040124017, 'subsample': 0.4765640245824562, 'colsample_bytree': 0.8701141653524622, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.03450486760900848, 'gamma': 0.08341798899543532, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:54,906]\u001b[0m Trial 29 finished with value: 0.0 and parameters: {'booster': 'gbtree', 'lambda': 0.00039088856727708787, 'alpha': 0.007775223155315823, 'subsample': 0.27999780615500625, 'colsample_bytree': 0.8867739720382404, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.004252168626785456, 'gamma': 1.3325412434800388e-08, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:55,070]\u001b[0m Trial 30 finished with value: 0.0 and parameters: {'booster': 'gbtree', 'lambda': 0.017653175555166614, 'alpha': 4.877759918581931e-05, 'subsample': 0.26707815922573763, 'colsample_bytree': 0.6798366774826303, 'max_depth': 7, 'min_child_weight': 7, 'eta': 2.859161101853832e-05, 'gamma': 1.5371977080487184e-06, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:55,237]\u001b[0m Trial 31 finished with value: 0.0 and parameters: {'booster': 'gbtree', 'lambda': 0.02553849591473558, 'alpha': 8.475883571875416e-05, 'subsample': 0.20618313098141244, 'colsample_bytree': 0.9069972029109558, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.0017654123262773748, 'gamma': 0.39336823231952783, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:55,342]\u001b[0m Trial 32 finished with value: 0.0 and parameters: {'booster': 'gbtree', 'lambda': 1.3519391264034812e-05, 'alpha': 0.010412145742995118, 'subsample': 0.49117571554622524, 'colsample_bytree': 0.6196345804840895, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.023239723569809096, 'gamma': 0.10677070096923745, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:55,449]\u001b[0m Trial 33 finished with value: 0.0 and parameters: {'booster': 'gbtree', 'lambda': 0.0002385341573781876, 'alpha': 0.010849245283359225, 'subsample': 0.2912475882555799, 'colsample_bytree': 0.6934890178972275, 'max_depth': 5, 'min_child_weight': 7, 'eta': 7.500916867557097e-06, 'gamma': 4.265400752987645e-08, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:55,556]\u001b[0m Trial 34 finished with value: 0.0 and parameters: {'booster': 'gbtree', 'lambda': 0.007138647943302207, 'alpha': 6.520270819921869e-05, 'subsample': 0.20446538894300764, 'colsample_bytree': 0.8218683397266804, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.0019163016187691865, 'gamma': 1.6648889689557913e-06, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:55,824]\u001b[0m Trial 35 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 0.23415789760253303, 'alpha': 5.1081051106465356e-06, 'subsample': 0.5731204583342748, 'colsample_bytree': 0.41358793828357493, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.00020542223636495238, 'gamma': 5.8181415487322335e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 4.160571883434679e-05, 'skip_drop': 0.048393392841583796}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:56,095]\u001b[0m Trial 36 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 0.3108421237898822, 'alpha': 0.25236880923751537, 'subsample': 0.39267229469765075, 'colsample_bytree': 0.573757877778079, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.12807235212708762, 'gamma': 0.00028373121855218737, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.0008127417396332495, 'skip_drop': 0.07174017902802586}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:56,365]\u001b[0m Trial 37 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 5.027862170749626e-07, 'alpha': 0.0011699603893979946, 'subsample': 0.5382614087217078, 'colsample_bytree': 0.7359392877560624, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.8757626762652343, 'gamma': 9.549732204203665e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 3.2148080592483615e-07, 'skip_drop': 0.0003427859006585351}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 16:55:56,447]\u001b[0m Trial 38 finished with value: 0.0 and parameters: {'booster': 'gblinear', 'lambda': 2.683636321717057e-07, 'alpha': 0.2444379698109332, 'subsample': 0.5538440137295264, 'colsample_bytree': 0.8123553258964702}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:56,736]\u001b[0m Trial 39 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 3.389557152367568e-07, 'alpha': 0.0004989948444814661, 'subsample': 0.3373236115923286, 'colsample_bytree': 0.7362994301199527, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.7644651137763824, 'gamma': 9.485175468615757e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 3.5608045057433687e-07, 'skip_drop': 0.0002806555860063997}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:56,814]\u001b[0m Trial 40 finished with value: 0.0 and parameters: {'booster': 'gblinear', 'lambda': 3.0020872344107656e-07, 'alpha': 0.00029108752803911004, 'subsample': 0.33818816248073474, 'colsample_bytree': 0.9190837047778175}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:57,084]\u001b[0m Trial 41 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 7.834977378925476e-07, 'alpha': 0.0005608643844823596, 'subsample': 0.37945866230395126, 'colsample_bytree': 0.6953697163904167, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.9183990713781812, 'gamma': 8.590915663545439e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 2.4078861236229724e-07, 'skip_drop': 0.00019186023593216247}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:57,354]\u001b[0m Trial 42 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 8.090139491459028e-07, 'alpha': 0.0006764904695826822, 'subsample': 0.33447598537181367, 'colsample_bytree': 0.7050050554440475, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.7423527023806222, 'gamma': 6.723126641271139e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 3.5843420296800324e-07, 'skip_drop': 0.00019923831725138566}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:57,737]\u001b[0m Trial 43 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 6.853889468918536e-06, 'alpha': 0.0022188133486644545, 'subsample': 0.6536938493127755, 'colsample_bytree': 0.6521304066491385, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.7803181650622903, 'gamma': 4.843414495794452e-07, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 4.0951785297265934e-07, 'skip_drop': 0.00011968122436691568}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:58,077]\u001b[0m Trial 44 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 8.565763191951993e-06, 'alpha': 0.0024420390212682164, 'subsample': 0.7537774307781895, 'colsample_bytree': 0.6542104197561117, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.8240262301377336, 'gamma': 6.481585493059481e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 4.332288732835704e-07, 'skip_drop': 0.0001011562820188757}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:58,374]\u001b[0m Trial 45 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 8.150902588302375e-06, 'alpha': 0.002091428672504413, 'subsample': 0.6708214609639952, 'colsample_bytree': 0.7749967240863956, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.2785218512724694, 'gamma': 6.653756832177674e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 2.39106308325795e-07, 'skip_drop': 9.569626571323497e-05}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:58,675]\u001b[0m Trial 46 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 1.940069802810898e-05, 'alpha': 0.0030479137055993313, 'subsample': 0.830491184259814, 'colsample_bytree': 0.7890619763463128, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.22888252396803563, 'gamma': 4.432347906005109e-07, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.0231694043618647e-06, 'skip_drop': 6.0400755116147946e-05}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:58,972]\u001b[0m Trial 47 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 5.324952918475649e-06, 'alpha': 0.00022600825832260035, 'subsample': 0.6695870860500502, 'colsample_bytree': 0.6471224747863537, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.1155366006152982, 'gamma': 5.538706771287786e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.0800817940018034e-07, 'skip_drop': 5.160628113244238e-05}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:59,264]\u001b[0m Trial 48 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 8.046197073443936e-06, 'alpha': 0.00016284332135545554, 'subsample': 0.6789452082365114, 'colsample_bytree': 0.643150458903577, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.10074602674677265, 'gamma': 5.868811312219913e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 5.333650237213776e-08, 'skip_drop': 4.442636317608369e-05}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:59,539]\u001b[0m Trial 49 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 5.691648389072688e-06, 'alpha': 0.0020298040399606945, 'subsample': 0.7349744866922678, 'colsample_bytree': 0.5976001228224737, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.27468352153014647, 'gamma': 2.8236523015692023e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 9.942522137668656e-08, 'skip_drop': 2.990044232319674e-06}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:55:59,823]\u001b[0m Trial 50 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 9.716738308988573e-08, 'alpha': 0.019424609832205706, 'subsample': 0.6531197935607725, 'colsample_bytree': 0.7216636141555124, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.08989642820686494, 'gamma': 4.3690364356973875e-07, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.0763213829997872e-08, 'skip_drop': 0.0009315951622439829}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:00,117]\u001b[0m Trial 51 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 5.408931410025159e-08, 'alpha': 0.006483329355139886, 'subsample': 0.638243856700885, 'colsample_bytree': 0.7205799705965503, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.47394943580580895, 'gamma': 1.1251683162927639e-07, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.1227540199891119e-08, 'skip_drop': 0.0005686533253695986}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:00,407]\u001b[0m Trial 52 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 7.63047887101556e-08, 'alpha': 0.0063030990551766804, 'subsample': 0.5262448262854929, 'colsample_bytree': 0.7397598045857338, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.45674458758517983, 'gamma': 1.406668976290432e-07, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.1158569155585368e-06, 'skip_drop': 0.0004494700160785763}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:00,704]\u001b[0m Trial 53 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 8.240795409519462e-07, 'alpha': 0.0019253386141899302, 'subsample': 0.8111608472920964, 'colsample_bytree': 0.7637117254294253, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.3362844123915726, 'gamma': 3.339432949419078e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 3.0648553331341975e-07, 'skip_drop': 0.0001236318708993838}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 16:56:01,002]\u001b[0m Trial 54 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 9.51966050786122e-08, 'alpha': 0.014708618412027707, 'subsample': 0.6509901029283156, 'colsample_bytree': 0.8122128402720098, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.0835419410198835, 'gamma': 2.9516805107182047e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.0810052104491214e-08, 'skip_drop': 0.0019493240450450526}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:01,305]\u001b[0m Trial 55 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 3.327959952816526e-05, 'alpha': 0.0003065291183731028, 'subsample': 0.5842601237433023, 'colsample_bytree': 0.6580333578810758, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.06385540847730152, 'gamma': 1.0693226916993145e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.410998396696441e-05, 'skip_drop': 2.7420359593931517e-05}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:01,728]\u001b[0m Trial 56 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 3.4067955465814397e-06, 'alpha': 0.0009758956451037475, 'subsample': 0.5956803732431759, 'colsample_bytree': 0.6631057065538026, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.013213133569659991, 'gamma': 1.0529496127208887e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 5.971567959133022e-06, 'skip_drop': 2.7632362034743244e-05}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:02,054]\u001b[0m Trial 57 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 0.00011854857814177061, 'alpha': 0.0004023129498305112, 'subsample': 0.7352642601397581, 'colsample_bytree': 0.59909332682073, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.2812714372275063, 'gamma': 3.1014400834153377e-07, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 2.3183406800240755e-05, 'skip_drop': 1.2327567939480888e-06}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:02,354]\u001b[0m Trial 58 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 8.64118027757284e-07, 'alpha': 0.0004073387227922957, 'subsample': 0.8527375056243744, 'colsample_bytree': 0.5935213369869334, 'max_depth': 9, 'min_child_weight': 3, 'eta': 2.631236002739375e-08, 'gamma': 1.1352625537845033e-07, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 2.173403709287496e-06, 'skip_drop': 2.876063500967296e-07}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:02,438]\u001b[0m Trial 59 finished with value: 0.0 and parameters: {'booster': 'gblinear', 'lambda': 1.3663158691678555e-06, 'alpha': 0.0038332998460482706, 'subsample': 0.7011420149104062, 'colsample_bytree': 0.7756758564440301}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:02,736]\u001b[0m Trial 60 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 4.339597265736961e-06, 'alpha': 0.0012434441143049564, 'subsample': 0.9165991269986091, 'colsample_bytree': 0.5531864653775693, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.16824622957296967, 'gamma': 6.666940554920138e-07, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.6621102993720294e-07, 'skip_drop': 0.000219428108400653}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:03,036]\u001b[0m Trial 61 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 5.16511096145899e-07, 'alpha': 0.00013896905730554043, 'subsample': 0.9438000649789965, 'colsample_bytree': 0.5096120789281012, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.9560420009903041, 'gamma': 8.295089570439823e-07, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.2052152461289424e-07, 'skip_drop': 0.0002674651991139137}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:03,333]\u001b[0m Trial 62 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 4.815984730214217e-07, 'alpha': 0.00012731652126204277, 'subsample': 0.8832301895904955, 'colsample_bytree': 0.5072339802629384, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.8825025778110845, 'gamma': 2.2027860610467182e-07, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 6.492721379628286e-07, 'skip_drop': 0.0002606536983441176}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:03,629]\u001b[0m Trial 63 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 1.7812742744197994e-07, 'alpha': 1.7554819871640723e-05, 'subsample': 0.9684457773079984, 'colsample_bytree': 0.481311709607884, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.5109833762457087, 'gamma': 2.2684240425891343e-07, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 6.551398844315187e-07, 'skip_drop': 0.00011855501178632152}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:03,927]\u001b[0m Trial 64 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 1.775705268750973e-05, 'alpha': 0.0009855176379284887, 'subsample': 0.6735972144541721, 'colsample_bytree': 0.6959128941610444, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.2253534336074458, 'gamma': 6.761692369982393e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 2.1307712242483643e-07, 'skip_drop': 6.955166735758258e-05}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:04,211]\u001b[0m Trial 65 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 4.5480368156597545e-08, 'alpha': 0.030398146772439277, 'subsample': 0.6320252123664167, 'colsample_bytree': 0.7115692857684226, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.014526598822362936, 'gamma': 2.1138662213937182e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 2.0040138646422846e-08, 'skip_drop': 0.0011150998978545403}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:04,593]\u001b[0m Trial 66 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 3.351631427794565e-08, 'alpha': 0.02315188890826591, 'subsample': 0.7615570912855162, 'colsample_bytree': 0.7537418211775205, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.008960060037000568, 'gamma': 2.2600546649385438e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 2.1694460833508227e-06, 'skip_drop': 0.0013235003302040412}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:04,888]\u001b[0m Trial 67 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 4.1832428012636664e-08, 'alpha': 0.004591959459832906, 'subsample': 0.6379201218330469, 'colsample_bytree': 0.7109519390821185, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.06754817641346436, 'gamma': 5.307497846209719e-07, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 2.5250125773599434e-08, 'skip_drop': 0.000878287408533644}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:05,235]\u001b[0m Trial 68 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 1.102325910510559e-07, 'alpha': 0.018643297125838725, 'subsample': 0.6492536712582724, 'colsample_bytree': 0.8197234517662718, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.0677469398682578, 'gamma': 3.6219592624987315e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.564738927342708e-08, 'skip_drop': 1.2262357801037593e-05}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:05,559]\u001b[0m Trial 69 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 1.8363312194442338e-06, 'alpha': 0.0027791969650675465, 'subsample': 0.6048501103944242, 'colsample_bytree': 0.8345851546086551, 'max_depth': 7, 'min_child_weight': 2, 'eta': 2.1963427136823423e-07, 'gamma': 1.0258063086754297e-07, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.21248686106275097, 'skip_drop': 8.591685878295089e-06}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 16:56:05,642]\u001b[0m Trial 70 finished with value: 0.0 and parameters: {'booster': 'gblinear', 'lambda': 2.4463206386272324e-06, 'alpha': 0.002225181327572886, 'subsample': 0.6132488221062231, 'colsample_bytree': 0.9409764233470017}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:05,927]\u001b[0m Trial 71 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 0.00011297358446708915, 'alpha': 0.008428782416957124, 'subsample': 0.5880867699380048, 'colsample_bytree': 0.791720330352792, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.05149341062457311, 'gamma': 1.016467604797941e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.15053814129904644, 'skip_drop': 1.4204068456299302e-05}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:06,317]\u001b[0m Trial 72 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 3.105516951897052e-05, 'alpha': 0.07399828106487714, 'subsample': 0.5724839588262836, 'colsample_bytree': 0.797786433699752, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.055676995286419485, 'gamma': 1.4497609595077733e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.2166304391602349e-08, 'skip_drop': 0.005501339636339816}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:06,639]\u001b[0m Trial 73 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 7.832846391380243e-06, 'alpha': 0.09633086225893679, 'subsample': 0.30520270096558505, 'colsample_bytree': 0.6277141635422075, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.1178168374922723, 'gamma': 4.809035518274766e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 5.1405404150680894e-08, 'skip_drop': 0.004538931044950848}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:06,938]\u001b[0m Trial 74 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 1.4653552132045445e-07, 'alpha': 0.017060690975398377, 'subsample': 0.6696711542089766, 'colsample_bytree': 0.6795846215937695, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.39649159859056443, 'gamma': 3.261121043399526e-07, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 9.426466499372867e-08, 'skip_drop': 0.002657851925368186}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:07,239]\u001b[0m Trial 75 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 6.720866282656178e-08, 'alpha': 0.014486970385809384, 'subsample': 0.6540127791642467, 'colsample_bytree': 0.6435368964950997, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.12816828350728593, 'gamma': 3.434279248843394e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.0342473829685537e-08, 'skip_drop': 0.0008223314144539863}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:07,535]\u001b[0m Trial 76 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 2.1175647995970086e-08, 'alpha': 0.004675160054326094, 'subsample': 0.6960964184476418, 'colsample_bytree': 0.7200205096519833, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.46430551257216224, 'gamma': 1.402913037846568e-07, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 4.3037469038067193e-08, 'skip_drop': 0.0005101401470325695}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:07,838]\u001b[0m Trial 77 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 8.792224199692935e-05, 'alpha': 0.0002656057116416045, 'subsample': 0.719251051131386, 'colsample_bytree': 0.6116091499698598, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.026231800984371965, 'gamma': 3.80861264798894e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 3.430000500994121e-05, 'skip_drop': 9.469114654349276e-07}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:08,127]\u001b[0m Trial 78 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 9.491539560620522e-06, 'alpha': 0.00023315713718375787, 'subsample': 0.7268351560217714, 'colsample_bytree': 0.5751325142190179, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.031210011107626102, 'gamma': 1.143596762590932e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.01056596212279131, 'skip_drop': 0.00011542378080907512}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:08,415]\u001b[0m Trial 79 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 1.1770017013916926e-06, 'alpha': 1.2787322973477244e-08, 'subsample': 0.36216455124889324, 'colsample_bytree': 0.7388069629622676, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.42326973779865185, 'gamma': 2.3442930358630414e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.2832505203826043e-07, 'skip_drop': 2.5024316068852682e-08}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:08,712]\u001b[0m Trial 80 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 2.495548364042643e-07, 'alpha': 4.2730265095186504e-05, 'subsample': 0.5392324343759548, 'colsample_bytree': 0.7241636492171222, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.17918228698682545, 'gamma': 0.0017708383313376477, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 3.200050139694786e-08, 'skip_drop': 0.0003798289590279489}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:09,009]\u001b[0m Trial 81 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 8.445022576070219e-08, 'alpha': 0.006246850110226746, 'subsample': 0.53694027130341, 'colsample_bytree': 0.7637191238526874, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.16153279869920129, 'gamma': 0.005294450261573019, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 2.8177039086315517e-08, 'skip_drop': 0.001756029891749001}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:09,305]\u001b[0m Trial 82 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 2.2707309639218643e-08, 'alpha': 0.0016161496876968774, 'subsample': 0.5020409436771711, 'colsample_bytree': 0.7675024860661529, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.5942050937673002, 'gamma': 0.011763864340422571, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 4.6730925113047e-07, 'skip_drop': 3.59897397101684e-05}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:09,601]\u001b[0m Trial 83 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 1.0523570886535732e-07, 'alpha': 0.006365064172230502, 'subsample': 0.6564374110153501, 'colsample_bytree': 0.6835136866516021, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.09529753435911187, 'gamma': 6.340837087757932e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 6.390794153403793e-08, 'skip_drop': 0.0017905392687390161}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:09,897]\u001b[0m Trial 84 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 2.1295366239846366e-08, 'alpha': 0.0017983794185747783, 'subsample': 0.6246814362158243, 'colsample_bytree': 0.6581337746563111, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.4659905048007191, 'gamma': 0.02014179294770002, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 9.152308239612995e-07, 'skip_drop': 3.789392677684262e-05}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:10,195]\u001b[0m Trial 85 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 3.31303731065416e-05, 'alpha': 0.00011867915421640627, 'subsample': 0.9111954616714815, 'colsample_bytree': 0.5270848227911379, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.23976839775678715, 'gamma': 9.493909133494428e-07, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 2.691940762820166e-05, 'skip_drop': 0.00023402798967793746}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 16:56:10,280]\u001b[0m Trial 86 finished with value: 0.0 and parameters: {'booster': 'gblinear', 'lambda': 4.204970224767965e-07, 'alpha': 0.0006739646198111092, 'subsample': 0.25297199679998644, 'colsample_bytree': 0.8409399588251331}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:10,579]\u001b[0m Trial 87 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 1.4148165076514772e-05, 'alpha': 0.00014238903618769082, 'subsample': 0.9279517344427977, 'colsample_bytree': 0.4427925139287538, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.9252918835183348, 'gamma': 2.672910321942565e-07, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.0004164648514949821, 'skip_drop': 2.674737299890383e-06}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:10,878]\u001b[0m Trial 88 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 4.752385902599969e-06, 'alpha': 0.013836806315533015, 'subsample': 0.7522835067416138, 'colsample_bytree': 0.667938241445679, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.08450865250869714, 'gamma': 1.9151117782977025e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.00011573281359760186, 'skip_drop': 1.8503068798660297e-05}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:11,176]\u001b[0m Trial 89 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 0.00018089246164510419, 'alpha': 3.1719019648200634e-05, 'subsample': 0.8993995767320667, 'colsample_bytree': 0.5451865829362356, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.0156253167368215, 'gamma': 2.177281751269753e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 9.041475930158689e-06, 'skip_drop': 0.01232498677919017}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:11,478]\u001b[0m Trial 90 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 5.192027622935622e-05, 'alpha': 0.0010098827195856891, 'subsample': 0.9888353283126978, 'colsample_bytree': 0.5103509203908714, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.22983360214949108, 'gamma': 2.077686259679654e-07, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.5944649185925284e-05, 'skip_drop': 7.199360389473109e-06}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:11,776]\u001b[0m Trial 91 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 2.2603170982092136e-05, 'alpha': 0.0009593013445189846, 'subsample': 0.9363203128146469, 'colsample_bytree': 0.4854510787914358, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.2785398070680848, 'gamma': 5.740239243845264e-07, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.8045917751276703e-07, 'skip_drop': 0.0002669849086350391}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:12,075]\u001b[0m Trial 92 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 0.0003303864197757599, 'alpha': 0.0003496026008477389, 'subsample': 0.7945621319753875, 'colsample_bytree': 0.6507660111271732, 'max_depth': 9, 'min_child_weight': 2, 'eta': 1.0001797373874792e-08, 'gamma': 3.1874173357843466e-07, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 3.6596677079433505e-06, 'skip_drop': 7.90942452517334e-05}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:12,376]\u001b[0m Trial 93 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 1.109137555434472e-08, 'alpha': 0.030075660230888052, 'subsample': 0.957089161044199, 'colsample_bytree': 0.5236679232446769, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.039790071721893736, 'gamma': 1.6936764505616622e-07, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.2919923793971632e-08, 'skip_drop': 0.0004884624876769711}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:12,778]\u001b[0m Trial 94 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 5.607675784354731e-07, 'alpha': 9.962704420456385e-05, 'subsample': 0.9556322993806711, 'colsample_bytree': 0.46038960391099204, 'max_depth': 7, 'min_child_weight': 2, 'eta': 2.6900405818910806e-06, 'gamma': 1.1530961256818026e-07, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.005035521696489067, 'skip_drop': 0.0005127707631814519}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:13,232]\u001b[0m Trial 95 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 3.066313711044287e-06, 'alpha': 0.04945980200497476, 'subsample': 0.6883497552830219, 'colsample_bytree': 0.626516194075763, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.039552785820681294, 'gamma': 6.84094333561526e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.01919583910973e-08, 'skip_drop': 0.00013609039908994635}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:13,567]\u001b[0m Trial 96 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 1.4263119784991856e-06, 'alpha': 8.979976930375698e-05, 'subsample': 0.4596090703761694, 'colsample_bytree': 0.7009107387914786, 'max_depth': 7, 'min_child_weight': 3, 'eta': 1.6271216458287698e-06, 'gamma': 8.522996691417702e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.00012285550502719105, 'skip_drop': 2.440046620430301e-05}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:13,839]\u001b[0m Trial 97 finished with value: 0.3333333333333333 and parameters: {'booster': 'dart', 'lambda': 0.0001445509297354897, 'alpha': 0.003153853625662846, 'subsample': 0.6047938615888673, 'colsample_bytree': 0.7910459248429781, 'max_depth': 9, 'min_child_weight': 2, 'eta': 4.554066675117101e-07, 'gamma': 3.633124328675951e-07, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.1748820123875673, 'skip_drop': 0.00516993892305688}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:14,109]\u001b[0m Trial 98 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 0.0007395688559194876, 'alpha': 0.01233893361764212, 'subsample': 0.5650568064732133, 'colsample_bytree': 0.8042245384519214, 'max_depth': 7, 'min_child_weight': 2, 'eta': 1.0381140860198864e-07, 'gamma': 3.9950392684979335e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.20529932612589613, 'skip_drop': 0.003967124558599598}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:14,399]\u001b[0m Trial 99 finished with value: 0.0 and parameters: {'booster': 'dart', 'lambda': 4.3721030500126534e-07, 'alpha': 0.0012406367090256843, 'subsample': 0.5893137104225329, 'colsample_bytree': 0.8296052123095798, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.007195160211226869, 'gamma': 1.1450865595683207e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.08161813163980206, 'skip_drop': 1.0585721569005536e-05}. Best is trial 37 with value: 0.3333333333333333.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 16:56:15,077]\u001b[0m A new study created in memory with name: no-name-39b41d3f-8e06-4c01-a582-efc5423988c0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 16:56:15,736]\u001b[0m Trial 0 finished with value: 0.6914285714285714 and parameters: {'booster': 'dart', 'lambda': 1.4546985163688167e-08, 'alpha': 3.2114290978502045e-06, 'subsample': 0.8688410033798346, 'colsample_bytree': 0.994028649416052, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.006041452179895356, 'gamma': 9.950194539070575e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 4.073245606471316e-07, 'skip_drop': 0.017969327525501563}. Best is trial 0 with value: 0.6914285714285714.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:16,386]\u001b[0m Trial 1 finished with value: 0.6914285714285714 and parameters: {'booster': 'dart', 'lambda': 1.2393681778515237e-06, 'alpha': 7.352367337649142e-06, 'subsample': 0.9897445839458188, 'colsample_bytree': 0.6361709231564476, 'max_depth': 7, 'min_child_weight': 10, 'eta': 1.7614897217952506e-07, 'gamma': 1.5376800941932284e-05, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.0035094433288763833, 'skip_drop': 1.614928556026641e-08}. Best is trial 0 with value: 0.6914285714285714.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:17,109]\u001b[0m Trial 2 finished with value: 0.6914285714285714 and parameters: {'booster': 'dart', 'lambda': 1.469296749076555e-08, 'alpha': 1.1249931522167315e-05, 'subsample': 0.2214984621476891, 'colsample_bytree': 0.36957624643886566, 'max_depth': 9, 'min_child_weight': 4, 'eta': 7.955996390733466e-05, 'gamma': 1.4128106823627522e-07, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.13518139256543935, 'skip_drop': 0.001291862405433808}. Best is trial 0 with value: 0.6914285714285714.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:17,764]\u001b[0m Trial 3 finished with value: 0.6914285714285714 and parameters: {'booster': 'dart', 'lambda': 0.3994629742353655, 'alpha': 2.64487947847347e-07, 'subsample': 0.423336819726932, 'colsample_bytree': 0.3178570487229096, 'max_depth': 9, 'min_child_weight': 2, 'eta': 2.6712803847806393e-08, 'gamma': 2.236915317466633e-07, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.2593271665550389e-08, 'skip_drop': 2.0427432500857545e-05}. Best is trial 0 with value: 0.6914285714285714.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:17,841]\u001b[0m Trial 4 finished with value: 0.7202380952380951 and parameters: {'booster': 'gblinear', 'lambda': 0.13037474859560896, 'alpha': 0.0031094066647642674, 'subsample': 0.21935202697700698, 'colsample_bytree': 0.5759552637059531}. Best is trial 4 with value: 0.7202380952380951.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:17,917]\u001b[0m Trial 5 finished with value: 0.6914285714285714 and parameters: {'booster': 'gblinear', 'lambda': 0.03655363977247536, 'alpha': 0.00028914765578813627, 'subsample': 0.8154569809498387, 'colsample_bytree': 0.8036182135281482}. Best is trial 4 with value: 0.7202380952380951.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:18,021]\u001b[0m Trial 6 finished with value: 0.6914285714285714 and parameters: {'booster': 'gbtree', 'lambda': 9.792904226726664e-07, 'alpha': 4.902722967872588e-06, 'subsample': 0.9450758669481032, 'colsample_bytree': 0.9755783070127568, 'max_depth': 3, 'min_child_weight': 5, 'eta': 4.6905750850553635e-06, 'gamma': 0.08092825489721128, 'grow_policy': 'lossguide'}. Best is trial 4 with value: 0.7202380952380951.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:18,689]\u001b[0m Trial 7 finished with value: 0.6914285714285714 and parameters: {'booster': 'dart', 'lambda': 1.9877073255722352e-07, 'alpha': 3.720281546557977e-08, 'subsample': 0.7166464681589562, 'colsample_bytree': 0.32962483687615596, 'max_depth': 9, 'min_child_weight': 9, 'eta': 1.0821163906660393e-06, 'gamma': 3.3550844566441416e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 6.516137195297591e-05, 'skip_drop': 6.177512188954546e-06}. Best is trial 4 with value: 0.7202380952380951.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:18,783]\u001b[0m Trial 8 finished with value: 0.6914285714285714 and parameters: {'booster': 'gbtree', 'lambda': 1.0370810338315805e-08, 'alpha': 3.01612653633142e-06, 'subsample': 0.8110727154359691, 'colsample_bytree': 0.9535009910512848, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.008369927365157582, 'gamma': 6.335405927095365e-05, 'grow_policy': 'lossguide'}. Best is trial 4 with value: 0.7202380952380951.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:19,448]\u001b[0m Trial 9 finished with value: 0.6914285714285714 and parameters: {'booster': 'dart', 'lambda': 1.1367412049820105e-07, 'alpha': 2.506145611001469e-06, 'subsample': 0.592978805365975, 'colsample_bytree': 0.6900805358961112, 'max_depth': 3, 'min_child_weight': 10, 'eta': 0.0610831731203768, 'gamma': 0.0006134062650210952, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.0004435462004318176, 'skip_drop': 2.600868018969196e-06}. Best is trial 4 with value: 0.7202380952380951.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:19,533]\u001b[0m Trial 10 finished with value: 0.7202380952380951 and parameters: {'booster': 'gblinear', 'lambda': 0.0011451385714025956, 'alpha': 0.09602931545981525, 'subsample': 0.20664557763575275, 'colsample_bytree': 0.48525888746625845}. Best is trial 4 with value: 0.7202380952380951.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:19,618]\u001b[0m Trial 11 finished with value: 0.7202380952380951 and parameters: {'booster': 'gblinear', 'lambda': 0.0010548425987412856, 'alpha': 0.10988184858392994, 'subsample': 0.22238897099280963, 'colsample_bytree': 0.4891860757093359}. Best is trial 4 with value: 0.7202380952380951.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:19,705]\u001b[0m Trial 12 finished with value: 0.7202380952380951 and parameters: {'booster': 'gblinear', 'lambda': 0.0009549134278565813, 'alpha': 0.05792242009474432, 'subsample': 0.37523604197498583, 'colsample_bytree': 0.517028255657075}. Best is trial 4 with value: 0.7202380952380951.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:19,794]\u001b[0m Trial 13 finished with value: 0.7202380952380951 and parameters: {'booster': 'gblinear', 'lambda': 0.021153089656819005, 'alpha': 0.003960764300047429, 'subsample': 0.3704356214271337, 'colsample_bytree': 0.493878888263239}. Best is trial 4 with value: 0.7202380952380951.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:19,876]\u001b[0m Trial 14 finished with value: 0.6914285714285714 and parameters: {'booster': 'gblinear', 'lambda': 9.138351472726785e-05, 'alpha': 0.6817730337598518, 'subsample': 0.502557245709135, 'colsample_bytree': 0.7442955477841966}. Best is trial 4 with value: 0.7202380952380951.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:19,966]\u001b[0m Trial 15 finished with value: 0.6914285714285714 and parameters: {'booster': 'gblinear', 'lambda': 0.5890611207657482, 'alpha': 0.002070642376390888, 'subsample': 0.2896126292867349, 'colsample_bytree': 0.2251387010989097}. Best is trial 4 with value: 0.7202380952380951.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:20,055]\u001b[0m Trial 16 finished with value: 0.7202380952380951 and parameters: {'booster': 'gblinear', 'lambda': 0.000333797914365608, 'alpha': 0.0069049054597807545, 'subsample': 0.5280847515265435, 'colsample_bytree': 0.5856253939899178}. Best is trial 4 with value: 0.7202380952380951.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:20,143]\u001b[0m Trial 17 finished with value: 0.7202380952380951 and parameters: {'booster': 'gblinear', 'lambda': 4.68752064686204e-05, 'alpha': 0.003737036448648189, 'subsample': 0.5428668349471286, 'colsample_bytree': 0.40649710490044005}. Best is trial 4 with value: 0.7202380952380951.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:20,263]\u001b[0m Trial 18 finished with value: 0.6914285714285714 and parameters: {'booster': 'gbtree', 'lambda': 1.5395315841777663e-05, 'alpha': 0.0001717718986060538, 'subsample': 0.659879607122217, 'colsample_bytree': 0.41291490690039034, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.9274323405501248, 'gamma': 0.43842428682815937, 'grow_policy': 'depthwise'}. Best is trial 4 with value: 0.7202380952380951.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:20,354]\u001b[0m Trial 19 finished with value: 0.7202380952380951 and parameters: {'booster': 'gblinear', 'lambda': 0.021947614030037782, 'alpha': 0.000832963842450089, 'subsample': 0.47366396298468116, 'colsample_bytree': 0.586459079275238}. Best is trial 4 with value: 0.7202380952380951.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 16:56:20,444]\u001b[0m Trial 20 finished with value: 0.6914285714285714 and parameters: {'booster': 'gblinear', 'lambda': 0.007824905526211097, 'alpha': 6.738494933043843e-05, 'subsample': 0.516443827460911, 'colsample_bytree': 0.2341333315017587}. Best is trial 4 with value: 0.7202380952380951.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:20,528]\u001b[0m Trial 21 finished with value: 0.7202380952380951 and parameters: {'booster': 'gblinear', 'lambda': 4.428855839059668e-05, 'alpha': 0.027180425131569135, 'subsample': 0.5767625304930123, 'colsample_bytree': 0.42877714027784214}. Best is trial 4 with value: 0.7202380952380951.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:20,612]\u001b[0m Trial 22 finished with value: 0.6914285714285714 and parameters: {'booster': 'gblinear', 'lambda': 0.00411139840120983, 'alpha': 0.5041868297967697, 'subsample': 0.43777391174031566, 'colsample_bytree': 0.5328950296336525}. Best is trial 4 with value: 0.7202380952380951.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:20,703]\u001b[0m Trial 23 finished with value: 0.6914285714285714 and parameters: {'booster': 'gblinear', 'lambda': 0.13065724903628806, 'alpha': 0.0006873894111164654, 'subsample': 0.30100089247495454, 'colsample_bytree': 0.6109354765969203}. Best is trial 4 with value: 0.7202380952380951.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:20,791]\u001b[0m Trial 24 finished with value: 0.7202380952380951 and parameters: {'booster': 'gblinear', 'lambda': 9.164532094733873e-06, 'alpha': 0.012062007426346909, 'subsample': 0.6401138491519883, 'colsample_bytree': 0.44329862078359417}. Best is trial 4 with value: 0.7202380952380951.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:20,915]\u001b[0m Trial 25 finished with value: 0.6914285714285714 and parameters: {'booster': 'gbtree', 'lambda': 0.0005417728814051672, 'alpha': 0.03295853985175012, 'subsample': 0.43711358832785574, 'colsample_bytree': 0.7667239753950008, 'max_depth': 5, 'min_child_weight': 2, 'eta': 6.438671268872965e-05, 'gamma': 1.126201630679682e-08, 'grow_policy': 'depthwise'}. Best is trial 4 with value: 0.7202380952380951.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:21,005]\u001b[0m Trial 26 finished with value: 0.7202380952380951 and parameters: {'booster': 'gblinear', 'lambda': 8.871492784036474e-06, 'alpha': 0.03540194515538225, 'subsample': 0.33474519784556245, 'colsample_bytree': 0.5323275264507364}. Best is trial 4 with value: 0.7202380952380951.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:21,090]\u001b[0m Trial 27 finished with value: 0.7202380952380951 and parameters: {'booster': 'gblinear', 'lambda': 5.4272345952683304e-06, 'alpha': 0.01906119776608174, 'subsample': 0.6872252413053681, 'colsample_bytree': 0.4264837507200065}. Best is trial 4 with value: 0.7202380952380951.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:21,177]\u001b[0m Trial 28 finished with value: 0.7202380952380951 and parameters: {'booster': 'gblinear', 'lambda': 4.100504651742809e-05, 'alpha': 0.008474649143008526, 'subsample': 0.6043621413701654, 'colsample_bytree': 0.2780951366914022}. Best is trial 4 with value: 0.7202380952380951.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:21,297]\u001b[0m Trial 29 finished with value: 0.009523809523809523 and parameters: {'booster': 'gbtree', 'lambda': 1.2666846813780163e-06, 'alpha': 3.252167929149245e-05, 'subsample': 0.7222850231705755, 'colsample_bytree': 0.3212832213785403, 'max_depth': 7, 'min_child_weight': 7, 'eta': 1.3164858586443494e-08, 'gamma': 0.007111774227006385, 'grow_policy': 'depthwise'}. Best is trial 4 with value: 0.7202380952380951.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:21,387]\u001b[0m Trial 30 finished with value: 0.7202380952380951 and parameters: {'booster': 'gblinear', 'lambda': 3.715320887159409e-05, 'alpha': 0.0006230166841301597, 'subsample': 0.616787705963751, 'colsample_bytree': 0.2951789695342286}. Best is trial 4 with value: 0.7202380952380951.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:21,474]\u001b[0m Trial 31 finished with value: 0.7202380952380951 and parameters: {'booster': 'gblinear', 'lambda': 0.009796036493295645, 'alpha': 0.0008213997356046658, 'subsample': 0.36477461816016693, 'colsample_bytree': 0.6602149569538649}. Best is trial 4 with value: 0.7202380952380951.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:21,566]\u001b[0m Trial 32 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 0.004077506328321876, 'alpha': 0.0003596263473409766, 'subsample': 0.42301842743796464, 'colsample_bytree': 0.668242691206224}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:21,656]\u001b[0m Trial 33 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 3.4787942223766307e-06, 'alpha': 2.5509400805674863e-05, 'subsample': 0.661933261720397, 'colsample_bytree': 0.2562228888913753}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:22,460]\u001b[0m Trial 34 finished with value: 0.6914285714285714 and parameters: {'booster': 'dart', 'lambda': 0.002485814418732995, 'alpha': 4.1886049122258865e-05, 'subsample': 0.7764927892291268, 'colsample_bytree': 0.6703241796353929, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.0005871417263098908, 'gamma': 1.2255561059440784e-06, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.720856976290988, 'skip_drop': 0.9220725228625957}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:22,575]\u001b[0m Trial 35 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 0.0003296001992807736, 'alpha': 7.423953086206162e-07, 'subsample': 0.5378147553476064, 'colsample_bytree': 0.36756933661164565}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:22,664]\u001b[0m Trial 36 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 0.00021874292313897657, 'alpha': 1.1404704292639588e-07, 'subsample': 0.40169130475105475, 'colsample_bytree': 0.8726883619837751}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:23,358]\u001b[0m Trial 37 finished with value: 0.6914285714285714 and parameters: {'booster': 'dart', 'lambda': 0.0002390072028383535, 'alpha': 4.653388762102655e-07, 'subsample': 0.4587775249739239, 'colsample_bytree': 0.8652718300256965, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.6763819089113882, 'gamma': 0.0031516859083610426, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 4.3468098033284494e-06, 'skip_drop': 4.899317781709049e-08}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:23,450]\u001b[0m Trial 38 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 0.0001243666314925134, 'alpha': 1.9182755403144675e-08, 'subsample': 0.39815230335826224, 'colsample_bytree': 0.8875281132901225}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:23,540]\u001b[0m Trial 39 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 0.00016253254195993955, 'alpha': 1.125520590395848e-08, 'subsample': 0.54998842961682, 'colsample_bytree': 0.9009408478957095}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:24,290]\u001b[0m Trial 40 finished with value: 0.6914285714285714 and parameters: {'booster': 'dart', 'lambda': 2.6246940789213156e-06, 'alpha': 1.4383118194260816e-07, 'subsample': 0.5549162993132049, 'colsample_bytree': 0.9317688158036772, 'max_depth': 7, 'min_child_weight': 3, 'eta': 6.427339366357004e-06, 'gamma': 0.8013269722944342, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.010978681859316814, 'skip_drop': 0.7690363014509807}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:24,442]\u001b[0m Trial 41 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 0.00014533875170842544, 'alpha': 1.1043892587033398e-08, 'subsample': 0.47887963141686807, 'colsample_bytree': 0.8801338492358243}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:24,532]\u001b[0m Trial 42 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 0.00016272969924128618, 'alpha': 1.0483694945579194e-08, 'subsample': 0.48321806298862585, 'colsample_bytree': 0.889760759789136}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 16:56:24,622]\u001b[0m Trial 43 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 0.0001343391784418524, 'alpha': 1.0048826643236839e-08, 'subsample': 0.40489747790478264, 'colsample_bytree': 0.8478938669692851}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:24,710]\u001b[0m Trial 44 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 0.00011568398322807594, 'alpha': 1.2134339930129295e-08, 'subsample': 0.3941379064353991, 'colsample_bytree': 0.8311628012068852}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:24,837]\u001b[0m Trial 45 finished with value: 0.6914285714285714 and parameters: {'booster': 'gbtree', 'lambda': 5.059091985652196e-07, 'alpha': 1.1623815927312433e-06, 'subsample': 0.9126302744807887, 'colsample_bytree': 0.8229236461923314, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.0012476930341675698, 'gamma': 2.2414257627821345e-06, 'grow_policy': 'depthwise'}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:24,927]\u001b[0m Trial 46 finished with value: 0.6914285714285714 and parameters: {'booster': 'gblinear', 'lambda': 0.0017107780630134155, 'alpha': 5.60071294178759e-08, 'subsample': 0.489538374338103, 'colsample_bytree': 0.7107661353160851}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:25,015]\u001b[0m Trial 47 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 7.318609877141837e-08, 'alpha': 1.1661309387014577e-05, 'subsample': 0.7507354778414871, 'colsample_bytree': 0.9994697612957572}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:25,105]\u001b[0m Trial 48 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 3.355984879066496e-08, 'alpha': 1.5873469910105855e-05, 'subsample': 0.7711157567833676, 'colsample_bytree': 0.9860146787320107}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:25,803]\u001b[0m Trial 49 finished with value: 0.6914285714285714 and parameters: {'booster': 'dart', 'lambda': 3.878312312426089e-08, 'alpha': 1.3869554827673025e-06, 'subsample': 0.8722662601727555, 'colsample_bytree': 0.9968746171282086, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.08957704255147222, 'gamma': 0.0269555126663161, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.1123767746144584e-08, 'skip_drop': 0.0008640900491453362}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:25,892]\u001b[0m Trial 50 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 4.031569499660634e-07, 'alpha': 9.683260751802515e-06, 'subsample': 0.8179702548955279, 'colsample_bytree': 0.9227775168312811}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:25,984]\u001b[0m Trial 51 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 0.0004558205009172553, 'alpha': 4.2290625342359184e-08, 'subsample': 0.5604328619160477, 'colsample_bytree': 0.9218370482329263}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:26,074]\u001b[0m Trial 52 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 0.0008779233404146215, 'alpha': 5.665837054964914e-08, 'subsample': 0.5678130680277443, 'colsample_bytree': 0.927863461004787}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:26,166]\u001b[0m Trial 53 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 0.0006028188539317789, 'alpha': 3.6530683920406613e-08, 'subsample': 0.6536893886070484, 'colsample_bytree': 0.35333612356271676}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:26,260]\u001b[0m Trial 54 finished with value: 0.6914285714285714 and parameters: {'booster': 'gblinear', 'lambda': 0.004447412499250007, 'alpha': 1.6341678196471239e-07, 'subsample': 0.6332660506362094, 'colsample_bytree': 0.34483770805534114}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:26,348]\u001b[0m Trial 55 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 8.042256305025794e-05, 'alpha': 1.9724014588783222e-08, 'subsample': 0.3893423777162607, 'colsample_bytree': 0.8254223978173071}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:26,440]\u001b[0m Trial 56 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 2.7128649926627417e-05, 'alpha': 5.117238493333252e-07, 'subsample': 0.2545547643467483, 'colsample_bytree': 0.7791166827840788}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:26,560]\u001b[0m Trial 57 finished with value: 0.6914285714285714 and parameters: {'booster': 'gbtree', 'lambda': 2.6025970459080073e-05, 'alpha': 6.383161420094804e-07, 'subsample': 0.2481064385539768, 'colsample_bytree': 0.7880457357435694, 'max_depth': 5, 'min_child_weight': 5, 'eta': 2.4389730440496716e-07, 'gamma': 2.0413114863440447e-08, 'grow_policy': 'lossguide'}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:26,650]\u001b[0m Trial 58 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 1.8308984661838423e-05, 'alpha': 3.0527134307557835e-07, 'subsample': 0.33676400352358304, 'colsample_bytree': 0.9580135101349213}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:26,741]\u001b[0m Trial 59 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 3.83636493441026e-06, 'alpha': 1.6026624847336152e-07, 'subsample': 0.31916000295377384, 'colsample_bytree': 0.7442612063773526}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:26,832]\u001b[0m Trial 60 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 4.373299481254223e-06, 'alpha': 8.633983565567426e-08, 'subsample': 0.4609788375669123, 'colsample_bytree': 0.20478962476054308}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:26,924]\u001b[0m Trial 61 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 3.3850228584751125e-06, 'alpha': 1.0700588532362313e-07, 'subsample': 0.3499320572645793, 'colsample_bytree': 0.20185281152853948}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:27,014]\u001b[0m Trial 62 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 1.0687519271473755e-06, 'alpha': 2.95208925606698e-06, 'subsample': 0.5156167914800152, 'colsample_bytree': 0.2122730532362161}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:27,106]\u001b[0m Trial 63 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 1.8380703618187408e-06, 'alpha': 3.406175067069618e-06, 'subsample': 0.4194474447225338, 'colsample_bytree': 0.25716236113377455}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:27,197]\u001b[0m Trial 64 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 1.5811468752846104e-06, 'alpha': 3.4649093255321517e-06, 'subsample': 0.4217534026389686, 'colsample_bytree': 0.26005394111188573}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:27,288]\u001b[0m Trial 65 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 0.000270931087956919, 'alpha': 2.7026323963524952e-08, 'subsample': 0.48608649326139497, 'colsample_bytree': 0.8940049388906774}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:27,381]\u001b[0m Trial 66 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 0.00018743747277276073, 'alpha': 1.5444056793064637e-08, 'subsample': 0.45009349957204237, 'colsample_bytree': 0.8846980346399095}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:27,473]\u001b[0m Trial 67 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 0.00011800144744953037, 'alpha': 2.754775249904196e-08, 'subsample': 0.5905831682757137, 'colsample_bytree': 0.8884112395877459}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 16:56:27,599]\u001b[0m Trial 68 finished with value: 0.6914285714285714 and parameters: {'booster': 'gbtree', 'lambda': 8.173974321882688e-05, 'alpha': 2.2346222501019725e-08, 'subsample': 0.5300193970730804, 'colsample_bytree': 0.3932442438138898, 'max_depth': 7, 'min_child_weight': 3, 'eta': 1.4111422800557757e-05, 'gamma': 0.000765338138072159, 'grow_policy': 'depthwise'}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:27,692]\u001b[0m Trial 69 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 0.0006830061005574268, 'alpha': 0.00014088979492057094, 'subsample': 0.6722078506315081, 'colsample_bytree': 0.967768092864773}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:28,411]\u001b[0m Trial 70 finished with value: 0.6914285714285714 and parameters: {'booster': 'dart', 'lambda': 0.000613991759577981, 'alpha': 0.0001822261298295996, 'subsample': 0.677457698765016, 'colsample_bytree': 0.9236951287952357, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.0007564112695071027, 'gamma': 8.640699739410209e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 2.190733397945511e-06, 'skip_drop': 3.834588275190953e-07}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:28,502]\u001b[0m Trial 71 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 0.001060781151627275, 'alpha': 3.227823066758745e-05, 'subsample': 0.7052525237947578, 'colsample_bytree': 0.9722144988127749}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:28,593]\u001b[0m Trial 72 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 0.00013914290906469627, 'alpha': 1.3548756500784053e-08, 'subsample': 0.3913154590058567, 'colsample_bytree': 0.8480036341377143}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:28,686]\u001b[0m Trial 73 finished with value: 0.6914285714285714 and parameters: {'booster': 'gblinear', 'lambda': 0.0014064029839195888, 'alpha': 1.2396758448373821e-08, 'subsample': 0.47944027674173756, 'colsample_bytree': 0.8572068532618294}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:28,778]\u001b[0m Trial 74 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 1.6996648840834278e-08, 'alpha': 1.4886526359255289e-05, 'subsample': 0.2513585148767298, 'colsample_bytree': 0.7116628677139858}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:28,874]\u001b[0m Trial 75 finished with value: 0.7202380952380951 and parameters: {'booster': 'gblinear', 'lambda': 7.012498323534118e-05, 'alpha': 0.00037683121302065135, 'subsample': 0.24272280734548435, 'colsample_bytree': 0.6252892811640542}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:28,966]\u001b[0m Trial 76 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 1.6067813749694267e-05, 'alpha': 6.687160049773661e-08, 'subsample': 0.3152391346820007, 'colsample_bytree': 0.7399884029775223}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:29,057]\u001b[0m Trial 77 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 0.0003270938919315532, 'alpha': 1.2247308475142463e-08, 'subsample': 0.3994348649232905, 'colsample_bytree': 0.8200691272088324}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:29,148]\u001b[0m Trial 78 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 1.0531071950830464e-05, 'alpha': 5.650955357718272e-08, 'subsample': 0.284723518546529, 'colsample_bytree': 0.8390987148869903}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:29,239]\u001b[0m Trial 79 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 0.0001556822803641917, 'alpha': 1.1829401485871618e-08, 'subsample': 0.39499836589940707, 'colsample_bytree': 0.8031021398681158}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:29,330]\u001b[0m Trial 80 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 4.7969756097270854e-05, 'alpha': 1.003903514958773e-08, 'subsample': 0.36157396557317223, 'colsample_bytree': 0.9017167308151862}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:29,421]\u001b[0m Trial 81 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 8.471994564354829e-07, 'alpha': 1.076901054640336e-07, 'subsample': 0.35092651854311396, 'colsample_bytree': 0.20358380647743507}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:29,513]\u001b[0m Trial 82 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 6.302705742168365e-07, 'alpha': 1.785850956242552e-06, 'subsample': 0.5099277331298414, 'colsample_bytree': 0.2480246281510092}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:29,603]\u001b[0m Trial 83 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 2.108083858042433e-05, 'alpha': 2.1625697672772465e-07, 'subsample': 0.5727830496263209, 'colsample_bytree': 0.9391284196710618}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:29,695]\u001b[0m Trial 84 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 6.811540402965285e-06, 'alpha': 2.779695628114919e-07, 'subsample': 0.3217960431753976, 'colsample_bytree': 0.9474285986551304}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:29,787]\u001b[0m Trial 85 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 2.80277606434346e-05, 'alpha': 3.866464825940172e-08, 'subsample': 0.2745235195123151, 'colsample_bytree': 0.9150532634487184}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:29,877]\u001b[0m Trial 86 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 5.293538160799746e-06, 'alpha': 3.1556750451089397e-07, 'subsample': 0.21397217218522685, 'colsample_bytree': 0.7865560148432171}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:30,001]\u001b[0m Trial 87 finished with value: 0.6914285714285714 and parameters: {'booster': 'gbtree', 'lambda': 0.0004460992667276781, 'alpha': 7.000163774537408e-08, 'subsample': 0.30473523579084766, 'colsample_bytree': 0.7487049251606729, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.06791286564759663, 'gamma': 0.000550306241142535, 'grow_policy': 'depthwise'}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:30,717]\u001b[0m Trial 88 finished with value: 0.6914285714285714 and parameters: {'booster': 'dart', 'lambda': 0.00023361195151813495, 'alpha': 0.0014356677977272099, 'subsample': 0.5844102955597308, 'colsample_bytree': 0.8786387513553462, 'max_depth': 7, 'min_child_weight': 5, 'eta': 1.4221205331589293e-07, 'gamma': 0.099967213986678, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 2.609710523485392e-05, 'skip_drop': 0.03308298382836551}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:30,808]\u001b[0m Trial 89 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 0.0022861290480406366, 'alpha': 0.00013427228206507475, 'subsample': 0.4417508939351501, 'colsample_bytree': 0.9699843838531318}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:30,899]\u001b[0m Trial 90 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 4.444460618837821e-06, 'alpha': 4.51638105171468e-07, 'subsample': 0.32708035055367196, 'colsample_bytree': 0.2082813064387003}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:30,990]\u001b[0m Trial 91 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 0.00015088950301964034, 'alpha': 2.0574507486103664e-08, 'subsample': 0.3751335496810529, 'colsample_bytree': 0.8546260584283223}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 16:56:31,083]\u001b[0m Trial 92 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 0.00017781981927878139, 'alpha': 1.9442995175008726e-08, 'subsample': 0.37781303661398885, 'colsample_bytree': 0.8536633452667121}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:31,176]\u001b[0m Trial 93 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 6.518543229311166e-05, 'alpha': 3.233231420981187e-08, 'subsample': 0.5422812190048498, 'colsample_bytree': 0.8661812231479109}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:31,270]\u001b[0m Trial 94 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 5.7474160413596434e-05, 'alpha': 3.690793740416902e-08, 'subsample': 0.5477823035877698, 'colsample_bytree': 0.878001780942688}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:31,475]\u001b[0m Trial 95 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 1.906420455163155e-06, 'alpha': 2.9056965164687913e-06, 'subsample': 0.4208679767332952, 'colsample_bytree': 0.2959071868812233}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:31,588]\u001b[0m Trial 96 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 1.1844148941120658e-07, 'alpha': 4.957012475926347e-06, 'subsample': 0.46296565386266436, 'colsample_bytree': 0.23138911433603454}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:31,681]\u001b[0m Trial 97 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 1.558147381455215e-06, 'alpha': 1.172613903700401e-06, 'subsample': 0.4587362382862398, 'colsample_bytree': 0.26520685966210183}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:31,776]\u001b[0m Trial 98 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 2.717248785639978e-06, 'alpha': 4.320271597585656e-06, 'subsample': 0.5052584073942777, 'colsample_bytree': 0.2963190842515233}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:31,898]\u001b[0m Trial 99 finished with value: 0.7916666666666666 and parameters: {'booster': 'gblinear', 'lambda': 0.00036344727143655436, 'alpha': 1.0415598181139724e-08, 'subsample': 0.3934103941173655, 'colsample_bytree': 0.8349570118201568}. Best is trial 32 with value: 0.7916666666666666.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 16:56:32,196]\u001b[0m A new study created in memory with name: no-name-c2fefec5-96c3-4e9a-88dd-2c1648b1f5e4\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:32,283]\u001b[0m Trial 0 finished with value: 0.9130434782608695 and parameters: {'booster': 'gbtree', 'lambda': 0.00017486598895964404, 'alpha': 3.0805600291708683e-07, 'subsample': 0.8327633488414317, 'colsample_bytree': 0.8601932453005008, 'max_depth': 7, 'min_child_weight': 3, 'eta': 1.0453763721174733e-07, 'gamma': 6.291370147447802e-06, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9130434782608695.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:32,369]\u001b[0m Trial 1 finished with value: 0.8226363008971703 and parameters: {'booster': 'gbtree', 'lambda': 0.12114172683444456, 'alpha': 0.5991187635599439, 'subsample': 0.8232577764686537, 'colsample_bytree': 0.9084758360670806, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.01069341645985473, 'gamma': 0.3573256920100908, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9130434782608695.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:32,441]\u001b[0m Trial 2 finished with value: 0.7834368530020704 and parameters: {'booster': 'gblinear', 'lambda': 1.9203079889154693e-08, 'alpha': 7.260969916681606e-07, 'subsample': 0.5182310570990128, 'colsample_bytree': 0.46358174940121216}. Best is trial 0 with value: 0.9130434782608695.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:32,515]\u001b[0m Trial 3 finished with value: 0.7834368530020704 and parameters: {'booster': 'gblinear', 'lambda': 0.051838444068219566, 'alpha': 0.00011363870605545663, 'subsample': 0.35391351776647373, 'colsample_bytree': 0.4335415732817407}. Best is trial 0 with value: 0.9130434782608695.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:32,597]\u001b[0m Trial 4 finished with value: 0.7809136367488769 and parameters: {'booster': 'gbtree', 'lambda': 0.18415993057098815, 'alpha': 0.0030335821964305033, 'subsample': 0.6870044757666373, 'colsample_bytree': 0.6172023512684244, 'max_depth': 3, 'min_child_weight': 6, 'eta': 1.4413122019705018e-08, 'gamma': 4.138424262973078e-06, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.9130434782608695.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:32,684]\u001b[0m Trial 5 finished with value: 0.8685481820493264 and parameters: {'booster': 'gbtree', 'lambda': 1.0180787227238952e-05, 'alpha': 1.999290020061587e-08, 'subsample': 0.7746776011682004, 'colsample_bytree': 0.5637989068961021, 'max_depth': 9, 'min_child_weight': 3, 'eta': 2.512266956459945e-06, 'gamma': 1.8868452547374746e-08, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.9130434782608695.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:33,054]\u001b[0m Trial 6 finished with value: 0.8648028926713114 and parameters: {'booster': 'dart', 'lambda': 0.47464109883687433, 'alpha': 5.214426995354616e-06, 'subsample': 0.3377361984318503, 'colsample_bytree': 0.44197205527343614, 'max_depth': 5, 'min_child_weight': 2, 'eta': 3.5682558850503665e-08, 'gamma': 1.3429489613486633e-07, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 2.6459427736571315e-06, 'skip_drop': 0.00019143573756679106}. Best is trial 0 with value: 0.9130434782608695.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:33,127]\u001b[0m Trial 7 finished with value: 0.7834368530020704 and parameters: {'booster': 'gblinear', 'lambda': 1.592043532617039e-05, 'alpha': 1.6040460370009122e-08, 'subsample': 0.2867366137878813, 'colsample_bytree': 0.5501889956377162}. Best is trial 0 with value: 0.9130434782608695.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:33,207]\u001b[0m Trial 8 finished with value: 0.4989271597967251 and parameters: {'booster': 'gbtree', 'lambda': 4.413355551073532e-05, 'alpha': 3.359320634704655e-08, 'subsample': 0.560922532721396, 'colsample_bytree': 0.5352190435549247, 'max_depth': 3, 'min_child_weight': 5, 'eta': 4.552041782089218e-05, 'gamma': 0.27065439200082597, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9130434782608695.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:33,574]\u001b[0m Trial 9 finished with value: 0.40821256038647347 and parameters: {'booster': 'dart', 'lambda': 3.3258137583775983e-07, 'alpha': 0.026763080875635326, 'subsample': 0.3181903090253337, 'colsample_bytree': 0.6320644139951701, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.29930220044359274, 'gamma': 0.00015865598952053878, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 5.014903133301936e-07, 'skip_drop': 0.06216364157658524}. Best is trial 0 with value: 0.9130434782608695.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:33,686]\u001b[0m Trial 10 finished with value: 0.40821256038647347 and parameters: {'booster': 'gbtree', 'lambda': 0.0013607570047848153, 'alpha': 3.073969048784785e-06, 'subsample': 0.9788513979265004, 'colsample_bytree': 0.9898616969901081, 'max_depth': 7, 'min_child_weight': 10, 'eta': 1.0245092467821902e-06, 'gamma': 0.00041746969318977626, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9130434782608695.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:33,805]\u001b[0m Trial 11 finished with value: 0.8226363008971703 and parameters: {'booster': 'gbtree', 'lambda': 0.0017594261576531402, 'alpha': 3.1404757202302057e-07, 'subsample': 0.7955355838478932, 'colsample_bytree': 0.21891057407796943, 'max_depth': 9, 'min_child_weight': 2, 'eta': 6.152312185839861e-06, 'gamma': 3.4039851064557835e-08, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.9130434782608695.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 16:56:33,924]\u001b[0m Trial 12 finished with value: 0.913372859025033 and parameters: {'booster': 'gbtree', 'lambda': 1.9451101403615134e-06, 'alpha': 6.446880990307475e-05, 'subsample': 0.9900952758708407, 'colsample_bytree': 0.7599614800847633, 'max_depth': 7, 'min_child_weight': 3, 'eta': 4.5724260617563155e-07, 'gamma': 1.88441562030349e-06, 'grow_policy': 'depthwise'}. Best is trial 12 with value: 0.913372859025033.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:34,043]\u001b[0m Trial 13 finished with value: 1.0 and parameters: {'booster': 'gbtree', 'lambda': 5.089617931464467e-07, 'alpha': 9.583658642239241e-05, 'subsample': 0.9980132539326209, 'colsample_bytree': 0.808002273420866, 'max_depth': 7, 'min_child_weight': 4, 'eta': 2.0015127254734018e-07, 'gamma': 3.755592166190869e-06, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:34,306]\u001b[0m Trial 14 finished with value: 0.40821256038647347 and parameters: {'booster': 'dart', 'lambda': 5.618732291200508e-07, 'alpha': 0.00018346861386041443, 'subsample': 0.9887857352992305, 'colsample_bytree': 0.7657563772677175, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.0007359118637211884, 'gamma': 2.856312098824658e-06, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.8767684164446843, 'skip_drop': 1.2641748701851797e-08}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:34,423]\u001b[0m Trial 15 finished with value: 0.8685481820493264 and parameters: {'booster': 'gbtree', 'lambda': 8.918894797205468e-07, 'alpha': 0.0017331180319150737, 'subsample': 0.9058643546948166, 'colsample_bytree': 0.7421193819032297, 'max_depth': 5, 'min_child_weight': 4, 'eta': 3.924681011061802e-07, 'gamma': 0.0034175796486138076, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:34,536]\u001b[0m Trial 16 finished with value: 0.40821256038647347 and parameters: {'booster': 'gbtree', 'lambda': 1.193663937434768e-08, 'alpha': 1.888053656492458e-05, 'subsample': 0.6630824369543229, 'colsample_bytree': 0.7336877969387705, 'max_depth': 7, 'min_child_weight': 8, 'eta': 5.4184677612422466e-05, 'gamma': 6.846090129629676e-07, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:34,672]\u001b[0m Trial 17 finished with value: 0.8685481820493264 and parameters: {'booster': 'gbtree', 'lambda': 8.832527723097018e-08, 'alpha': 0.002139039565506677, 'subsample': 0.9140834146365414, 'colsample_bytree': 0.849155691705925, 'max_depth': 5, 'min_child_weight': 4, 'eta': 8.769039486952262e-06, 'gamma': 3.6000342637449704e-05, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:35,082]\u001b[0m Trial 18 finished with value: 0.40821256038647347 and parameters: {'booster': 'dart', 'lambda': 2.5713772771662058e-06, 'alpha': 3.2485056418086306e-05, 'subsample': 0.49270597435572117, 'colsample_bytree': 0.6976516226351431, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.0007359057636782099, 'gamma': 0.003818374148446378, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.008012962888784782, 'skip_drop': 1.585220501738746e-08}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:35,174]\u001b[0m Trial 19 finished with value: 0.7834368530020704 and parameters: {'booster': 'gblinear', 'lambda': 0.0003176791492982674, 'alpha': 0.00042563029878604655, 'subsample': 0.6848822245896099, 'colsample_bytree': 0.985889245635553}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:35,287]\u001b[0m Trial 20 finished with value: 0.40821256038647347 and parameters: {'booster': 'gbtree', 'lambda': 1.2728005340193634e-07, 'alpha': 0.0861928251166549, 'subsample': 0.21253921252447905, 'colsample_bytree': 0.8173203455392826, 'max_depth': 5, 'min_child_weight': 4, 'eta': 1.912075428137908e-07, 'gamma': 3.661446914610712e-07, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:35,408]\u001b[0m Trial 21 finished with value: 0.956687370600414 and parameters: {'booster': 'gbtree', 'lambda': 0.00022434056688360458, 'alpha': 3.2943541760936706e-07, 'subsample': 0.8860419490648713, 'colsample_bytree': 0.8560138784265088, 'max_depth': 7, 'min_child_weight': 3, 'eta': 1.426162034952667e-07, 'gamma': 2.1441186699439817e-05, 'grow_policy': 'lossguide'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:35,531]\u001b[0m Trial 22 finished with value: 0.913372859025033 and parameters: {'booster': 'gbtree', 'lambda': 4.303580903448678e-06, 'alpha': 1.3918614748404676e-05, 'subsample': 0.9012791138987452, 'colsample_bytree': 0.9237255482462065, 'max_depth': 7, 'min_child_weight': 3, 'eta': 3.5967234141056916e-07, 'gamma': 2.1991404582781028e-05, 'grow_policy': 'lossguide'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:35,657]\u001b[0m Trial 23 finished with value: 0.913372859025033 and parameters: {'booster': 'gbtree', 'lambda': 0.007906005582893644, 'alpha': 3.371182762457901e-06, 'subsample': 0.9056946402247366, 'colsample_bytree': 0.9165720286450051, 'max_depth': 9, 'min_child_weight': 2, 'eta': 1.2007792557198127e-08, 'gamma': 2.4010571580857137e-05, 'grow_policy': 'lossguide'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:35,781]\u001b[0m Trial 24 finished with value: 0.913372859025033 and parameters: {'booster': 'gbtree', 'lambda': 0.0070934846861590095, 'alpha': 1.6358675224428587e-06, 'subsample': 0.8725023581621295, 'colsample_bytree': 0.9177866078592347, 'max_depth': 9, 'min_child_weight': 2, 'eta': 1.0592039210323638e-08, 'gamma': 0.00114807603343771, 'grow_policy': 'lossguide'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:35,901]\u001b[0m Trial 25 finished with value: 0.7391304347826086 and parameters: {'booster': 'gbtree', 'lambda': 4.473485779212358e-05, 'alpha': 1.01772973144778e-07, 'subsample': 0.9999681758367388, 'colsample_bytree': 0.8066591904077509, 'max_depth': 7, 'min_child_weight': 5, 'eta': 7.993111651393994e-08, 'gamma': 8.353412535857516e-07, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:36,019]\u001b[0m Trial 26 finished with value: 0.8685481820493264 and parameters: {'booster': 'gbtree', 'lambda': 1.0440624596990518e-06, 'alpha': 0.0006867115594999687, 'subsample': 0.7305215664326619, 'colsample_bytree': 0.6718327585130723, 'max_depth': 7, 'min_child_weight': 3, 'eta': 1.7534397486625013e-06, 'gamma': 1.567553442679897e-07, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:36,111]\u001b[0m Trial 27 finished with value: 0.7834368530020704 and parameters: {'booster': 'gblinear', 'lambda': 0.013935160510839708, 'alpha': 1.3153697213683182e-06, 'subsample': 0.8554111432880191, 'colsample_bytree': 0.8845815251159399}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:36,236]\u001b[0m Trial 28 finished with value: 0.8260869565217391 and parameters: {'booster': 'gbtree', 'lambda': 0.0006596921670944211, 'alpha': 1.03227040339296e-07, 'subsample': 0.7563286748137783, 'colsample_bytree': 0.970291896719199, 'max_depth': 9, 'min_child_weight': 2, 'eta': 4.837480412788596e-08, 'gamma': 0.001282754769402662, 'grow_policy': 'lossguide'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:36,664]\u001b[0m Trial 29 finished with value: 0.8685481820493264 and parameters: {'booster': 'dart', 'lambda': 0.00010555010543961822, 'alpha': 2.995920527595745e-07, 'subsample': 0.8524694375616688, 'colsample_bytree': 0.8472500343471908, 'max_depth': 9, 'min_child_weight': 4, 'eta': 1.1535186699815605e-08, 'gamma': 0.04139152444058713, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.0009494645592360278, 'skip_drop': 0.2189664791675361}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:36,792]\u001b[0m Trial 30 finished with value: 0.8226363008971703 and parameters: {'booster': 'gbtree', 'lambda': 0.008061537952594398, 'alpha': 1.1523569633903304e-05, 'subsample': 0.6227194965352789, 'colsample_bytree': 0.8039186159481453, 'max_depth': 9, 'min_child_weight': 2, 'eta': 7.993244169572769e-08, 'gamma': 0.017886138832456506, 'grow_policy': 'lossguide'}. Best is trial 13 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 16:56:36,919]\u001b[0m Trial 31 finished with value: 0.913372859025033 and parameters: {'booster': 'gbtree', 'lambda': 0.016667176660114566, 'alpha': 2.404577462802781e-06, 'subsample': 0.9303940354203076, 'colsample_bytree': 0.9340185115979227, 'max_depth': 9, 'min_child_weight': 2, 'eta': 1.2367579839461207e-08, 'gamma': 1.600110118762412e-05, 'grow_policy': 'lossguide'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:37,042]\u001b[0m Trial 32 finished with value: 0.913372859025033 and parameters: {'booster': 'gbtree', 'lambda': 0.026476232552966383, 'alpha': 8.462977813438515e-07, 'subsample': 0.9310534657718958, 'colsample_bytree': 0.935779720509395, 'max_depth': 9, 'min_child_weight': 3, 'eta': 1.1080945827294662e-08, 'gamma': 0.0001786576390841006, 'grow_policy': 'lossguide'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:37,165]\u001b[0m Trial 33 finished with value: 0.8685481820493264 and parameters: {'booster': 'gbtree', 'lambda': 0.9227427260991856, 'alpha': 6.030806457538447e-07, 'subsample': 0.8344383401210065, 'colsample_bytree': 0.8748279312771653, 'max_depth': 9, 'min_child_weight': 3, 'eta': 4.0285727256445614e-08, 'gamma': 0.00012564840161355127, 'grow_policy': 'lossguide'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:37,292]\u001b[0m Trial 34 finished with value: 0.913372859025033 and parameters: {'booster': 'gbtree', 'lambda': 0.002917810562419851, 'alpha': 7.831592047691504e-08, 'subsample': 0.9480314833799482, 'colsample_bytree': 0.9574627993524312, 'max_depth': 9, 'min_child_weight': 2, 'eta': 1.8630692405910479e-07, 'gamma': 1.53557813704761e-05, 'grow_policy': 'lossguide'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:37,412]\u001b[0m Trial 35 finished with value: 0.956687370600414 and parameters: {'booster': 'gbtree', 'lambda': 0.11055404167411752, 'alpha': 7.821841370546809e-08, 'subsample': 0.9474287062634105, 'colsample_bytree': 0.9451510152407481, 'max_depth': 7, 'min_child_weight': 4, 'eta': 1.1360489660949967e-05, 'gamma': 6.1825562007719115e-06, 'grow_policy': 'lossguide'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:37,505]\u001b[0m Trial 36 finished with value: 0.7834368530020704 and parameters: {'booster': 'gblinear', 'lambda': 0.08276835249353776, 'alpha': 2.4983213891013387e-07, 'subsample': 0.8101356916819062, 'colsample_bytree': 0.86702481667698}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:37,622]\u001b[0m Trial 37 finished with value: 0.8226363008971703 and parameters: {'booster': 'gbtree', 'lambda': 5.572229849575782e-06, 'alpha': 8.523054441181558e-06, 'subsample': 0.8812909400289768, 'colsample_bytree': 0.3898502817303784, 'max_depth': 7, 'min_child_weight': 4, 'eta': 8.471187478422929e-06, 'gamma': 6.0764474597702e-06, 'grow_policy': 'lossguide'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:37,742]\u001b[0m Trial 38 finished with value: 0.7391304347826086 and parameters: {'booster': 'gbtree', 'lambda': 0.002763843424426635, 'alpha': 5.3570620177631685e-08, 'subsample': 0.9431250664669587, 'colsample_bytree': 0.9601982484545231, 'max_depth': 5, 'min_child_weight': 5, 'eta': 0.00039724945343378533, 'gamma': 4.518229654671584e-05, 'grow_policy': 'lossguide'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:37,861]\u001b[0m Trial 39 finished with value: 0.7391304347826086 and parameters: {'booster': 'gbtree', 'lambda': 4.272296601292808e-08, 'alpha': 5.2062805037133524e-05, 'subsample': 0.9635970756441956, 'colsample_bytree': 0.7757257274640619, 'max_depth': 7, 'min_child_weight': 5, 'eta': 6.19128890173875e-07, 'gamma': 2.1650169144138736e-06, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:37,951]\u001b[0m Trial 40 finished with value: 0.7809136367488769 and parameters: {'booster': 'gblinear', 'lambda': 2.5262288679609808e-05, 'alpha': 0.025290262510348976, 'subsample': 0.5047345344249162, 'colsample_bytree': 0.7024990874004995}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:38,071]\u001b[0m Trial 41 finished with value: 0.956687370600414 and parameters: {'booster': 'gbtree', 'lambda': 0.15343862675417105, 'alpha': 4.065927300830963e-06, 'subsample': 0.8725301841122441, 'colsample_bytree': 0.9067171765596073, 'max_depth': 7, 'min_child_weight': 3, 'eta': 3.789311131835655e-08, 'gamma': 0.000557891806151682, 'grow_policy': 'lossguide'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:38,190]\u001b[0m Trial 42 finished with value: 0.956687370600414 and parameters: {'booster': 'gbtree', 'lambda': 0.25983936606649183, 'alpha': 1.0026105234277452e-07, 'subsample': 0.9586939195389016, 'colsample_bytree': 0.8331355408716075, 'max_depth': 7, 'min_child_weight': 4, 'eta': 1.5262474055868474e-07, 'gamma': 9.31419326971499e-06, 'grow_policy': 'lossguide'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:38,309]\u001b[0m Trial 43 finished with value: 0.7809136367488769 and parameters: {'booster': 'gbtree', 'lambda': 0.1648317906213683, 'alpha': 1.2835036832346761e-08, 'subsample': 0.8232010558664448, 'colsample_bytree': 0.826852181691474, 'max_depth': 7, 'min_child_weight': 4, 'eta': 2.0993970688573864e-06, 'gamma': 9.897358225021668e-06, 'grow_policy': 'lossguide'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:38,425]\u001b[0m Trial 44 finished with value: 0.7809136367488769 and parameters: {'booster': 'gbtree', 'lambda': 0.37320870425822633, 'alpha': 3.0251669270468515e-08, 'subsample': 0.7324822235090561, 'colsample_bytree': 0.889545930829863, 'max_depth': 7, 'min_child_weight': 6, 'eta': 1.4701706188733672e-07, 'gamma': 6.0007221042594705e-06, 'grow_policy': 'lossguide'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:38,841]\u001b[0m Trial 45 finished with value: 0.956687370600414 and parameters: {'booster': 'dart', 'lambda': 0.07964541413980468, 'alpha': 1.5058923992303988e-07, 'subsample': 0.9588470390611482, 'colsample_bytree': 0.7821607511983338, 'max_depth': 7, 'min_child_weight': 4, 'eta': 3.963311935551857e-08, 'gamma': 5.8997292626841505e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.7552976848493626e-08, 'skip_drop': 2.1136095194728906e-05}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:39,246]\u001b[0m Trial 46 finished with value: 0.7809136367488769 and parameters: {'booster': 'dart', 'lambda': 0.334495774262107, 'alpha': 1.8441526778333762e-07, 'subsample': 0.4137539094165982, 'colsample_bytree': 0.650535151500535, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.13646100263252492, 'gamma': 7.357643027282989e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 2.1853667978887163e-08, 'skip_drop': 1.7911991863501297e-05}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:39,660]\u001b[0m Trial 47 finished with value: 0.7391304347826086 and parameters: {'booster': 'dart', 'lambda': 0.04708546717510846, 'alpha': 0.00018440266728174853, 'subsample': 0.9777683342703856, 'colsample_bytree': 0.776981704680904, 'max_depth': 5, 'min_child_weight': 5, 'eta': 3.3548530304537555e-08, 'gamma': 0.00033745936314926535, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.6875804548246554e-05, 'skip_drop': 2.6826574594856843e-05}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:40,066]\u001b[0m Trial 48 finished with value: 0.8685481820493264 and parameters: {'booster': 'dart', 'lambda': 0.06411281766837242, 'alpha': 1.0800611235985385e-08, 'subsample': 0.946029937311118, 'colsample_bytree': 0.5900456654296492, 'max_depth': 7, 'min_child_weight': 4, 'eta': 2.4263423104832513e-05, 'gamma': 0.0004448673519913166, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.270065884512348e-08, 'skip_drop': 0.0008839395945016528}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:40,558]\u001b[0m Trial 49 finished with value: 0.8648028926713114 and parameters: {'booster': 'dart', 'lambda': 0.6845169627767484, 'alpha': 3.671406980350739e-08, 'subsample': 0.7709975687738582, 'colsample_bytree': 0.3359029508094406, 'max_depth': 7, 'min_child_weight': 6, 'eta': 0.00015624590291835858, 'gamma': 1.1264487788051133e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.00016153485421982946, 'skip_drop': 9.45834618767517e-07}. Best is trial 13 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 16:56:40,981]\u001b[0m Trial 50 finished with value: 0.6968115942028984 and parameters: {'booster': 'dart', 'lambda': 0.2115217970926829, 'alpha': 7.029580795547326e-07, 'subsample': 0.9626060295104845, 'colsample_bytree': 0.49854457645891426, 'max_depth': 3, 'min_child_weight': 7, 'eta': 7.30349130709048e-07, 'gamma': 5.4289393722023795e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 2.9773481581604674e-07, 'skip_drop': 0.0027554043858150456}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:41,097]\u001b[0m Trial 51 finished with value: 0.956687370600414 and parameters: {'booster': 'gbtree', 'lambda': 0.11433468906897713, 'alpha': 1.9003677198885854e-07, 'subsample': 0.8869146649581187, 'colsample_bytree': 0.8419431662114416, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.004377050740625973, 'gamma': 6.231663386372509e-05, 'grow_policy': 'lossguide'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:41,213]\u001b[0m Trial 52 finished with value: 0.8685481820493264 and parameters: {'booster': 'gbtree', 'lambda': 0.10979230337616928, 'alpha': 5.120637479736695e-06, 'subsample': 0.8553430485474517, 'colsample_bytree': 0.7193043037234397, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.008353362110049577, 'gamma': 9.72864869336634e-05, 'grow_policy': 'lossguide'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:41,357]\u001b[0m Trial 53 finished with value: 0.7391304347826086 and parameters: {'booster': 'gbtree', 'lambda': 0.03304992827508665, 'alpha': 6.748288596000207e-07, 'subsample': 0.9965628501710325, 'colsample_bytree': 0.8976286277697277, 'max_depth': 7, 'min_child_weight': 5, 'eta': 3.0871483786065895e-08, 'gamma': 4.382459712644129e-06, 'grow_policy': 'lossguide'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:41,811]\u001b[0m Trial 54 finished with value: 0.9130434782608695 and parameters: {'booster': 'dart', 'lambda': 0.000264896881427777, 'alpha': 1.9051122578546493e-07, 'subsample': 0.8734239269191482, 'colsample_bytree': 0.8423314984555126, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.00598309413407348, 'gamma': 7.454646588858262e-05, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.07189241768453775, 'skip_drop': 1.2910942357896786e-06}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:41,953]\u001b[0m Trial 55 finished with value: 0.8226363008971703 and parameters: {'booster': 'gbtree', 'lambda': 0.23447142190905715, 'alpha': 3.216892504048253e-08, 'subsample': 0.9177452350664758, 'colsample_bytree': 0.9946850717410406, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.05020983634226702, 'gamma': 0.0007527917708035894, 'grow_policy': 'lossguide'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:42,061]\u001b[0m Trial 56 finished with value: 0.7834368530020704 and parameters: {'booster': 'gbtree', 'lambda': 2.455368795204824e-07, 'alpha': 4.920716406855401e-07, 'subsample': 0.8892166065828955, 'colsample_bytree': 0.7865018824474244, 'max_depth': 5, 'min_child_weight': 3, 'eta': 0.8609444787826068, 'gamma': 0.00022065476925103324, 'grow_policy': 'lossguide'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:42,149]\u001b[0m Trial 57 finished with value: 0.8226363008971703 and parameters: {'booster': 'gblinear', 'lambda': 0.7027420808044927, 'alpha': 1.6695035072542509e-06, 'subsample': 0.8023000704706714, 'colsample_bytree': 0.8267686937522356}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:42,265]\u001b[0m Trial 58 finished with value: 0.956687370600414 and parameters: {'booster': 'gbtree', 'lambda': 0.048252012879393714, 'alpha': 4.8681982780210404e-06, 'subsample': 0.9033370761141015, 'colsample_bytree': 0.7351272846593997, 'max_depth': 7, 'min_child_weight': 3, 'eta': 3.4121261962331905e-07, 'gamma': 4.3168589926648856e-05, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:42,383]\u001b[0m Trial 59 finished with value: 0.913372859025033 and parameters: {'booster': 'gbtree', 'lambda': 0.021615867625804933, 'alpha': 0.0001244499577247088, 'subsample': 0.9748233165451891, 'colsample_bytree': 0.7276473734070585, 'max_depth': 7, 'min_child_weight': 3, 'eta': 4.225704520942481e-06, 'gamma': 0.003142905875324991, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:42,807]\u001b[0m Trial 60 finished with value: 0.8648028926713114 and parameters: {'booster': 'dart', 'lambda': 0.0009633447018486617, 'alpha': 2.7405253400862857e-05, 'subsample': 0.5745872001861742, 'colsample_bytree': 0.7559875192411295, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.0017384979793565033, 'gamma': 1.181169093962237e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.791964591660862e-05, 'skip_drop': 6.243181078689027e-07}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:42,982]\u001b[0m Trial 61 finished with value: 0.956687370600414 and parameters: {'booster': 'gbtree', 'lambda': 0.05160114444869448, 'alpha': 1.4157577820789933e-07, 'subsample': 0.9077255646869669, 'colsample_bytree': 0.859314662407418, 'max_depth': 7, 'min_child_weight': 3, 'eta': 1.7343931655456404e-07, 'gamma': 3.293884699228141e-05, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:43,126]\u001b[0m Trial 62 finished with value: 0.956687370600414 and parameters: {'booster': 'gbtree', 'lambda': 0.08001420206620023, 'alpha': 8.17845526790201e-08, 'subsample': 0.9333047494645766, 'colsample_bytree': 0.9082392283073892, 'max_depth': 7, 'min_child_weight': 4, 'eta': 3.5367440802893096e-07, 'gamma': 3.6392085247789847e-06, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:43,238]\u001b[0m Trial 63 finished with value: 0.6968115942028984 and parameters: {'booster': 'gbtree', 'lambda': 0.31783995243899976, 'alpha': 0.005557458438173068, 'subsample': 0.8380249706380007, 'colsample_bytree': 0.7901512848627386, 'max_depth': 7, 'min_child_weight': 6, 'eta': 3.2410042525339965e-07, 'gamma': 1.916855493076948e-06, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:43,356]\u001b[0m Trial 64 finished with value: 0.956687370600414 and parameters: {'booster': 'gbtree', 'lambda': 0.11947994135833999, 'alpha': 6.74552096326578e-08, 'subsample': 0.9570363230705914, 'colsample_bytree': 0.9109170140066799, 'max_depth': 7, 'min_child_weight': 4, 'eta': 9.701537475998688e-08, 'gamma': 3.5047583610562823e-06, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:43,475]\u001b[0m Trial 65 finished with value: 0.6968115942028984 and parameters: {'booster': 'gbtree', 'lambda': 0.1710605544450845, 'alpha': 2.081560619632867e-08, 'subsample': 0.9570462925498551, 'colsample_bytree': 0.9460848269291361, 'max_depth': 7, 'min_child_weight': 5, 'eta': 6.87428333839367e-08, 'gamma': 3.223504148104051e-07, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:43,593]\u001b[0m Trial 66 finished with value: 1.0 and parameters: {'booster': 'gbtree', 'lambda': 0.004907158797179217, 'alpha': 5.4724524134347653e-08, 'subsample': 0.9871098756643315, 'colsample_bytree': 0.8803731436659759, 'max_depth': 7, 'min_child_weight': 4, 'eta': 1.1665550686876472e-06, 'gamma': 9.764906317613774e-06, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:43,711]\u001b[0m Trial 67 finished with value: 1.0 and parameters: {'booster': 'gbtree', 'lambda': 0.012117344573515463, 'alpha': 0.9183830744007502, 'subsample': 0.9957152847087363, 'colsample_bytree': 0.8303061493318851, 'max_depth': 7, 'min_child_weight': 4, 'eta': 1.6047781502212905e-06, 'gamma': 7.1442812602036425e-06, 'grow_policy': 'lossguide'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:43,829]\u001b[0m Trial 68 finished with value: 0.956687370600414 and parameters: {'booster': 'gbtree', 'lambda': 0.01000657065736315, 'alpha': 0.8528397841875368, 'subsample': 0.999142107561571, 'colsample_bytree': 0.8131927060543832, 'max_depth': 7, 'min_child_weight': 4, 'eta': 2.5852693769338096e-05, 'gamma': 9.993322818867441e-06, 'grow_policy': 'lossguide'}. Best is trial 13 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 16:56:43,918]\u001b[0m Trial 69 finished with value: 0.40821256038647347 and parameters: {'booster': 'gblinear', 'lambda': 0.006416042145867476, 'alpha': 0.8076272978314823, 'subsample': 0.9990186049839181, 'colsample_bytree': 0.877789896395548}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:44,038]\u001b[0m Trial 70 finished with value: 0.7391304347826086 and parameters: {'booster': 'gbtree', 'lambda': 0.0004477485312498534, 'alpha': 0.3486194064785968, 'subsample': 0.9719118911294797, 'colsample_bytree': 0.7570424265338815, 'max_depth': 7, 'min_child_weight': 5, 'eta': 1.3510954703783257e-06, 'gamma': 1.2315871155570499e-06, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:44,158]\u001b[0m Trial 71 finished with value: 0.913372859025033 and parameters: {'booster': 'gbtree', 'lambda': 0.004286352834563236, 'alpha': 4.6148798662051165e-07, 'subsample': 0.9277206701358511, 'colsample_bytree': 0.8333746032262055, 'max_depth': 7, 'min_child_weight': 3, 'eta': 3.2940021454399686e-06, 'gamma': 2.0333532819268907e-05, 'grow_policy': 'lossguide'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:44,282]\u001b[0m Trial 72 finished with value: 0.956687370600414 and parameters: {'booster': 'gbtree', 'lambda': 0.037453269957393356, 'alpha': 0.0006396910358565227, 'subsample': 0.8922459185491315, 'colsample_bytree': 0.8586026783548094, 'max_depth': 7, 'min_child_weight': 3, 'eta': 1.0461530386206832e-06, 'gamma': 8.04852093982904e-06, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:44,403]\u001b[0m Trial 73 finished with value: 0.8685481820493264 and parameters: {'booster': 'gbtree', 'lambda': 0.035938028246490776, 'alpha': 0.010236759705994377, 'subsample': 0.8613762215374023, 'colsample_bytree': 0.8036799277715081, 'max_depth': 7, 'min_child_weight': 4, 'eta': 2.348214117430465e-08, 'gamma': 6.090619791364903e-05, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:44,518]\u001b[0m Trial 74 finished with value: 0.40821256038647347 and parameters: {'booster': 'gbtree', 'lambda': 0.015064933385838355, 'alpha': 0.2622498622202635, 'subsample': 0.8952117307807095, 'colsample_bytree': 0.8635416394518034, 'max_depth': 7, 'min_child_weight': 10, 'eta': 8.987239939173624e-07, 'gamma': 2.2654541224956657e-05, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:44,644]\u001b[0m Trial 75 finished with value: 0.913372859025033 and parameters: {'booster': 'gbtree', 'lambda': 0.49258134998275865, 'alpha': 1.2826397585964263e-07, 'subsample': 0.9289742990511264, 'colsample_bytree': 0.9026372790454168, 'max_depth': 7, 'min_child_weight': 2, 'eta': 2.120191671483012e-07, 'gamma': 6.253764334303546e-07, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:44,766]\u001b[0m Trial 76 finished with value: 0.6968115942028984 and parameters: {'booster': 'gbtree', 'lambda': 0.0023321829947917246, 'alpha': 0.24538165288022684, 'subsample': 0.9814756739374061, 'colsample_bytree': 0.9772622602463626, 'max_depth': 7, 'min_child_weight': 5, 'eta': 1.6131539300758607e-05, 'gamma': 8.988589355820576e-06, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:44,890]\u001b[0m Trial 77 finished with value: 0.956687370600414 and parameters: {'booster': 'gbtree', 'lambda': 0.011710236788655603, 'alpha': 0.06761810458038793, 'subsample': 0.9106854172473372, 'colsample_bytree': 0.8090711557456988, 'max_depth': 5, 'min_child_weight': 3, 'eta': 1.7710107676543966e-05, 'gamma': 5.344398771681342e-06, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:45,307]\u001b[0m Trial 78 finished with value: 0.8648028926713114 and parameters: {'booster': 'dart', 'lambda': 0.000109979529768577, 'alpha': 3.768063308367393e-07, 'subsample': 0.46133289509435216, 'colsample_bytree': 0.9356251822126999, 'max_depth': 7, 'min_child_weight': 4, 'eta': 6.107676669487843e-08, 'gamma': 2.3884330829517057e-06, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 1.320697831316085e-07, 'skip_drop': 0.006601008561327467}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:45,431]\u001b[0m Trial 79 finished with value: 0.8685481820493264 and parameters: {'booster': 'gbtree', 'lambda': 0.0010849235208939749, 'alpha': 0.04894240497437647, 'subsample': 0.7844991687732736, 'colsample_bytree': 0.6787544373848222, 'max_depth': 5, 'min_child_weight': 2, 'eta': 4.1988333952125763e-07, 'gamma': 2.6930881250656353e-05, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:45,550]\u001b[0m Trial 80 finished with value: 0.6968115942028984 and parameters: {'booster': 'gbtree', 'lambda': 0.022090234061418357, 'alpha': 5.6927324973826905e-08, 'subsample': 0.9181059458873979, 'colsample_bytree': 0.8812281280616281, 'max_depth': 7, 'min_child_weight': 7, 'eta': 2.405181302134736e-07, 'gamma': 3.029660158924999e-05, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:45,673]\u001b[0m Trial 81 finished with value: 0.956687370600414 and parameters: {'booster': 'gbtree', 'lambda': 0.079414349020401, 'alpha': 5.2933749559640934e-08, 'subsample': 0.9553206603429133, 'colsample_bytree': 0.9122940283615222, 'max_depth': 7, 'min_child_weight': 4, 'eta': 2.0479495549164563e-08, 'gamma': 3.5590455452803714e-06, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:45,796]\u001b[0m Trial 82 finished with value: 0.956687370600414 and parameters: {'booster': 'gbtree', 'lambda': 3.38119732286723e-05, 'alpha': 1.0672507613950093e-06, 'subsample': 0.9450074966391658, 'colsample_bytree': 0.8439040192527949, 'max_depth': 7, 'min_child_weight': 4, 'eta': 1.2971037929403522e-07, 'gamma': 0.00015957017044443574, 'grow_policy': 'lossguide'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:45,921]\u001b[0m Trial 83 finished with value: 0.913372859025033 and parameters: {'booster': 'gbtree', 'lambda': 0.13402850172168668, 'alpha': 5.482722658085642e-06, 'subsample': 0.9768957231969565, 'colsample_bytree': 0.7397040112491133, 'max_depth': 7, 'min_child_weight': 3, 'eta': 2.66214651209336e-08, 'gamma': 4.593781810210879e-05, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:46,044]\u001b[0m Trial 84 finished with value: 0.956687370600414 and parameters: {'booster': 'gbtree', 'lambda': 1.180702005730218e-05, 'alpha': 1.0636530976556343e-06, 'subsample': 0.9433315331640828, 'colsample_bytree': 0.9514495755204087, 'max_depth': 7, 'min_child_weight': 4, 'eta': 1.1461755460368657e-07, 'gamma': 0.936428849085017, 'grow_policy': 'lossguide'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:46,168]\u001b[0m Trial 85 finished with value: 0.956687370600414 and parameters: {'booster': 'gbtree', 'lambda': 0.056769936140718416, 'alpha': 1.54701002865195e-07, 'subsample': 0.8755447266577011, 'colsample_bytree': 0.7872115299615733, 'max_depth': 7, 'min_child_weight': 3, 'eta': 6.030494496394011e-07, 'gamma': 0.00028201958088156973, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:46,282]\u001b[0m Trial 86 finished with value: 0.40821256038647347 and parameters: {'booster': 'gbtree', 'lambda': 1.5546442370536767e-05, 'alpha': 2.239666664320322e-06, 'subsample': 0.2256258836620496, 'colsample_bytree': 0.7071624685431899, 'max_depth': 7, 'min_child_weight': 5, 'eta': 5.277901492678874e-08, 'gamma': 0.051985993089856186, 'grow_policy': 'lossguide'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:46,707]\u001b[0m Trial 87 finished with value: 1.0 and parameters: {'booster': 'dart', 'lambda': 0.014642501076872514, 'alpha': 0.0009203088752081838, 'subsample': 0.9867402095778431, 'colsample_bytree': 0.8571083344852545, 'max_depth': 7, 'min_child_weight': 4, 'eta': 9.55080539144023e-05, 'gamma': 1.1674714568840092e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.0007646444482223582, 'skip_drop': 0.9505961089155096}. Best is trial 13 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 16:56:47,126]\u001b[0m Trial 88 finished with value: 0.40821256038647347 and parameters: {'booster': 'dart', 'lambda': 0.2146696947360526, 'alpha': 0.00101885021934445, 'subsample': 0.9840302774298982, 'colsample_bytree': 0.8942481717428009, 'max_depth': 7, 'min_child_weight': 9, 'eta': 5.871270633796366e-06, 'gamma': 1.3599184768730374e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.0012661382748252485, 'skip_drop': 0.47616342046559557}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:47,219]\u001b[0m Trial 89 finished with value: 0.7834368530020704 and parameters: {'booster': 'gblinear', 'lambda': 0.005584425652472255, 'alpha': 0.0003701787441391015, 'subsample': 0.8333358573749077, 'colsample_bytree': 0.8603825720436243}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:47,340]\u001b[0m Trial 90 finished with value: 1.0 and parameters: {'booster': 'gbtree', 'lambda': 0.009320649845571294, 'alpha': 0.0026313868541603643, 'subsample': 0.9952618315364067, 'colsample_bytree': 0.8199789578492113, 'max_depth': 7, 'min_child_weight': 4, 'eta': 4.8607065860447735e-05, 'gamma': 7.319213836536842e-06, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:47,465]\u001b[0m Trial 91 finished with value: 0.956687370600414 and parameters: {'booster': 'gbtree', 'lambda': 1.8066630453620614e-06, 'alpha': 6.144289469031328e-05, 'subsample': 0.9717374559099278, 'colsample_bytree': 0.8296831924070668, 'max_depth': 7, 'min_child_weight': 4, 'eta': 7.060977262977045e-05, 'gamma': 0.0001298823262735384, 'grow_policy': 'lossguide'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:47,590]\u001b[0m Trial 92 finished with value: 0.956687370600414 and parameters: {'booster': 'gbtree', 'lambda': 0.017702709539605392, 'alpha': 0.0033545957853324516, 'subsample': 0.9310523239374315, 'colsample_bytree': 0.847877315996034, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.00014013963235623336, 'gamma': 1.2652111206614009e-06, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:48,019]\u001b[0m Trial 93 finished with value: 0.956687370600414 and parameters: {'booster': 'dart', 'lambda': 7.407873668629525e-07, 'alpha': 0.002629499893956653, 'subsample': 0.972422522139793, 'colsample_bytree': 0.8265987925371279, 'max_depth': 7, 'min_child_weight': 4, 'eta': 7.04863200441273e-05, 'gamma': 1.6624425795587482e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 9.764421136466466e-05, 'skip_drop': 0.019897397833045918}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:48,437]\u001b[0m Trial 94 finished with value: 0.8685481820493264 and parameters: {'booster': 'dart', 'lambda': 5.614611007848623e-07, 'alpha': 0.0030451062335161596, 'subsample': 0.9979962290779975, 'colsample_bytree': 0.21441510298327288, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.00012278156649434539, 'gamma': 1.364442100496142e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.00786695471746737, 'skip_drop': 0.043080386824677484}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:48,849]\u001b[0m Trial 95 finished with value: 0.6968115942028984 and parameters: {'booster': 'dart', 'lambda': 2.6678083305216374e-07, 'alpha': 0.001537684599968216, 'subsample': 0.9827330243800543, 'colsample_bytree': 0.7585666119778018, 'max_depth': 7, 'min_child_weight': 5, 'eta': 1.1208261047442448e-05, 'gamma': 5.036101552486663e-07, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.00015350362669065888, 'skip_drop': 0.5855645348462752}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:49,263]\u001b[0m Trial 96 finished with value: 0.956687370600414 and parameters: {'booster': 'dart', 'lambda': 0.004351191984602162, 'alpha': 2.2031238285781872e-08, 'subsample': 0.9536635160917567, 'colsample_bytree': 0.9230080160019877, 'max_depth': 7, 'min_child_weight': 4, 'eta': 1.565329354679831e-08, 'gamma': 0.0006265329288978113, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 2.681781184880397e-06, 'skip_drop': 7.727088714678928e-06}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:49,670]\u001b[0m Trial 97 finished with value: 0.913372859025033 and parameters: {'booster': 'dart', 'lambda': 0.04739834321312458, 'alpha': 2.2144906102374535e-07, 'subsample': 0.9124485789797244, 'colsample_bytree': 0.791342214910337, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.00032520122920105826, 'gamma': 3.89822698250652e-05, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.02470012948501284, 'skip_drop': 0.00026693257861360933}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:50,081]\u001b[0m Trial 98 finished with value: 0.6968115942028984 and parameters: {'booster': 'dart', 'lambda': 0.004555938735924882, 'alpha': 2.1843262802347542e-08, 'subsample': 0.9468274830354547, 'colsample_bytree': 0.9317128437039809, 'max_depth': 7, 'min_child_weight': 5, 'eta': 3.833515984433095e-05, 'gamma': 9.332324150864968e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 5.491740596846546e-06, 'skip_drop': 8.981733490748497e-06}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:50,203]\u001b[0m Trial 99 finished with value: 0.956687370600414 and parameters: {'booster': 'gbtree', 'lambda': 0.011234941587166147, 'alpha': 0.009886656339395016, 'subsample': 0.9106420590609043, 'colsample_bytree': 0.8084639610832918, 'max_depth': 5, 'min_child_weight': 3, 'eta': 1.9225363341553934e-06, 'gamma': 3.5383193537354794e-06, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 1.0.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 16:56:50,366]\u001b[0m A new study created in memory with name: no-name-eadb8c57-c93d-4089-9787-c92e13c1b696\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:52,263]\u001b[0m Trial 0 finished with value: 0.39085714285714285 and parameters: {'booster': 'dart', 'lambda': 0.004820729630235005, 'alpha': 0.041068602762962175, 'subsample': 0.9986042306746168, 'colsample_bytree': 0.41376620871959785, 'max_depth': 3, 'min_child_weight': 6, 'eta': 1.0788373609220642e-07, 'gamma': 0.22245458067701537, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 4.0618589785385875e-08, 'skip_drop': 0.7237617194280546}. Best is trial 0 with value: 0.39085714285714285.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:52,353]\u001b[0m Trial 1 finished with value: 0.41180592991913745 and parameters: {'booster': 'gblinear', 'lambda': 1.6204305822517052e-07, 'alpha': 0.1041011910032829, 'subsample': 0.21500268363557035, 'colsample_bytree': 0.6866468658995701}. Best is trial 1 with value: 0.41180592991913745.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:52,527]\u001b[0m Trial 2 finished with value: 0.41673601479426725 and parameters: {'booster': 'gbtree', 'lambda': 1.8587554049825322e-07, 'alpha': 0.9330802268864036, 'subsample': 0.8556558629166369, 'colsample_bytree': 0.5525125050460322, 'max_depth': 3, 'min_child_weight': 3, 'eta': 7.564502767189614e-05, 'gamma': 0.03714526699765804, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 0.41673601479426725.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:54,365]\u001b[0m Trial 3 finished with value: 0.4569327731092437 and parameters: {'booster': 'dart', 'lambda': 1.4724038874371332e-08, 'alpha': 0.009943890501584396, 'subsample': 0.2708872705673582, 'colsample_bytree': 0.4722360866656697, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.04174852140550351, 'gamma': 0.00012550012305573757, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.454506216686118e-07, 'skip_drop': 0.002042053024079206}. Best is trial 3 with value: 0.4569327731092437.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 16:56:56,371]\u001b[0m Trial 4 finished with value: 0.3737609329446064 and parameters: {'booster': 'dart', 'lambda': 0.19828931416412254, 'alpha': 0.14837242933221087, 'subsample': 0.9904190582285151, 'colsample_bytree': 0.6206930043609054, 'max_depth': 9, 'min_child_weight': 6, 'eta': 1.433664781966475e-07, 'gamma': 0.00020038896365745173, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 9.199212687604023e-08, 'skip_drop': 0.004356568629488974}. Best is trial 3 with value: 0.4569327731092437.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:56,499]\u001b[0m Trial 5 finished with value: 0.43991244710345834 and parameters: {'booster': 'gblinear', 'lambda': 8.575204622515183e-08, 'alpha': 0.0034702672400989346, 'subsample': 0.9151757121111985, 'colsample_bytree': 0.2726986802082064}. Best is trial 3 with value: 0.4569327731092437.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:56:58,252]\u001b[0m Trial 6 finished with value: 0.40915275200989487 and parameters: {'booster': 'dart', 'lambda': 0.00045914681542915943, 'alpha': 8.991537178627852e-05, 'subsample': 0.4697282865550772, 'colsample_bytree': 0.576118779534411, 'max_depth': 9, 'min_child_weight': 2, 'eta': 1.7164603717388065e-07, 'gamma': 8.820318949324119e-07, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.12966730361896112, 'skip_drop': 0.0008489265395418483}. Best is trial 3 with value: 0.4569327731092437.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:00,160]\u001b[0m Trial 7 finished with value: 0.3737609329446064 and parameters: {'booster': 'dart', 'lambda': 1.5680738335131842e-07, 'alpha': 0.03274207514521111, 'subsample': 0.7209534391119885, 'colsample_bytree': 0.9550090864132654, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.00014828704878505554, 'gamma': 1.43494444864971e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.06076467890948017, 'skip_drop': 6.440672618626677e-05}. Best is trial 3 with value: 0.4569327731092437.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:00,295]\u001b[0m Trial 8 finished with value: 0.42605042016806727 and parameters: {'booster': 'gblinear', 'lambda': 0.4365197049629039, 'alpha': 0.002461957775406125, 'subsample': 0.7828733265193706, 'colsample_bytree': 0.7607414793926406}. Best is trial 3 with value: 0.4569327731092437.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:00,513]\u001b[0m Trial 9 finished with value: 0.36579002735114663 and parameters: {'booster': 'gbtree', 'lambda': 3.19504312256315e-08, 'alpha': 4.326320575670864e-06, 'subsample': 0.9462220347913324, 'colsample_bytree': 0.694101634841271, 'max_depth': 5, 'min_child_weight': 7, 'eta': 3.739451602756611e-05, 'gamma': 0.04513436107358404, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 0.4569327731092437.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:02,416]\u001b[0m Trial 10 finished with value: 0.453781512605042 and parameters: {'booster': 'dart', 'lambda': 1.0439190450221723e-05, 'alpha': 2.0085433718816505e-08, 'subsample': 0.2945192718525441, 'colsample_bytree': 0.21260980537868723, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.17272490752550343, 'gamma': 6.397211368945055e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.8629380705212222e-05, 'skip_drop': 1.6427845054346154e-08}. Best is trial 3 with value: 0.4569327731092437.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:04,333]\u001b[0m Trial 11 finished with value: 0.4945598629256801 and parameters: {'booster': 'dart', 'lambda': 1.5947126858829636e-05, 'alpha': 1.1782638896215504e-08, 'subsample': 0.22102353031802358, 'colsample_bytree': 0.23843918201203787, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.8697933590630444, 'gamma': 2.428050496441717e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.861568727620759e-05, 'skip_drop': 1.7731052449507893e-08}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:06,566]\u001b[0m Trial 12 finished with value: 0.40694463431305544 and parameters: {'booster': 'dart', 'lambda': 8.49368397456784e-06, 'alpha': 4.799826356135344e-08, 'subsample': 0.38960147933683353, 'colsample_bytree': 0.3832948749269668, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.15218627334795926, 'gamma': 0.00018137812799907992, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.104607812064532e-05, 'skip_drop': 1.609420955456601e-08}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:08,403]\u001b[0m Trial 13 finished with value: 0.46234850863422283 and parameters: {'booster': 'dart', 'lambda': 4.614051495950731e-06, 'alpha': 2.186673309609376e-06, 'subsample': 0.4561635535876257, 'colsample_bytree': 0.3992181826866937, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.7894511670343108, 'gamma': 1.2732052560263328e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.473630615135796e-06, 'skip_drop': 2.767089677512674e-06}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:10,496]\u001b[0m Trial 14 finished with value: 0.40952380952380957 and parameters: {'booster': 'dart', 'lambda': 6.323673908050464e-06, 'alpha': 5.963462833897415e-07, 'subsample': 0.5114756320983338, 'colsample_bytree': 0.3238291213922213, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.0037867709827062077, 'gamma': 1.0121296005237299e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.0007917352400405735, 'skip_drop': 5.596568977691365e-07}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:10,729]\u001b[0m Trial 15 finished with value: 0.4101153504880212 and parameters: {'booster': 'gbtree', 'lambda': 0.000175076896820413, 'alpha': 6.528191335367167e-07, 'subsample': 0.6417285449281223, 'colsample_bytree': 0.20317989736956082, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.49508585543681954, 'gamma': 4.070011955661097e-07, 'grow_policy': 'lossguide'}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:12,623]\u001b[0m Trial 16 finished with value: 0.3920634920634921 and parameters: {'booster': 'dart', 'lambda': 1.6819938912140547e-06, 'alpha': 3.436306964023497e-05, 'subsample': 0.38319669362385117, 'colsample_bytree': 0.456567461090551, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.003146686782482278, 'gamma': 1.7197297687337508e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.0003216667151299921, 'skip_drop': 1.6891099089098894e-06}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:14,722]\u001b[0m Trial 17 finished with value: 0.4021687883074021 and parameters: {'booster': 'dart', 'lambda': 0.0008467883409889328, 'alpha': 1.9522008600834319e-07, 'subsample': 0.5578548584783438, 'colsample_bytree': 0.31996325226276295, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.01691384907884743, 'gamma': 1.6095878168937933e-06, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 2.141010859654276e-06, 'skip_drop': 1.1615159398321073e-06}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:14,901]\u001b[0m Trial 18 finished with value: 0.46714859437751 and parameters: {'booster': 'gbtree', 'lambda': 0.0073739198777877865, 'alpha': 7.033872507027708e-06, 'subsample': 0.3566146969478238, 'colsample_bytree': 0.34932827730834026, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.9436709528442186, 'gamma': 1.2971236192704188e-07, 'grow_policy': 'depthwise'}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:15,075]\u001b[0m Trial 19 finished with value: 0.398689384010485 and parameters: {'booster': 'gbtree', 'lambda': 0.01576377192679038, 'alpha': 0.00044726317077819014, 'subsample': 0.3444412845059534, 'colsample_bytree': 0.9184526635109477, 'max_depth': 5, 'min_child_weight': 9, 'eta': 5.374001060888197e-06, 'gamma': 6.508689656088306e-06, 'grow_policy': 'depthwise'}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:15,221]\u001b[0m Trial 20 finished with value: 0.398689384010485 and parameters: {'booster': 'gbtree', 'lambda': 0.02381428480106641, 'alpha': 1.0461194002834636e-05, 'subsample': 0.21818529553290544, 'colsample_bytree': 0.28954767352710026, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.0018036836872728924, 'gamma': 1.513448985581481e-07, 'grow_policy': 'depthwise'}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 16:57:15,380]\u001b[0m Trial 21 finished with value: 0.4203026038001408 and parameters: {'booster': 'gbtree', 'lambda': 4.2441240163984575e-05, 'alpha': 3.6956924458634316e-06, 'subsample': 0.4459905991767919, 'colsample_bytree': 0.3707143715649237, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.7076502296546304, 'gamma': 7.883545309452833e-08, 'grow_policy': 'depthwise'}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:15,530]\u001b[0m Trial 22 finished with value: 0.4265534637627661 and parameters: {'booster': 'gbtree', 'lambda': 4.7919296954470745e-05, 'alpha': 1.2210601023805308e-08, 'subsample': 0.30224786431535894, 'colsample_bytree': 0.5106922091378574, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.931529692413819, 'gamma': 1.2156770394131056e-08, 'grow_policy': 'depthwise'}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:15,676]\u001b[0m Trial 23 finished with value: 0.47268080756452846 and parameters: {'booster': 'gblinear', 'lambda': 0.00186197901688643, 'alpha': 1.691608782003537e-07, 'subsample': 0.4393800069820787, 'colsample_bytree': 0.2537752862611104}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:15,825]\u001b[0m Trial 24 finished with value: 0.47268080756452846 and parameters: {'booster': 'gblinear', 'lambda': 0.0017434713480156887, 'alpha': 9.06732480410231e-08, 'subsample': 0.3867474587025088, 'colsample_bytree': 0.2457050013769093}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:15,969]\u001b[0m Trial 25 finished with value: 0.48837750484809306 and parameters: {'booster': 'gblinear', 'lambda': 0.0010790874104054271, 'alpha': 1.1802100056364514e-07, 'subsample': 0.5734129360307922, 'colsample_bytree': 0.23932143011472454}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:16,114]\u001b[0m Trial 26 finished with value: 0.44935064935064933 and parameters: {'booster': 'gblinear', 'lambda': 0.07161929176858901, 'alpha': 6.236705894564868e-08, 'subsample': 0.5211381213784384, 'colsample_bytree': 0.24663519205921677}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:16,261]\u001b[0m Trial 27 finished with value: 0.45247947454844006 and parameters: {'booster': 'gblinear', 'lambda': 0.0001977632248200982, 'alpha': 1.0384648398921992e-08, 'subsample': 0.6412264385784587, 'colsample_bytree': 0.20136511642539467}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:16,405]\u001b[0m Trial 28 finished with value: 0.47268080756452846 and parameters: {'booster': 'gblinear', 'lambda': 0.0020071291938704473, 'alpha': 4.933390928432122e-07, 'subsample': 0.5958419616156349, 'colsample_bytree': 0.3062863462848434}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:16,548]\u001b[0m Trial 29 finished with value: 0.4499818594104309 and parameters: {'booster': 'gblinear', 'lambda': 6.508264489706954e-07, 'alpha': 7.30818883663809e-07, 'subsample': 0.7346131738695053, 'colsample_bytree': 0.4383518726868989}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:16,807]\u001b[0m Trial 30 finished with value: 0.4302365869424693 and parameters: {'booster': 'gblinear', 'lambda': 2.9568768528115952e-05, 'alpha': 7.327466973544271e-08, 'subsample': 0.2575793983564855, 'colsample_bytree': 0.793811748612745}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:16,977]\u001b[0m Trial 31 finished with value: 0.47268080756452846 and parameters: {'booster': 'gblinear', 'lambda': 0.0027091635984506012, 'alpha': 1.180789786042734e-07, 'subsample': 0.42109497364421833, 'colsample_bytree': 0.27852730597229486}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:17,122]\u001b[0m Trial 32 finished with value: 0.47268080756452846 and parameters: {'booster': 'gblinear', 'lambda': 0.002178461654815665, 'alpha': 2.300932924342785e-07, 'subsample': 0.42798032627282256, 'colsample_bytree': 0.26803196713879746}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:17,264]\u001b[0m Trial 33 finished with value: 0.47268080756452846 and parameters: {'booster': 'gblinear', 'lambda': 0.0005802070805555252, 'alpha': 2.3309378920450946e-08, 'subsample': 0.5087075001574124, 'colsample_bytree': 0.3427541229969083}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:17,402]\u001b[0m Trial 34 finished with value: 0.47268080756452846 and parameters: {'booster': 'gblinear', 'lambda': 0.0004893332560970526, 'alpha': 2.9574428581636324e-08, 'subsample': 0.505146503658674, 'colsample_bytree': 0.3402501262736379}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:17,548]\u001b[0m Trial 35 finished with value: 0.4409063804412641 and parameters: {'booster': 'gblinear', 'lambda': 0.00010549014623697633, 'alpha': 2.9199795810532078e-08, 'subsample': 0.20104030064155168, 'colsample_bytree': 0.5099221850075645}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:17,691]\u001b[0m Trial 36 finished with value: 0.43991244710345834 and parameters: {'booster': 'gblinear', 'lambda': 0.013873429193719738, 'alpha': 1.389580586323417e-06, 'subsample': 0.5757031309522814, 'colsample_bytree': 0.2362390821346662}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:17,834]\u001b[0m Trial 37 finished with value: 0.4615539754363283 and parameters: {'booster': 'gblinear', 'lambda': 0.0004430953713294406, 'alpha': 3.131502427859239e-08, 'subsample': 0.641088073543997, 'colsample_bytree': 0.422003562767278}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:17,974]\u001b[0m Trial 38 finished with value: 0.48837750484809306 and parameters: {'booster': 'gblinear', 'lambda': 0.000479692407662519, 'alpha': 1.4383814129626718e-08, 'subsample': 0.4998173824703731, 'colsample_bytree': 0.35887731241311854}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:18,119]\u001b[0m Trial 39 finished with value: 0.43015726179463465 and parameters: {'booster': 'gblinear', 'lambda': 0.05190891036083886, 'alpha': 3.2953365184252765e-07, 'subsample': 0.7021629235837715, 'colsample_bytree': 0.30500053188027776}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:18,263]\u001b[0m Trial 40 finished with value: 0.40743486767583154 and parameters: {'booster': 'gblinear', 'lambda': 1.9029982323355302e-05, 'alpha': 1.318273265029985e-08, 'subsample': 0.8274170711979006, 'colsample_bytree': 0.6267511354418024}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:18,396]\u001b[0m Trial 41 finished with value: 0.46528735632183904 and parameters: {'booster': 'gblinear', 'lambda': 0.004643213785307549, 'alpha': 1.2533735775570983e-07, 'subsample': 0.5481680286654762, 'colsample_bytree': 0.3864508629038488}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:18,489]\u001b[0m Trial 42 finished with value: 0.398689384010485 and parameters: {'booster': 'gblinear', 'lambda': 0.00018633570095417392, 'alpha': 0.5175241593636685, 'subsample': 0.4718233524383496, 'colsample_bytree': 0.2802326588179916}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:18,627]\u001b[0m Trial 43 finished with value: 0.48837750484809306 and parameters: {'booster': 'gblinear', 'lambda': 0.0011947046011615524, 'alpha': 4.195175389343159e-08, 'subsample': 0.49254241758940154, 'colsample_bytree': 0.2527010822801644}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:20,463]\u001b[0m Trial 44 finished with value: 0.398689384010485 and parameters: {'booster': 'dart', 'lambda': 6.93844647196564e-05, 'alpha': 6.686535206745237e-08, 'subsample': 0.25044508535481363, 'colsample_bytree': 0.26031161901440175, 'max_depth': 3, 'min_child_weight': 7, 'eta': 2.108712514270831e-06, 'gamma': 0.0009211449675180897, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.005539156502662769, 'skip_drop': 0.2877058465000687}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:20,627]\u001b[0m Trial 45 finished with value: 0.48837750484809306 and parameters: {'booster': 'gblinear', 'lambda': 0.0008604473991930268, 'alpha': 3.545984383093905e-08, 'subsample': 0.4837529221050516, 'colsample_bytree': 0.346207570783862}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 16:57:22,493]\u001b[0m Trial 46 finished with value: 0.05017421602787456 and parameters: {'booster': 'dart', 'lambda': 0.0007317300844542811, 'alpha': 1.0148651921805255e-08, 'subsample': 0.6817018438162739, 'colsample_bytree': 0.478109864952083, 'max_depth': 5, 'min_child_weight': 5, 'eta': 1.3091871507603677e-08, 'gamma': 0.00203203954689848, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.0061604599819327695, 'skip_drop': 5.598398947950105e-05}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:22,632]\u001b[0m Trial 47 finished with value: 0.41999901647405946 and parameters: {'booster': 'gblinear', 'lambda': 2.9628504000415297e-06, 'alpha': 0.0006820794557818089, 'subsample': 0.605926887358216, 'colsample_bytree': 0.22399192467863674}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:23,410]\u001b[0m Trial 48 finished with value: 0.398689384010485 and parameters: {'booster': 'dart', 'lambda': 0.006028323428464654, 'alpha': 4.740988832965203e-08, 'subsample': 0.4852094778308424, 'colsample_bytree': 0.36571501580818416, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.00048440796040253307, 'gamma': 1.3818229148670371e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.7098663712423199, 'skip_drop': 7.71468065538424e-08}. Best is trial 11 with value: 0.4945598629256801.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 16:57:25,905]\u001b[0m A new study created in memory with name: no-name-50810b63-5117-41b7-8023-c7515a679f7c\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:26,952]\u001b[0m Trial 0 finished with value: 0.366703606623471 and parameters: {'booster': 'dart', 'lambda': 1.2298363033281117e-06, 'alpha': 5.004011147438522e-07, 'subsample': 0.3374273775869895, 'colsample_bytree': 0.9428308095939368, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.001984339231277796, 'gamma': 3.499721986084233e-07, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 3.149108178456667e-06, 'skip_drop': 9.857060667443202e-05}. Best is trial 0 with value: 0.366703606623471.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:27,081]\u001b[0m Trial 1 finished with value: 0.7842799595110738 and parameters: {'booster': 'gblinear', 'lambda': 1.1586597823070402e-08, 'alpha': 3.131739281720099e-05, 'subsample': 0.38782428533422586, 'colsample_bytree': 0.7493470472909123}. Best is trial 0 with value: 0.366703606623471.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:27,193]\u001b[0m Trial 2 finished with value: 0.49290756769261335 and parameters: {'booster': 'gbtree', 'lambda': 0.002986598644556347, 'alpha': 0.40017630347948685, 'subsample': 0.21296419802068636, 'colsample_bytree': 0.4539505652256713, 'max_depth': 3, 'min_child_weight': 7, 'eta': 8.88227258000179e-05, 'gamma': 0.0003568923174781568, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.366703606623471.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:27,291]\u001b[0m Trial 3 finished with value: 0.7656857324239196 and parameters: {'booster': 'gblinear', 'lambda': 1.484158502303651e-07, 'alpha': 0.0005721692304213909, 'subsample': 0.557848328337283, 'colsample_bytree': 0.5655278613205093}. Best is trial 0 with value: 0.366703606623471.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:28,142]\u001b[0m Trial 4 finished with value: 0.12034499555926302 and parameters: {'booster': 'dart', 'lambda': 5.262165522988781e-07, 'alpha': 0.004725491850664579, 'subsample': 0.26651314527400993, 'colsample_bytree': 0.3985016417660374, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.03333391924060139, 'gamma': 0.010472086910984335, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.001874791585493491, 'skip_drop': 0.03001992353434265}. Best is trial 4 with value: 0.12034499555926302.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:28,229]\u001b[0m Trial 5 finished with value: 0.15717786178418675 and parameters: {'booster': 'gblinear', 'lambda': 2.435523660207549e-05, 'alpha': 0.050719889639009454, 'subsample': 0.9406262346885077, 'colsample_bytree': 0.8542141114832131}. Best is trial 4 with value: 0.12034499555926302.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:28,324]\u001b[0m Trial 6 finished with value: 0.8149378728486681 and parameters: {'booster': 'gblinear', 'lambda': 1.8972991769234166e-07, 'alpha': 3.3285038477403023e-07, 'subsample': 0.4264444382924973, 'colsample_bytree': 0.5296622952832185}. Best is trial 4 with value: 0.12034499555926302.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:28,552]\u001b[0m Trial 7 finished with value: 0.49597037922291626 and parameters: {'booster': 'gbtree', 'lambda': 1.0335782339290027e-06, 'alpha': 1.027309993663597e-07, 'subsample': 0.45581245241590235, 'colsample_bytree': 0.851512044214765, 'max_depth': 5, 'min_child_weight': 8, 'eta': 3.726128940514974e-05, 'gamma': 2.843247941149299e-07, 'grow_policy': 'depthwise'}. Best is trial 4 with value: 0.12034499555926302.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:29,539]\u001b[0m Trial 8 finished with value: 0.4190406825943903 and parameters: {'booster': 'dart', 'lambda': 6.290278931841274e-07, 'alpha': 0.07758155719089546, 'subsample': 0.8776189477646335, 'colsample_bytree': 0.457863857700786, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.0017332798873213248, 'gamma': 0.0002878681438439227, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.04571448737820337, 'skip_drop': 0.00048152905347406043}. Best is trial 4 with value: 0.12034499555926302.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:29,715]\u001b[0m Trial 9 finished with value: 0.4988693927236228 and parameters: {'booster': 'gbtree', 'lambda': 6.434165043321831e-05, 'alpha': 0.021001812087630845, 'subsample': 0.48516250750174267, 'colsample_bytree': 0.5465441877300394, 'max_depth': 7, 'min_child_weight': 6, 'eta': 1.2191001341509652e-08, 'gamma': 5.250258195345101e-08, 'grow_policy': 'depthwise'}. Best is trial 4 with value: 0.12034499555926302.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:30,698]\u001b[0m Trial 10 finished with value: 0.6281094809532134 and parameters: {'booster': 'dart', 'lambda': 0.5576872266875891, 'alpha': 0.000322722694132082, 'subsample': 0.7222574748760218, 'colsample_bytree': 0.21697124038931417, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.8820662521910669, 'gamma': 0.49552015772721103, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.00909584124802343, 'skip_drop': 0.7244703599603883}. Best is trial 4 with value: 0.12034499555926302.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:31,665]\u001b[0m Trial 11 finished with value: 0.6607102267869592 and parameters: {'booster': 'dart', 'lambda': 7.03300185436328e-05, 'alpha': 0.005987844868168357, 'subsample': 0.993109999349739, 'colsample_bytree': 0.35741458154490496, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.9788690683625035, 'gamma': 0.3530319301412231, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 2.667964641816524e-08, 'skip_drop': 1.2064646106465936e-08}. Best is trial 4 with value: 0.12034499555926302.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:31,770]\u001b[0m Trial 12 finished with value: 0.19015041593814058 and parameters: {'booster': 'gblinear', 'lambda': 0.0017506824234760688, 'alpha': 0.8944248437069177, 'subsample': 0.7118224450450894, 'colsample_bytree': 0.6938570934579802}. Best is trial 4 with value: 0.12034499555926302.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:32,720]\u001b[0m Trial 13 finished with value: 0.14994293796268274 and parameters: {'booster': 'dart', 'lambda': 8.038462828397455e-06, 'alpha': 1.805988253527472e-05, 'subsample': 0.7159031845477313, 'colsample_bytree': 0.2639802755172065, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.011349934044080153, 'gamma': 0.009995322769742078, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.00015192015473519473, 'skip_drop': 0.3265528718245154}. Best is trial 4 with value: 0.12034499555926302.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 16:57:33,664]\u001b[0m Trial 14 finished with value: 0.15623305742344668 and parameters: {'booster': 'dart', 'lambda': 4.309696853365969e-06, 'alpha': 1.1711035182126496e-05, 'subsample': 0.6899856331772327, 'colsample_bytree': 0.21329950902064007, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.010524332658949918, 'gamma': 0.00919712765205401, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.0001828218813651624, 'skip_drop': 0.30193777940578864}. Best is trial 4 with value: 0.12034499555926302.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:34,608]\u001b[0m Trial 15 finished with value: 0.12832795678833261 and parameters: {'booster': 'dart', 'lambda': 0.0005583974204086497, 'alpha': 1.0373904669330863e-08, 'subsample': 0.221336853346895, 'colsample_bytree': 0.345173862270024, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.03122560115713942, 'gamma': 0.00955591106565213, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.00022245249906952523, 'skip_drop': 0.006191320572294522}. Best is trial 4 with value: 0.12034499555926302.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:35,568]\u001b[0m Trial 16 finished with value: 0.4987588448629398 and parameters: {'booster': 'dart', 'lambda': 0.002227575668489229, 'alpha': 0.0012380575551519876, 'subsample': 0.20873421342250603, 'colsample_bytree': 0.3390381443685011, 'max_depth': 5, 'min_child_weight': 2, 'eta': 1.5128348748982808e-06, 'gamma': 0.011955201803814201, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.002617935988446234, 'skip_drop': 0.0017540617827721586}. Best is trial 4 with value: 0.12034499555926302.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:36,035]\u001b[0m Trial 17 finished with value: 0.10314887258083477 and parameters: {'booster': 'dart', 'lambda': 0.07677131091611464, 'alpha': 3.0895963935804626e-08, 'subsample': 0.30519306260788936, 'colsample_bytree': 0.3796503427258969, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.07352981484630615, 'gamma': 1.7852794755058847e-05, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.9084714344826171, 'skip_drop': 0.006622360318995287}. Best is trial 17 with value: 0.10314887258083477.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:36,685]\u001b[0m Trial 18 finished with value: 0.15236360527455006 and parameters: {'booster': 'dart', 'lambda': 0.12371442152762009, 'alpha': 2.4800390368446758e-06, 'subsample': 0.3121101466160939, 'colsample_bytree': 0.4493600746623698, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.10199096563329466, 'gamma': 7.288809170964435e-06, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.5024493755101579, 'skip_drop': 1.6409954872221377e-05}. Best is trial 17 with value: 0.10314887258083477.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:37,335]\u001b[0m Trial 19 finished with value: 0.49853162059638406 and parameters: {'booster': 'dart', 'lambda': 0.042874103013027624, 'alpha': 1.2410906456974572e-08, 'subsample': 0.31292161948559805, 'colsample_bytree': 0.6527333284693181, 'max_depth': 9, 'min_child_weight': 5, 'eta': 4.274442852332271e-06, 'gamma': 1.6598802883201776e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.5007428096552613, 'skip_drop': 0.025084479022386478}. Best is trial 17 with value: 0.10314887258083477.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:37,493]\u001b[0m Trial 20 finished with value: 0.423664956015112 and parameters: {'booster': 'gbtree', 'lambda': 2.6181173205053783e-08, 'alpha': 0.004313693018575693, 'subsample': 0.5431147839658732, 'colsample_bytree': 0.4198069160993221, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.0011251983544534195, 'gamma': 2.249148387236518e-05, 'grow_policy': 'lossguide'}. Best is trial 17 with value: 0.10314887258083477.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:38,429]\u001b[0m Trial 21 finished with value: 0.16126830249046636 and parameters: {'booster': 'dart', 'lambda': 0.0004012401939769899, 'alpha': 1.893566279376835e-08, 'subsample': 0.26352012457513385, 'colsample_bytree': 0.33019461382501547, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.05108618846628779, 'gamma': 0.0018744816743723955, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 5.908890053093917e-06, 'skip_drop': 0.0080076309670729}. Best is trial 17 with value: 0.10314887258083477.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:39,381]\u001b[0m Trial 22 finished with value: 0.19600377483475134 and parameters: {'booster': 'dart', 'lambda': 0.02261815854430722, 'alpha': 1.392433441918945e-07, 'subsample': 0.36780511803502136, 'colsample_bytree': 0.2971996208825123, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.10681994872607481, 'gamma': 0.06994627963968522, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.001061811842987273, 'skip_drop': 0.019110941668281093}. Best is trial 17 with value: 0.10314887258083477.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:40,342]\u001b[0m Trial 23 finished with value: 0.11871137239427865 and parameters: {'booster': 'dart', 'lambda': 0.00042909753739834157, 'alpha': 4.825790976198788e-08, 'subsample': 0.26432220457861444, 'colsample_bytree': 0.37586742206905177, 'max_depth': 5, 'min_child_weight': 3, 'eta': 0.014662950833943877, 'gamma': 0.0014359390598939008, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 1.8758090652389667e-05, 'skip_drop': 2.732263819182964e-05}. Best is trial 17 with value: 0.10314887258083477.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:41,305]\u001b[0m Trial 24 finished with value: 0.4654045560610454 and parameters: {'booster': 'dart', 'lambda': 0.9565592702183167, 'alpha': 0.00014045757552303052, 'subsample': 0.274521757708901, 'colsample_bytree': 0.49283469616934245, 'max_depth': 5, 'min_child_weight': 3, 'eta': 0.00047487432656325785, 'gamma': 9.331249036906044e-05, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 2.927725064012881e-06, 'skip_drop': 2.961055989875409e-06}. Best is trial 17 with value: 0.10314887258083477.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:42,306]\u001b[0m Trial 25 finished with value: 0.4692139210656411 and parameters: {'booster': 'dart', 'lambda': 0.01560641239064406, 'alpha': 3.1770834863851472e-06, 'subsample': 0.3975500596335676, 'colsample_bytree': 0.3904084033866757, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.2759592155367053, 'gamma': 0.0012551109520607805, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.0319373025096522e-05, 'skip_drop': 9.094836424887634e-07}. Best is trial 17 with value: 0.10314887258083477.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:43,279]\u001b[0m Trial 26 finished with value: 0.15707817876322913 and parameters: {'booster': 'dart', 'lambda': 0.00041471130825184246, 'alpha': 6.844631073043655e-08, 'subsample': 0.28015260212600973, 'colsample_bytree': 0.6166863017695635, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.010307112978665751, 'gamma': 2.340507710495328e-06, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 1.8780206790200034e-07, 'skip_drop': 4.877433536679596e-05}. Best is trial 17 with value: 0.10314887258083477.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:44,216]\u001b[0m Trial 27 finished with value: 0.24107861835201708 and parameters: {'booster': 'dart', 'lambda': 0.17117681956472328, 'alpha': 1.7119114588692245e-06, 'subsample': 0.4907300217106403, 'colsample_bytree': 0.27603038242114775, 'max_depth': 5, 'min_child_weight': 5, 'eta': 0.008002335899613446, 'gamma': 9.448824372978735e-05, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.04327554060835042, 'skip_drop': 0.0006977221403000713}. Best is trial 17 with value: 0.10314887258083477.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:44,372]\u001b[0m Trial 28 finished with value: 0.21854951314476964 and parameters: {'booster': 'gbtree', 'lambda': 0.009247484243846303, 'alpha': 4.198984789837698e-08, 'subsample': 0.6303755796664997, 'colsample_bytree': 0.3934916407206132, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.26469956142642515, 'gamma': 0.05182496590554547, 'grow_policy': 'lossguide'}. Best is trial 17 with value: 0.10314887258083477.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 16:57:45,384]\u001b[0m Trial 29 finished with value: 0.4735641465781903 and parameters: {'booster': 'dart', 'lambda': 3.922243168858304e-06, 'alpha': 5.419452509784795e-07, 'subsample': 0.34592293940527263, 'colsample_bytree': 0.4898306974750215, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.0003357080237009458, 'gamma': 0.0009701098263677879, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 3.178520412971725e-05, 'skip_drop': 0.053422853732550825}. Best is trial 17 with value: 0.10314887258083477.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:46,375]\u001b[0m Trial 30 finished with value: 0.49743964242506256 and parameters: {'booster': 'dart', 'lambda': 1.9486799605580122e-05, 'alpha': 5.785133779057013e-07, 'subsample': 0.3435078880338874, 'colsample_bytree': 0.9799502737703873, 'max_depth': 5, 'min_child_weight': 7, 'eta': 1.8698446470185664e-05, 'gamma': 1.8613570347943607e-06, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 3.07790050381937e-07, 'skip_drop': 5.615613777367298e-07}. Best is trial 17 with value: 0.10314887258083477.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:47,360]\u001b[0m Trial 31 finished with value: 0.12856740503684938 and parameters: {'booster': 'dart', 'lambda': 0.0005692282992369415, 'alpha': 1.0590348017300707e-08, 'subsample': 0.2342951086314821, 'colsample_bytree': 0.36523263716297266, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.030938030130156405, 'gamma': 0.004375207201322149, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.0007102096174570209, 'skip_drop': 0.0032942672829964696}. Best is trial 17 with value: 0.10314887258083477.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:48,380]\u001b[0m Trial 32 finished with value: 0.12937358687886952 and parameters: {'booster': 'dart', 'lambda': 0.00017217963460560673, 'alpha': 3.867708479004273e-08, 'subsample': 0.2733354816549422, 'colsample_bytree': 0.3116216094683121, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.03371931518191317, 'gamma': 0.055016195850292604, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 5.245585017172675e-05, 'skip_drop': 0.08173442802421152}. Best is trial 17 with value: 0.10314887258083477.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:49,460]\u001b[0m Trial 33 finished with value: 0.30079481460652857 and parameters: {'booster': 'dart', 'lambda': 0.0009207028586394793, 'alpha': 2.128310741066165e-07, 'subsample': 0.20789303085890332, 'colsample_bytree': 0.2504077507530678, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.2170788495631707, 'gamma': 0.00030442738048790314, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.012052972678129072, 'skip_drop': 0.00033713473579784664}. Best is trial 17 with value: 0.10314887258083477.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:50,448]\u001b[0m Trial 34 finished with value: 0.2841001149868925 and parameters: {'booster': 'dart', 'lambda': 0.004779281016345698, 'alpha': 2.9259153746666323e-08, 'subsample': 0.40251051384126035, 'colsample_bytree': 0.4224573648685577, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.004237676431105989, 'gamma': 0.0419555022294448, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.0003708145046794565, 'skip_drop': 0.004826220040312719}. Best is trial 17 with value: 0.10314887258083477.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:50,567]\u001b[0m Trial 35 finished with value: 0.8167329662467778 and parameters: {'booster': 'gblinear', 'lambda': 0.00013136327178363776, 'alpha': 1.0788036666900806e-06, 'subsample': 0.31094844647528175, 'colsample_bytree': 0.5031177259335456}. Best is trial 17 with value: 0.10314887258083477.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:51,583]\u001b[0m Trial 36 finished with value: 0.14418779101771417 and parameters: {'booster': 'dart', 'lambda': 3.390541938283958e-08, 'alpha': 7.76171555445876e-06, 'subsample': 0.2008613517618286, 'colsample_bytree': 0.5783703035573144, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.03316212595026081, 'gamma': 0.002507387659684191, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 2.4132515477565938e-05, 'skip_drop': 1.0728774901745179e-05}. Best is trial 17 with value: 0.10314887258083477.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:51,736]\u001b[0m Trial 37 finished with value: 0.337490179156093 and parameters: {'booster': 'gbtree', 'lambda': 2.6231382722273375e-05, 'alpha': 6.016020465234448e-05, 'subsample': 0.24999609770803444, 'colsample_bytree': 0.3938177999541978, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.002874156418940169, 'gamma': 3.761684436190109e-05, 'grow_policy': 'lossguide'}. Best is trial 17 with value: 0.10314887258083477.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:51,839]\u001b[0m Trial 38 finished with value: 0.15144249183321584 and parameters: {'booster': 'gblinear', 'lambda': 4.8886561425315e-07, 'alpha': 0.1372948769754171, 'subsample': 0.43802021795148427, 'colsample_bytree': 0.8421056044749304}. Best is trial 17 with value: 0.10314887258083477.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:52,786]\u001b[0m Trial 39 finished with value: 0.44000652011149327 and parameters: {'booster': 'dart', 'lambda': 0.07899691471203758, 'alpha': 1.643902491234662e-07, 'subsample': 0.38151583572400755, 'colsample_bytree': 0.449387143301261, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.0008579040403062231, 'gamma': 0.1937319559432356, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.004304723094806602, 'skip_drop': 0.10335584556061068}. Best is trial 17 with value: 0.10314887258083477.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:52,903]\u001b[0m Trial 40 finished with value: 0.6644269593159036 and parameters: {'booster': 'gblinear', 'lambda': 2.1238347659555774e-07, 'alpha': 0.0017506664848315058, 'subsample': 0.8079093475656449, 'colsample_bytree': 0.31244215471251957}. Best is trial 17 with value: 0.10314887258083477.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:53,845]\u001b[0m Trial 41 finished with value: 0.12402830283239824 and parameters: {'booster': 'dart', 'lambda': 0.0004727148008239104, 'alpha': 1.4072863360683119e-08, 'subsample': 0.22698534245819224, 'colsample_bytree': 0.3747616069790434, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.028180999767148572, 'gamma': 0.007784141689452178, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.0006067465558178748, 'skip_drop': 0.00328412203066159}. Best is trial 17 with value: 0.10314887258083477.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:54,729]\u001b[0m Trial 42 finished with value: 0.14269890196882323 and parameters: {'booster': 'dart', 'lambda': 0.0012901895471095614, 'alpha': 5.736448500640872e-08, 'subsample': 0.2421564131357522, 'colsample_bytree': 0.358615154405388, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.08054163282588035, 'gamma': 0.015250785670183287, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.059868442646884325, 'skip_drop': 0.01208130141969114}. Best is trial 17 with value: 0.10314887258083477.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:55,643]\u001b[0m Trial 43 finished with value: 0.602728724002585 and parameters: {'booster': 'dart', 'lambda': 0.004515229358457909, 'alpha': 1.0373520742940668e-08, 'subsample': 0.2991385458669597, 'colsample_bytree': 0.5316119833304335, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.35518073105596776, 'gamma': 0.0009363241819384885, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.0009052068306847713, 'skip_drop': 0.002063372507976326}. Best is trial 17 with value: 0.10314887258083477.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:56,570]\u001b[0m Trial 44 finished with value: 0.10246014091530488 and parameters: {'booster': 'dart', 'lambda': 4.801526131925515e-05, 'alpha': 0.02189318680537028, 'subsample': 0.3521456700293498, 'colsample_bytree': 0.25831011874046156, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.02072851955898096, 'gamma': 0.005718016382264975, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.00010703153634245474, 'skip_drop': 0.0002859410440543758}. Best is trial 44 with value: 0.10246014091530488.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 16:57:57,509]\u001b[0m Trial 45 finished with value: 0.49083660836490434 and parameters: {'booster': 'dart', 'lambda': 2.7595145285004857e-06, 'alpha': 0.009253449286117463, 'subsample': 0.35339588205369266, 'colsample_bytree': 0.2393900569013534, 'max_depth': 5, 'min_child_weight': 3, 'eta': 0.00010967020185204913, 'gamma': 0.0003035493882886054, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 9.925926716721164e-07, 'skip_drop': 0.0001382429217182337}. Best is trial 44 with value: 0.10246014091530488.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:57,674]\u001b[0m Trial 46 finished with value: 0.30740748610089963 and parameters: {'booster': 'gbtree', 'lambda': 1.6844321965796355e-06, 'alpha': 0.03394448351080267, 'subsample': 0.5196395088534794, 'colsample_bytree': 0.2058659660365569, 'max_depth': 5, 'min_child_weight': 5, 'eta': 0.0035708624961020763, 'gamma': 0.0031770624229871757, 'grow_policy': 'depthwise'}. Best is trial 44 with value: 0.10246014091530488.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:58,604]\u001b[0m Trial 47 finished with value: 0.11842231739337816 and parameters: {'booster': 'dart', 'lambda': 3.855420172530245e-05, 'alpha': 0.21690351589918666, 'subsample': 0.42427686159095046, 'colsample_bytree': 0.2796206062866716, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.01716781123922869, 'gamma': 0.0005576608129610435, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 8.671426156742562e-05, 'skip_drop': 0.00010190302177641134}. Best is trial 44 with value: 0.10246014091530488.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:57:59,555]\u001b[0m Trial 48 finished with value: 0.49886322394122373 and parameters: {'booster': 'dart', 'lambda': 1.354597786345461e-05, 'alpha': 0.2086783035367683, 'subsample': 0.46715929217656693, 'colsample_bytree': 0.29737080710712593, 'max_depth': 7, 'min_child_weight': 10, 'eta': 8.964612004397745e-08, 'gamma': 0.000534993212094234, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 7.630359063006404e-05, 'skip_drop': 8.82393678049105e-05}. Best is trial 44 with value: 0.10246014091530488.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:58:00,704]\u001b[0m A new study created in memory with name: no-name-6234da23-ab7d-44e2-8f63-a8f75b69d415\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:58:20,644]\u001b[0m Trial 0 finished with value: 0.19338252783630938 and parameters: {'booster': 'dart', 'lambda': 0.0014971729645493737, 'alpha': 8.398652320741475e-05, 'subsample': 0.6562516219188832, 'colsample_bytree': 0.4150454624515108, 'max_depth': 3, 'min_child_weight': 6, 'eta': 1.4590164149446647e-07, 'gamma': 1.1145540906146994e-07, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.015595996408846582, 'skip_drop': 1.2142350605168246e-06}. Best is trial 0 with value: 0.19338252783630938.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:58:20,865]\u001b[0m Trial 1 finished with value: 0.04665146174580137 and parameters: {'booster': 'gblinear', 'lambda': 0.0385517357338039, 'alpha': 0.23798341251141522, 'subsample': 0.9612895396182344, 'colsample_bytree': 0.9488909720008922}. Best is trial 0 with value: 0.19338252783630938.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:58:21,572]\u001b[0m Trial 2 finished with value: 0.18549330454185733 and parameters: {'booster': 'gbtree', 'lambda': 0.0004431525764117286, 'alpha': 0.0006913716922453801, 'subsample': 0.6429460342502914, 'colsample_bytree': 0.3648164200662378, 'max_depth': 5, 'min_child_weight': 7, 'eta': 4.768688897117825e-08, 'gamma': 1.6970723128562735e-08, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.19338252783630938.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:58:23,206]\u001b[0m Trial 3 finished with value: 0.4705686097288118 and parameters: {'booster': 'gblinear', 'lambda': 2.712648054531067e-06, 'alpha': 1.786462436701663e-05, 'subsample': 0.47297122109527995, 'colsample_bytree': 0.5151866697480165}. Best is trial 3 with value: 0.4705686097288118.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:58:23,578]\u001b[0m Trial 4 finished with value: 0.1516066133109204 and parameters: {'booster': 'gblinear', 'lambda': 0.021645874314014886, 'alpha': 0.042653729593776064, 'subsample': 0.7159972422940737, 'colsample_bytree': 0.7750824048835232}. Best is trial 3 with value: 0.4705686097288118.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:58:24,023]\u001b[0m Trial 5 finished with value: 0.04665146174580137 and parameters: {'booster': 'gbtree', 'lambda': 0.07430410296718837, 'alpha': 6.097528007859554e-06, 'subsample': 0.3617514911570613, 'colsample_bytree': 0.40724406059408286, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.0005657621996710789, 'gamma': 0.0002913341996375243, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 0.4705686097288118.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:58:25,747]\u001b[0m Trial 6 finished with value: 0.4631687496008659 and parameters: {'booster': 'gblinear', 'lambda': 1.866222981016425e-06, 'alpha': 3.7305983774838822e-06, 'subsample': 0.4533515297635005, 'colsample_bytree': 0.9291472012073962}. Best is trial 3 with value: 0.4705686097288118.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:58:45,560]\u001b[0m Trial 7 finished with value: 0.37416187794339056 and parameters: {'booster': 'dart', 'lambda': 1.3044306392557428e-06, 'alpha': 3.3827138607687644e-05, 'subsample': 0.7521652331059223, 'colsample_bytree': 0.3457862111155059, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.011129326813386572, 'gamma': 4.93769980738307e-07, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 1.0107049094806294e-06, 'skip_drop': 5.572056411806788e-06}. Best is trial 3 with value: 0.4705686097288118.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 16:58:48,681]\u001b[0m A new study created in memory with name: no-name-7a6bd2c7-abcb-4d34-a4ce-17bee3f7cb11\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:58:49,172]\u001b[0m Trial 0 finished with value: 0.7635213717438066 and parameters: {'booster': 'gbtree', 'lambda': 0.0008865507305811274, 'alpha': 1.58424158391469e-05, 'subsample': 0.6344976321459981, 'colsample_bytree': 0.7778216521340453, 'max_depth': 7, 'min_child_weight': 4, 'eta': 3.1432897758551473e-07, 'gamma': 0.002803164357928617, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.7635213717438066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:58:51,178]\u001b[0m Trial 1 finished with value: 0.7544268674587823 and parameters: {'booster': 'dart', 'lambda': 1.6397697480335687e-08, 'alpha': 0.007176515691706494, 'subsample': 0.9724493665793543, 'colsample_bytree': 0.32229400117696355, 'max_depth': 3, 'min_child_weight': 7, 'eta': 4.9349903648642965e-05, 'gamma': 5.27303662253759e-06, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.5866971247112623, 'skip_drop': 0.023410437079216157}. Best is trial 0 with value: 0.7635213717438066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:58:51,448]\u001b[0m Trial 2 finished with value: 0.6517864665279723 and parameters: {'booster': 'gblinear', 'lambda': 3.440730779857275e-08, 'alpha': 0.001043751651796076, 'subsample': 0.5763042191845243, 'colsample_bytree': 0.2040147878367339}. Best is trial 0 with value: 0.7635213717438066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:58:51,736]\u001b[0m Trial 3 finished with value: 0.6087967757525546 and parameters: {'booster': 'gblinear', 'lambda': 4.453389336278237e-06, 'alpha': 1.0729425119874497e-06, 'subsample': 0.5723940912501222, 'colsample_bytree': 0.8056022364325881}. Best is trial 0 with value: 0.7635213717438066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:58:52,020]\u001b[0m Trial 4 finished with value: 0.6074920407411216 and parameters: {'booster': 'gblinear', 'lambda': 1.3919288356980265e-08, 'alpha': 3.806441654984536e-05, 'subsample': 0.6800816667393834, 'colsample_bytree': 0.9371720722662926}. Best is trial 0 with value: 0.7635213717438066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:58:52,119]\u001b[0m Trial 5 finished with value: 0.3988642697881828 and parameters: {'booster': 'gblinear', 'lambda': 0.0005428026273836474, 'alpha': 0.3738028052741019, 'subsample': 0.22503127672456902, 'colsample_bytree': 0.9681468986155364}. Best is trial 0 with value: 0.7635213717438066.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 16:58:56,160]\u001b[0m Trial 6 finished with value: 0.7490338414540543 and parameters: {'booster': 'dart', 'lambda': 3.0443126873270926e-06, 'alpha': 0.000395840761125542, 'subsample': 0.3381593890911363, 'colsample_bytree': 0.36482421814916627, 'max_depth': 9, 'min_child_weight': 8, 'eta': 2.9112359918436738e-08, 'gamma': 0.00010574548415014525, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.007401229920299203, 'skip_drop': 8.126302154909596e-08}. Best is trial 0 with value: 0.7635213717438066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:00,459]\u001b[0m Trial 7 finished with value: 0.7689919952450057 and parameters: {'booster': 'dart', 'lambda': 1.8144457010564274e-05, 'alpha': 0.013606748656556138, 'subsample': 0.6089579172518143, 'colsample_bytree': 0.6627633298029233, 'max_depth': 9, 'min_child_weight': 9, 'eta': 8.934712235207984e-08, 'gamma': 0.5361169614523819, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.722519444600921e-07, 'skip_drop': 6.969003691614781e-08}. Best is trial 7 with value: 0.7689919952450057.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:00,749]\u001b[0m Trial 8 finished with value: 0.6210146917962588 and parameters: {'booster': 'gblinear', 'lambda': 1.9822952175145805e-06, 'alpha': 0.00043634970487209645, 'subsample': 0.5983401731253111, 'colsample_bytree': 0.487988799882368}. Best is trial 7 with value: 0.7689919952450057.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:01,054]\u001b[0m Trial 9 finished with value: 0.6105560923739431 and parameters: {'booster': 'gblinear', 'lambda': 7.812517041641777e-08, 'alpha': 9.172233068072039e-06, 'subsample': 0.6978604798855753, 'colsample_bytree': 0.8125024886050036}. Best is trial 7 with value: 0.7689919952450057.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:05,285]\u001b[0m Trial 10 finished with value: 0.7206087562369734 and parameters: {'booster': 'dart', 'lambda': 0.2830142933447616, 'alpha': 1.2461885628937226e-08, 'subsample': 0.9106189729301465, 'colsample_bytree': 0.6191747412476325, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.718043098817063, 'gamma': 0.8429198253074329, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 2.4427666171521887e-08, 'skip_drop': 1.4049132217573674e-08}. Best is trial 7 with value: 0.7689919952450057.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:05,837]\u001b[0m Trial 11 finished with value: 0.7640819555011227 and parameters: {'booster': 'gbtree', 'lambda': 0.0023442323700433613, 'alpha': 0.10102182686903656, 'subsample': 0.775495317696874, 'colsample_bytree': 0.6191254656515662, 'max_depth': 7, 'min_child_weight': 3, 'eta': 2.6447878238732088e-08, 'gamma': 0.2441055704464501, 'grow_policy': 'lossguide'}. Best is trial 7 with value: 0.7689919952450057.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:06,388]\u001b[0m Trial 12 finished with value: 0.7650383291614519 and parameters: {'booster': 'gbtree', 'lambda': 0.02303224213019093, 'alpha': 0.3614764590889234, 'subsample': 0.8118393035739664, 'colsample_bytree': 0.5783573924044066, 'max_depth': 7, 'min_child_weight': 2, 'eta': 1.5623962961765055e-08, 'gamma': 0.5951097047415983, 'grow_policy': 'lossguide'}. Best is trial 7 with value: 0.7689919952450057.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:06,858]\u001b[0m Trial 13 finished with value: 0.7490348795672587 and parameters: {'booster': 'gbtree', 'lambda': 0.14412887526939044, 'alpha': 0.04223670274363763, 'subsample': 0.8312401842556892, 'colsample_bytree': 0.5382569151445442, 'max_depth': 5, 'min_child_weight': 2, 'eta': 5.1768860088634175e-06, 'gamma': 3.125806769254471e-08, 'grow_policy': 'lossguide'}. Best is trial 7 with value: 0.7689919952450057.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:11,200]\u001b[0m Trial 14 finished with value: 0.7694370024494795 and parameters: {'booster': 'dart', 'lambda': 0.023381554583497714, 'alpha': 0.7449402316322015, 'subsample': 0.4645372404652895, 'colsample_bytree': 0.7439626926454612, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.008403310028396112, 'gamma': 0.015984979753103357, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.773361661558925e-07, 'skip_drop': 2.999410893054244e-05}. Best is trial 14 with value: 0.7694370024494795.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:15,613]\u001b[0m Trial 15 finished with value: 0.7694699656135825 and parameters: {'booster': 'dart', 'lambda': 4.86734225665237e-05, 'alpha': 0.020870291055869832, 'subsample': 0.446541734990317, 'colsample_bytree': 0.7131195651530722, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.016856793615099112, 'gamma': 0.005242669010287163, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 2.1672480137317023e-07, 'skip_drop': 1.990870986608866e-05}. Best is trial 15 with value: 0.7694699656135825.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:19,994]\u001b[0m Trial 16 finished with value: 0.7645840331429851 and parameters: {'booster': 'dart', 'lambda': 0.009048316310413734, 'alpha': 0.4974424945670853, 'subsample': 0.45033538261869976, 'colsample_bytree': 0.7239806242945437, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.01748307993829405, 'gamma': 0.004119431355920707, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 3.625726209989185e-06, 'skip_drop': 0.00010130972885699321}. Best is trial 15 with value: 0.7694699656135825.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:24,399]\u001b[0m Trial 17 finished with value: 0.7635985693050911 and parameters: {'booster': 'dart', 'lambda': 0.0001336849442329108, 'alpha': 0.004819755311038234, 'subsample': 0.44508119140466534, 'colsample_bytree': 0.8940872650611433, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.0031769076725389044, 'gamma': 0.005069511223117456, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.3355781953961209e-05, 'skip_drop': 4.2662688970337405e-05}. Best is trial 15 with value: 0.7694699656135825.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 16:59:29,962]\u001b[0m A new study created in memory with name: no-name-9ef8f041-e9c5-4ffb-a2a4-6247c53904c3\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:30,153]\u001b[0m Trial 0 finished with value: 0.5473067817302676 and parameters: {'booster': 'gbtree', 'lambda': 7.804059088614913e-08, 'alpha': 0.15791248636788457, 'subsample': 0.9594868111443113, 'colsample_bytree': 0.8640043807491791, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.14359983131146523, 'gamma': 0.14448140136965307, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.5473067817302676.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:30,336]\u001b[0m Trial 1 finished with value: 1.4918558316558257 and parameters: {'booster': 'gbtree', 'lambda': 8.858318071528227e-07, 'alpha': 8.667474726337282e-08, 'subsample': 0.5984306285841807, 'colsample_bytree': 0.9262660377595968, 'max_depth': 3, 'min_child_weight': 8, 'eta': 3.399408170389128e-05, 'gamma': 5.21572976720148e-07, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.5473067817302676.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:30,485]\u001b[0m Trial 2 finished with value: 1.3638097555947521 and parameters: {'booster': 'gbtree', 'lambda': 0.023434436419980578, 'alpha': 0.002025555722294612, 'subsample': 0.511658830198496, 'colsample_bytree': 0.47009491622231164, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.0010412709770221673, 'gamma': 0.2953185253899859, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.5473067817302676.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:30,987]\u001b[0m Trial 3 finished with value: 0.6018523169162456 and parameters: {'booster': 'gbtree', 'lambda': 0.00018929932756536863, 'alpha': 6.383164273930776e-08, 'subsample': 0.9678073043875315, 'colsample_bytree': 0.6447258832554241, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.017117555463176694, 'gamma': 5.515016300024627e-07, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.5473067817302676.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 16:59:31,105]\u001b[0m Trial 4 finished with value: 0.5181499846410568 and parameters: {'booster': 'gblinear', 'lambda': 0.001503400680987078, 'alpha': 6.466988771713976e-07, 'subsample': 0.9863710071237226, 'colsample_bytree': 0.2683365706718503}. Best is trial 4 with value: 0.5181499846410568.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:32,460]\u001b[0m Trial 5 finished with value: 1.4396153514761842 and parameters: {'booster': 'dart', 'lambda': 0.0008487546849923034, 'alpha': 1.644591726410706e-06, 'subsample': 0.832311440317083, 'colsample_bytree': 0.8562826616568864, 'max_depth': 7, 'min_child_weight': 5, 'eta': 0.00034240592084106784, 'gamma': 2.053975685879292e-07, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 2.9857675890275648e-05, 'skip_drop': 8.387498815206392e-08}. Best is trial 4 with value: 0.5181499846410568.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:32,694]\u001b[0m Trial 6 finished with value: 0.4774409678156282 and parameters: {'booster': 'gblinear', 'lambda': 1.5552290142660411e-07, 'alpha': 0.020803253599794225, 'subsample': 0.6947490791393718, 'colsample_bytree': 0.5075949161537189}. Best is trial 6 with value: 0.4774409678156282.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:32,907]\u001b[0m Trial 7 finished with value: 1.4738714343344805 and parameters: {'booster': 'gbtree', 'lambda': 1.3110544636796792e-08, 'alpha': 0.07903548359848499, 'subsample': 0.8515546872306325, 'colsample_bytree': 0.35105569829377753, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.0001623623097754986, 'gamma': 0.005555915716469482, 'grow_policy': 'depthwise'}. Best is trial 6 with value: 0.4774409678156282.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:33,013]\u001b[0m Trial 8 finished with value: 0.537719799358593 and parameters: {'booster': 'gblinear', 'lambda': 1.7323036664558466e-08, 'alpha': 2.3596667139062366e-05, 'subsample': 0.4621958018260139, 'colsample_bytree': 0.6099549410575446}. Best is trial 6 with value: 0.4774409678156282.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:33,226]\u001b[0m Trial 9 finished with value: 1.4969935227301165 and parameters: {'booster': 'gbtree', 'lambda': 1.7512828644374611e-06, 'alpha': 0.0010855398262459583, 'subsample': 0.8293902689074253, 'colsample_bytree': 0.2726015783466263, 'max_depth': 7, 'min_child_weight': 9, 'eta': 1.1444682643320836e-06, 'gamma': 7.585029456258883e-08, 'grow_policy': 'lossguide'}. Best is trial 6 with value: 0.4774409678156282.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:33,325]\u001b[0m Trial 10 finished with value: 1.2854298219677416 and parameters: {'booster': 'gblinear', 'lambda': 5.656413790650411e-06, 'alpha': 0.7722931256616982, 'subsample': 0.2896589847465819, 'colsample_bytree': 0.4909589265779477}. Best is trial 6 with value: 0.4774409678156282.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:33,469]\u001b[0m Trial 11 finished with value: 0.6204750712715807 and parameters: {'booster': 'gblinear', 'lambda': 0.5962578582127236, 'alpha': 6.074419649375008e-06, 'subsample': 0.675222454115193, 'colsample_bytree': 0.20173140923126007}. Best is trial 6 with value: 0.4774409678156282.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:33,597]\u001b[0m Trial 12 finished with value: 0.47320212284091173 and parameters: {'booster': 'gblinear', 'lambda': 0.00860642427084093, 'alpha': 0.0013163758352816096, 'subsample': 0.7010940518376593, 'colsample_bytree': 0.4195633880097819}. Best is trial 12 with value: 0.47320212284091173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:33,720]\u001b[0m Trial 13 finished with value: 0.4638670636852222 and parameters: {'booster': 'gblinear', 'lambda': 0.013157363491300651, 'alpha': 0.0019829716204289452, 'subsample': 0.6933964987735644, 'colsample_bytree': 0.4559762094016265}. Best is trial 13 with value: 0.4638670636852222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:34,825]\u001b[0m Trial 14 finished with value: 1.4971496754472629 and parameters: {'booster': 'dart', 'lambda': 0.02058426020787151, 'alpha': 0.0002700232963880254, 'subsample': 0.7195635341824345, 'colsample_bytree': 0.7141493194045176, 'max_depth': 9, 'min_child_weight': 2, 'eta': 3.542284232068325e-08, 'gamma': 0.00010288933071016933, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.8798062689918404, 'skip_drop': 0.6638005051293686}. Best is trial 13 with value: 0.4638670636852222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:34,949]\u001b[0m Trial 15 finished with value: 0.6810544482275966 and parameters: {'booster': 'gblinear', 'lambda': 0.8361822912483983, 'alpha': 0.007046166904266554, 'subsample': 0.3954760007963074, 'colsample_bytree': 0.4065574870161348}. Best is trial 13 with value: 0.4638670636852222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:35,077]\u001b[0m Trial 16 finished with value: 0.4788305917567654 and parameters: {'booster': 'gblinear', 'lambda': 0.026149097001385554, 'alpha': 7.420879574229644e-05, 'subsample': 0.5896054543131288, 'colsample_bytree': 0.3586833420134218}. Best is trial 13 with value: 0.4638670636852222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:35,204]\u001b[0m Trial 17 finished with value: 0.5246210115571072 and parameters: {'booster': 'gblinear', 'lambda': 4.7666506510104686e-05, 'alpha': 0.00039836062424246295, 'subsample': 0.7600690620334011, 'colsample_bytree': 0.7443635882393419}. Best is trial 13 with value: 0.4638670636852222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:36,413]\u001b[0m Trial 18 finished with value: 1.497154389933185 and parameters: {'booster': 'dart', 'lambda': 0.00296797525461205, 'alpha': 0.006311711133848038, 'subsample': 0.5422158048184578, 'colsample_bytree': 0.5733564118034806, 'max_depth': 5, 'min_child_weight': 10, 'eta': 1.0139749782513221e-08, 'gamma': 5.5295778376254014e-05, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 4.692756962914064e-08, 'skip_drop': 0.005180442547529617}. Best is trial 13 with value: 0.4638670636852222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:36,536]\u001b[0m Trial 19 finished with value: 0.5088661525301174 and parameters: {'booster': 'gblinear', 'lambda': 0.12240326648311566, 'alpha': 4.8969434468832864e-05, 'subsample': 0.3801377016705141, 'colsample_bytree': 0.4374391143703745}. Best is trial 13 with value: 0.4638670636852222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:36,651]\u001b[0m Trial 20 finished with value: 0.5577233041800714 and parameters: {'booster': 'gblinear', 'lambda': 8.71028268423316e-05, 'alpha': 0.034379457604103866, 'subsample': 0.20147193389603724, 'colsample_bytree': 0.525599504012162}. Best is trial 13 with value: 0.4638670636852222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:36,775]\u001b[0m Trial 21 finished with value: 0.446356428616257 and parameters: {'booster': 'gblinear', 'lambda': 0.00471510421212595, 'alpha': 0.008763208127400274, 'subsample': 0.6653674814491662, 'colsample_bytree': 0.5526023705856711}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:36,900]\u001b[0m Trial 22 finished with value: 0.4695650947586766 and parameters: {'booster': 'gblinear', 'lambda': 0.005023585745498667, 'alpha': 0.002007049514909695, 'subsample': 0.6496400382071862, 'colsample_bytree': 0.6780673676215487}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:37,022]\u001b[0m Trial 23 finished with value: 0.5206245545675239 and parameters: {'booster': 'gblinear', 'lambda': 0.13502872712961858, 'alpha': 0.006458859821858287, 'subsample': 0.6496775918968798, 'colsample_bytree': 0.6903745007972055}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:37,123]\u001b[0m Trial 24 finished with value: 1.2854298219677416 and parameters: {'booster': 'gblinear', 'lambda': 0.00034312032816290937, 'alpha': 0.37086357628773114, 'subsample': 0.7755878934526178, 'colsample_bytree': 0.7717403683032845}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:37,582]\u001b[0m Trial 25 finished with value: 0.5655828389617318 and parameters: {'booster': 'dart', 'lambda': 0.09181607690982098, 'alpha': 0.00033949797959928983, 'subsample': 0.6217827875385257, 'colsample_bytree': 0.5965091745595421, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.8783443967294039, 'gamma': 5.42097917785973e-05, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.8603734850270158, 'skip_drop': 2.787332882172288e-08}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 16:59:37,701]\u001b[0m Trial 26 finished with value: 0.49492020791658564 and parameters: {'booster': 'gblinear', 'lambda': 0.003917070023798744, 'alpha': 0.023097196975196785, 'subsample': 0.5268547316835502, 'colsample_bytree': 0.5463655736415411}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:37,824]\u001b[0m Trial 27 finished with value: 0.4605709268515402 and parameters: {'booster': 'gblinear', 'lambda': 0.0007154698072173713, 'alpha': 0.003180151718419205, 'subsample': 0.7624769719372699, 'colsample_bytree': 0.6412085688456427}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:37,929]\u001b[0m Trial 28 finished with value: 0.8422051505275233 and parameters: {'booster': 'gblinear', 'lambda': 1.9035619391012384e-05, 'alpha': 0.12417775766144634, 'subsample': 0.9003055191729907, 'colsample_bytree': 0.7861555084540227}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:39,194]\u001b[0m Trial 29 finished with value: 1.496731190212576 and parameters: {'booster': 'dart', 'lambda': 0.0003997237053964115, 'alpha': 1.3376711635879676e-08, 'subsample': 0.7695019167887128, 'colsample_bytree': 0.9836100712006174, 'max_depth': 5, 'min_child_weight': 10, 'eta': 2.49482717529247e-06, 'gamma': 0.011413136367713234, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.0829364038359195e-08, 'skip_drop': 4.7080779748872814e-05}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:39,319]\u001b[0m Trial 30 finished with value: 0.514710964464431 and parameters: {'booster': 'gblinear', 'lambda': 0.0010837509190328848, 'alpha': 0.00020497532704512542, 'subsample': 0.8835348030588255, 'colsample_bytree': 0.835772056893659}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:39,443]\u001b[0m Trial 31 finished with value: 0.454639521658768 and parameters: {'booster': 'gblinear', 'lambda': 0.006160824546997043, 'alpha': 0.003626008901273593, 'subsample': 0.7399416422997689, 'colsample_bytree': 0.6569744489456995}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:39,568]\u001b[0m Trial 32 finished with value: 0.44902301324900973 and parameters: {'booster': 'gblinear', 'lambda': 0.01122208856639137, 'alpha': 0.005675652869652833, 'subsample': 0.7510193777841834, 'colsample_bytree': 0.6656946523360373}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:39,689]\u001b[0m Trial 33 finished with value: 0.483939965324893 and parameters: {'booster': 'gblinear', 'lambda': 0.05495679087907975, 'alpha': 0.008915060526799351, 'subsample': 0.7821763143180916, 'colsample_bytree': 0.6597470890464753}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:40,042]\u001b[0m Trial 34 finished with value: 0.8436178829115474 and parameters: {'booster': 'gbtree', 'lambda': 0.0017368070013753197, 'alpha': 0.07708557051373323, 'subsample': 0.5780905813134926, 'colsample_bytree': 0.6329971584661154, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.006827722132007534, 'gamma': 1.9253989263353526e-08, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:40,143]\u001b[0m Trial 35 finished with value: 1.1524370874170657 and parameters: {'booster': 'gblinear', 'lambda': 0.0003346510965501184, 'alpha': 0.2757486757379476, 'subsample': 0.9196677869683694, 'colsample_bytree': 0.5635195353272642}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:40,267]\u001b[0m Trial 36 finished with value: 0.477546104654964 and parameters: {'booster': 'gblinear', 'lambda': 0.007546724579022837, 'alpha': 0.0009048700861113114, 'subsample': 0.7426443305662738, 'colsample_bytree': 0.7215278933218519}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:40,521]\u001b[0m Trial 37 finished with value: 1.497113692342046 and parameters: {'booster': 'gbtree', 'lambda': 0.0007724985519251561, 'alpha': 0.0137046910657183, 'subsample': 0.8074951232067472, 'colsample_bytree': 0.8112128917835264, 'max_depth': 5, 'min_child_weight': 6, 'eta': 2.524830259628813e-07, 'gamma': 0.0009373230716611477, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:40,642]\u001b[0m Trial 38 finished with value: 0.5516092832479637 and parameters: {'booster': 'gblinear', 'lambda': 0.23753399565466263, 'alpha': 0.003972283039323229, 'subsample': 0.9523526630401018, 'colsample_bytree': 0.6152773448489555}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:40,754]\u001b[0m Trial 39 finished with value: 0.6031343058108158 and parameters: {'booster': 'gblinear', 'lambda': 0.029330139288285824, 'alpha': 0.038546961052383054, 'subsample': 0.6280438302952134, 'colsample_bytree': 0.8867527297726965}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:42,042]\u001b[0m Trial 40 finished with value: 1.4948951949397928 and parameters: {'booster': 'dart', 'lambda': 0.0001135792712460733, 'alpha': 1.686154512674087e-05, 'subsample': 0.8550513324747024, 'colsample_bytree': 0.6486870110817963, 'max_depth': 7, 'min_child_weight': 8, 'eta': 1.3345166429364363e-05, 'gamma': 4.9092583942827915e-06, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.0002671933124552441, 'skip_drop': 1.1254581573447438e-05}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:42,168]\u001b[0m Trial 41 finished with value: 0.45825385035536953 and parameters: {'booster': 'gblinear', 'lambda': 0.012118413751196945, 'alpha': 0.002888855026741252, 'subsample': 0.7247681951968271, 'colsample_bytree': 0.4626296583980976}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:42,290]\u001b[0m Trial 42 finished with value: 0.45618246808382273 and parameters: {'booster': 'gblinear', 'lambda': 0.002635761684950505, 'alpha': 0.003285507647596836, 'subsample': 0.7305492787871288, 'colsample_bytree': 0.5119285984234824}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:42,412]\u001b[0m Trial 43 finished with value: 0.47719119724378134 and parameters: {'booster': 'gblinear', 'lambda': 0.04609115797934611, 'alpha': 0.0008202901518088518, 'subsample': 0.7281894885664163, 'colsample_bytree': 0.5053337682126979}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:42,577]\u001b[0m Trial 44 finished with value: 1.1887601589391215 and parameters: {'booster': 'gbtree', 'lambda': 0.0021458287935300076, 'alpha': 0.014727108727385153, 'subsample': 0.6664189231397801, 'colsample_bytree': 0.38653949586608516, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.0028180630065390436, 'gamma': 0.7277382810435045, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:42,685]\u001b[0m Trial 45 finished with value: 0.6006216071640864 and parameters: {'booster': 'gblinear', 'lambda': 0.008949066832390856, 'alpha': 0.04091805670532217, 'subsample': 0.7954490295328606, 'colsample_bytree': 0.5325489013292022}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:42,809]\u001b[0m Trial 46 finished with value: 0.5534613103982421 and parameters: {'booster': 'gblinear', 'lambda': 0.2674802907390117, 'alpha': 0.0006252911444109407, 'subsample': 0.8307802402657933, 'colsample_bytree': 0.47284263816973243}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:42,929]\u001b[0m Trial 47 finished with value: 0.45792317494982865 and parameters: {'booster': 'gblinear', 'lambda': 0.01793195139204479, 'alpha': 0.0034183635937376834, 'subsample': 0.715478485544209, 'colsample_bytree': 0.5660480732031383}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:43,052]\u001b[0m Trial 48 finished with value: 0.4967455910290303 and parameters: {'booster': 'gblinear', 'lambda': 0.0039588130410894845, 'alpha': 0.0001364064102408372, 'subsample': 0.4837829802487825, 'colsample_bytree': 0.5823580480992105}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:43,374]\u001b[0m Trial 49 finished with value: 0.555858576919863 and parameters: {'booster': 'gbtree', 'lambda': 0.019047424008727915, 'alpha': 2.65448420550369e-06, 'subsample': 0.6968487645106523, 'colsample_bytree': 0.7004589007828399, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.03484416790885284, 'gamma': 7.0902951795574435e-06, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 16:59:43,496]\u001b[0m Trial 50 finished with value: 0.48642682776423185 and parameters: {'booster': 'gblinear', 'lambda': 0.06258475944142529, 'alpha': 2.0374763912820743e-07, 'subsample': 0.5673587508605442, 'colsample_bytree': 0.6096514273865096}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:43,616]\u001b[0m Trial 51 finished with value: 0.4585172581660805 and parameters: {'booster': 'gblinear', 'lambda': 0.012980013172292314, 'alpha': 0.003227441944169727, 'subsample': 0.7289541891607972, 'colsample_bytree': 0.4998415889242752}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:43,736]\u001b[0m Trial 52 finished with value: 0.4632870553494013 and parameters: {'booster': 'gblinear', 'lambda': 0.005983365620459486, 'alpha': 0.0022468492873247954, 'subsample': 0.6925755537195207, 'colsample_bytree': 0.45239027386909875}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:43,841]\u001b[0m Trial 53 finished with value: 0.751228906061418 and parameters: {'booster': 'gblinear', 'lambda': 0.030680365149368827, 'alpha': 0.0744028366568289, 'subsample': 0.6313883491880283, 'colsample_bytree': 0.3219841702319514}. Best is trial 21 with value: 0.446356428616257.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:43,958]\u001b[0m Trial 54 finished with value: 0.44578697984238846 and parameters: {'booster': 'gblinear', 'lambda': 8.285060106829508e-08, 'alpha': 0.01147500280029035, 'subsample': 0.8100940679151263, 'colsample_bytree': 0.5504170836548526}. Best is trial 54 with value: 0.44578697984238846.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:44,075]\u001b[0m Trial 55 finished with value: 0.4488214006909519 and parameters: {'booster': 'gblinear', 'lambda': 4.042102856273576e-07, 'alpha': 0.012785153121738377, 'subsample': 0.8036339201219828, 'colsample_bytree': 0.554454910006293}. Best is trial 54 with value: 0.44578697984238846.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:44,193]\u001b[0m Trial 56 finished with value: 0.44516242469587175 and parameters: {'booster': 'gblinear', 'lambda': 2.179274240692007e-07, 'alpha': 0.010755059369610107, 'subsample': 0.8609776797408852, 'colsample_bytree': 0.5426304859132068}. Best is trial 56 with value: 0.44516242469587175.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:44,311]\u001b[0m Trial 57 finished with value: 0.4445984722870086 and parameters: {'booster': 'gblinear', 'lambda': 2.0588133336108068e-07, 'alpha': 0.010348129921206636, 'subsample': 0.8671267126577318, 'colsample_bytree': 0.7419444041227468}. Best is trial 57 with value: 0.4445984722870086.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:45,513]\u001b[0m Trial 58 finished with value: 1.4971195815054947 and parameters: {'booster': 'dart', 'lambda': 1.7409269538603413e-07, 'alpha': 0.011692797812541837, 'subsample': 0.9763117011285004, 'colsample_bytree': 0.7252328766920609, 'max_depth': 5, 'min_child_weight': 3, 'eta': 2.2212499915786802e-07, 'gamma': 0.01742388352687847, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.00027427405092216993, 'skip_drop': 0.9362601629760241}. Best is trial 57 with value: 0.4445984722870086.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:45,613]\u001b[0m Trial 59 finished with value: 0.9599146256787248 and parameters: {'booster': 'gblinear', 'lambda': 4.52832862628586e-08, 'alpha': 0.18773134663215374, 'subsample': 0.8579916538268288, 'colsample_bytree': 0.7561417820126428}. Best is trial 57 with value: 0.4445984722870086.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:45,708]\u001b[0m Trial 60 finished with value: 1.2854298219677416 and parameters: {'booster': 'gblinear', 'lambda': 3.460550436868145e-07, 'alpha': 0.5291654621635828, 'subsample': 0.9364081392215307, 'colsample_bytree': 0.5467785799741469}. Best is trial 57 with value: 0.4445984722870086.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:45,820]\u001b[0m Trial 61 finished with value: 0.5044450151938119 and parameters: {'booster': 'gblinear', 'lambda': 1.1609284006302597e-06, 'alpha': 0.02596401512259503, 'subsample': 0.8122223219839128, 'colsample_bytree': 0.6862959108472207}. Best is trial 57 with value: 0.4445984722870086.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:45,941]\u001b[0m Trial 62 finished with value: 0.44872554080566024 and parameters: {'booster': 'gblinear', 'lambda': 4.57247041745543e-08, 'alpha': 0.005616163524368151, 'subsample': 0.8627639654383144, 'colsample_bytree': 0.6026446424894726}. Best is trial 57 with value: 0.4445984722870086.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:46,048]\u001b[0m Trial 63 finished with value: 0.6786794282672158 and parameters: {'booster': 'gblinear', 'lambda': 3.40359468683913e-08, 'alpha': 0.05699109143375742, 'subsample': 0.8830812917440436, 'colsample_bytree': 0.596120400885897}. Best is trial 57 with value: 0.4445984722870086.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:46,166]\u001b[0m Trial 64 finished with value: 0.446609482989944 and parameters: {'booster': 'gblinear', 'lambda': 3.306618712748668e-07, 'alpha': 0.007178039336223324, 'subsample': 0.8462469338554206, 'colsample_bytree': 0.5460192558477716}. Best is trial 57 with value: 0.4445984722870086.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:46,281]\u001b[0m Trial 65 finished with value: 0.4638769482470332 and parameters: {'booster': 'gblinear', 'lambda': 3.14181411315805e-06, 'alpha': 0.01748704671705173, 'subsample': 0.996081692175846, 'colsample_bytree': 0.43083749900993273}. Best is trial 57 with value: 0.4445984722870086.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:46,399]\u001b[0m Trial 66 finished with value: 0.44446442444744794 and parameters: {'booster': 'gblinear', 'lambda': 4.181559345195423e-07, 'alpha': 0.008933814547527012, 'subsample': 0.874112217730363, 'colsample_bytree': 0.5399798829432956}. Best is trial 66 with value: 0.44446442444744794.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:46,523]\u001b[0m Trial 67 finished with value: 0.4863926729748686 and parameters: {'booster': 'gblinear', 'lambda': 1.207793624799284e-07, 'alpha': 0.0015722892906629405, 'subsample': 0.899845623707129, 'colsample_bytree': 0.4861852671208195}. Best is trial 66 with value: 0.44446442444744794.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:46,626]\u001b[0m Trial 68 finished with value: 0.8782007503148763 and parameters: {'booster': 'gblinear', 'lambda': 1.2775044748216318e-08, 'alpha': 0.14475360942327764, 'subsample': 0.8756718540687635, 'colsample_bytree': 0.528842416223241}. Best is trial 66 with value: 0.44446442444744794.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:47,857]\u001b[0m Trial 69 finished with value: 0.8731241863211759 and parameters: {'booster': 'dart', 'lambda': 5.18978718594098e-07, 'alpha': 0.007571541356671777, 'subsample': 0.8384697444584708, 'colsample_bytree': 0.6225726402162202, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.7586905904497845, 'gamma': 0.0008073709310955335, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 2.0934902767243663e-06, 'skip_drop': 0.004659740911347436}. Best is trial 66 with value: 0.44446442444744794.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:48,026]\u001b[0m Trial 70 finished with value: 1.4916819393378953 and parameters: {'booster': 'gbtree', 'lambda': 2.8733935062280404e-08, 'alpha': 0.0005350573439402864, 'subsample': 0.9114945605180338, 'colsample_bytree': 0.4029134611303268, 'max_depth': 3, 'min_child_weight': 7, 'eta': 4.005756876428396e-05, 'gamma': 1.1264632210817124e-08, 'grow_policy': 'depthwise'}. Best is trial 66 with value: 0.44446442444744794.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:48,140]\u001b[0m Trial 71 finished with value: 0.47544382491772885 and parameters: {'booster': 'gblinear', 'lambda': 7.377314896110675e-08, 'alpha': 0.02029994584384614, 'subsample': 0.9383755375156013, 'colsample_bytree': 0.5540743424416742}. Best is trial 66 with value: 0.44446442444744794.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:48,258]\u001b[0m Trial 72 finished with value: 0.4446086196044812 and parameters: {'booster': 'gblinear', 'lambda': 2.4982123307601916e-07, 'alpha': 0.008544160899637953, 'subsample': 0.8534909917201273, 'colsample_bytree': 0.5762323446894578}. Best is trial 66 with value: 0.44446442444744794.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:48,382]\u001b[0m Trial 73 finished with value: 0.49096861338385434 and parameters: {'booster': 'gblinear', 'lambda': 2.0619698716953032e-07, 'alpha': 0.001355927693610757, 'subsample': 0.863433961810518, 'colsample_bytree': 0.583255531623605}. Best is trial 66 with value: 0.44446442444744794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 16:59:48,502]\u001b[0m Trial 74 finished with value: 0.44767055487693863 and parameters: {'booster': 'gblinear', 'lambda': 7.669711380469837e-08, 'alpha': 0.006266248099038254, 'subsample': 0.8360449310523954, 'colsample_bytree': 0.5275456014835251}. Best is trial 66 with value: 0.44446442444744794.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:48,610]\u001b[0m Trial 75 finished with value: 0.6148199371217674 and parameters: {'booster': 'gblinear', 'lambda': 7.414549217661811e-07, 'alpha': 0.04514730889502883, 'subsample': 0.8290878381759922, 'colsample_bytree': 0.47669373504512136}. Best is trial 66 with value: 0.44446442444744794.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:48,725]\u001b[0m Trial 76 finished with value: 0.44409683832350066 and parameters: {'booster': 'gblinear', 'lambda': 1.7879821389852961e-06, 'alpha': 0.008878146589581486, 'subsample': 0.7865304307341106, 'colsample_bytree': 0.5749414366013252}. Best is trial 76 with value: 0.44409683832350066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:48,833]\u001b[0m Trial 77 finished with value: 0.5272351331176829 and parameters: {'booster': 'gblinear', 'lambda': 9.376720337638067e-06, 'alpha': 0.029846997874034994, 'subsample': 0.8907054375070507, 'colsample_bytree': 0.5102714731339252}. Best is trial 76 with value: 0.44409683832350066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:48,939]\u001b[0m Trial 78 finished with value: 0.7908350900766521 and parameters: {'booster': 'gblinear', 'lambda': 2.620669726151771e-06, 'alpha': 0.09148199242495748, 'subsample': 0.7846444531019008, 'colsample_bytree': 0.5788143796084544}. Best is trial 76 with value: 0.44409683832350066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:49,037]\u001b[0m Trial 79 finished with value: 1.2854298219677416 and parameters: {'booster': 'gblinear', 'lambda': 2.755636239633939e-07, 'alpha': 0.9591760721725727, 'subsample': 0.8113507975881233, 'colsample_bytree': 0.6344989784029581}. Best is trial 76 with value: 0.44409683832350066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:49,155]\u001b[0m Trial 80 finished with value: 0.4446933342223953 and parameters: {'booster': 'gblinear', 'lambda': 8.718285596114823e-07, 'alpha': 0.008354105719885619, 'subsample': 0.9234137421263771, 'colsample_bytree': 0.5319786008710117}. Best is trial 76 with value: 0.44409683832350066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:49,272]\u001b[0m Trial 81 finished with value: 0.4444493808756037 and parameters: {'booster': 'gblinear', 'lambda': 1.0478560920788733e-06, 'alpha': 0.010113602966063678, 'subsample': 0.9288598431420134, 'colsample_bytree': 0.5394714159447738}. Best is trial 76 with value: 0.44409683832350066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:49,392]\u001b[0m Trial 82 finished with value: 0.44436912471618084 and parameters: {'booster': 'gblinear', 'lambda': 1.0605322489962318e-06, 'alpha': 0.00992226461029709, 'subsample': 0.9652189427862753, 'colsample_bytree': 0.49165918182889445}. Best is trial 76 with value: 0.44409683832350066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:49,509]\u001b[0m Trial 83 finished with value: 0.4446610208194733 and parameters: {'booster': 'gblinear', 'lambda': 1.6159512803811735e-06, 'alpha': 0.010527438333205626, 'subsample': 0.9487856854660213, 'colsample_bytree': 0.45268365133916505}. Best is trial 76 with value: 0.44409683832350066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:49,623]\u001b[0m Trial 84 finished with value: 0.4724744704598888 and parameters: {'booster': 'gblinear', 'lambda': 1.0563759703039629e-06, 'alpha': 0.01967448424979188, 'subsample': 0.9533950443973837, 'colsample_bytree': 0.4508993581921364}. Best is trial 76 with value: 0.44409683832350066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:49,743]\u001b[0m Trial 85 finished with value: 0.45097154231314546 and parameters: {'booster': 'gblinear', 'lambda': 5.558649403952263e-06, 'alpha': 0.004772512341683146, 'subsample': 0.9701943407497298, 'colsample_bytree': 0.49315033322473584}. Best is trial 76 with value: 0.44409683832350066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:49,862]\u001b[0m Trial 86 finished with value: 0.4444075389816956 and parameters: {'booster': 'gblinear', 'lambda': 1.854809649947969e-06, 'alpha': 0.009616497333540797, 'subsample': 0.9192878141198781, 'colsample_bytree': 0.4209112006676604}. Best is trial 76 with value: 0.44409683832350066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:51,157]\u001b[0m Trial 87 finished with value: 1.496471723429265 and parameters: {'booster': 'dart', 'lambda': 1.4695117405864802e-06, 'alpha': 0.0018631745480973266, 'subsample': 0.9257429499783948, 'colsample_bytree': 0.3853621047530731, 'max_depth': 9, 'min_child_weight': 5, 'eta': 4.313605761677033e-06, 'gamma': 0.04732073886405943, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.013765335791981302, 'skip_drop': 1.3907904043881128e-06}. Best is trial 76 with value: 0.44409683832350066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:51,268]\u001b[0m Trial 88 finished with value: 0.5287128720001744 and parameters: {'booster': 'gblinear', 'lambda': 7.018039752030397e-07, 'alpha': 0.030067129901740153, 'subsample': 0.9537857225627004, 'colsample_bytree': 0.31183720047895713}. Best is trial 76 with value: 0.44409683832350066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:51,477]\u001b[0m Trial 89 finished with value: 0.6025615868452566 and parameters: {'booster': 'gbtree', 'lambda': 2.315414704195237e-06, 'alpha': 0.0009183499133418952, 'subsample': 0.9850033117103819, 'colsample_bytree': 0.41544220271183496, 'max_depth': 5, 'min_child_weight': 3, 'eta': 0.14071948441517207, 'gamma': 3.9432303449644755e-06, 'grow_policy': 'depthwise'}. Best is trial 76 with value: 0.44409683832350066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:51,584]\u001b[0m Trial 90 finished with value: 0.6932648407857376 and parameters: {'booster': 'gblinear', 'lambda': 2.5240343455952344e-05, 'alpha': 0.0602344449249139, 'subsample': 0.9094808761042781, 'colsample_bytree': 0.44202574746502}. Best is trial 76 with value: 0.44409683832350066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:51,703]\u001b[0m Trial 91 finished with value: 0.4449760730522782 and parameters: {'booster': 'gblinear', 'lambda': 4.580812467389979e-06, 'alpha': 0.010693746286236405, 'subsample': 0.9265392094649764, 'colsample_bytree': 0.5157759497738129}. Best is trial 76 with value: 0.44409683832350066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:51,821]\u001b[0m Trial 92 finished with value: 0.4446132531842223 and parameters: {'booster': 'gblinear', 'lambda': 4.138558971938778e-06, 'alpha': 0.009152996639710854, 'subsample': 0.9332028308679702, 'colsample_bytree': 0.35762577079754354}. Best is trial 76 with value: 0.44409683832350066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:51,943]\u001b[0m Trial 93 finished with value: 0.45160357868790757 and parameters: {'booster': 'gblinear', 'lambda': 1.1834806458594978e-05, 'alpha': 0.004861620135637935, 'subsample': 0.9406667468550676, 'colsample_bytree': 0.34954347774630956}. Best is trial 76 with value: 0.44409683832350066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:52,059]\u001b[0m Trial 94 finished with value: 0.4631489978421911 and parameters: {'booster': 'gblinear', 'lambda': 4.967674097558311e-07, 'alpha': 0.01725081085206886, 'subsample': 0.9978727203699681, 'colsample_bytree': 0.358056164728335}. Best is trial 76 with value: 0.44409683832350066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:52,181]\u001b[0m Trial 95 finished with value: 0.47606316314108654 and parameters: {'booster': 'gblinear', 'lambda': 1.635080447277328e-06, 'alpha': 0.0022024934860633083, 'subsample': 0.9621226994373531, 'colsample_bytree': 0.28183227775809516}. Best is trial 76 with value: 0.44409683832350066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:52,290]\u001b[0m Trial 96 finished with value: 0.5255960460206578 and parameters: {'booster': 'gblinear', 'lambda': 3.840631071943025e-06, 'alpha': 0.029581631765762482, 'subsample': 0.8975060588960652, 'colsample_bytree': 0.46925333761429033}. Best is trial 76 with value: 0.44409683832350066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:52,412]\u001b[0m Trial 97 finished with value: 0.45182773595462467 and parameters: {'booster': 'gblinear', 'lambda': 8.021360648780412e-06, 'alpha': 0.004554825468006701, 'subsample': 0.9176899040956883, 'colsample_bytree': 0.9287181630588804}. Best is trial 76 with value: 0.44409683832350066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:52,515]\u001b[0m Trial 98 finished with value: 0.8174305954315093 and parameters: {'booster': 'gblinear', 'lambda': 7.597727203074086e-07, 'alpha': 0.10900962836777682, 'subsample': 0.8747421949378277, 'colsample_bytree': 0.385097398270151}. Best is trial 76 with value: 0.44409683832350066.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 16:59:52,634]\u001b[0m Trial 99 finished with value: 0.4450445618373863 and parameters: {'booster': 'gblinear', 'lambda': 1.204922071351064e-07, 'alpha': 0.008510216001228494, 'subsample': 0.9771099505921096, 'colsample_bytree': 0.4256924997804776}. Best is trial 76 with value: 0.44409683832350066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:52,808]\u001b[0m A new study created in memory with name: no-name-15d8d538-2ec6-4aa1-ad12-e221598966d3\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:57,694]\u001b[0m Trial 0 finished with value: 0.9280886462598297 and parameters: {'booster': 'dart', 'lambda': 2.7624231160098158e-08, 'alpha': 1.4982420919444278e-08, 'subsample': 0.6440450849472177, 'colsample_bytree': 0.7244260412079597, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.06232629380761426, 'gamma': 0.6438385999203725, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 2.5568086549810582e-05, 'skip_drop': 4.700365334621682e-06}. Best is trial 0 with value: 0.9280886462598297.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 16:59:57,960]\u001b[0m Trial 1 finished with value: 0.9278514821139281 and parameters: {'booster': 'gblinear', 'lambda': 5.881882150720982e-07, 'alpha': 6.688995782287642e-07, 'subsample': 0.9169791113509376, 'colsample_bytree': 0.7175984186273328}. Best is trial 0 with value: 0.9280886462598297.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:00:02,854]\u001b[0m Trial 2 finished with value: 0.9224378881987578 and parameters: {'booster': 'dart', 'lambda': 5.662540254380046e-08, 'alpha': 0.0713171978051017, 'subsample': 0.7300443359731836, 'colsample_bytree': 0.7862972910399975, 'max_depth': 3, 'min_child_weight': 7, 'eta': 4.572062510116851e-07, 'gamma': 0.003227867217959505, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 2.483881564957158e-07, 'skip_drop': 2.245456319493979e-06}. Best is trial 0 with value: 0.9280886462598297.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:00:07,744]\u001b[0m Trial 3 finished with value: 0.9299345171376319 and parameters: {'booster': 'dart', 'lambda': 0.04608106196013171, 'alpha': 0.0007658252015956801, 'subsample': 0.9520529800319859, 'colsample_bytree': 0.8935035225413834, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.10764464847774581, 'gamma': 0.0026045842612567693, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.0027375304516689698, 'skip_drop': 5.31708425446215e-07}. Best is trial 3 with value: 0.9299345171376319.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:00:08,015]\u001b[0m Trial 4 finished with value: 0.9224378881987578 and parameters: {'booster': 'gblinear', 'lambda': 0.18036722656174692, 'alpha': 8.777012510435097e-07, 'subsample': 0.5553391881852452, 'colsample_bytree': 0.25580839892092294}. Best is trial 3 with value: 0.9299345171376319.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:00:08,424]\u001b[0m Trial 5 finished with value: 0.9224378881987578 and parameters: {'booster': 'gbtree', 'lambda': 0.005495784340877361, 'alpha': 7.613236864789895e-07, 'subsample': 0.6037059435625272, 'colsample_bytree': 0.5023252493982923, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.013713017824407646, 'gamma': 3.503543871908449e-08, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 0.9299345171376319.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:00:08,600]\u001b[0m Trial 6 finished with value: 0.9224378881987578 and parameters: {'booster': 'gbtree', 'lambda': 0.8077700966381133, 'alpha': 1.0294361217169176e-05, 'subsample': 0.23756578636629158, 'colsample_bytree': 0.7262383468469393, 'max_depth': 3, 'min_child_weight': 8, 'eta': 0.5841778168911035, 'gamma': 0.00023840572871281719, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 0.9299345171376319.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:00:08,732]\u001b[0m Trial 7 finished with value: 0.9224378881987578 and parameters: {'booster': 'gblinear', 'lambda': 0.05040984818872882, 'alpha': 0.08484199681530957, 'subsample': 0.8816358956898915, 'colsample_bytree': 0.6697694198184029}. Best is trial 3 with value: 0.9299345171376319.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:00:13,613]\u001b[0m Trial 8 finished with value: 0.9224378881987578 and parameters: {'booster': 'dart', 'lambda': 6.111463411340018e-06, 'alpha': 1.4577534573373435e-08, 'subsample': 0.3909766560805749, 'colsample_bytree': 0.4770134911107965, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.014563855187510725, 'gamma': 2.448090444224144e-06, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 3.003540649617203e-05, 'skip_drop': 0.028443150768198942}. Best is trial 3 with value: 0.9299345171376319.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:00:13,946]\u001b[0m Trial 9 finished with value: 0.9224378881987578 and parameters: {'booster': 'gbtree', 'lambda': 1.006477808367876e-07, 'alpha': 0.00301612097941604, 'subsample': 0.8564956031376982, 'colsample_bytree': 0.5596088435828162, 'max_depth': 3, 'min_child_weight': 2, 'eta': 2.142360619541918e-07, 'gamma': 3.373125842646332e-07, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 0.9299345171376319.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:00:17,345]\u001b[0m Trial 10 finished with value: 0.9224378881987578 and parameters: {'booster': 'dart', 'lambda': 0.0010202322583187534, 'alpha': 0.0006093435565847202, 'subsample': 0.9970550206087867, 'colsample_bytree': 0.966922637903549, 'max_depth': 9, 'min_child_weight': 5, 'eta': 9.963753480404475e-05, 'gamma': 0.04745797416236719, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.8150881715739693, 'skip_drop': 2.4968894197364804e-08}. Best is trial 3 with value: 0.9299345171376319.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:00:22,258]\u001b[0m Trial 11 finished with value: 0.9291370436384754 and parameters: {'booster': 'dart', 'lambda': 4.630631719601964e-05, 'alpha': 1.0064028926183639e-08, 'subsample': 0.7054597840540274, 'colsample_bytree': 0.9703970119442552, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.3927566349247543, 'gamma': 0.6234147058375192, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.004811138950543905, 'skip_drop': 1.4818569417256388e-05}. Best is trial 3 with value: 0.9299345171376319.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:00:27,040]\u001b[0m Trial 12 finished with value: 0.9262992409829172 and parameters: {'booster': 'dart', 'lambda': 5.7064262904756147e-05, 'alpha': 4.3378140098717685e-05, 'subsample': 0.7637037937719674, 'colsample_bytree': 0.9730560950502464, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.7784995311289791, 'gamma': 0.8721306510501632, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.03579787157096296, 'skip_drop': 0.0006215949267101427}. Best is trial 3 with value: 0.9299345171376319.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:00:34,281]\u001b[0m A new study created in memory with name: no-name-f4924832-bfea-4794-b0d9-a912571413b0\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:00:37,879]\u001b[0m Trial 0 finished with value: 0.6834930438236704 and parameters: {'booster': 'dart', 'lambda': 0.9630144768432868, 'alpha': 5.943825672801004e-07, 'subsample': 0.6821115795140842, 'colsample_bytree': 0.7148393510092614, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.006513756671640069, 'gamma': 6.317311569284436e-06, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.18692037617691531, 'skip_drop': 0.0012289083033609823}. Best is trial 0 with value: 0.6834930438236704.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:00:42,250]\u001b[0m Trial 1 finished with value: 0.6536544617712768 and parameters: {'booster': 'dart', 'lambda': 3.102084790093932e-05, 'alpha': 1.5064436026276244e-08, 'subsample': 0.6725902326221895, 'colsample_bytree': 0.9641173877111044, 'max_depth': 9, 'min_child_weight': 2, 'eta': 2.613344581623705e-05, 'gamma': 4.0028585631686934e-05, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.016877690595540326, 'skip_drop': 0.010897075723401388}. Best is trial 0 with value: 0.6834930438236704.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:00:42,675]\u001b[0m Trial 2 finished with value: 0.6452271185605334 and parameters: {'booster': 'gbtree', 'lambda': 1.4067166442280904e-07, 'alpha': 0.07509876503218324, 'subsample': 0.5183860714026851, 'colsample_bytree': 0.8792016692629516, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.18104193368620605, 'gamma': 1.6160727683448642e-05, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.6834930438236704.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:00:43,219]\u001b[0m Trial 3 finished with value: 0.6989913836955953 and parameters: {'booster': 'gbtree', 'lambda': 0.2754513186879079, 'alpha': 8.420693800718955e-05, 'subsample': 0.804557874815264, 'colsample_bytree': 0.4409689818499947, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.00010446844947544465, 'gamma': 0.00020601361595031593, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 0.6989913836955953.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:00:43,415]\u001b[0m Trial 4 finished with value: 0.6180455427556877 and parameters: {'booster': 'gblinear', 'lambda': 1.543675480587667e-07, 'alpha': 0.0005135694961328209, 'subsample': 0.9238884094158943, 'colsample_bytree': 0.21862371136412273}. Best is trial 3 with value: 0.6989913836955953.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:00:43,519]\u001b[0m Trial 5 finished with value: 0.5007944002491954 and parameters: {'booster': 'gblinear', 'lambda': 1.50128573100553e-08, 'alpha': 0.08597764071382687, 'subsample': 0.7103486260679228, 'colsample_bytree': 0.9033286721340466}. Best is trial 3 with value: 0.6989913836955953.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:00:43,923]\u001b[0m Trial 6 finished with value: 0.6746306505457141 and parameters: {'booster': 'gbtree', 'lambda': 7.99918301518635e-07, 'alpha': 0.0012419852936570814, 'subsample': 0.5611417874333453, 'colsample_bytree': 0.5627126556012259, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.07110405831098016, 'gamma': 0.5786942856168822, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 0.6989913836955953.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:00:44,121]\u001b[0m Trial 7 finished with value: 0.5956745059889025 and parameters: {'booster': 'gblinear', 'lambda': 1.9675665145119026e-06, 'alpha': 7.326184253442751e-07, 'subsample': 0.4406941184188747, 'colsample_bytree': 0.228442275642694}. Best is trial 3 with value: 0.6989913836955953.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:00:44,881]\u001b[0m Trial 8 finished with value: 0.6661894236733953 and parameters: {'booster': 'gbtree', 'lambda': 1.1736907420166217e-06, 'alpha': 0.00011720775422579098, 'subsample': 0.622971550621557, 'colsample_bytree': 0.9155377949005565, 'max_depth': 9, 'min_child_weight': 4, 'eta': 1.1937155183332501e-06, 'gamma': 0.42528331741742575, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 0.6989913836955953.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:00:48,626]\u001b[0m Trial 9 finished with value: 0.693848522649123 and parameters: {'booster': 'dart', 'lambda': 0.0015917816922468196, 'alpha': 8.403622927792048e-08, 'subsample': 0.5311292573076307, 'colsample_bytree': 0.3435063365771399, 'max_depth': 9, 'min_child_weight': 7, 'eta': 5.3543665516784726e-05, 'gamma': 7.313572460886408e-08, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.07062215010100867, 'skip_drop': 1.7176943265903225e-07}. Best is trial 3 with value: 0.6989913836955953.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:00:48,872]\u001b[0m Trial 10 finished with value: 0.09128737738858907 and parameters: {'booster': 'gbtree', 'lambda': 0.8658966299817376, 'alpha': 0.0038898798864557384, 'subsample': 0.23144120096664544, 'colsample_bytree': 0.4776525695657777, 'max_depth': 3, 'min_child_weight': 10, 'eta': 1.2476999573574803e-08, 'gamma': 0.003898776389831569, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 0.6989913836955953.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:00:52,883]\u001b[0m Trial 11 finished with value: 0.6896606590605884 and parameters: {'booster': 'dart', 'lambda': 0.006828422029480529, 'alpha': 4.5925206137367685e-06, 'subsample': 0.8894872451954268, 'colsample_bytree': 0.3923347994732419, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.00022808880565165765, 'gamma': 1.855553982347591e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 8.454940517812894e-07, 'skip_drop': 2.0026813907490597e-08}. Best is trial 3 with value: 0.6989913836955953.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:00:57,004]\u001b[0m Trial 12 finished with value: 0.6822186641441716 and parameters: {'booster': 'dart', 'lambda': 0.008229716224645224, 'alpha': 1.4212806978825392e-08, 'subsample': 0.8226679785357172, 'colsample_bytree': 0.3728903772417539, 'max_depth': 9, 'min_child_weight': 5, 'eta': 7.9450147993218e-05, 'gamma': 2.3831906702407764e-08, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.000355191368495161, 'skip_drop': 1.0908862580276087e-07}. Best is trial 3 with value: 0.6989913836955953.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:00:57,339]\u001b[0m Trial 13 finished with value: 0.6653675735147481 and parameters: {'booster': 'gbtree', 'lambda': 0.008060357335636354, 'alpha': 8.872272688667144e-06, 'subsample': 0.289360055836602, 'colsample_bytree': 0.3673381877626317, 'max_depth': 7, 'min_child_weight': 7, 'eta': 2.0371845738547024e-06, 'gamma': 0.0016880476245910408, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 0.6989913836955953.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:01,348]\u001b[0m Trial 14 finished with value: 0.6702639753835518 and parameters: {'booster': 'dart', 'lambda': 0.0003912195522745552, 'alpha': 0.766228793276184, 'subsample': 0.38900322986811897, 'colsample_bytree': 0.5788711574048484, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.0021991869264697365, 'gamma': 5.935365980598081e-07, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.1583224733313247e-08, 'skip_drop': 4.434408829884751e-06}. Best is trial 3 with value: 0.6989913836955953.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:01,992]\u001b[0m Trial 15 finished with value: 0.6574931502766256 and parameters: {'booster': 'gbtree', 'lambda': 0.053995975498692395, 'alpha': 1.6419848421300492e-07, 'subsample': 0.7964145889894708, 'colsample_bytree': 0.7110084306437964, 'max_depth': 7, 'min_child_weight': 6, 'eta': 4.351715009694314e-06, 'gamma': 0.002107402065467831, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 0.6989913836955953.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:05,860]\u001b[0m Trial 16 finished with value: 0.6766252982460668 and parameters: {'booster': 'dart', 'lambda': 7.334067737721636e-05, 'alpha': 2.629483460419221e-05, 'subsample': 0.9932466875520092, 'colsample_bytree': 0.30346270763401295, 'max_depth': 5, 'min_child_weight': 4, 'eta': 4.9376849472100385e-08, 'gamma': 5.926448815887884e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.0006032242722735511, 'skip_drop': 1.524455241579547e-05}. Best is trial 3 with value: 0.6989913836955953.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:09,180]\u001b[0m Trial 17 finished with value: 0.6941937037785245 and parameters: {'booster': 'dart', 'lambda': 0.0007629445847580905, 'alpha': 1.2287497894142068e-07, 'subsample': 0.7708093570530762, 'colsample_bytree': 0.4265501983465716, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.0013887603394825462, 'gamma': 0.00020932559643098737, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.5761302341676381, 'skip_drop': 0.34297514816828084}. Best is trial 3 with value: 0.6989913836955953.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:01:10,103]\u001b[0m A new study created in memory with name: no-name-35346b07-b78d-49cd-8ccd-2bbc193ef9b2\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:10,457]\u001b[0m Trial 0 finished with value: 0.9352657004830917 and parameters: {'booster': 'gblinear', 'lambda': 0.5624755889633818, 'alpha': 1.6996978393247263e-05, 'subsample': 0.2679180642167743, 'colsample_bytree': 0.8507689540601657}. Best is trial 0 with value: 0.9352657004830917.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:01:10,632]\u001b[0m Trial 1 finished with value: 0.9352657004830917 and parameters: {'booster': 'gblinear', 'lambda': 3.388606477172692e-06, 'alpha': 0.015341774939641967, 'subsample': 0.7334565332723015, 'colsample_bytree': 0.9265632686109806}. Best is trial 0 with value: 0.9352657004830917.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:16,691]\u001b[0m Trial 2 finished with value: 0.9352657004830917 and parameters: {'booster': 'dart', 'lambda': 2.1653810712058664e-05, 'alpha': 9.441080192109405e-05, 'subsample': 0.9607289218464161, 'colsample_bytree': 0.27600125072907195, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.00016303055526773448, 'gamma': 0.4094973017416563, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.01075660401338917, 'skip_drop': 0.0008742559575283359}. Best is trial 0 with value: 0.9352657004830917.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:17,004]\u001b[0m Trial 3 finished with value: 0.9352657004830917 and parameters: {'booster': 'gbtree', 'lambda': 0.007653045936103302, 'alpha': 0.005945506915862015, 'subsample': 0.43632757744955947, 'colsample_bytree': 0.4173488357597629, 'max_depth': 5, 'min_child_weight': 9, 'eta': 4.3306572710418554e-05, 'gamma': 0.10770960598700112, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.9352657004830917.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:17,384]\u001b[0m Trial 4 finished with value: 0.9338149916139852 and parameters: {'booster': 'gbtree', 'lambda': 1.6571349996287023e-08, 'alpha': 1.3360388972562007e-06, 'subsample': 0.8065792938819547, 'colsample_bytree': 0.55695624183136, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.004128558444259514, 'gamma': 0.00011502507073378195, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.9352657004830917.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:23,395]\u001b[0m Trial 5 finished with value: 0.9352657004830917 and parameters: {'booster': 'dart', 'lambda': 6.867703278178061e-06, 'alpha': 0.01382827018167905, 'subsample': 0.20229311788298895, 'colsample_bytree': 0.6633055439296773, 'max_depth': 9, 'min_child_weight': 4, 'eta': 7.781736707201561e-05, 'gamma': 0.017084713668576498, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.003440007171577811, 'skip_drop': 0.0003542971684414384}. Best is trial 0 with value: 0.9352657004830917.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:23,740]\u001b[0m Trial 6 finished with value: 0.9323599715743909 and parameters: {'booster': 'gbtree', 'lambda': 1.0616921804203245e-07, 'alpha': 2.9564688275463187e-05, 'subsample': 0.543020891937867, 'colsample_bytree': 0.4076590199618664, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.054871901534051276, 'gamma': 8.524969531911049e-07, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.9352657004830917.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:23,982]\u001b[0m Trial 7 finished with value: 0.9420045056221035 and parameters: {'booster': 'gblinear', 'lambda': 8.653635908304986e-05, 'alpha': 0.005148768009005868, 'subsample': 0.993205370570218, 'colsample_bytree': 0.29004863196993186}. Best is trial 7 with value: 0.9420045056221035.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:24,335]\u001b[0m Trial 8 finished with value: 0.9352657004830917 and parameters: {'booster': 'gbtree', 'lambda': 0.02285536543700922, 'alpha': 0.03589182381322522, 'subsample': 0.8706201955068915, 'colsample_bytree': 0.3077671563893401, 'max_depth': 7, 'min_child_weight': 10, 'eta': 1.0397379270744884e-07, 'gamma': 0.00017481056667567827, 'grow_policy': 'lossguide'}. Best is trial 7 with value: 0.9420045056221035.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:24,580]\u001b[0m Trial 9 finished with value: 0.9352657004830917 and parameters: {'booster': 'gbtree', 'lambda': 0.06880746235471068, 'alpha': 0.5661689638045976, 'subsample': 0.5459677708301492, 'colsample_bytree': 0.3109962736351592, 'max_depth': 5, 'min_child_weight': 5, 'eta': 1.464495926811371e-08, 'gamma': 4.979162245443496e-07, 'grow_policy': 'lossguide'}. Best is trial 7 with value: 0.9420045056221035.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:24,989]\u001b[0m Trial 10 finished with value: 0.9204538002491968 and parameters: {'booster': 'gblinear', 'lambda': 0.00047775618465363984, 'alpha': 1.0232783642517972e-08, 'subsample': 0.6850161019198182, 'colsample_bytree': 0.6568602457860375}. Best is trial 7 with value: 0.9420045056221035.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:25,387]\u001b[0m Trial 11 finished with value: 0.9352657004830917 and parameters: {'booster': 'gblinear', 'lambda': 0.3787339217444032, 'alpha': 2.9435149115474974e-06, 'subsample': 0.21419433422786682, 'colsample_bytree': 0.9294760795033754}. Best is trial 7 with value: 0.9420045056221035.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:25,729]\u001b[0m Trial 12 finished with value: 0.9285862521560461 and parameters: {'booster': 'gblinear', 'lambda': 0.00017283669873820775, 'alpha': 0.0012934383715524252, 'subsample': 0.339410524445137, 'colsample_bytree': 0.8062129262582265}. Best is trial 7 with value: 0.9420045056221035.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:26,084]\u001b[0m Trial 13 finished with value: 0.9234390323635174 and parameters: {'booster': 'gblinear', 'lambda': 0.0008609341636969665, 'alpha': 0.0005633480353830314, 'subsample': 0.9875048580593326, 'colsample_bytree': 0.7857213754555218}. Best is trial 7 with value: 0.9420045056221035.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:26,442]\u001b[0m Trial 14 finished with value: 0.917789240972734 and parameters: {'booster': 'gblinear', 'lambda': 6.330573918596752e-07, 'alpha': 1.8485643205125783e-06, 'subsample': 0.36979291788825147, 'colsample_bytree': 0.20054267994537933}. Best is trial 7 with value: 0.9420045056221035.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:26,819]\u001b[0m Trial 15 finished with value: 0.9264063620363732 and parameters: {'booster': 'gblinear', 'lambda': 0.002906551864848351, 'alpha': 9.365193998310326e-08, 'subsample': 0.6318651873243981, 'colsample_bytree': 0.5215515319576457}. Best is trial 7 with value: 0.9420045056221035.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:26,963]\u001b[0m Trial 16 finished with value: 0.9352657004830917 and parameters: {'booster': 'gblinear', 'lambda': 0.8394739833299945, 'alpha': 0.3075971929982778, 'subsample': 0.45456951854919575, 'colsample_bytree': 0.7785609208288017}. Best is trial 7 with value: 0.9420045056221035.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:32,959]\u001b[0m Trial 17 finished with value: 0.9488109325495288 and parameters: {'booster': 'dart', 'lambda': 4.538250473325404e-05, 'alpha': 1.7702931010828548e-05, 'subsample': 0.8772157276060324, 'colsample_bytree': 0.4634105340958282, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.8559750608927669, 'gamma': 2.107034406200963e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 2.4899091568497772e-08, 'skip_drop': 1.5589385343559536e-08}. Best is trial 17 with value: 0.9488109325495288.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:38,806]\u001b[0m Trial 18 finished with value: 0.9363075782077309 and parameters: {'booster': 'dart', 'lambda': 4.060848210411605e-05, 'alpha': 0.0005072970578429417, 'subsample': 0.8592452112094456, 'colsample_bytree': 0.4247806625294669, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.9122766705564299, 'gamma': 1.612442407864591e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 2.999733799678986e-08, 'skip_drop': 1.861675105448156e-08}. Best is trial 17 with value: 0.9488109325495288.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:44,678]\u001b[0m Trial 19 finished with value: 0.9438346400570206 and parameters: {'booster': 'dart', 'lambda': 1.2950726462814597e-06, 'alpha': 0.10476891796070438, 'subsample': 0.9138029749007909, 'colsample_bytree': 0.4961708553694947, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.8782333514536129, 'gamma': 2.1662249941558015e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.1876195039123288e-08, 'skip_drop': 1.0252340140175177e-08}. Best is trial 17 with value: 0.9488109325495288.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:01:51,434]\u001b[0m A new study created in memory with name: no-name-8ea4436f-0c5b-4f3a-91bd-c8f5f8e9bc17\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:51,846]\u001b[0m Trial 0 finished with value: 0.7706352988777858 and parameters: {'booster': 'gblinear', 'lambda': 1.1114952166696487e-05, 'alpha': 0.0012109848136103807, 'subsample': 0.43935210543269787, 'colsample_bytree': 0.655492225810245}. Best is trial 0 with value: 0.7706352988777858.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:52,046]\u001b[0m Trial 1 finished with value: 0.7164787140200902 and parameters: {'booster': 'gblinear', 'lambda': 0.0002779589306445863, 'alpha': 0.0464533540288491, 'subsample': 0.8896626301478903, 'colsample_bytree': 0.8934227239893411}. Best is trial 0 with value: 0.7706352988777858.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:52,582]\u001b[0m Trial 2 finished with value: 0.7851718218421299 and parameters: {'booster': 'gbtree', 'lambda': 0.004846414457175828, 'alpha': 5.565964810948246e-05, 'subsample': 0.7886704841177394, 'colsample_bytree': 0.7871283213264579, 'max_depth': 3, 'min_child_weight': 3, 'eta': 6.825336587828454e-05, 'gamma': 0.00029636762252400426, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 0.7851718218421299.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:52,925]\u001b[0m Trial 3 finished with value: 0.7034366315696239 and parameters: {'booster': 'gblinear', 'lambda': 0.32734552019508706, 'alpha': 0.011194750988930007, 'subsample': 0.26081052351755574, 'colsample_bytree': 0.7684212188973918}. Best is trial 2 with value: 0.7851718218421299.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:53,618]\u001b[0m Trial 4 finished with value: 0.7923050546237909 and parameters: {'booster': 'gbtree', 'lambda': 0.06162156178303724, 'alpha': 2.119266136192482e-06, 'subsample': 0.7215226974002595, 'colsample_bytree': 0.4118131233075178, 'max_depth': 9, 'min_child_weight': 3, 'eta': 2.6724656480285585e-05, 'gamma': 0.016298882304347145, 'grow_policy': 'depthwise'}. Best is trial 4 with value: 0.7923050546237909.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:54,018]\u001b[0m Trial 5 finished with value: 0.7923729578826209 and parameters: {'booster': 'gbtree', 'lambda': 2.2201598580535106e-07, 'alpha': 0.0017070870833959665, 'subsample': 0.850461684383587, 'colsample_bytree': 0.32976310875566117, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.35657096116415826, 'gamma': 0.00022241671928051093, 'grow_policy': 'depthwise'}. Best is trial 5 with value: 0.7923729578826209.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:54,397]\u001b[0m Trial 6 finished with value: 0.7217031559597085 and parameters: {'booster': 'gbtree', 'lambda': 0.0018588410648154843, 'alpha': 0.22542071355959264, 'subsample': 0.8732259714801585, 'colsample_bytree': 0.42965967026210505, 'max_depth': 3, 'min_child_weight': 9, 'eta': 4.704416156110449e-06, 'gamma': 0.07102726862784683, 'grow_policy': 'depthwise'}. Best is trial 5 with value: 0.7923729578826209.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:54,994]\u001b[0m Trial 7 finished with value: 0.7812113720405541 and parameters: {'booster': 'gbtree', 'lambda': 2.9369890980260753e-08, 'alpha': 3.5524168967764645e-06, 'subsample': 0.335613717595615, 'colsample_bytree': 0.9286528331331942, 'max_depth': 7, 'min_child_weight': 4, 'eta': 1.2735172257548148e-07, 'gamma': 1.8781634900349039e-06, 'grow_policy': 'lossguide'}. Best is trial 5 with value: 0.7923729578826209.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:55,502]\u001b[0m Trial 8 finished with value: 0.7775193810928348 and parameters: {'booster': 'gblinear', 'lambda': 0.0005927143845704831, 'alpha': 8.66035523045036e-06, 'subsample': 0.2937183594377067, 'colsample_bytree': 0.42705260777599907}. Best is trial 5 with value: 0.7923729578826209.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:01:56,012]\u001b[0m Trial 9 finished with value: 0.7468821919548212 and parameters: {'booster': 'gblinear', 'lambda': 3.494583768955697e-08, 'alpha': 5.882449205301434e-06, 'subsample': 0.5502626518606906, 'colsample_bytree': 0.3883955872336663}. Best is trial 5 with value: 0.7923729578826209.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:03,426]\u001b[0m Trial 10 finished with value: 0.8155309604235981 and parameters: {'booster': 'dart', 'lambda': 2.153474075428285e-06, 'alpha': 3.104074854768916e-08, 'subsample': 0.997699376644588, 'colsample_bytree': 0.20739273808505235, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.23344995031157256, 'gamma': 1.1973257300347973e-08, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.00010035294383056492, 'skip_drop': 3.5187885519219154e-07}. Best is trial 10 with value: 0.8155309604235981.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:10,681]\u001b[0m Trial 11 finished with value: 0.8018008515957655 and parameters: {'booster': 'dart', 'lambda': 2.619014369591958e-06, 'alpha': 3.2031511028908697e-08, 'subsample': 0.9552227389223866, 'colsample_bytree': 0.2208755032733422, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.7255333297969041, 'gamma': 1.1818411312661466e-08, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 7.572263508108694e-05, 'skip_drop': 1.4673017259267523e-07}. Best is trial 10 with value: 0.8155309604235981.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:17,920]\u001b[0m Trial 12 finished with value: 0.7903920907763172 and parameters: {'booster': 'dart', 'lambda': 6.43998076397884e-06, 'alpha': 2.457592343072339e-08, 'subsample': 0.9977343820147863, 'colsample_bytree': 0.20001081198508106, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.7757856827885267, 'gamma': 2.286112195222955e-08, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 9.599839106847468e-05, 'skip_drop': 1.0914378536189472e-07}. Best is trial 10 with value: 0.8155309604235981.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:25,365]\u001b[0m Trial 13 finished with value: 0.7875583348730031 and parameters: {'booster': 'dart', 'lambda': 2.1878080106909507e-06, 'alpha': 1.6109853359049613e-08, 'subsample': 0.9800783581193051, 'colsample_bytree': 0.20222439213189283, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.016710986505580706, 'gamma': 1.5566230050718185e-08, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 5.761444793107529e-05, 'skip_drop': 3.0662328239183847e-07}. Best is trial 10 with value: 0.8155309604235981.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:02:33,697]\u001b[0m A new study created in memory with name: no-name-6b36fbc7-4e95-406d-8c72-c0788e992144\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:33,804]\u001b[0m Trial 0 finished with value: 0.29601474948116585 and parameters: {'booster': 'gblinear', 'lambda': 7.645683486257332e-08, 'alpha': 5.0917604068150116e-06, 'subsample': 0.24819813773875474, 'colsample_bytree': 0.8106278380791134}. Best is trial 0 with value: 0.29601474948116585.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:33,945]\u001b[0m Trial 1 finished with value: 1.3650666704356031 and parameters: {'booster': 'gbtree', 'lambda': 0.0012895162043678602, 'alpha': 1.9245247940973863e-05, 'subsample': 0.7654231941146392, 'colsample_bytree': 0.3026473429178461, 'max_depth': 3, 'min_child_weight': 5, 'eta': 1.2810752231911e-06, 'gamma': 0.0010947085056178302, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.29601474948116585.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:34,050]\u001b[0m Trial 2 finished with value: 0.30085946457839496 and parameters: {'booster': 'gblinear', 'lambda': 0.5808106746350662, 'alpha': 0.0003857723249169525, 'subsample': 0.7690445606795147, 'colsample_bytree': 0.726512244080048}. Best is trial 0 with value: 0.29601474948116585.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:34,186]\u001b[0m Trial 3 finished with value: 0.20846774134584276 and parameters: {'booster': 'gbtree', 'lambda': 2.191861618532897e-06, 'alpha': 0.00011974214094843784, 'subsample': 0.22112984645240275, 'colsample_bytree': 0.5783013413979271, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.04724127125432293, 'gamma': 0.2121062879029415, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 0.20846774134584276.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:02:35,697]\u001b[0m Trial 4 finished with value: 0.44822025281969663 and parameters: {'booster': 'dart', 'lambda': 1.7603702821499953e-05, 'alpha': 0.00013266692196133768, 'subsample': 0.4643170162236816, 'colsample_bytree': 0.2774609028891263, 'max_depth': 5, 'min_child_weight': 2, 'eta': 0.4840634429455342, 'gamma': 8.64268978452073e-08, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.0002720889691477159, 'skip_drop': 0.0005744834693225526}. Best is trial 3 with value: 0.20846774134584276.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:37,320]\u001b[0m Trial 5 finished with value: 1.36530506068666 and parameters: {'booster': 'dart', 'lambda': 0.011170202605926778, 'alpha': 6.2151039401962096e-06, 'subsample': 0.8963643312394847, 'colsample_bytree': 0.3381729252019251, 'max_depth': 7, 'min_child_weight': 5, 'eta': 4.6666156171423023e-08, 'gamma': 9.665826766885622e-07, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.06338509532872923, 'skip_drop': 8.426467730514075e-06}. Best is trial 3 with value: 0.20846774134584276.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:37,438]\u001b[0m Trial 6 finished with value: 0.29121800707058676 and parameters: {'booster': 'gblinear', 'lambda': 0.0028802477962078105, 'alpha': 1.046672518661212e-07, 'subsample': 0.8355335580246861, 'colsample_bytree': 0.9009072090710135}. Best is trial 3 with value: 0.20846774134584276.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:38,913]\u001b[0m Trial 7 finished with value: 0.19529250185167404 and parameters: {'booster': 'dart', 'lambda': 0.9434417203921273, 'alpha': 1.1561371950845776e-07, 'subsample': 0.6041096792853229, 'colsample_bytree': 0.8036613477626617, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.044644409048108284, 'gamma': 0.2792323947654847, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.08453365951777397, 'skip_drop': 0.09288991913730447}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:39,025]\u001b[0m Trial 8 finished with value: 0.27312732472107343 and parameters: {'booster': 'gblinear', 'lambda': 5.8714462643704634e-08, 'alpha': 0.002146068444811362, 'subsample': 0.2581019992589284, 'colsample_bytree': 0.9670492515641749}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:39,301]\u001b[0m Trial 9 finished with value: 1.3652592631094307 and parameters: {'booster': 'gbtree', 'lambda': 8.088168436927938e-06, 'alpha': 0.00016852588879855812, 'subsample': 0.7561444735635792, 'colsample_bytree': 0.9839967638946476, 'max_depth': 5, 'min_child_weight': 4, 'eta': 2.1533027563791753e-07, 'gamma': 1.5677015336984625e-06, 'grow_policy': 'lossguide'}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:40,774]\u001b[0m Trial 10 finished with value: 1.0742632123782891 and parameters: {'booster': 'dart', 'lambda': 0.938065633175668, 'alpha': 0.2181613652589835, 'subsample': 0.5705004206230898, 'colsample_bytree': 0.5648278072755286, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.0016012350643894804, 'gamma': 0.7977810616997195, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 3.475565135433039e-08, 'skip_drop': 0.5267041684559691}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:40,960]\u001b[0m Trial 11 finished with value: 0.2025808687636527 and parameters: {'booster': 'gbtree', 'lambda': 1.533625850547258e-06, 'alpha': 1.967961800253828e-08, 'subsample': 0.4381293642668001, 'colsample_bytree': 0.5862510255493044, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.05707416104919988, 'gamma': 0.777303578695209, 'grow_policy': 'lossguide'}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:42,398]\u001b[0m Trial 12 finished with value: 1.036318562570158 and parameters: {'booster': 'dart', 'lambda': 1.1813126568786431e-06, 'alpha': 1.1732384895675578e-08, 'subsample': 0.42378905385336785, 'colsample_bytree': 0.46043697965020447, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.0017977167234438753, 'gamma': 0.0029655960594701884, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.31509103644250724, 'skip_drop': 0.8312141405544001}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:42,705]\u001b[0m Trial 13 finished with value: 1.1093830413092083 and parameters: {'booster': 'gbtree', 'lambda': 0.0001688865853887293, 'alpha': 2.236931350472621e-07, 'subsample': 0.5179128089409131, 'colsample_bytree': 0.716409335731074, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.9476973383574531, 'gamma': 0.028911697513087965, 'grow_policy': 'lossguide'}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:44,072]\u001b[0m Trial 14 finished with value: 1.3553443882434073 and parameters: {'booster': 'dart', 'lambda': 0.033345638825516666, 'alpha': 1.1402135662409272e-08, 'subsample': 0.3401318664373123, 'colsample_bytree': 0.6860099309877323, 'max_depth': 5, 'min_child_weight': 7, 'eta': 4.543080558089737e-05, 'gamma': 7.454351297505963e-05, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.000308319824262779, 'skip_drop': 0.0029031212596836776}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:44,387]\u001b[0m Trial 15 finished with value: 0.38088522791636964 and parameters: {'booster': 'gbtree', 'lambda': 0.00013502094473272908, 'alpha': 4.808715452641483e-07, 'subsample': 0.6583946027920353, 'colsample_bytree': 0.4544314845790367, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.010276267750140615, 'gamma': 0.028605464670606935, 'grow_policy': 'lossguide'}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:44,585]\u001b[0m Trial 16 finished with value: 1.3600622359704564 and parameters: {'booster': 'gbtree', 'lambda': 3.999138078359766e-07, 'alpha': 1.0381063154347841e-06, 'subsample': 0.6464830081370624, 'colsample_bytree': 0.8471437451444568, 'max_depth': 3, 'min_child_weight': 4, 'eta': 2.424096793611753e-05, 'gamma': 0.703764960203518, 'grow_policy': 'lossguide'}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:45,997]\u001b[0m Trial 17 finished with value: 0.20387716751101442 and parameters: {'booster': 'dart', 'lambda': 0.0476252254052929, 'alpha': 0.009913875347640346, 'subsample': 0.3788753008555875, 'colsample_bytree': 0.47418911812168685, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.037784814145158656, 'gamma': 0.00012168159058011994, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 7.611097067388825e-08, 'skip_drop': 2.5320932496106135e-08}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:47,370]\u001b[0m Trial 18 finished with value: 1.2658803554985953 and parameters: {'booster': 'dart', 'lambda': 2.0706837857304988e-05, 'alpha': 9.329861269022602e-08, 'subsample': 0.5644987357700733, 'colsample_bytree': 0.6329190060601672, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.00047135689212626124, 'gamma': 0.061606690857025324, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.0109982376966948, 'skip_drop': 0.010529202690430992}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:47,760]\u001b[0m Trial 19 finished with value: 0.20438605845097296 and parameters: {'booster': 'gbtree', 'lambda': 1.2544964074966683e-08, 'alpha': 3.3557368938156876e-08, 'subsample': 0.6677277875927609, 'colsample_bytree': 0.8079887813458274, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.09898509866472542, 'gamma': 0.0026280044347585397, 'grow_policy': 'lossguide'}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:49,058]\u001b[0m Trial 20 finished with value: 0.7952235308077961 and parameters: {'booster': 'dart', 'lambda': 0.0009233952179410924, 'alpha': 1.5474034904330172e-06, 'subsample': 0.971102370877592, 'colsample_bytree': 0.21218394755597086, 'max_depth': 3, 'min_child_weight': 10, 'eta': 0.004613924534124747, 'gamma': 0.00010107709172460218, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 5.698690367684199e-06, 'skip_drop': 5.591737768696906e-06}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:02:50,465]\u001b[0m Trial 21 finished with value: 0.2022292240855508 and parameters: {'booster': 'dart', 'lambda': 0.06184819218104198, 'alpha': 0.053374008112297706, 'subsample': 0.4016910513478528, 'colsample_bytree': 0.46372928455457574, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.057133542171478986, 'gamma': 5.8309249246445904e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.319457375973298e-08, 'skip_drop': 2.0645861130571148e-08}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:51,864]\u001b[0m Trial 22 finished with value: 0.25944935913267175 and parameters: {'booster': 'dart', 'lambda': 0.13035146073918213, 'alpha': 0.705609674223056, 'subsample': 0.3295194367923721, 'colsample_bytree': 0.520082796188539, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.16899562445457336, 'gamma': 9.276896744129923e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 2.2410275783377808e-06, 'skip_drop': 3.0049613026721746e-08}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:53,262]\u001b[0m Trial 23 finished with value: 0.3020291173026378 and parameters: {'booster': 'dart', 'lambda': 0.24137869984368443, 'alpha': 0.009775041876776662, 'subsample': 0.49314296275095404, 'colsample_bytree': 0.3698119984865059, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.015237679870468207, 'gamma': 0.006072559243089873, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.006026411338200286, 'skip_drop': 6.771991085566351e-07}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:54,645]\u001b[0m Trial 24 finished with value: 1.3182040297215936 and parameters: {'booster': 'dart', 'lambda': 0.012240633848667807, 'alpha': 0.05845074173603354, 'subsample': 0.42342548300367694, 'colsample_bytree': 0.6699429515625277, 'max_depth': 5, 'min_child_weight': 3, 'eta': 0.0002205743654241406, 'gamma': 1.630223909466214e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 5.681865645451487e-06, 'skip_drop': 0.04554175570244702}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:54,954]\u001b[0m Trial 25 finished with value: 0.26646415732887163 and parameters: {'booster': 'gbtree', 'lambda': 0.11608395299268319, 'alpha': 0.0008628703516223848, 'subsample': 0.5302780453137981, 'colsample_bytree': 0.42415887760562854, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.3181202268253933, 'gamma': 0.13014654387837254, 'grow_policy': 'lossguide'}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:55,327]\u001b[0m Trial 26 finished with value: 1.3634128632146947 and parameters: {'booster': 'dart', 'lambda': 0.9807471360315553, 'alpha': 2.3252192941407666e-05, 'subsample': 0.3087970482921055, 'colsample_bytree': 0.5302355920159937, 'max_depth': 7, 'min_child_weight': 3, 'eta': 9.52800836113833e-06, 'gamma': 0.0004692426369712825, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.8917522935509196, 'skip_drop': 0.00010913308339187842}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:55,437]\u001b[0m Trial 27 finished with value: 0.26989879559308894 and parameters: {'booster': 'gblinear', 'lambda': 0.00029477791430231417, 'alpha': 0.023725288539484822, 'subsample': 0.6098450359327007, 'colsample_bytree': 0.6142624879428679}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:56,778]\u001b[0m Trial 28 finished with value: 0.20698795969956055 and parameters: {'booster': 'dart', 'lambda': 0.005902010873329298, 'alpha': 4.0374063003562374e-08, 'subsample': 0.4336502596873133, 'colsample_bytree': 0.7584609706514538, 'max_depth': 5, 'min_child_weight': 5, 'eta': 0.021085117584195828, 'gamma': 2.416420812264813e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 3.6631286444565115e-07, 'skip_drop': 2.867790407047469e-07}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:57,047]\u001b[0m Trial 29 finished with value: 0.9192752396976764 and parameters: {'booster': 'gbtree', 'lambda': 1.7556333060670538e-07, 'alpha': 1.6022726462493332e-06, 'subsample': 0.3880387646926056, 'colsample_bytree': 0.7950635528679548, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.0024677231899817497, 'gamma': 1.5852985577062935e-05, 'grow_policy': 'lossguide'}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:57,164]\u001b[0m Trial 30 finished with value: 0.29474272160166604 and parameters: {'booster': 'gblinear', 'lambda': 4.8867599475888606e-05, 'alpha': 2.4932678251008543e-05, 'subsample': 0.29319524150880205, 'colsample_bytree': 0.867283955069437}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:58,527]\u001b[0m Trial 31 finished with value: 0.21168985151118766 and parameters: {'booster': 'dart', 'lambda': 0.04040833915536464, 'alpha': 0.006950557252705127, 'subsample': 0.36831665320640417, 'colsample_bytree': 0.5027266710875619, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.041144981244689745, 'gamma': 0.0002590706531888962, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 2.768009169632548e-08, 'skip_drop': 1.1875238052442177e-08}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:02:59,897]\u001b[0m Trial 32 finished with value: 0.24157791516983268 and parameters: {'booster': 'dart', 'lambda': 0.04958562265480075, 'alpha': 0.319632055455578, 'subsample': 0.4768822375143549, 'colsample_bytree': 0.39926358907679566, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.09314697061797748, 'gamma': 0.012752815134179507, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.290515601498256e-08, 'skip_drop': 9.654332227787518e-08}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:03:01,264]\u001b[0m Trial 33 finished with value: 0.3357346922179437 and parameters: {'booster': 'dart', 'lambda': 0.10468716887188567, 'alpha': 0.08182182179130748, 'subsample': 0.384553331898851, 'colsample_bytree': 0.49038745021520797, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.01217832050025674, 'gamma': 2.243811642553957e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.9159395022818768e-07, 'skip_drop': 2.193109570476609e-06}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:03:02,645]\u001b[0m Trial 34 finished with value: 0.31293323567084774 and parameters: {'booster': 'dart', 'lambda': 0.327677194154749, 'alpha': 0.008560599332696118, 'subsample': 0.2533838255820489, 'colsample_bytree': 0.651309246111063, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.25200188229641124, 'gamma': 0.31134991990220917, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 2.578749608916073e-05, 'skip_drop': 2.3156795136425405e-05}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:03:02,944]\u001b[0m Trial 35 finished with value: 1.2619627353323497 and parameters: {'booster': 'gbtree', 'lambda': 0.0009523099560398123, 'alpha': 0.0012843698708781004, 'subsample': 0.4552230748948048, 'colsample_bytree': 0.5619299304316356, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.0004922833769204771, 'gamma': 1.2045539354555235e-07, 'grow_policy': 'lossguide'}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:03:04,215]\u001b[0m Trial 36 finished with value: 0.22645280355405847 and parameters: {'booster': 'dart', 'lambda': 2.8028426335877676e-06, 'alpha': 5.485126495974024e-06, 'subsample': 0.7031226938572964, 'colsample_bytree': 0.3089395670627093, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.04653924452662259, 'gamma': 0.000879921516400868, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 2.1040269426196747e-07, 'skip_drop': 1.3117180909001898e-07}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:03:05,575]\u001b[0m Trial 37 finished with value: 1.3646970615629326 and parameters: {'booster': 'dart', 'lambda': 0.011543893559840673, 'alpha': 0.023442343783712752, 'subsample': 0.5480944178404243, 'colsample_bytree': 0.5911836950755333, 'max_depth': 5, 'min_child_weight': 2, 'eta': 2.8246930881040984e-06, 'gamma': 8.855108051683414e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.0022844790282418783, 'skip_drop': 1.0069073205428154e-08}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:03:05,691]\u001b[0m Trial 38 finished with value: 0.2854490113090765 and parameters: {'booster': 'gblinear', 'lambda': 0.3637914131310976, 'alpha': 0.0036283160555525343, 'subsample': 0.2066054680346685, 'colsample_bytree': 0.3707818417199452}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:03:05,940]\u001b[0m Trial 39 finished with value: 0.5517431137404369 and parameters: {'booster': 'gbtree', 'lambda': 0.003052652848526377, 'alpha': 6.200011937359513e-05, 'subsample': 0.5930366351303057, 'colsample_bytree': 0.4495292651072509, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.7655240574663595, 'gamma': 0.2588377336436025, 'grow_policy': 'depthwise'}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:03:07,215]\u001b[0m Trial 40 finished with value: 0.7997287202054838 and parameters: {'booster': 'dart', 'lambda': 0.02798643494790221, 'alpha': 0.00043165336793254185, 'subsample': 0.2911388229198298, 'colsample_bytree': 0.551472404935158, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.0039045022433980264, 'gamma': 0.06040750469734134, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 8.393706022828112e-07, 'skip_drop': 0.041992794778504434}. Best is trial 7 with value: 0.19529250185167404.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:03:08,732]\u001b[0m A new study created in memory with name: no-name-76228848-25a7-48af-b61b-170b59205ed2\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:03:13,767]\u001b[0m Trial 0 finished with value: 0.6151367452123124 and parameters: {'booster': 'dart', 'lambda': 4.023312775899365e-07, 'alpha': 0.01700961280834833, 'subsample': 0.24877715575094206, 'colsample_bytree': 0.7556676394125141, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.007436526231085558, 'gamma': 0.09327791445054691, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 4.567891525781973e-08, 'skip_drop': 1.0980467876855333e-05}. Best is trial 0 with value: 0.6151367452123124.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:03:14,188]\u001b[0m Trial 1 finished with value: 0.6763774961932933 and parameters: {'booster': 'gbtree', 'lambda': 5.504115288029073e-07, 'alpha': 0.0008488888720158079, 'subsample': 0.5686611530500001, 'colsample_bytree': 0.3608643792917423, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.3289324094545204, 'gamma': 0.04574807613264726, 'grow_policy': 'depthwise'}. Best is trial 1 with value: 0.6763774961932933.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:03:14,667]\u001b[0m Trial 2 finished with value: 0.5957705291343058 and parameters: {'booster': 'gbtree', 'lambda': 0.010337364949459948, 'alpha': 0.0004339443723204821, 'subsample': 0.35833842697741036, 'colsample_bytree': 0.6415052142399262, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.00010802111931619145, 'gamma': 9.667064778697332e-08, 'grow_policy': 'depthwise'}. Best is trial 1 with value: 0.6763774961932933.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:03:15,240]\u001b[0m Trial 3 finished with value: 0.645018616697952 and parameters: {'booster': 'gbtree', 'lambda': 3.70193498831987e-07, 'alpha': 1.3135499228553859e-05, 'subsample': 0.2987498288371515, 'colsample_bytree': 0.7419944105570739, 'max_depth': 9, 'min_child_weight': 3, 'eta': 4.697046871240622e-05, 'gamma': 0.40532394130806704, 'grow_policy': 'lossguide'}. Best is trial 1 with value: 0.6763774961932933.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:03:15,557]\u001b[0m Trial 4 finished with value: 0.6193323672581698 and parameters: {'booster': 'gbtree', 'lambda': 2.2922192978500583e-07, 'alpha': 0.0004270062997785232, 'subsample': 0.5627768551419724, 'colsample_bytree': 0.4746376410802311, 'max_depth': 3, 'min_child_weight': 3, 'eta': 2.2926064181231166e-08, 'gamma': 7.204863786477947e-08, 'grow_policy': 'lossguide'}. Best is trial 1 with value: 0.6763774961932933.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:03:21,116]\u001b[0m Trial 5 finished with value: 0.6285352842856696 and parameters: {'booster': 'dart', 'lambda': 0.05024599886908925, 'alpha': 2.0062212128587337e-06, 'subsample': 0.7901736088411377, 'colsample_bytree': 0.8792596706658315, 'max_depth': 7, 'min_child_weight': 7, 'eta': 4.190931077079746e-07, 'gamma': 0.003980352806652941, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.014490721503678276, 'skip_drop': 1.1078400928714188e-07}. Best is trial 1 with value: 0.6763774961932933.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:03:21,980]\u001b[0m Trial 6 finished with value: 0.6823025257628224 and parameters: {'booster': 'gbtree', 'lambda': 4.250530928415226e-06, 'alpha': 0.0008293878405467072, 'subsample': 0.5127837243603541, 'colsample_bytree': 0.7490411087410835, 'max_depth': 9, 'min_child_weight': 2, 'eta': 2.8581342915350937e-05, 'gamma': 0.1907922691367452, 'grow_policy': 'lossguide'}. Best is trial 6 with value: 0.6823025257628224.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:03:22,517]\u001b[0m Trial 7 finished with value: 0.6577904613913459 and parameters: {'booster': 'gbtree', 'lambda': 5.862861547954537e-05, 'alpha': 2.0891183957536227e-08, 'subsample': 0.5028281361840672, 'colsample_bytree': 0.7061438031628251, 'max_depth': 5, 'min_child_weight': 3, 'eta': 0.00042729289469247827, 'gamma': 3.179955253136764e-05, 'grow_policy': 'lossguide'}. Best is trial 6 with value: 0.6823025257628224.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:03:22,769]\u001b[0m Trial 8 finished with value: 0.6505915103912149 and parameters: {'booster': 'gbtree', 'lambda': 6.819066141497339e-06, 'alpha': 2.0203452564844438e-06, 'subsample': 0.22114720469630536, 'colsample_bytree': 0.4528091229973339, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.8039369901533796, 'gamma': 4.196144559717401e-08, 'grow_policy': 'depthwise'}. Best is trial 6 with value: 0.6823025257628224.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:03:28,151]\u001b[0m Trial 9 finished with value: 0.6272177947224653 and parameters: {'booster': 'dart', 'lambda': 0.002030213129789247, 'alpha': 6.444743135475231e-07, 'subsample': 0.3443454076253206, 'colsample_bytree': 0.9016953922859328, 'max_depth': 7, 'min_child_weight': 5, 'eta': 2.3849531530822356e-07, 'gamma': 3.998681144601659e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.0026446341053887185, 'skip_drop': 0.19403305468636683}. Best is trial 6 with value: 0.6823025257628224.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:03:28,295]\u001b[0m Trial 10 finished with value: 0.5538162855695823 and parameters: {'booster': 'gblinear', 'lambda': 0.8827590285581829, 'alpha': 0.15365658772130833, 'subsample': 0.9941525651286744, 'colsample_bytree': 0.2473514547809031}. Best is trial 6 with value: 0.6823025257628224.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:03:28,537]\u001b[0m Trial 11 finished with value: 0.6245599914700055 and parameters: {'booster': 'gblinear', 'lambda': 1.3054298174228208e-08, 'alpha': 0.010887951414794206, 'subsample': 0.6838071420431348, 'colsample_bytree': 0.2149817370744479}. Best is trial 6 with value: 0.6823025257628224.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:03:29,159]\u001b[0m Trial 12 finished with value: 0.6769294927551507 and parameters: {'booster': 'gbtree', 'lambda': 1.9498065876741676e-05, 'alpha': 0.002052361962625842, 'subsample': 0.47041808988476747, 'colsample_bytree': 0.48914336625265487, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.2696565863856074, 'gamma': 0.0066232050539316726, 'grow_policy': 'lossguide'}. Best is trial 6 with value: 0.6823025257628224.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:03:29,668]\u001b[0m Trial 13 finished with value: 0.6226603234703474 and parameters: {'booster': 'gbtree', 'lambda': 0.00013299779935568154, 'alpha': 0.42220488975910736, 'subsample': 0.4619207993907534, 'colsample_bytree': 0.5521984027011908, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.006353876610677221, 'gamma': 0.0011755901192260318, 'grow_policy': 'lossguide'}. Best is trial 6 with value: 0.6823025257628224.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:03:30,259]\u001b[0m Trial 14 finished with value: 0.6543448390447906 and parameters: {'booster': 'gbtree', 'lambda': 9.68099096576422e-06, 'alpha': 0.00785938149258437, 'subsample': 0.6916101294300687, 'colsample_bytree': 0.5686649825667135, 'max_depth': 5, 'min_child_weight': 2, 'eta': 6.030495494877495e-06, 'gamma': 0.0036726270966282166, 'grow_policy': 'lossguide'}. Best is trial 6 with value: 0.6823025257628224.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:03:30,553]\u001b[0m Trial 15 finished with value: 0.6682214549833034 and parameters: {'booster': 'gblinear', 'lambda': 0.0006031880063415496, 'alpha': 2.4952665772928247e-05, 'subsample': 0.4180767029801433, 'colsample_bytree': 0.9710127693616762}. Best is trial 6 with value: 0.6823025257628224.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:03:31,294]\u001b[0m Trial 16 finished with value: 0.6669633737049467 and parameters: {'booster': 'gbtree', 'lambda': 6.6688882456239035e-06, 'alpha': 0.0030019249036346246, 'subsample': 0.6593498411817051, 'colsample_bytree': 0.348918276140334, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.006228745320779034, 'gamma': 0.812481378801125, 'grow_policy': 'lossguide'}. Best is trial 6 with value: 0.6823025257628224.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:03:31,997]\u001b[0m Trial 17 finished with value: 0.6650828061282189 and parameters: {'booster': 'gbtree', 'lambda': 1.511222130020139e-08, 'alpha': 6.26557490208195e-05, 'subsample': 0.8152380901307792, 'colsample_bytree': 0.7855542957154514, 'max_depth': 5, 'min_child_weight': 5, 'eta': 6.167459967321572e-06, 'gamma': 0.018996557867454803, 'grow_policy': 'lossguide'}. Best is trial 6 with value: 0.6823025257628224.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:03:37,593]\u001b[0m Trial 18 finished with value: 0.6933584776062196 and parameters: {'booster': 'dart', 'lambda': 5.094106795293072e-05, 'alpha': 0.050595856738664347, 'subsample': 0.4176912672197061, 'colsample_bytree': 0.6660230981990232, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.06790967609317684, 'gamma': 0.00029413349016883686, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 1.6841152248271052e-07, 'skip_drop': 0.9008511496876715}. Best is trial 18 with value: 0.6933584776062196.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:03:43,047]\u001b[0m Trial 19 finished with value: 0.6976312341786205 and parameters: {'booster': 'dart', 'lambda': 0.0001208808632237664, 'alpha': 0.13549704714767732, 'subsample': 0.3978595935634932, 'colsample_bytree': 0.6625982004382274, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.049740614480453346, 'gamma': 4.190466420553791e-06, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 1.1601619846026233e-07, 'skip_drop': 0.7898978005947557}. Best is trial 19 with value: 0.6976312341786205.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:03:49,554]\u001b[0m A new study created in memory with name: no-name-5d874cb9-fbd4-4f3b-8a75-6bf0cdcb8ba3\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:03:57,532]\u001b[0m Trial 0 finished with value: 0.9051498127340825 and parameters: {'booster': 'dart', 'lambda': 2.9883915003763616e-05, 'alpha': 0.01642785788363811, 'subsample': 0.39622792173815036, 'colsample_bytree': 0.7957215061068006, 'max_depth': 5, 'min_child_weight': 9, 'eta': 2.0872965138129677e-05, 'gamma': 1.5445330353563834e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 3.5304190876397727e-07, 'skip_drop': 4.554578304577266e-07}. Best is trial 0 with value: 0.9051498127340825.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:04:05,099]\u001b[0m Trial 1 finished with value: 0.9241251166767658 and parameters: {'booster': 'dart', 'lambda': 1.6639530227967086e-07, 'alpha': 2.7156308905839936e-06, 'subsample': 0.3505185780174749, 'colsample_bytree': 0.8148307754464683, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.00012575915244385406, 'gamma': 0.015110913708503251, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.05189118827987544, 'skip_drop': 0.39755016625069406}. Best is trial 1 with value: 0.9241251166767658.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:04:05,532]\u001b[0m Trial 2 finished with value: 0.8227020036613426 and parameters: {'booster': 'gbtree', 'lambda': 0.00027263150501936125, 'alpha': 0.005726070409312984, 'subsample': 0.5653445255339811, 'colsample_bytree': 0.2711370123560796, 'max_depth': 9, 'min_child_weight': 6, 'eta': 2.1758253193934346e-07, 'gamma': 0.4417536798142373, 'grow_policy': 'depthwise'}. Best is trial 1 with value: 0.9241251166767658.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:04:05,696]\u001b[0m Trial 3 finished with value: 0.8419276738674532 and parameters: {'booster': 'gblinear', 'lambda': 0.0028571587497758072, 'alpha': 0.07859020840843607, 'subsample': 0.5027665282801259, 'colsample_bytree': 0.5202369629940158}. Best is trial 1 with value: 0.9241251166767658.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:04:13,224]\u001b[0m Trial 4 finished with value: 0.8227020036613426 and parameters: {'booster': 'dart', 'lambda': 1.468165824520343e-08, 'alpha': 3.999413268609432e-06, 'subsample': 0.2959559281696302, 'colsample_bytree': 0.30278506032027064, 'max_depth': 7, 'min_child_weight': 3, 'eta': 5.724898108113386e-06, 'gamma': 1.2882001418580761e-06, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 4.533807168063114e-08, 'skip_drop': 0.000584322857149253}. Best is trial 1 with value: 0.9241251166767658.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:04:13,444]\u001b[0m Trial 5 finished with value: 0.8837535197973706 and parameters: {'booster': 'gblinear', 'lambda': 1.1274816491553906e-08, 'alpha': 0.013177631016859972, 'subsample': 0.4861333915515115, 'colsample_bytree': 0.2955763416884938}. Best is trial 1 with value: 0.9241251166767658.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:04:20,930]\u001b[0m Trial 6 finished with value: 0.9186488644002689 and parameters: {'booster': 'dart', 'lambda': 9.862312155057465e-05, 'alpha': 2.3441566413708795e-08, 'subsample': 0.9428063915883438, 'colsample_bytree': 0.8411852583995019, 'max_depth': 5, 'min_child_weight': 2, 'eta': 1.588847917268904e-05, 'gamma': 8.780918648064051e-06, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.0003273200615627565, 'skip_drop': 5.60028750997314e-07}. Best is trial 1 with value: 0.9241251166767658.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:04:21,345]\u001b[0m Trial 7 finished with value: 0.8320858325589254 and parameters: {'booster': 'gblinear', 'lambda': 0.25141416604685324, 'alpha': 0.0022347238070265767, 'subsample': 0.926338085967241, 'colsample_bytree': 0.7862601408692809}. Best is trial 1 with value: 0.9241251166767658.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:04:21,834]\u001b[0m Trial 8 finished with value: 0.9045566325060705 and parameters: {'booster': 'gblinear', 'lambda': 6.836583748173929e-06, 'alpha': 7.564204383904829e-07, 'subsample': 0.913486330722922, 'colsample_bytree': 0.27380249151080377}. Best is trial 1 with value: 0.9241251166767658.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:04:27,489]\u001b[0m Trial 9 finished with value: 0.9117170347410564 and parameters: {'booster': 'dart', 'lambda': 3.4858027820562584e-08, 'alpha': 0.004838925644381868, 'subsample': 0.5240211046159835, 'colsample_bytree': 0.9012902536030218, 'max_depth': 7, 'min_child_weight': 5, 'eta': 0.007223074403716498, 'gamma': 4.053222355091779e-06, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.2881519348730919, 'skip_drop': 0.009769564342975262}. Best is trial 1 with value: 0.9241251166767658.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:04:35,563]\u001b[0m A new study created in memory with name: no-name-34b9523a-7c0b-49eb-9b4a-d65d3ef2264d\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:04:40,539]\u001b[0m Trial 0 finished with value: 0.8918334589052315 and parameters: {'booster': 'dart', 'lambda': 0.0001890098263863456, 'alpha': 9.15438202308836e-07, 'subsample': 0.23597862921248824, 'colsample_bytree': 0.35284590497661555, 'max_depth': 5, 'min_child_weight': 8, 'eta': 9.00592741173151e-07, 'gamma': 0.00048006009507677917, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 5.252762868925713e-08, 'skip_drop': 5.2382805892738455e-08}. Best is trial 0 with value: 0.8918334589052315.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:04:45,576]\u001b[0m Trial 1 finished with value: 0.8918334589052315 and parameters: {'booster': 'dart', 'lambda': 0.07316439629378069, 'alpha': 0.0007397403328492873, 'subsample': 0.6400593971187656, 'colsample_bytree': 0.575623480241773, 'max_depth': 3, 'min_child_weight': 3, 'eta': 9.899536603108186e-07, 'gamma': 0.22184841889008305, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 2.5264151567611446e-05, 'skip_drop': 0.0013371762572517102}. Best is trial 0 with value: 0.8918334589052315.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:04:46,173]\u001b[0m Trial 2 finished with value: 0.8918334589052315 and parameters: {'booster': 'gbtree', 'lambda': 0.010233217912596598, 'alpha': 0.00727447847175221, 'subsample': 0.855949040186603, 'colsample_bytree': 0.7957047095085041, 'max_depth': 7, 'min_child_weight': 10, 'eta': 1.929454246125166e-06, 'gamma': 0.48399211732666025, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.8918334589052315.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:04:51,235]\u001b[0m Trial 3 finished with value: 0.8918334589052315 and parameters: {'booster': 'dart', 'lambda': 0.006350218282661681, 'alpha': 9.462176257882137e-07, 'subsample': 0.5764243933517288, 'colsample_bytree': 0.4252038047766862, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.0010135037845323634, 'gamma': 9.060197149420932e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 4.864466460982975e-07, 'skip_drop': 1.4493659365909063e-07}. Best is trial 0 with value: 0.8918334589052315.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:04:51,522]\u001b[0m Trial 4 finished with value: 0.8918334589052315 and parameters: {'booster': 'gbtree', 'lambda': 4.460248281267271e-07, 'alpha': 0.5747526427655621, 'subsample': 0.3824325515930574, 'colsample_bytree': 0.6585438073326815, 'max_depth': 7, 'min_child_weight': 7, 'eta': 4.6817079533244626e-07, 'gamma': 0.0034084528142705297, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.8918334589052315.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:04:51,794]\u001b[0m Trial 5 finished with value: 0.8904289346346264 and parameters: {'booster': 'gblinear', 'lambda': 0.026994262231205816, 'alpha': 4.294722933253097e-08, 'subsample': 0.20428240436026687, 'colsample_bytree': 0.45402461697671204}. Best is trial 0 with value: 0.8918334589052315.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:04:52,027]\u001b[0m Trial 6 finished with value: 0.8873695826645265 and parameters: {'booster': 'gbtree', 'lambda': 0.002019241377586119, 'alpha': 1.557431326246512e-07, 'subsample': 0.611314592425148, 'colsample_bytree': 0.3434625036124376, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.985537424337192, 'gamma': 4.4515950571032427e-08, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.8918334589052315.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:04:52,297]\u001b[0m Trial 7 finished with value: 0.8818263488207309 and parameters: {'booster': 'gblinear', 'lambda': 1.0371162127627892e-07, 'alpha': 1.2201137922859097e-08, 'subsample': 0.7990810595875191, 'colsample_bytree': 0.4974896058128622}. Best is trial 0 with value: 0.8918334589052315.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:04:57,492]\u001b[0m Trial 8 finished with value: 0.8918334589052315 and parameters: {'booster': 'dart', 'lambda': 3.093526519564861e-08, 'alpha': 0.5282979977827307, 'subsample': 0.7431472319461674, 'colsample_bytree': 0.8714807935763784, 'max_depth': 7, 'min_child_weight': 6, 'eta': 0.010701576499522969, 'gamma': 3.5214408756739426e-07, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 7.967954184719155e-05, 'skip_drop': 0.7908070469984823}. Best is trial 0 with value: 0.8918334589052315.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:04:57,766]\u001b[0m Trial 9 finished with value: 0.8918334589052315 and parameters: {'booster': 'gblinear', 'lambda': 0.0794435636892805, 'alpha': 2.431049344582155e-05, 'subsample': 0.8836953249784112, 'colsample_bytree': 0.6614943087904598}. Best is trial 0 with value: 0.8918334589052315.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:05:02,798]\u001b[0m Trial 10 finished with value: 0.003407129228625942 and parameters: {'booster': 'dart', 'lambda': 1.4515326495738949e-05, 'alpha': 9.499159512866428e-06, 'subsample': 0.23497587800867148, 'colsample_bytree': 0.24182228393839517, 'max_depth': 9, 'min_child_weight': 10, 'eta': 1.4140759349256511e-08, 'gamma': 5.602518955303216e-05, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 2.8005307888184475e-08, 'skip_drop': 1.3112112847221145e-08}. Best is trial 0 with value: 0.8918334589052315.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:05:06,830]\u001b[0m Trial 11 finished with value: 0.8918334589052315 and parameters: {'booster': 'dart', 'lambda': 8.728356526654081e-05, 'alpha': 0.0010752018285118967, 'subsample': 0.47852917735165984, 'colsample_bytree': 0.21134705435067402, 'max_depth': 3, 'min_child_weight': 2, 'eta': 8.085431874918489e-06, 'gamma': 0.9172466895199993, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.29158586969693884, 'skip_drop': 0.0006392460713119305}. Best is trial 0 with value: 0.8918334589052315.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:05:12,158]\u001b[0m Trial 12 finished with value: 0.8918334589052315 and parameters: {'booster': 'dart', 'lambda': 0.5967066135794031, 'alpha': 0.000694074740420014, 'subsample': 0.6681078747179878, 'colsample_bytree': 0.5311989761790201, 'max_depth': 5, 'min_child_weight': 8, 'eta': 3.1772422982222486e-08, 'gamma': 0.002455869973411857, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.9469362538386077e-05, 'skip_drop': 0.0003074321742052375}. Best is trial 0 with value: 0.8918334589052315.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:05:17,958]\u001b[0m A new study created in memory with name: no-name-e35b1139-7827-462e-9f09-d91b5eebb870\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:05:26,694]\u001b[0m Trial 0 finished with value: 0.6586101305080975 and parameters: {'booster': 'dart', 'lambda': 9.642595645101966e-07, 'alpha': 1.3344681577469087e-08, 'subsample': 0.8149460917689557, 'colsample_bytree': 0.837557720538479, 'max_depth': 7, 'min_child_weight': 5, 'eta': 0.0006286092086141924, 'gamma': 7.832223405593378e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 1.3540244855028898e-08, 'skip_drop': 1.7242372020960457e-06}. Best is trial 0 with value: 0.6586101305080975.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:05:27,094]\u001b[0m Trial 1 finished with value: 0.5838181117061508 and parameters: {'booster': 'gblinear', 'lambda': 0.009009580141576915, 'alpha': 0.00499860785298567, 'subsample': 0.5179469917421501, 'colsample_bytree': 0.6895959392340243}. Best is trial 0 with value: 0.6586101305080975.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:05:27,606]\u001b[0m Trial 2 finished with value: 0.6129176171277612 and parameters: {'booster': 'gblinear', 'lambda': 0.0008520540333704662, 'alpha': 6.309243368015337e-07, 'subsample': 0.9949993704321718, 'colsample_bytree': 0.6158599932040307}. Best is trial 0 with value: 0.6586101305080975.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:05:35,641]\u001b[0m Trial 3 finished with value: 0.6245851239772086 and parameters: {'booster': 'dart', 'lambda': 0.02171122294056219, 'alpha': 0.08046225351097404, 'subsample': 0.5642807693331751, 'colsample_bytree': 0.4229900574985441, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.0008163073971888229, 'gamma': 2.1465287053300734e-05, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 6.556054129395794e-05, 'skip_drop': 4.034987505810201e-08}. Best is trial 0 with value: 0.6586101305080975.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:05:36,082]\u001b[0m Trial 4 finished with value: 0.6431822572974258 and parameters: {'booster': 'gbtree', 'lambda': 0.06569209019544746, 'alpha': 0.009406115528078034, 'subsample': 0.47715876537755286, 'colsample_bytree': 0.566832175514846, 'max_depth': 3, 'min_child_weight': 8, 'eta': 0.0067072912816235385, 'gamma': 0.05345587836567998, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.6586101305080975.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:05:36,608]\u001b[0m Trial 5 finished with value: 0.603781784405375 and parameters: {'booster': 'gblinear', 'lambda': 7.696998342794208e-05, 'alpha': 1.653382745308835e-06, 'subsample': 0.9394538826409982, 'colsample_bytree': 0.6640472336788885}. Best is trial 0 with value: 0.6586101305080975.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:05:44,213]\u001b[0m Trial 6 finished with value: 0.6345046138263294 and parameters: {'booster': 'dart', 'lambda': 4.444464280518435e-05, 'alpha': 0.00015617821232051852, 'subsample': 0.4152269095889203, 'colsample_bytree': 0.7267528387382076, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.10039146480931221, 'gamma': 0.6071034794128365, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.0008295645391782321, 'skip_drop': 0.0638108646141904}. Best is trial 0 with value: 0.6586101305080975.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:05:44,334]\u001b[0m Trial 7 finished with value: 0.11031210986267163 and parameters: {'booster': 'gblinear', 'lambda': 0.3605402495716608, 'alpha': 0.5239840717225679, 'subsample': 0.7710429793567148, 'colsample_bytree': 0.3405306329517763}. Best is trial 0 with value: 0.6586101305080975.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:05:44,748]\u001b[0m Trial 8 finished with value: 0.6103061019138885 and parameters: {'booster': 'gbtree', 'lambda': 1.0332384341780702e-05, 'alpha': 0.6484623445203028, 'subsample': 0.36508498369604947, 'colsample_bytree': 0.60593661920626, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.7560496390083237, 'gamma': 0.0013970253657406941, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.6586101305080975.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:05:52,048]\u001b[0m Trial 9 finished with value: 0.6514722579407607 and parameters: {'booster': 'dart', 'lambda': 5.127326525217484e-07, 'alpha': 0.11377232381304676, 'subsample': 0.6067318002456848, 'colsample_bytree': 0.9817311623307095, 'max_depth': 7, 'min_child_weight': 3, 'eta': 1.2542123482562752e-08, 'gamma': 0.0014628984882536023, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.13606253136989424, 'skip_drop': 0.003980331044339713}. Best is trial 0 with value: 0.6586101305080975.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:06:01,566]\u001b[0m A new study created in memory with name: no-name-42afcb21-002d-4c7d-b90a-3fd72e58cc7f\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:01,828]\u001b[0m Trial 0 finished with value: 0.7728458556946931 and parameters: {'booster': 'gblinear', 'lambda': 0.0020304695954137613, 'alpha': 0.00013770631728811052, 'subsample': 0.8957521709558742, 'colsample_bytree': 0.3690282548011486}. Best is trial 0 with value: 0.7728458556946931.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:02,103]\u001b[0m Trial 1 finished with value: 0.7680915005390169 and parameters: {'booster': 'gblinear', 'lambda': 2.3907375600682502e-06, 'alpha': 1.0100140944258364e-06, 'subsample': 0.6406238916985353, 'colsample_bytree': 0.5337859308409827}. Best is trial 0 with value: 0.7728458556946931.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:05,306]\u001b[0m Trial 2 finished with value: 0.7769311740604439 and parameters: {'booster': 'dart', 'lambda': 0.001986416329270041, 'alpha': 0.0053823214843453345, 'subsample': 0.4240460960420415, 'colsample_bytree': 0.21112989850360703, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.1631766341380436, 'gamma': 0.0006859075366852491, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.8008855036011993, 'skip_drop': 5.371811995339877e-07}. Best is trial 2 with value: 0.7769311740604439.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:05,584]\u001b[0m Trial 3 finished with value: 0.7789803680863402 and parameters: {'booster': 'gblinear', 'lambda': 0.00016836293937293103, 'alpha': 1.1080117064736172e-07, 'subsample': 0.35197587776671135, 'colsample_bytree': 0.45106216379162406}. Best is trial 3 with value: 0.7789803680863402.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:06,079]\u001b[0m Trial 4 finished with value: 0.8012792734925737 and parameters: {'booster': 'gbtree', 'lambda': 0.0030595318946677803, 'alpha': 0.1965909633407186, 'subsample': 0.39287412517939035, 'colsample_bytree': 0.8238743293873294, 'max_depth': 7, 'min_child_weight': 6, 'eta': 5.97132211817955e-08, 'gamma': 0.003203204496018221, 'grow_policy': 'lossguide'}. Best is trial 4 with value: 0.8012792734925737.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:06,359]\u001b[0m Trial 5 finished with value: 0.7761851045627756 and parameters: {'booster': 'gblinear', 'lambda': 0.0004778149247991276, 'alpha': 7.852173091136149e-08, 'subsample': 0.5093877391993509, 'colsample_bytree': 0.4830818794040937}. Best is trial 4 with value: 0.8012792734925737.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:06,639]\u001b[0m Trial 6 finished with value: 0.7754725817790533 and parameters: {'booster': 'gblinear', 'lambda': 5.236097655792292e-05, 'alpha': 1.4674673903496146e-05, 'subsample': 0.7416949937991644, 'colsample_bytree': 0.3827049615710322}. Best is trial 4 with value: 0.8012792734925737.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:06,811]\u001b[0m Trial 7 finished with value: 0.7713113666038924 and parameters: {'booster': 'gblinear', 'lambda': 0.09790704628174833, 'alpha': 0.02930432210285532, 'subsample': 0.8412626263955392, 'colsample_bytree': 0.6312726989982038}. Best is trial 4 with value: 0.8012792734925737.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:11,972]\u001b[0m Trial 8 finished with value: 0.7827091324402135 and parameters: {'booster': 'dart', 'lambda': 6.804659857913836e-07, 'alpha': 0.0005438183952519603, 'subsample': 0.2790060016076143, 'colsample_bytree': 0.28089984010879504, 'max_depth': 7, 'min_child_weight': 2, 'eta': 2.0925859700120263e-05, 'gamma': 0.00010382281086118477, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.0004440117103952325, 'skip_drop': 0.00010487905729857684}. Best is trial 4 with value: 0.8012792734925737.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:17,055]\u001b[0m Trial 9 finished with value: 0.011470037453183523 and parameters: {'booster': 'dart', 'lambda': 1.8145869759005902e-08, 'alpha': 3.472994823053391e-07, 'subsample': 0.21932012119247288, 'colsample_bytree': 0.5834471402258977, 'max_depth': 9, 'min_child_weight': 6, 'eta': 1.3358622929243308e-08, 'gamma': 0.003147060769744337, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 2.4166184794384468e-05, 'skip_drop': 0.00038318049189070243}. Best is trial 4 with value: 0.8012792734925737.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:17,493]\u001b[0m Trial 10 finished with value: 0.011470037453183523 and parameters: {'booster': 'gbtree', 'lambda': 0.7655688119282907, 'alpha': 0.458314989142186, 'subsample': 0.5566512340815792, 'colsample_bytree': 0.8766861005595977, 'max_depth': 3, 'min_child_weight': 6, 'eta': 1.2657065563082714e-08, 'gamma': 1.1585291901808178e-08, 'grow_policy': 'lossguide'}. Best is trial 4 with value: 0.8012792734925737.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:18,018]\u001b[0m Trial 11 finished with value: 0.7971187907052735 and parameters: {'booster': 'gbtree', 'lambda': 4.840909973752115e-07, 'alpha': 0.0003691683785142785, 'subsample': 0.2761390209473815, 'colsample_bytree': 0.8373864520775258, 'max_depth': 7, 'min_child_weight': 2, 'eta': 4.913055429751171e-05, 'gamma': 1.0644384416614408e-05, 'grow_policy': 'lossguide'}. Best is trial 4 with value: 0.8012792734925737.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:18,567]\u001b[0m Trial 12 finished with value: 0.7985041355770882 and parameters: {'booster': 'gbtree', 'lambda': 1.4643611332120443e-08, 'alpha': 0.8270098503875929, 'subsample': 0.4087352135313568, 'colsample_bytree': 0.9115542565796448, 'max_depth': 5, 'min_child_weight': 2, 'eta': 3.545149293959166e-05, 'gamma': 4.514744071158735e-07, 'grow_policy': 'lossguide'}. Best is trial 4 with value: 0.8012792734925737.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:18,993]\u001b[0m Trial 13 finished with value: 0.7956723795408253 and parameters: {'booster': 'gbtree', 'lambda': 0.02196191012128447, 'alpha': 0.35542027259574116, 'subsample': 0.42762988092147775, 'colsample_bytree': 0.9979797539298837, 'max_depth': 3, 'min_child_weight': 4, 'eta': 1.597646635454699e-06, 'gamma': 0.4427376371543294, 'grow_policy': 'lossguide'}. Best is trial 4 with value: 0.8012792734925737.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:06:19,473]\u001b[0m Trial 14 finished with value: 0.791580990714407 and parameters: {'booster': 'gbtree', 'lambda': 3.883316255832628e-08, 'alpha': 0.019796091419818994, 'subsample': 0.6560223343687989, 'colsample_bytree': 0.7505602747486217, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.09657979260569366, 'gamma': 2.1204158465190704e-07, 'grow_policy': 'lossguide'}. Best is trial 4 with value: 0.8012792734925737.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:20,000]\u001b[0m Trial 15 finished with value: 0.7998840814938718 and parameters: {'booster': 'gbtree', 'lambda': 1.2266122264167399e-05, 'alpha': 0.49237525091583995, 'subsample': 0.4652634114415662, 'colsample_bytree': 0.9840709344729434, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.0023474361676129696, 'gamma': 0.028024866706238362, 'grow_policy': 'lossguide'}. Best is trial 4 with value: 0.8012792734925737.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:20,631]\u001b[0m Trial 16 finished with value: 0.7998840814938718 and parameters: {'booster': 'gbtree', 'lambda': 1.4719170282388182e-05, 'alpha': 0.04850683344542136, 'subsample': 0.5401872775913646, 'colsample_bytree': 0.7698938646429144, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.0034005953388861086, 'gamma': 0.09053586731533407, 'grow_policy': 'lossguide'}. Best is trial 4 with value: 0.8012792734925737.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:21,449]\u001b[0m Trial 17 finished with value: 0.7957247980747103 and parameters: {'booster': 'gbtree', 'lambda': 0.008664850463247529, 'alpha': 0.003035438072161346, 'subsample': 0.9948001339544025, 'colsample_bytree': 0.7239386017258658, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.005181886328348813, 'gamma': 0.6329287204543033, 'grow_policy': 'depthwise'}. Best is trial 4 with value: 0.8012792734925737.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:22,042]\u001b[0m Trial 18 finished with value: 0.7972623849837713 and parameters: {'booster': 'gbtree', 'lambda': 1.179182840413936e-05, 'alpha': 0.09958509702071895, 'subsample': 0.4858123004512501, 'colsample_bytree': 0.9616239425115836, 'max_depth': 5, 'min_child_weight': 5, 'eta': 9.501764440411018e-07, 'gamma': 0.013829658678487915, 'grow_policy': 'lossguide'}. Best is trial 4 with value: 0.8012792734925737.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:22,792]\u001b[0m Trial 19 finished with value: 0.8012792734925737 and parameters: {'booster': 'gbtree', 'lambda': 4.2197639373147074e-05, 'alpha': 6.832942767263744e-06, 'subsample': 0.7054146670761324, 'colsample_bytree': 0.7325767963628116, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.0019885833424489623, 'gamma': 0.06269510254954921, 'grow_policy': 'lossguide'}. Best is trial 4 with value: 0.8012792734925737.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:23,561]\u001b[0m Trial 20 finished with value: 0.7955732805261125 and parameters: {'booster': 'gbtree', 'lambda': 0.0004833519738054609, 'alpha': 1.1823765810075097e-05, 'subsample': 0.7376029048979804, 'colsample_bytree': 0.659224346405911, 'max_depth': 9, 'min_child_weight': 4, 'eta': 8.461362930531968e-07, 'gamma': 0.0006264608928737019, 'grow_policy': 'lossguide'}. Best is trial 4 with value: 0.8012792734925737.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:24,330]\u001b[0m Trial 21 finished with value: 0.8012792734925737 and parameters: {'booster': 'gbtree', 'lambda': 2.118299841696519e-05, 'alpha': 8.51844383993029e-06, 'subsample': 0.6022913861556025, 'colsample_bytree': 0.7933322104210431, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.0027123662582467585, 'gamma': 0.06766348010133075, 'grow_policy': 'lossguide'}. Best is trial 4 with value: 0.8012792734925737.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:25,029]\u001b[0m Trial 22 finished with value: 0.8012792734925737 and parameters: {'booster': 'gbtree', 'lambda': 4.8709991442974455e-05, 'alpha': 1.4900814266450532e-05, 'subsample': 0.7135435491853742, 'colsample_bytree': 0.8104596399514253, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.0004965299453829891, 'gamma': 0.008879554936123303, 'grow_policy': 'lossguide'}. Best is trial 4 with value: 0.8012792734925737.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:25,697]\u001b[0m Trial 23 finished with value: 0.803919228765284 and parameters: {'booster': 'gbtree', 'lambda': 0.00010813234302453301, 'alpha': 3.084125185259233e-06, 'subsample': 0.7224867434654723, 'colsample_bytree': 0.7077984547612852, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.0003947386692706178, 'gamma': 0.0031554559333220843, 'grow_policy': 'lossguide'}. Best is trial 23 with value: 0.803919228765284.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:26,490]\u001b[0m Trial 24 finished with value: 0.7955387494132505 and parameters: {'booster': 'gbtree', 'lambda': 3.5410794838343534e-06, 'alpha': 1.4098142814871403e-08, 'subsample': 0.828012847519807, 'colsample_bytree': 0.6973060107351338, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.023612069631675267, 'gamma': 0.12305557180284951, 'grow_policy': 'depthwise'}. Best is trial 23 with value: 0.803919228765284.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:32,176]\u001b[0m Trial 25 finished with value: 0.8012792734925737 and parameters: {'booster': 'dart', 'lambda': 0.00020846768899960793, 'alpha': 2.4555264595563634e-06, 'subsample': 0.6123255383543067, 'colsample_bytree': 0.8043013746320219, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.00025984882215133423, 'gamma': 0.0018784571621102415, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.2113493976983398e-08, 'skip_drop': 0.7906287842131764}. Best is trial 23 with value: 0.803919228765284.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:37,739]\u001b[0m Trial 26 finished with value: 0.7931053070157409 and parameters: {'booster': 'dart', 'lambda': 0.0002797192609499797, 'alpha': 2.1150391191826417e-06, 'subsample': 0.7841926921129461, 'colsample_bytree': 0.8998779200677811, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.0003070862647764518, 'gamma': 5.135104946045841e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.2241303421840385e-08, 'skip_drop': 0.43811617231094885}. Best is trial 23 with value: 0.803919228765284.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:06:38,832]\u001b[0m A new study created in memory with name: no-name-0754c909-538e-4607-b990-90f35d348c4a\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:39,994]\u001b[0m Trial 0 finished with value: 1.3255388593308366 and parameters: {'booster': 'dart', 'lambda': 0.002372937614879886, 'alpha': 0.0007643129718833815, 'subsample': 0.9516045592690763, 'colsample_bytree': 0.9463719966750326, 'max_depth': 7, 'min_child_weight': 7, 'eta': 1.5865544514923556e-08, 'gamma': 0.0002258863470480503, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.4198060176324131, 'skip_drop': 5.2833225592139534e-08}. Best is trial 0 with value: 1.3255388593308366.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:41,531]\u001b[0m Trial 1 finished with value: 1.3255186507453165 and parameters: {'booster': 'dart', 'lambda': 0.8317173093352014, 'alpha': 0.0010327395931970774, 'subsample': 0.6421701822901149, 'colsample_bytree': 0.7678602902803309, 'max_depth': 9, 'min_child_weight': 7, 'eta': 1.7593068462325326e-07, 'gamma': 0.010821342924070814, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.00010693189973902966, 'skip_drop': 2.6275983446050864e-06}. Best is trial 1 with value: 1.3255186507453165.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:41,619]\u001b[0m Trial 2 finished with value: 0.8252838127654909 and parameters: {'booster': 'gblinear', 'lambda': 0.00014722293392198827, 'alpha': 0.12486986488164604, 'subsample': 0.784389283378061, 'colsample_bytree': 0.695958199457834}. Best is trial 2 with value: 0.8252838127654909.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:41,718]\u001b[0m Trial 3 finished with value: 0.7375874841896973 and parameters: {'booster': 'gblinear', 'lambda': 9.101266504846838e-06, 'alpha': 0.029262368785703596, 'subsample': 0.3406584984068286, 'colsample_bytree': 0.6532675871101041}. Best is trial 3 with value: 0.7375874841896973.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:06:41,973]\u001b[0m Trial 4 finished with value: 1.3196044784671561 and parameters: {'booster': 'gbtree', 'lambda': 1.1230341326443954e-06, 'alpha': 6.706260829283033e-07, 'subsample': 0.6648084757682371, 'colsample_bytree': 0.35771961937358826, 'max_depth': 9, 'min_child_weight': 10, 'eta': 5.300753173820534e-05, 'gamma': 0.0976509943507514, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 0.7375874841896973.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:42,083]\u001b[0m Trial 5 finished with value: 0.7954211244645515 and parameters: {'booster': 'gblinear', 'lambda': 0.0002739718296396662, 'alpha': 0.00017433114882463231, 'subsample': 0.7365171813329481, 'colsample_bytree': 0.8685111482832641}. Best is trial 3 with value: 0.7375874841896973.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:42,230]\u001b[0m Trial 6 finished with value: 0.7087068909045077 and parameters: {'booster': 'gbtree', 'lambda': 1.4666423199780109e-08, 'alpha': 0.00011961169106747514, 'subsample': 0.7271372939427629, 'colsample_bytree': 0.3909676031244863, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.26527808653009555, 'gamma': 0.07534625179728927, 'grow_policy': 'depthwise'}. Best is trial 6 with value: 0.7087068909045077.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:42,395]\u001b[0m Trial 7 finished with value: 0.8325148704407557 and parameters: {'booster': 'gbtree', 'lambda': 9.826117346945943e-05, 'alpha': 0.11132884503232222, 'subsample': 0.23719469400901297, 'colsample_bytree': 0.5550171692795425, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.009219937645407265, 'gamma': 5.22996647752274e-06, 'grow_policy': 'depthwise'}. Best is trial 6 with value: 0.7087068909045077.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:42,580]\u001b[0m Trial 8 finished with value: 1.3248018631047258 and parameters: {'booster': 'gbtree', 'lambda': 0.002770331969453111, 'alpha': 0.2517808788435478, 'subsample': 0.3145154059864421, 'colsample_bytree': 0.5757426746218807, 'max_depth': 5, 'min_child_weight': 4, 'eta': 6.74508883378166e-06, 'gamma': 0.008661397458063696, 'grow_policy': 'lossguide'}. Best is trial 6 with value: 0.7087068909045077.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:43,927]\u001b[0m Trial 9 finished with value: 1.2358356611565509 and parameters: {'booster': 'dart', 'lambda': 1.701804823812288e-07, 'alpha': 0.018899651259454527, 'subsample': 0.42008622870526724, 'colsample_bytree': 0.5840461098976353, 'max_depth': 3, 'min_child_weight': 9, 'eta': 0.0009708625593183755, 'gamma': 0.0006940646695243612, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.003442062457394534, 'skip_drop': 0.3681627787929299}. Best is trial 6 with value: 0.7087068909045077.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:44,094]\u001b[0m Trial 10 finished with value: 2.060761727083052 and parameters: {'booster': 'gbtree', 'lambda': 1.0763685967244237e-08, 'alpha': 9.790618285212095e-07, 'subsample': 0.5126792705983519, 'colsample_bytree': 0.20271252786042757, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.9068202941938306, 'gamma': 5.894945717068276e-08, 'grow_policy': 'depthwise'}. Best is trial 6 with value: 0.7087068909045077.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:44,220]\u001b[0m Trial 11 finished with value: 0.8034084640339945 and parameters: {'booster': 'gblinear', 'lambda': 1.1636322017123528e-06, 'alpha': 1.7518958201011168e-08, 'subsample': 0.8963834260544409, 'colsample_bytree': 0.4243741859234439}. Best is trial 6 with value: 0.7087068909045077.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:44,347]\u001b[0m Trial 12 finished with value: 0.8005987219124611 and parameters: {'booster': 'gblinear', 'lambda': 1.0453184483645341e-08, 'alpha': 8.449571602612419e-06, 'subsample': 0.49932319426771876, 'colsample_bytree': 0.4129421373417723}. Best is trial 6 with value: 0.7087068909045077.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:44,514]\u001b[0m Trial 13 finished with value: 0.7957108916088711 and parameters: {'booster': 'gbtree', 'lambda': 4.392629653165956e-06, 'alpha': 0.0058319573890712306, 'subsample': 0.3850797297813916, 'colsample_bytree': 0.23629499603889, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.2700802418585522, 'gamma': 0.8224039089823816, 'grow_policy': 'depthwise'}. Best is trial 6 with value: 0.7087068909045077.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:44,642]\u001b[0m Trial 14 finished with value: 0.7984323715416557 and parameters: {'booster': 'gblinear', 'lambda': 1.115503788324336e-05, 'alpha': 3.957762978051635e-05, 'subsample': 0.8225063966449978, 'colsample_bytree': 0.7236293100779948}. Best is trial 6 with value: 0.7087068909045077.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:44,939]\u001b[0m Trial 15 finished with value: 0.6719054060673813 and parameters: {'booster': 'gbtree', 'lambda': 9.390433986872921e-08, 'alpha': 0.007954277162414647, 'subsample': 0.5604725283457923, 'colsample_bytree': 0.48449409525463083, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.01861167937480064, 'gamma': 6.136728493246562e-06, 'grow_policy': 'depthwise'}. Best is trial 15 with value: 0.6719054060673813.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:45,216]\u001b[0m Trial 16 finished with value: 0.656891248320552 and parameters: {'booster': 'gbtree', 'lambda': 1.2962595142409474e-07, 'alpha': 0.002007191583714014, 'subsample': 0.5615368537412296, 'colsample_bytree': 0.3205727805871965, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.026192819476293646, 'gamma': 4.310204249006983e-06, 'grow_policy': 'depthwise'}. Best is trial 16 with value: 0.656891248320552.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:45,487]\u001b[0m Trial 17 finished with value: 0.7559482165801529 and parameters: {'booster': 'gbtree', 'lambda': 1.4525814442220191e-07, 'alpha': 0.0047321265712065045, 'subsample': 0.5554897423484956, 'colsample_bytree': 0.2994221449539922, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.01125311806744876, 'gamma': 2.4289012272169925e-06, 'grow_policy': 'depthwise'}. Best is trial 16 with value: 0.656891248320552.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:45,780]\u001b[0m Trial 18 finished with value: 0.8083755168870539 and parameters: {'booster': 'gbtree', 'lambda': 1.6289297495338266e-07, 'alpha': 0.0020777470950321623, 'subsample': 0.5996479722284693, 'colsample_bytree': 0.4772480695598258, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.008255355985338364, 'gamma': 3.651929895196907e-06, 'grow_policy': 'depthwise'}. Best is trial 16 with value: 0.656891248320552.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:46,042]\u001b[0m Trial 19 finished with value: 1.2868464858898039 and parameters: {'booster': 'gbtree', 'lambda': 0.4992746879934151, 'alpha': 0.9249542491963642, 'subsample': 0.4510907954689285, 'colsample_bytree': 0.4809505222664958, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.0003647974960818853, 'gamma': 7.858280131212885e-08, 'grow_policy': 'depthwise'}. Best is trial 16 with value: 0.656891248320552.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:46,397]\u001b[0m Trial 20 finished with value: 0.6189034889884738 and parameters: {'booster': 'gbtree', 'lambda': 5.7059106975947863e-08, 'alpha': 3.3226793351205975e-05, 'subsample': 0.563153040991703, 'colsample_bytree': 0.34136268249808704, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.032396999270568154, 'gamma': 1.9728096768570745e-05, 'grow_policy': 'depthwise'}. Best is trial 20 with value: 0.6189034889884738.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:46,750]\u001b[0m Trial 21 finished with value: 0.6363302087577957 and parameters: {'booster': 'gbtree', 'lambda': 1.8714955312112222e-07, 'alpha': 3.155524875893486e-05, 'subsample': 0.5728256938364449, 'colsample_bytree': 0.3183595303415149, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.03827727444901715, 'gamma': 2.9820038059557515e-05, 'grow_policy': 'depthwise'}. Best is trial 20 with value: 0.6189034889884738.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:47,068]\u001b[0m Trial 22 finished with value: 0.6759396977363051 and parameters: {'booster': 'gbtree', 'lambda': 8.249357255769812e-07, 'alpha': 2.236741467073775e-05, 'subsample': 0.6582997751932469, 'colsample_bytree': 0.28598077638734365, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.06672097234657097, 'gamma': 4.3054598686405164e-05, 'grow_policy': 'depthwise'}. Best is trial 20 with value: 0.6189034889884738.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:47,382]\u001b[0m Trial 23 finished with value: 1.221144943006079 and parameters: {'booster': 'gbtree', 'lambda': 5.051237402063846e-08, 'alpha': 1.289479440628596e-06, 'subsample': 0.4832241141574273, 'colsample_bytree': 0.329507207670209, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.0009937308732921625, 'gamma': 4.919310038716378e-05, 'grow_policy': 'depthwise'}. Best is trial 20 with value: 0.6189034889884738.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:06:47,711]\u001b[0m Trial 24 finished with value: 0.6562882630657231 and parameters: {'booster': 'gbtree', 'lambda': 5.825902471243236e-07, 'alpha': 6.1723924079740155e-06, 'subsample': 0.5682945458104165, 'colsample_bytree': 0.2586645109890454, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.07513824618420509, 'gamma': 9.464978398668462e-07, 'grow_policy': 'depthwise'}. Best is trial 20 with value: 0.6189034889884738.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:49,227]\u001b[0m Trial 25 finished with value: 0.6746862717241712 and parameters: {'booster': 'dart', 'lambda': 7.536934733895243e-07, 'alpha': 5.592046883873409e-06, 'subsample': 0.6125786999414446, 'colsample_bytree': 0.25991664669598247, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.0867179838457415, 'gamma': 6.45402372671959e-07, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 3.2704990756274344e-08, 'skip_drop': 0.020031923644094417}. Best is trial 20 with value: 0.6189034889884738.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:49,571]\u001b[0m Trial 26 finished with value: 1.0667733077860704 and parameters: {'booster': 'gbtree', 'lambda': 3.421495262308161e-05, 'alpha': 1.0145716687362485e-07, 'subsample': 0.7013720967508078, 'colsample_bytree': 0.22264403492857626, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.0029198354162162338, 'gamma': 3.8853298863213967e-07, 'grow_policy': 'depthwise'}. Best is trial 20 with value: 0.6189034889884738.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:49,965]\u001b[0m Trial 27 finished with value: 1.3193224996362716 and parameters: {'booster': 'gbtree', 'lambda': 2.9774185876507435e-06, 'alpha': 0.00024749218213355415, 'subsample': 0.8112144258944983, 'colsample_bytree': 0.36359241618263816, 'max_depth': 9, 'min_child_weight': 2, 'eta': 5.2709009102254e-05, 'gamma': 0.0006967600021157687, 'grow_policy': 'depthwise'}. Best is trial 20 with value: 0.6189034889884738.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:50,269]\u001b[0m Trial 28 finished with value: 28.711234087662216 and parameters: {'booster': 'gbtree', 'lambda': 3.40572851838752e-08, 'alpha': 5.7210295433789685e-06, 'subsample': 0.41058985907829104, 'colsample_bytree': 0.4315880918338771, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.8753808919034811, 'gamma': 2.852707111967429e-05, 'grow_policy': 'depthwise'}. Best is trial 20 with value: 0.6189034889884738.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:51,860]\u001b[0m Trial 29 finished with value: 1.3252253572606367 and parameters: {'booster': 'dart', 'lambda': 0.004879034358423694, 'alpha': 0.00031984089218073305, 'subsample': 0.9149375237496294, 'colsample_bytree': 0.2793012551836736, 'max_depth': 9, 'min_child_weight': 3, 'eta': 2.6509532655707015e-06, 'gamma': 1.261491648398381e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.4633834171418321e-08, 'skip_drop': 0.0002662079875509004}. Best is trial 20 with value: 0.6189034889884738.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:52,132]\u001b[0m Trial 30 finished with value: 0.6985116349638647 and parameters: {'booster': 'gbtree', 'lambda': 4.4317722102760523e-07, 'alpha': 3.4383868689180586e-05, 'subsample': 0.5583541765577136, 'colsample_bytree': 0.9821367519003021, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.11395611870458776, 'gamma': 4.630495942631345e-07, 'grow_policy': 'depthwise'}. Best is trial 20 with value: 0.6189034889884738.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:52,403]\u001b[0m Trial 31 finished with value: 0.6634101980953157 and parameters: {'booster': 'gbtree', 'lambda': 3.3054395336534213e-07, 'alpha': 2.3711958343110413e-06, 'subsample': 0.5324042485907814, 'colsample_bytree': 0.34067128010670766, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.04039277774433503, 'gamma': 1.9460016809313327e-05, 'grow_policy': 'depthwise'}. Best is trial 20 with value: 0.6189034889884738.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:52,763]\u001b[0m Trial 32 finished with value: 0.9766479505281576 and parameters: {'booster': 'gbtree', 'lambda': 4.204019269546553e-08, 'alpha': 0.0008016082718296076, 'subsample': 0.5900339702920989, 'colsample_bytree': 0.3152604313531229, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.004372802530764153, 'gamma': 0.0002235009525871522, 'grow_policy': 'depthwise'}. Best is trial 20 with value: 0.6189034889884738.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:54,254]\u001b[0m Trial 33 finished with value: 0.6349221169040902 and parameters: {'booster': 'dart', 'lambda': 0.028295637281196544, 'alpha': 2.2142460812668974e-05, 'subsample': 0.46960192124221933, 'colsample_bytree': 0.5339183612005247, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.033245983701179704, 'gamma': 1.1623829323339616e-06, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 3.3165262251428297e-06, 'skip_drop': 1.4842247748012715e-08}. Best is trial 20 with value: 0.6189034889884738.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:55,795]\u001b[0m Trial 34 finished with value: 0.8803420301498976 and parameters: {'booster': 'dart', 'lambda': 0.04892252366565497, 'alpha': 3.3390729189404494e-07, 'subsample': 0.44314674300733514, 'colsample_bytree': 0.5265127926964208, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.21225841063457385, 'gamma': 1.1457445682579867e-06, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 3.2599276124505446e-06, 'skip_drop': 1.0280989495752435e-08}. Best is trial 20 with value: 0.6189034889884738.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:57,264]\u001b[0m Trial 35 finished with value: 1.1638949270940784 and parameters: {'booster': 'dart', 'lambda': 0.253283789700257, 'alpha': 2.0788386503738894e-05, 'subsample': 0.346992301620851, 'colsample_bytree': 0.6435010814924305, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.0016592168175870866, 'gamma': 1.1533726894993598e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 5.3921106451484976e-06, 'skip_drop': 7.146831526016575e-06}. Best is trial 20 with value: 0.6189034889884738.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:06:58,747]\u001b[0m Trial 36 finished with value: 1.2877633245653035 and parameters: {'booster': 'dart', 'lambda': 0.015759810781358227, 'alpha': 6.773286039568828e-05, 'subsample': 0.476572208420839, 'colsample_bytree': 0.7957128280626855, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.00033400530368689146, 'gamma': 1.4161823199173336e-05, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.0013729007406023566, 'skip_drop': 0.0004304352595330261}. Best is trial 20 with value: 0.6189034889884738.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:07:00,206]\u001b[0m Trial 37 finished with value: 0.6319891064250838 and parameters: {'booster': 'dart', 'lambda': 0.0006914955338551324, 'alpha': 1.5112396052184306e-07, 'subsample': 0.6343059501232486, 'colsample_bytree': 0.6343446914142997, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.03332785392892165, 'gamma': 0.00014506755608283952, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.0234496803694902e-06, 'skip_drop': 2.716299965697006e-07}. Best is trial 20 with value: 0.6189034889884738.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:07:01,609]\u001b[0m Trial 38 finished with value: 1.32553777291972 and parameters: {'booster': 'dart', 'lambda': 0.0004441641425270173, 'alpha': 1.0639473622052578e-08, 'subsample': 0.6905449092258712, 'colsample_bytree': 0.6380809961036097, 'max_depth': 5, 'min_child_weight': 8, 'eta': 1.5013425798395293e-08, 'gamma': 0.00014441865993099906, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.0845547089841953e-06, 'skip_drop': 4.258309476963866e-07}. Best is trial 20 with value: 0.6189034889884738.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:07:03,105]\u001b[0m Trial 39 finished with value: 1.2988611288212892 and parameters: {'booster': 'dart', 'lambda': 0.0006363626130186778, 'alpha': 1.5369114222178436e-07, 'subsample': 0.636288536035593, 'colsample_bytree': 0.8094268135965279, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.0002306964992231927, 'gamma': 0.0009875355745145931, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 5.049177748342081e-07, 'skip_drop': 1.7667530000541335e-07}. Best is trial 20 with value: 0.6189034889884738.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:07:04,614]\u001b[0m Trial 40 finished with value: 0.6474242142296469 and parameters: {'booster': 'dart', 'lambda': 0.07034018220973477, 'alpha': 5.87350112497575e-08, 'subsample': 0.7527634898479177, 'colsample_bytree': 0.8868673618097875, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.029038165275362997, 'gamma': 0.002430584200200496, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 2.0859067150927114e-05, 'skip_drop': 1.0508340164946787e-08}. Best is trial 20 with value: 0.6189034889884738.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:07:06,105]\u001b[0m Trial 41 finished with value: 0.6363102639815633 and parameters: {'booster': 'dart', 'lambda': 0.07699294999944488, 'alpha': 5.342477451669181e-08, 'subsample': 0.7608657442326614, 'colsample_bytree': 0.8432813807279071, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.030422464423969398, 'gamma': 0.00200085445352349, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 5.8447246122143754e-05, 'skip_drop': 1.241270848304621e-08}. Best is trial 20 with value: 0.6189034889884738.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:07:07,570]\u001b[0m Trial 42 finished with value: 0.7776288112268873 and parameters: {'booster': 'dart', 'lambda': 0.009404453658575819, 'alpha': 3.1153807547124816e-08, 'subsample': 0.7715561201220891, 'colsample_bytree': 0.7060448738318318, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.3548991720221208, 'gamma': 9.567674286070634e-05, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.00020157104138727127, 'skip_drop': 7.881450513258521e-07}. Best is trial 20 with value: 0.6189034889884738.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:07:09,021]\u001b[0m Trial 43 finished with value: 0.9627256319798382 and parameters: {'booster': 'dart', 'lambda': 0.0872443782952277, 'alpha': 3.0655122579857846e-06, 'subsample': 0.8382825705459994, 'colsample_bytree': 0.8985584529958719, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.00485813923933527, 'gamma': 0.004744507428473435, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 9.849271950979388e-08, 'skip_drop': 6.585597480451756e-08}. Best is trial 20 with value: 0.6189034889884738.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:07:10,525]\u001b[0m Trial 44 finished with value: 1.325526875313563 and parameters: {'booster': 'dart', 'lambda': 0.0015793810608088071, 'alpha': 2.3423218776601535e-07, 'subsample': 0.7001257537442845, 'colsample_bytree': 0.5308640873464552, 'max_depth': 7, 'min_child_weight': 6, 'eta': 9.95968421957947e-08, 'gamma': 0.0002967614198931271, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.8030883461727167e-05, 'skip_drop': 1.1305117935800872e-08}. Best is trial 20 with value: 0.6189034889884738.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:07:11,985]\u001b[0m Trial 45 finished with value: 0.7148053871999327 and parameters: {'booster': 'dart', 'lambda': 6.881188578663979e-05, 'alpha': 5.663070795259459e-07, 'subsample': 0.9984569074627249, 'colsample_bytree': 0.7627848878979447, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.01366092888446466, 'gamma': 0.06021171670739254, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 2.640384500705238e-07, 'skip_drop': 1.9674552634615226e-05}. Best is trial 20 with value: 0.6189034889884738.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:07:12,410]\u001b[0m A new study created in memory with name: no-name-633ebcec-6c67-48d2-9063-e6b36aa959b1\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:07:12,692]\u001b[0m Trial 0 finished with value: 0.6366164333514294 and parameters: {'booster': 'gblinear', 'lambda': 0.4332202495575049, 'alpha': 1.3915350503240092e-07, 'subsample': 0.47545089044364697, 'colsample_bytree': 0.904440032077974}. Best is trial 0 with value: 0.6366164333514294.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:07:13,002]\u001b[0m Trial 1 finished with value: 0.733602104336183 and parameters: {'booster': 'gbtree', 'lambda': 0.5594441413670846, 'alpha': 0.626096271895479, 'subsample': 0.4266961622490225, 'colsample_bytree': 0.2831629574141887, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.0004444038403186537, 'gamma': 0.3637271376874372, 'grow_policy': 'lossguide'}. Best is trial 1 with value: 0.733602104336183.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:07:13,440]\u001b[0m Trial 2 finished with value: 0.7149945722440527 and parameters: {'booster': 'gbtree', 'lambda': 0.13110677983298571, 'alpha': 3.277179009984571e-07, 'subsample': 0.5763293168397788, 'colsample_bytree': 0.9435738721637068, 'max_depth': 3, 'min_child_weight': 10, 'eta': 4.865183013080374e-06, 'gamma': 5.530387661030549e-08, 'grow_policy': 'depthwise'}. Best is trial 1 with value: 0.733602104336183.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:07:13,725]\u001b[0m Trial 3 finished with value: 0.7194407895748999 and parameters: {'booster': 'gblinear', 'lambda': 6.238584279678486e-08, 'alpha': 1.3369280682786916e-07, 'subsample': 0.6631725576774501, 'colsample_bytree': 0.9560376977467597}. Best is trial 1 with value: 0.733602104336183.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:07:19,011]\u001b[0m Trial 4 finished with value: 0.7384356623550681 and parameters: {'booster': 'dart', 'lambda': 3.148496726213848e-05, 'alpha': 1.730463040236971e-07, 'subsample': 0.3560337661514546, 'colsample_bytree': 0.46494429967211465, 'max_depth': 9, 'min_child_weight': 5, 'eta': 6.688354007527791e-08, 'gamma': 8.101068554564472e-06, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 2.9822255585188685e-08, 'skip_drop': 0.20340467716322008}. Best is trial 4 with value: 0.7384356623550681.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:07:19,313]\u001b[0m Trial 5 finished with value: 0.7388550384135371 and parameters: {'booster': 'gblinear', 'lambda': 0.0004626715679486838, 'alpha': 5.453429837614928e-05, 'subsample': 0.846356505074016, 'colsample_bytree': 0.7084958106974597}. Best is trial 5 with value: 0.7388550384135371.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:07:19,666]\u001b[0m Trial 6 finished with value: 0.7066930441955565 and parameters: {'booster': 'gbtree', 'lambda': 6.11160250920684e-05, 'alpha': 0.004224281726002081, 'subsample': 0.593738166655216, 'colsample_bytree': 0.5558015115726418, 'max_depth': 3, 'min_child_weight': 4, 'eta': 6.6188286003914466e-06, 'gamma': 1.4698557880625941e-05, 'grow_policy': 'lossguide'}. Best is trial 5 with value: 0.7388550384135371.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:07:25,271]\u001b[0m Trial 7 finished with value: 0.7472381701223791 and parameters: {'booster': 'dart', 'lambda': 8.47808024394817e-06, 'alpha': 7.614968699089001e-06, 'subsample': 0.7818408342923633, 'colsample_bytree': 0.6825073533251855, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.0006288039950538679, 'gamma': 0.0001027890308526525, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 8.141922652680643e-08, 'skip_drop': 2.8663880329568886e-07}. Best is trial 7 with value: 0.7472381701223791.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:07:25,401]\u001b[0m Trial 8 finished with value: 0.5410263171709809 and parameters: {'booster': 'gblinear', 'lambda': 9.68888479310217e-05, 'alpha': 0.10532870260502042, 'subsample': 0.7693736709419321, 'colsample_bytree': 0.9191210131020502}. Best is trial 7 with value: 0.7472381701223791.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:07:31,190]\u001b[0m Trial 9 finished with value: 0.7501336395764548 and parameters: {'booster': 'dart', 'lambda': 0.1677137193200922, 'alpha': 0.0353791457882829, 'subsample': 0.8761674166807727, 'colsample_bytree': 0.6371001990946701, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.0016256964390364377, 'gamma': 1.0152574053102555e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 9.290587361433268e-07, 'skip_drop': 8.64402888608775e-05}. Best is trial 9 with value: 0.7501336395764548.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:07:36,440]\u001b[0m Trial 10 finished with value: 0.756183504322219 and parameters: {'booster': 'dart', 'lambda': 0.005986059391890985, 'alpha': 0.003363180150349746, 'subsample': 0.9976289204418503, 'colsample_bytree': 0.36258010445835903, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.9918581806435421, 'gamma': 8.97768676334678e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.03399963692631864, 'skip_drop': 0.00040958930799434967}. Best is trial 10 with value: 0.756183504322219.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:07:40,928]\u001b[0m Trial 11 finished with value: 0.7503733895961354 and parameters: {'booster': 'dart', 'lambda': 0.007954898396226128, 'alpha': 0.0033849802578156877, 'subsample': 0.985402668539753, 'colsample_bytree': 0.22207986394668877, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.5585991562949878, 'gamma': 1.7458657158384974e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.285465473502641, 'skip_drop': 0.00028756824365970004}. Best is trial 10 with value: 0.756183504322219.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:07:44,752]\u001b[0m Trial 12 finished with value: 0.7300275482093662 and parameters: {'booster': 'dart', 'lambda': 0.005855220917675534, 'alpha': 0.0014269017316530929, 'subsample': 0.9669998811519716, 'colsample_bytree': 0.21313359629476736, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.3983646348665855, 'gamma': 3.16120381251851e-07, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.5654976352843156, 'skip_drop': 0.003051553629984854}. Best is trial 10 with value: 0.756183504322219.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:07:49,043]\u001b[0m Trial 13 finished with value: 0.7346476144686398 and parameters: {'booster': 'dart', 'lambda': 0.004506273182705845, 'alpha': 0.0017867821010917773, 'subsample': 0.203535352409844, 'colsample_bytree': 0.3688075883443338, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.4597058920917512, 'gamma': 7.402298574411327e-07, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.19697863837439855, 'skip_drop': 6.165877543964e-05}. Best is trial 10 with value: 0.756183504322219.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:07:54,764]\u001b[0m A new study created in memory with name: no-name-7bff6f49-9779-487d-a4e5-686176895054\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:07:55,135]\u001b[0m Trial 0 finished with value: 0.8609192573756598 and parameters: {'booster': 'gblinear', 'lambda': 0.0002032094513988515, 'alpha': 1.8325903613431306e-08, 'subsample': 0.737196937620958, 'colsample_bytree': 0.2702945307854887}. Best is trial 0 with value: 0.8609192573756598.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:01,659]\u001b[0m Trial 1 finished with value: 0.8705028064528793 and parameters: {'booster': 'dart', 'lambda': 0.013575119698113645, 'alpha': 1.584930444213761e-07, 'subsample': 0.9019766565675713, 'colsample_bytree': 0.6492674413665986, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.00034084711082867135, 'gamma': 2.6807761065134363e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.6420177900066793e-08, 'skip_drop': 2.9091549217883737e-05}. Best is trial 1 with value: 0.8705028064528793.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:02,216]\u001b[0m Trial 2 finished with value: 0.8677609825224376 and parameters: {'booster': 'gbtree', 'lambda': 6.49433835296924e-05, 'alpha': 8.093675397664882e-07, 'subsample': 0.7746033315567624, 'colsample_bytree': 0.35822667642085293, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.03303794868243085, 'gamma': 0.1874991785914097, 'grow_policy': 'depthwise'}. Best is trial 1 with value: 0.8705028064528793.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:02,503]\u001b[0m Trial 3 finished with value: 0.8749560187065184 and parameters: {'booster': 'gblinear', 'lambda': 2.0768396004101388e-08, 'alpha': 0.004883839229543966, 'subsample': 0.22527606618916007, 'colsample_bytree': 0.9083925881588353}. Best is trial 3 with value: 0.8749560187065184.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:02,957]\u001b[0m Trial 4 finished with value: 0.8705028064528793 and parameters: {'booster': 'gbtree', 'lambda': 8.030053925336313e-05, 'alpha': 0.20012202663394849, 'subsample': 0.8514377188734055, 'colsample_bytree': 0.6151229168970742, 'max_depth': 7, 'min_child_weight': 10, 'eta': 2.9805944453530005e-07, 'gamma': 1.8230398271052372e-08, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 0.8749560187065184.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:03,227]\u001b[0m Trial 5 finished with value: 0.8705028064528793 and parameters: {'booster': 'gbtree', 'lambda': 5.427304444455381e-07, 'alpha': 8.91197984384299e-07, 'subsample': 0.21131332737822917, 'colsample_bytree': 0.2545538124855331, 'max_depth': 9, 'min_child_weight': 6, 'eta': 1.3171672692561768e-05, 'gamma': 1.3174957205145841e-05, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 0.8749560187065184.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:03,587]\u001b[0m Trial 6 finished with value: 0.8705028064528793 and parameters: {'booster': 'gbtree', 'lambda': 2.53738888040443e-07, 'alpha': 3.2466219474100715e-07, 'subsample': 0.2559563289894537, 'colsample_bytree': 0.8375265980662416, 'max_depth': 9, 'min_child_weight': 9, 'eta': 1.6487585262355684e-06, 'gamma': 1.0221444391445633e-07, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 0.8749560187065184.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:03,881]\u001b[0m Trial 7 finished with value: 0.8705028064528793 and parameters: {'booster': 'gbtree', 'lambda': 0.12871808770520232, 'alpha': 2.685242403902804e-08, 'subsample': 0.24619265899112464, 'colsample_bytree': 0.44630508005867436, 'max_depth': 3, 'min_child_weight': 2, 'eta': 5.8530877369926526e-08, 'gamma': 0.00032838957029191336, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 0.8749560187065184.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:04,239]\u001b[0m Trial 8 finished with value: 0.8705028064528793 and parameters: {'booster': 'gbtree', 'lambda': 7.011035534298994e-08, 'alpha': 6.474329156510292e-07, 'subsample': 0.42545765750670966, 'colsample_bytree': 0.3344360216552077, 'max_depth': 7, 'min_child_weight': 9, 'eta': 6.615875541738261e-07, 'gamma': 0.0002246600897081049, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 0.8749560187065184.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:04,490]\u001b[0m Trial 9 finished with value: 0.8763411911652392 and parameters: {'booster': 'gblinear', 'lambda': 3.089037653578116e-08, 'alpha': 0.00885618755129735, 'subsample': 0.2824323254485604, 'colsample_bytree': 0.9446854486507532}. Best is trial 9 with value: 0.8763411911652392.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:04,909]\u001b[0m Trial 10 finished with value: 0.8649395552803096 and parameters: {'booster': 'gblinear', 'lambda': 4.360959649003214e-06, 'alpha': 0.0003893973356987035, 'subsample': 0.5234846097559552, 'colsample_bytree': 0.9865316794689034}. Best is trial 9 with value: 0.8763411911652392.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:05,172]\u001b[0m Trial 11 finished with value: 0.8723562106673165 and parameters: {'booster': 'gblinear', 'lambda': 1.4709945243466819e-08, 'alpha': 0.011501806042751504, 'subsample': 0.40966104329893227, 'colsample_bytree': 0.933573508014614}. Best is trial 9 with value: 0.8763411911652392.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:05,537]\u001b[0m Trial 12 finished with value: 0.8754184609988503 and parameters: {'booster': 'gblinear', 'lambda': 1.2187059484541691e-08, 'alpha': 0.001292256139376535, 'subsample': 0.3797463174977657, 'colsample_bytree': 0.7855868719424662}. Best is trial 9 with value: 0.8763411911652392.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:05,939]\u001b[0m Trial 13 finished with value: 0.8655636243604556 and parameters: {'booster': 'gblinear', 'lambda': 2.6637493105079783e-06, 'alpha': 3.981748381788859e-05, 'subsample': 0.37812107687647223, 'colsample_bytree': 0.773598446013418}. Best is trial 9 with value: 0.8763411911652392.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:11,469]\u001b[0m Trial 14 finished with value: 0.8784707347447073 and parameters: {'booster': 'dart', 'lambda': 1.1532570096422811e-08, 'alpha': 0.5396784537450393, 'subsample': 0.5836889070768451, 'colsample_bytree': 0.7591379145671358, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.4378215069642685, 'gamma': 0.8453979957119454, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.26841530028031785, 'skip_drop': 0.47797503000915503}. Best is trial 14 with value: 0.8784707347447073.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:08:17,363]\u001b[0m Trial 15 finished with value: 0.8812939380548749 and parameters: {'booster': 'dart', 'lambda': 3.3345320331849645e-06, 'alpha': 0.9809131388115236, 'subsample': 0.6684389892280768, 'colsample_bytree': 0.7212990407635721, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.11301060080833014, 'gamma': 0.7311509037770878, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.431508002621593, 'skip_drop': 0.8664460885077635}. Best is trial 15 with value: 0.8812939380548749.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:22,764]\u001b[0m Trial 16 finished with value: 0.8883710422199936 and parameters: {'booster': 'dart', 'lambda': 0.0013805076626348376, 'alpha': 0.7633852828997056, 'subsample': 0.6377609548107063, 'colsample_bytree': 0.5144466971264, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.5547267809807371, 'gamma': 0.4461747208229613, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.7266043814937806, 'skip_drop': 0.802008063327894}. Best is trial 16 with value: 0.8883710422199936.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:29,257]\u001b[0m Trial 17 finished with value: 0.8691338613627877 and parameters: {'booster': 'dart', 'lambda': 0.0018309812320291955, 'alpha': 0.07722909460079894, 'subsample': 0.6855196594731149, 'colsample_bytree': 0.5296706131350447, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.005093175823909189, 'gamma': 0.019995896655233575, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.5946060609694259, 'skip_drop': 0.9972503857695507}. Best is trial 16 with value: 0.8883710422199936.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:08:35,678]\u001b[0m A new study created in memory with name: no-name-b7567cab-4d99-41ae-a0bf-a3beddf7d226\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:35,838]\u001b[0m Trial 0 finished with value: 0.0743303718941046 and parameters: {'booster': 'gbtree', 'lambda': 0.0009442447736667428, 'alpha': 0.0009691702087695915, 'subsample': 0.8449282088984094, 'colsample_bytree': 0.4248867284341909, 'max_depth': 3, 'min_child_weight': 8, 'eta': 0.03976092159662031, 'gamma': 0.033012962066826246, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.0743303718941046.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:36,052]\u001b[0m Trial 1 finished with value: 1.100755074601482 and parameters: {'booster': 'gbtree', 'lambda': 0.01255423763357929, 'alpha': 0.0006243126741299433, 'subsample': 0.2904901656281162, 'colsample_bytree': 0.4794858699681501, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.00011573104113118465, 'gamma': 0.14380887019363825, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.0743303718941046.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:36,271]\u001b[0m Trial 2 finished with value: 1.1225958701269232 and parameters: {'booster': 'gbtree', 'lambda': 0.051560737237946325, 'alpha': 0.12125591936242704, 'subsample': 0.21641796816757009, 'colsample_bytree': 0.3319962302594231, 'max_depth': 7, 'min_child_weight': 2, 'eta': 3.2005249381537214e-08, 'gamma': 0.00022729689927670056, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.0743303718941046.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:36,506]\u001b[0m Trial 3 finished with value: 1.0678779419830124 and parameters: {'booster': 'gbtree', 'lambda': 1.121068709097316e-08, 'alpha': 3.1872691068263663e-08, 'subsample': 0.921630481942799, 'colsample_bytree': 0.5938272421407907, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.00029126263625398453, 'gamma': 4.816319303858777e-06, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.0743303718941046.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:37,990]\u001b[0m Trial 4 finished with value: 1.1225930654585587 and parameters: {'booster': 'dart', 'lambda': 0.0793416974204383, 'alpha': 1.735641617355251e-07, 'subsample': 0.5600852450283471, 'colsample_bytree': 0.2618963173051362, 'max_depth': 7, 'min_child_weight': 9, 'eta': 4.6597253124258133e-08, 'gamma': 0.00048232473159385707, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.0031071382486818613, 'skip_drop': 1.0681359207253485e-07}. Best is trial 0 with value: 0.0743303718941046.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:38,251]\u001b[0m Trial 5 finished with value: 1.1222764253075912 and parameters: {'booster': 'gbtree', 'lambda': 1.4363675459305902e-05, 'alpha': 0.0023091755647523405, 'subsample': 0.5346530531406011, 'colsample_bytree': 0.8449940488216741, 'max_depth': 5, 'min_child_weight': 7, 'eta': 1.6304531874180703e-06, 'gamma': 0.4222393528729659, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.0743303718941046.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:38,614]\u001b[0m Trial 6 finished with value: 0.05746192866979402 and parameters: {'booster': 'gbtree', 'lambda': 0.04947853086670749, 'alpha': 5.504902792532975e-05, 'subsample': 0.920126412588022, 'colsample_bytree': 0.6594397821328133, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.25394585939289954, 'gamma': 0.174751327558783, 'grow_policy': 'depthwise'}. Best is trial 6 with value: 0.05746192866979402.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:38,794]\u001b[0m Trial 7 finished with value: 1.0520680753216156 and parameters: {'booster': 'gbtree', 'lambda': 1.1961923360286088e-07, 'alpha': 0.002498906912269897, 'subsample': 0.4259429264363255, 'colsample_bytree': 0.7415815496479432, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.00040504793086812863, 'gamma': 4.975811869563751e-06, 'grow_policy': 'depthwise'}. Best is trial 6 with value: 0.05746192866979402.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:38,964]\u001b[0m Trial 8 finished with value: 1.1225819965358428 and parameters: {'booster': 'gbtree', 'lambda': 2.9315145936516243e-06, 'alpha': 2.5902290414911124e-08, 'subsample': 0.23598190478740966, 'colsample_bytree': 0.9397736414148457, 'max_depth': 3, 'min_child_weight': 8, 'eta': 1.0029755587217417e-07, 'gamma': 4.805061812284079e-08, 'grow_policy': 'lossguide'}. Best is trial 6 with value: 0.05746192866979402.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:40,485]\u001b[0m Trial 9 finished with value: 1.0227792567610143 and parameters: {'booster': 'dart', 'lambda': 0.0006328282782287659, 'alpha': 0.1420758873253776, 'subsample': 0.8074564775408459, 'colsample_bytree': 0.9784360736952407, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.0005216590043638587, 'gamma': 0.0075171490524817775, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 2.5954963180659554e-06, 'skip_drop': 8.454340786357455e-05}. Best is trial 6 with value: 0.05746192866979402.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:40,626]\u001b[0m Trial 10 finished with value: 0.13156267961035198 and parameters: {'booster': 'gblinear', 'lambda': 0.6222140906261941, 'alpha': 2.5983377591627697e-06, 'subsample': 0.7292578704365618, 'colsample_bytree': 0.70695680036857}. Best is trial 6 with value: 0.05746192866979402.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:40,767]\u001b[0m Trial 11 finished with value: 0.0034351403382723443 and parameters: {'booster': 'gblinear', 'lambda': 0.0008310318304447361, 'alpha': 1.850484749452548e-05, 'subsample': 0.9941477592976492, 'colsample_bytree': 0.5523169688002756}. Best is trial 11 with value: 0.0034351403382723443.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:40,908]\u001b[0m Trial 12 finished with value: 0.003120565754051155 and parameters: {'booster': 'gblinear', 'lambda': 0.0011193060311405576, 'alpha': 7.4455947718984835e-06, 'subsample': 0.9938303227307413, 'colsample_bytree': 0.5843005838134706}. Best is trial 12 with value: 0.003120565754051155.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:41,047]\u001b[0m Trial 13 finished with value: 0.00596006902876594 and parameters: {'booster': 'gblinear', 'lambda': 0.0001576326777679897, 'alpha': 1.0046177115035466e-05, 'subsample': 0.9884021678798945, 'colsample_bytree': 0.5558716955834487}. Best is trial 12 with value: 0.003120565754051155.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:08:41,186]\u001b[0m Trial 14 finished with value: 0.004311250277094583 and parameters: {'booster': 'gblinear', 'lambda': 0.004057782490617598, 'alpha': 1.16373636150646e-06, 'subsample': 0.6976136347288003, 'colsample_bytree': 0.46835470306275767}. Best is trial 12 with value: 0.003120565754051155.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:41,324]\u001b[0m Trial 15 finished with value: 0.002974953483313221 and parameters: {'booster': 'gblinear', 'lambda': 1.301698779862089e-05, 'alpha': 5.114136870910064e-05, 'subsample': 0.9794456949512539, 'colsample_bytree': 0.7854537984203018}. Best is trial 15 with value: 0.002974953483313221.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:41,465]\u001b[0m Trial 16 finished with value: 0.0026739673264059216 and parameters: {'booster': 'gblinear', 'lambda': 4.023230251625315e-06, 'alpha': 0.00021209817580558656, 'subsample': 0.6907334698882975, 'colsample_bytree': 0.8039033645460285}. Best is trial 16 with value: 0.0026739673264059216.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:41,602]\u001b[0m Trial 17 finished with value: 0.0025139554735481183 and parameters: {'booster': 'gblinear', 'lambda': 2.6379512245898755e-06, 'alpha': 0.0001613909783175377, 'subsample': 0.46930160052442266, 'colsample_bytree': 0.8424130276726846}. Best is trial 17 with value: 0.0025139554735481183.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:41,732]\u001b[0m Trial 18 finished with value: 0.004747372389857858 and parameters: {'booster': 'gblinear', 'lambda': 7.800218484307835e-07, 'alpha': 0.019754091869615173, 'subsample': 0.43023909179695163, 'colsample_bytree': 0.880619233022427}. Best is trial 17 with value: 0.0025139554735481183.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:41,871]\u001b[0m Trial 19 finished with value: 0.002229978325073922 and parameters: {'booster': 'gblinear', 'lambda': 2.8837082378499716e-07, 'alpha': 0.00024733434020867247, 'subsample': 0.6517050879286568, 'colsample_bytree': 0.8662914589631875}. Best is trial 19 with value: 0.002229978325073922.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:43,359]\u001b[0m Trial 20 finished with value: 0.21461250686979247 and parameters: {'booster': 'dart', 'lambda': 1.4434421734697588e-07, 'alpha': 0.006250246556959096, 'subsample': 0.42883976195657664, 'colsample_bytree': 0.9074305748137056, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.009792453085798514, 'gamma': 1.5072155360619126e-08, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.43246695556303316, 'skip_drop': 0.5953977808787546}. Best is trial 19 with value: 0.002229978325073922.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:43,498]\u001b[0m Trial 21 finished with value: 0.0023695105742448644 and parameters: {'booster': 'gblinear', 'lambda': 7.500391096266352e-07, 'alpha': 0.00021365306906554927, 'subsample': 0.6511705501183035, 'colsample_bytree': 0.8000459487730928}. Best is trial 19 with value: 0.002229978325073922.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:43,638]\u001b[0m Trial 22 finished with value: 0.0022340212701535992 and parameters: {'booster': 'gblinear', 'lambda': 1.7996249550065728e-07, 'alpha': 0.00017480480138388964, 'subsample': 0.5014800163261388, 'colsample_bytree': 0.8311399614212622}. Best is trial 19 with value: 0.002229978325073922.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:43,776]\u001b[0m Trial 23 finished with value: 0.0018951306849404885 and parameters: {'booster': 'gblinear', 'lambda': 1.0059278029480873e-08, 'alpha': 0.0003361872854665379, 'subsample': 0.6230897230924801, 'colsample_bytree': 0.9964266039055593}. Best is trial 23 with value: 0.0018951306849404885.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:43,909]\u001b[0m Trial 24 finished with value: 0.0043155972097743064 and parameters: {'booster': 'gblinear', 'lambda': 1.0512339302893105e-08, 'alpha': 0.01875949742354467, 'subsample': 0.6147954528371555, 'colsample_bytree': 0.9959744078232883}. Best is trial 23 with value: 0.0018951306849404885.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:44,048]\u001b[0m Trial 25 finished with value: 0.0016007620191296767 and parameters: {'booster': 'gblinear', 'lambda': 6.321880232294534e-08, 'alpha': 0.0006444756637946374, 'subsample': 0.5077700534704315, 'colsample_bytree': 0.9325122017885382}. Best is trial 25 with value: 0.0016007620191296767.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:44,175]\u001b[0m Trial 26 finished with value: 0.0033321582719591635 and parameters: {'booster': 'gblinear', 'lambda': 4.510504411895568e-08, 'alpha': 0.016143129951786676, 'subsample': 0.7755476433511918, 'colsample_bytree': 0.9273787849129611}. Best is trial 25 with value: 0.0016007620191296767.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:45,706]\u001b[0m Trial 27 finished with value: 1.1207449097321542 and parameters: {'booster': 'dart', 'lambda': 3.059985106585681e-08, 'alpha': 0.5241598206943159, 'subsample': 0.3587642834832656, 'colsample_bytree': 0.9873875151830835, 'max_depth': 9, 'min_child_weight': 4, 'eta': 9.27415762637811e-06, 'gamma': 4.870924279095283e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 6.838569601507366e-08, 'skip_drop': 1.4524588157700217e-08}. Best is trial 25 with value: 0.0016007620191296767.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:45,841]\u001b[0m Trial 28 finished with value: 0.0021646758789827594 and parameters: {'booster': 'gblinear', 'lambda': 4.4356991261085284e-07, 'alpha': 0.0006798567506842432, 'subsample': 0.6065520473992914, 'colsample_bytree': 0.8887172066005697}. Best is trial 25 with value: 0.0016007620191296767.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:45,977]\u001b[0m Trial 29 finished with value: 0.001662970739787257 and parameters: {'booster': 'gblinear', 'lambda': 3.498473569195993e-08, 'alpha': 0.0007564124505475927, 'subsample': 0.570596703637321, 'colsample_bytree': 0.6721322202096496}. Best is trial 25 with value: 0.0016007620191296767.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:46,110]\u001b[0m Trial 30 finished with value: 0.0009790446810736921 and parameters: {'booster': 'gblinear', 'lambda': 2.9990811321474106e-08, 'alpha': 0.00280423554658984, 'subsample': 0.3536101661713313, 'colsample_bytree': 0.6899725771922949}. Best is trial 30 with value: 0.0009790446810736921.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:46,246]\u001b[0m Trial 31 finished with value: 0.001525432420212422 and parameters: {'booster': 'gblinear', 'lambda': 4.1245713216532586e-08, 'alpha': 0.0017202814818294537, 'subsample': 0.3534699828442338, 'colsample_bytree': 0.6510850339803739}. Best is trial 30 with value: 0.0009790446810736921.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:46,381]\u001b[0m Trial 32 finished with value: 0.0011381677796427885 and parameters: {'booster': 'gblinear', 'lambda': 4.248878045072626e-08, 'alpha': 0.0024466418321165517, 'subsample': 0.33528842588356333, 'colsample_bytree': 0.6794128136069875}. Best is trial 30 with value: 0.0009790446810736921.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:46,515]\u001b[0m Trial 33 finished with value: 0.0014053130513226651 and parameters: {'booster': 'gblinear', 'lambda': 6.713009677520722e-08, 'alpha': 0.002544986792492768, 'subsample': 0.3318994997259957, 'colsample_bytree': 0.6558277848132958}. Best is trial 30 with value: 0.0009790446810736921.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:46,648]\u001b[0m Trial 34 finished with value: 0.000997564069968912 and parameters: {'booster': 'gblinear', 'lambda': 3.0440486204849376e-08, 'alpha': 0.003281023268060307, 'subsample': 0.3170313908476145, 'colsample_bytree': 0.633806041147555}. Best is trial 30 with value: 0.0009790446810736921.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:48,128]\u001b[0m Trial 35 finished with value: 1.1222188257803045 and parameters: {'booster': 'dart', 'lambda': 1.168199619312227e-06, 'alpha': 0.007149166490122404, 'subsample': 0.2974140740565326, 'colsample_bytree': 0.5189391258017252, 'max_depth': 7, 'min_child_weight': 6, 'eta': 1.9902000252679284e-06, 'gamma': 0.002211731894129569, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.00043790759445551034, 'skip_drop': 0.9769624851077194}. Best is trial 30 with value: 0.0009790446810736921.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:48,242]\u001b[0m Trial 36 finished with value: 0.08926765058176968 and parameters: {'booster': 'gblinear', 'lambda': 2.6953783988446348e-05, 'alpha': 0.10640751522348228, 'subsample': 0.28659465875839524, 'colsample_bytree': 0.6267782017077869}. Best is trial 30 with value: 0.0009790446810736921.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:48,375]\u001b[0m Trial 37 finished with value: 0.0010327819894179408 and parameters: {'booster': 'gblinear', 'lambda': 1.8817990149251047e-08, 'alpha': 0.004600171583546913, 'subsample': 0.3591412088894159, 'colsample_bytree': 0.4043598885644128}. Best is trial 30 with value: 0.0009790446810736921.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:08:48,568]\u001b[0m Trial 38 finished with value: 465.09758127276604 and parameters: {'booster': 'gbtree', 'lambda': 2.0691676845234617e-08, 'alpha': 0.060108314258006626, 'subsample': 0.20897432151070672, 'colsample_bytree': 0.3362080481555862, 'max_depth': 5, 'min_child_weight': 2, 'eta': 0.788834602753849, 'gamma': 1.1021098110093952e-05, 'grow_policy': 'depthwise'}. Best is trial 30 with value: 0.0009790446810736921.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:48,700]\u001b[0m Trial 39 finished with value: 0.0012512533360983726 and parameters: {'booster': 'gblinear', 'lambda': 1.1136120605679067e-07, 'alpha': 0.006340456427469082, 'subsample': 0.3897770696091185, 'colsample_bytree': 0.4131185672502696}. Best is trial 30 with value: 0.0009790446810736921.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:49,299]\u001b[0m Trial 40 finished with value: 1.045919797626566 and parameters: {'booster': 'dart', 'lambda': 1.9111744449204634e-08, 'alpha': 0.03310169331781163, 'subsample': 0.27169570714083396, 'colsample_bytree': 0.2086483513837096, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.006942410764039814, 'gamma': 2.2935903897744295e-07, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.6651901830784016, 'skip_drop': 0.0003824418630101571}. Best is trial 30 with value: 0.0009790446810736921.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:49,432]\u001b[0m Trial 41 finished with value: 0.0011735614482670399 and parameters: {'booster': 'gblinear', 'lambda': 1.3608409706869307e-07, 'alpha': 0.005351260895146436, 'subsample': 0.3669602825718935, 'colsample_bytree': 0.3838495310908648}. Best is trial 30 with value: 0.0009790446810736921.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:49,565]\u001b[0m Trial 42 finished with value: 0.00102030398308457 and parameters: {'booster': 'gblinear', 'lambda': 3.3408063181402174e-07, 'alpha': 0.0045733893022634736, 'subsample': 0.38869174821133595, 'colsample_bytree': 0.40428967198825777}. Best is trial 30 with value: 0.0009790446810736921.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:49,827]\u001b[0m Trial 43 finished with value: 1.1209524665027812 and parameters: {'booster': 'gbtree', 'lambda': 3.5145212911620094e-07, 'alpha': 0.43703827530595907, 'subsample': 0.24489107279364808, 'colsample_bytree': 0.7290493432396759, 'max_depth': 9, 'min_child_weight': 4, 'eta': 8.50710293879049e-06, 'gamma': 3.0942508645878905e-05, 'grow_policy': 'depthwise'}. Best is trial 30 with value: 0.0009790446810736921.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:49,961]\u001b[0m Trial 44 finished with value: 0.001459600084905695 and parameters: {'booster': 'gblinear', 'lambda': 1.5702187323357306e-08, 'alpha': 0.0023168455672830544, 'subsample': 0.3039626878087902, 'colsample_bytree': 0.48412689665136244}. Best is trial 30 with value: 0.0009790446810736921.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:50,096]\u001b[0m Trial 45 finished with value: 0.003356090917182459 and parameters: {'booster': 'gblinear', 'lambda': 7.239212860402928e-08, 'alpha': 6.0702034341172656e-05, 'subsample': 0.40297439648470273, 'colsample_bytree': 0.3441405322665672}. Best is trial 30 with value: 0.0009790446810736921.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:50,234]\u001b[0m Trial 46 finished with value: 0.0012349021588027422 and parameters: {'booster': 'gblinear', 'lambda': 1.5271531263699926e-06, 'alpha': 0.001284046828630959, 'subsample': 0.326316601694474, 'colsample_bytree': 0.2881763123994381}. Best is trial 30 with value: 0.0009790446810736921.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:50,470]\u001b[0m Trial 47 finished with value: 1.1225997897279132 and parameters: {'booster': 'gbtree', 'lambda': 8.264832754773683e-06, 'alpha': 0.05033780285297376, 'subsample': 0.24746631617182685, 'colsample_bytree': 0.5933501029824212, 'max_depth': 7, 'min_child_weight': 7, 'eta': 1.1058302041486751e-08, 'gamma': 7.097828880563905e-07, 'grow_policy': 'lossguide'}. Best is trial 30 with value: 0.0009790446810736921.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:50,597]\u001b[0m Trial 48 finished with value: 0.0023258132261947083 and parameters: {'booster': 'gblinear', 'lambda': 7.625461984583505e-05, 'alpha': 0.012184982754595897, 'subsample': 0.3949178305408423, 'colsample_bytree': 0.7117540028805128}. Best is trial 30 with value: 0.0009790446810736921.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:50,727]\u001b[0m Trial 49 finished with value: 0.0011464006607580918 and parameters: {'booster': 'gblinear', 'lambda': 2.669711569824627e-07, 'alpha': 0.002854360539379124, 'subsample': 0.4810314585270187, 'colsample_bytree': 0.763130734473871}. Best is trial 30 with value: 0.0009790446810736921.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:50,857]\u001b[0m Trial 50 finished with value: 0.003238220936360096 and parameters: {'booster': 'gblinear', 'lambda': 2.914432136724344e-08, 'alpha': 1.1206837087501402e-08, 'subsample': 0.45554730563842577, 'colsample_bytree': 0.46656677182540596}. Best is trial 30 with value: 0.0009790446810736921.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:50,985]\u001b[0m Trial 51 finished with value: 0.00093134111666895 and parameters: {'booster': 'gblinear', 'lambda': 2.1245379987652178e-07, 'alpha': 0.0034720893376163856, 'subsample': 0.46048028832121346, 'colsample_bytree': 0.7686212224466433}. Best is trial 51 with value: 0.00093134111666895.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:51,117]\u001b[0m Trial 52 finished with value: 0.0009638187178211611 and parameters: {'booster': 'gblinear', 'lambda': 8.705654136398546e-08, 'alpha': 0.0034788939922512, 'subsample': 0.33384659481669393, 'colsample_bytree': 0.6878609319928919}. Best is trial 51 with value: 0.00093134111666895.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:51,245]\u001b[0m Trial 53 finished with value: 0.001792726993424706 and parameters: {'booster': 'gblinear', 'lambda': 9.971389216209538e-08, 'alpha': 0.009119786953650007, 'subsample': 0.3801196758877038, 'colsample_bytree': 0.5539163973466027}. Best is trial 51 with value: 0.00093134111666895.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:51,353]\u001b[0m Trial 54 finished with value: 0.28917277558317833 and parameters: {'booster': 'gblinear', 'lambda': 4.816290524454996e-07, 'alpha': 0.25412628701768564, 'subsample': 0.4359250351178104, 'colsample_bytree': 0.7563797411222392}. Best is trial 51 with value: 0.00093134111666895.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:51,484]\u001b[0m Trial 55 finished with value: 0.001036789437199037 and parameters: {'booster': 'gblinear', 'lambda': 2.0526083420513606e-07, 'alpha': 0.004085958206995152, 'subsample': 0.2667473650737872, 'colsample_bytree': 0.6212009660095007}. Best is trial 51 with value: 0.00093134111666895.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:51,615]\u001b[0m Trial 56 finished with value: 0.002196185901541567 and parameters: {'booster': 'gblinear', 'lambda': 1.8953618516076654e-08, 'alpha': 0.0004148879300548053, 'subsample': 0.5480057654894157, 'colsample_bytree': 0.694628826922561}. Best is trial 51 with value: 0.00093134111666895.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:53,027]\u001b[0m Trial 57 finished with value: 1.122516795726454 and parameters: {'booster': 'dart', 'lambda': 0.14661216916640035, 'alpha': 0.0015039820010153075, 'subsample': 0.412827352576822, 'colsample_bytree': 0.507032137740338, 'max_depth': 5, 'min_child_weight': 3, 'eta': 4.4622815810618477e-07, 'gamma': 0.9569165853735926, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 2.142421301805948e-08, 'skip_drop': 2.1976258021609786e-05}. Best is trial 51 with value: 0.00093134111666895.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:53,200]\u001b[0m Trial 58 finished with value: 0.60681493699728 and parameters: {'booster': 'gbtree', 'lambda': 5.800881282626645e-06, 'alpha': 0.031154977703713033, 'subsample': 0.3064615271952167, 'colsample_bytree': 0.4248891589174371, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.004482173893793624, 'gamma': 0.0026518093196009392, 'grow_policy': 'lossguide'}. Best is trial 51 with value: 0.00093134111666895.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:53,333]\u001b[0m Trial 59 finished with value: 0.0022324611439205077 and parameters: {'booster': 'gblinear', 'lambda': 7.883868383715454e-08, 'alpha': 0.00010327341539796619, 'subsample': 0.4429672352594266, 'colsample_bytree': 0.7281722174107372}. Best is trial 51 with value: 0.00093134111666895.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:53,465]\u001b[0m Trial 60 finished with value: 0.0023298760164477046 and parameters: {'booster': 'gblinear', 'lambda': 1.9735634565292283e-06, 'alpha': 0.0009321660182132679, 'subsample': 0.5155942011251999, 'colsample_bytree': 0.7855143750006883}. Best is trial 51 with value: 0.00093134111666895.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:08:53,594]\u001b[0m Trial 61 finished with value: 0.0010442226997729694 and parameters: {'booster': 'gblinear', 'lambda': 2.3584870641440282e-07, 'alpha': 0.004353790199890138, 'subsample': 0.25764271725660215, 'colsample_bytree': 0.625394276010004}. Best is trial 51 with value: 0.00093134111666895.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:53,726]\u001b[0m Trial 62 finished with value: 0.0010318118095097822 and parameters: {'booster': 'gblinear', 'lambda': 8.053501937714007e-07, 'alpha': 0.004477306077607641, 'subsample': 0.2145881080447385, 'colsample_bytree': 0.5766162292981192}. Best is trial 51 with value: 0.00093134111666895.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:53,853]\u001b[0m Trial 63 finished with value: 0.0023480148895637285 and parameters: {'booster': 'gblinear', 'lambda': 6.907977140858043e-07, 'alpha': 0.012416047834331305, 'subsample': 0.34286452691287517, 'colsample_bytree': 0.5786191617754486}. Best is trial 51 with value: 0.00093134111666895.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:53,985]\u001b[0m Trial 64 finished with value: 0.0029831066910373494 and parameters: {'booster': 'gblinear', 'lambda': 1.06664875996926e-08, 'alpha': 3.409887045091832e-07, 'subsample': 0.2211377717133415, 'colsample_bytree': 0.3865330775745771}. Best is trial 51 with value: 0.00093134111666895.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:54,117]\u001b[0m Trial 65 finished with value: 0.002803703565499459 and parameters: {'booster': 'gblinear', 'lambda': 7.417787169578729e-07, 'alpha': 0.00038928124940722036, 'subsample': 0.3824758806282194, 'colsample_bytree': 0.43427533997637985}. Best is trial 51 with value: 0.00093134111666895.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:54,246]\u001b[0m Trial 66 finished with value: 0.08156406027785718 and parameters: {'booster': 'gblinear', 'lambda': 0.014289660759085446, 'alpha': 0.09083407646098614, 'subsample': 0.30792506242051226, 'colsample_bytree': 0.6883498585587449}. Best is trial 51 with value: 0.00093134111666895.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:54,407]\u001b[0m Trial 67 finished with value: 0.0012960473502659994 and parameters: {'booster': 'gblinear', 'lambda': 4.232326681796503e-08, 'alpha': 0.00134245920051448, 'subsample': 0.4765383838282848, 'colsample_bytree': 0.29846654744108286}. Best is trial 51 with value: 0.00093134111666895.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:54,535]\u001b[0m Trial 68 finished with value: 0.0053252504055786715 and parameters: {'booster': 'gblinear', 'lambda': 1.557066197446966e-07, 'alpha': 0.021115139411772274, 'subsample': 0.22737768111317735, 'colsample_bytree': 0.8298507027083708}. Best is trial 51 with value: 0.00093134111666895.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:54,670]\u001b[0m Trial 69 finished with value: 0.0031337540118014577 and parameters: {'booster': 'gblinear', 'lambda': 3.4987847413077867e-06, 'alpha': 2.6264608403589046e-05, 'subsample': 0.20174576844787084, 'colsample_bytree': 0.5164021876843392}. Best is trial 51 with value: 0.00093134111666895.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:56,372]\u001b[0m Trial 70 finished with value: 1.1178848626379478 and parameters: {'booster': 'dart', 'lambda': 2.3100333014288346e-08, 'alpha': 0.0036226212597047793, 'subsample': 0.8713530802678531, 'colsample_bytree': 0.6528636019554728, 'max_depth': 9, 'min_child_weight': 7, 'eta': 2.2820014956407174e-05, 'gamma': 8.40071811387434e-05, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 5.318882326807207e-06, 'skip_drop': 0.00734857226777002}. Best is trial 51 with value: 0.00093134111666895.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:56,500]\u001b[0m Trial 71 finished with value: 0.0017644029090402142 and parameters: {'booster': 'gblinear', 'lambda': 1.9678164310877102e-07, 'alpha': 0.009170601505020224, 'subsample': 0.2720518795007014, 'colsample_bytree': 0.6276636443598645}. Best is trial 51 with value: 0.00093134111666895.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:56,630]\u001b[0m Trial 72 finished with value: 0.0011135767165895223 and parameters: {'booster': 'gblinear', 'lambda': 5.950545694028841e-08, 'alpha': 0.004964516877482163, 'subsample': 0.27401866799185076, 'colsample_bytree': 0.6345632091632035}. Best is trial 51 with value: 0.00093134111666895.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:56,757]\u001b[0m Trial 73 finished with value: 0.0010007425037128045 and parameters: {'booster': 'gblinear', 'lambda': 4.355948513880472e-07, 'alpha': 0.003675781324850895, 'subsample': 0.32319509061887697, 'colsample_bytree': 0.5720874868807523}. Best is trial 51 with value: 0.00093134111666895.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:56,880]\u001b[0m Trial 74 finished with value: 0.008385918606357175 and parameters: {'booster': 'gblinear', 'lambda': 1.146486927653086e-06, 'alpha': 0.02687077493327745, 'subsample': 0.31963405374322007, 'colsample_bytree': 0.573929527526318}. Best is trial 51 with value: 0.00093134111666895.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:57,012]\u001b[0m Trial 75 finished with value: 0.0019625076348874382 and parameters: {'booster': 'gblinear', 'lambda': 8.754825148012686e-08, 'alpha': 0.000528465342317739, 'subsample': 0.3573145244068524, 'colsample_bytree': 0.5390674689264818}. Best is trial 51 with value: 0.00093134111666895.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:57,146]\u001b[0m Trial 76 finished with value: 0.0022607181494682916 and parameters: {'booster': 'gblinear', 'lambda': 5.350737847196654e-07, 'alpha': 0.0010228944292283426, 'subsample': 0.4167540558891196, 'colsample_bytree': 0.6030312810078113}. Best is trial 51 with value: 0.00093134111666895.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:57,277]\u001b[0m Trial 77 finished with value: 0.0012076201995706475 and parameters: {'booster': 'gblinear', 'lambda': 3.7212217909764547e-07, 'alpha': 0.002032282723624539, 'subsample': 0.3494211515625828, 'colsample_bytree': 0.4513255883223602}. Best is trial 51 with value: 0.00093134111666895.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:57,507]\u001b[0m Trial 78 finished with value: 0.03938889994596289 and parameters: {'booster': 'gbtree', 'lambda': 1.50935129659605e-08, 'alpha': 0.0523517606454759, 'subsample': 0.371918113404783, 'colsample_bytree': 0.6939948638563347, 'max_depth': 5, 'min_child_weight': 3, 'eta': 0.06878262834029647, 'gamma': 0.03290226978711494, 'grow_policy': 'lossguide'}. Best is trial 51 with value: 0.00093134111666895.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:57,633]\u001b[0m Trial 79 finished with value: 0.0022281091000331166 and parameters: {'booster': 'gblinear', 'lambda': 3.353915411253792e-05, 'alpha': 0.01177972723196131, 'subsample': 0.32843688109000146, 'colsample_bytree': 0.3912546179562304}. Best is trial 51 with value: 0.00093134111666895.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:57,761]\u001b[0m Trial 80 finished with value: 0.0014142311328148483 and parameters: {'booster': 'gblinear', 'lambda': 1.1803244999937742e-07, 'alpha': 0.007137250394529102, 'subsample': 0.2962234620762785, 'colsample_bytree': 0.7618999148190867}. Best is trial 51 with value: 0.00093134111666895.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:57,892]\u001b[0m Trial 81 finished with value: 0.0010050989625027943 and parameters: {'booster': 'gblinear', 'lambda': 2.2695666227104472e-07, 'alpha': 0.00357562130311128, 'subsample': 0.2500079751828355, 'colsample_bytree': 0.6077900190756913}. Best is trial 51 with value: 0.00093134111666895.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:58,023]\u001b[0m Trial 82 finished with value: 0.0009210415117666699 and parameters: {'booster': 'gblinear', 'lambda': 4.895749338979815e-08, 'alpha': 0.0030939339150673414, 'subsample': 0.23659364970697372, 'colsample_bytree': 0.36074552137593213}. Best is trial 82 with value: 0.0009210415117666699.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:58,154]\u001b[0m Trial 83 finished with value: 0.0009780306695248856 and parameters: {'booster': 'gblinear', 'lambda': 5.004962397379938e-08, 'alpha': 0.003095583614094133, 'subsample': 0.24083341701784555, 'colsample_bytree': 0.7222884484797734}. Best is trial 82 with value: 0.0009210415117666699.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:58,286]\u001b[0m Trial 84 finished with value: 0.0016270631711846895 and parameters: {'booster': 'gblinear', 'lambda': 5.117280108653545e-08, 'alpha': 0.0017793211123789646, 'subsample': 0.23864483461030392, 'colsample_bytree': 0.7192527917484526}. Best is trial 82 with value: 0.0009210415117666699.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:58,419]\u001b[0m Trial 85 finished with value: 0.00235255782696134 and parameters: {'booster': 'gblinear', 'lambda': 2.7417953820451504e-08, 'alpha': 0.0007658921439844395, 'subsample': 0.2463669774872741, 'colsample_bytree': 0.7391048685873778}. Best is trial 82 with value: 0.0009210415117666699.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:08:58,549]\u001b[0m Trial 86 finished with value: 0.001002871312731809 and parameters: {'booster': 'gblinear', 'lambda': 9.59621896942017e-08, 'alpha': 0.0030483532653275756, 'subsample': 0.26334378494074334, 'colsample_bytree': 0.6628420640061234}. Best is trial 82 with value: 0.0009210415117666699.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:08:59,980]\u001b[0m Trial 87 finished with value: 0.7075806763629132 and parameters: {'booster': 'dart', 'lambda': 3.4330204083869426e-08, 'alpha': 0.000249757236205683, 'subsample': 0.29166111604568484, 'colsample_bytree': 0.6693421718515168, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.0026546455422875783, 'gamma': 1.0473578805020023e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.005326435812888448, 'skip_drop': 1.158595597609822e-06}. Best is trial 82 with value: 0.0009210415117666699.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:00,084]\u001b[0m Trial 88 finished with value: 0.8069341160177408 and parameters: {'booster': 'gblinear', 'lambda': 1.417521004109646e-07, 'alpha': 0.998976215816765, 'subsample': 0.2832413413402218, 'colsample_bytree': 0.7054686404505555}. Best is trial 82 with value: 0.0009210415117666699.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:00,215]\u001b[0m Trial 89 finished with value: 0.001005385364323785 and parameters: {'booster': 'gblinear', 'lambda': 6.019365154252133e-08, 'alpha': 0.003073096187520221, 'subsample': 0.2554051016500896, 'colsample_bytree': 0.8096017101241966}. Best is trial 82 with value: 0.0009210415117666699.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:00,339]\u001b[0m Trial 90 finished with value: 0.004167483602836066 and parameters: {'booster': 'gblinear', 'lambda': 0.0002998298754914934, 'alpha': 0.017967860120122536, 'subsample': 0.2307861208347235, 'colsample_bytree': 0.607334607106236}. Best is trial 82 with value: 0.0009210415117666699.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:00,470]\u001b[0m Trial 91 finished with value: 0.0009957075191151688 and parameters: {'booster': 'gblinear', 'lambda': 6.708033381426641e-08, 'alpha': 0.0029349419207905093, 'subsample': 0.25736028267959193, 'colsample_bytree': 0.81751669646409}. Best is trial 82 with value: 0.0009210415117666699.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:00,603]\u001b[0m Trial 92 finished with value: 0.002351715969911515 and parameters: {'booster': 'gblinear', 'lambda': 9.518111471310645e-08, 'alpha': 0.0013231135411379989, 'subsample': 0.3187996066953096, 'colsample_bytree': 0.7830829558355304}. Best is trial 82 with value: 0.0009210415117666699.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:00,734]\u001b[0m Trial 93 finished with value: 0.0010422460682295161 and parameters: {'booster': 'gblinear', 'lambda': 2.2997451308996093e-07, 'alpha': 0.0027018366651400056, 'subsample': 0.20205204431369972, 'colsample_bytree': 0.8601539326449983}. Best is trial 82 with value: 0.0009210415117666699.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:00,862]\u001b[0m Trial 94 finished with value: 0.0015517099673820927 and parameters: {'booster': 'gblinear', 'lambda': 3.8308475220012014e-08, 'alpha': 0.007838958730283105, 'subsample': 0.283186691269197, 'colsample_bytree': 0.6679279091838297}. Best is trial 82 with value: 0.0009210415117666699.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:00,995]\u001b[0m Trial 95 finished with value: 0.0018638578357286102 and parameters: {'booster': 'gblinear', 'lambda': 7.809603701511663e-08, 'alpha': 0.0005963730354653776, 'subsample': 0.2566243639314569, 'colsample_bytree': 0.2070231355329381}. Best is trial 82 with value: 0.0009210415117666699.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:01,124]\u001b[0m Trial 96 finished with value: 0.0014214340065237775 and parameters: {'booster': 'gblinear', 'lambda': 1.3970709891905479e-08, 'alpha': 0.0018695052791738722, 'subsample': 0.22550501527855085, 'colsample_bytree': 0.6466579875130938}. Best is trial 82 with value: 0.0009210415117666699.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:01,323]\u001b[0m Trial 97 finished with value: 1.122552950585167 and parameters: {'booster': 'gbtree', 'lambda': 1.5917153017396504e-07, 'alpha': 0.0009962450318787537, 'subsample': 0.34010011535692375, 'colsample_bytree': 0.7439347870564138, 'max_depth': 3, 'min_child_weight': 8, 'eta': 2.6708726205038736e-07, 'gamma': 9.65750370670966e-08, 'grow_policy': 'depthwise'}. Best is trial 82 with value: 0.0009210415117666699.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:01,457]\u001b[0m Trial 98 finished with value: 0.0009346370058066309 and parameters: {'booster': 'gblinear', 'lambda': 2.7974551193082236e-08, 'alpha': 0.003151995385402096, 'subsample': 0.3042044384875266, 'colsample_bytree': 0.7793991303255624}. Best is trial 82 with value: 0.0009210415117666699.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:01,582]\u001b[0m Trial 99 finished with value: 0.002027625564120542 and parameters: {'booster': 'gblinear', 'lambda': 3.031400578195826e-08, 'alpha': 0.010240853195311154, 'subsample': 0.5841593924657746, 'colsample_bytree': 0.8172752443339678}. Best is trial 82 with value: 0.0009210415117666699.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:01,727]\u001b[0m A new study created in memory with name: no-name-a8a0a4ff-4157-46a6-82e6-e32261716f1d\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:01,844]\u001b[0m Trial 0 finished with value: 0.002432994008161043 and parameters: {'booster': 'gblinear', 'lambda': 3.2308654507190993e-06, 'alpha': 5.2664889909597565e-06, 'subsample': 0.7997163350839662, 'colsample_bytree': 0.9276995843588474}. Best is trial 0 with value: 0.002432994008161043.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:02,014]\u001b[0m Trial 1 finished with value: 0.038423191674063085 and parameters: {'booster': 'gbtree', 'lambda': 0.5282723332718161, 'alpha': 0.23834782858022435, 'subsample': 0.9195242835160469, 'colsample_bytree': 0.6432921370143876, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.6797188641243059, 'gamma': 0.00013560628134583257, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.002432994008161043.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:02,129]\u001b[0m Trial 2 finished with value: 0.11433774602007783 and parameters: {'booster': 'gblinear', 'lambda': 0.5058808301322781, 'alpha': 4.12534723928707e-07, 'subsample': 0.540172610768737, 'colsample_bytree': 0.3892713852717564}. Best is trial 0 with value: 0.002432994008161043.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:02,246]\u001b[0m Trial 3 finished with value: 0.0023944920483745095 and parameters: {'booster': 'gblinear', 'lambda': 0.005124174540832515, 'alpha': 0.00014396501610312236, 'subsample': 0.6060941065021576, 'colsample_bytree': 0.7684861714013811}. Best is trial 3 with value: 0.0023944920483745095.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:03,670]\u001b[0m Trial 4 finished with value: 1.1879666262410056 and parameters: {'booster': 'dart', 'lambda': 1.9361918188145677e-05, 'alpha': 0.08662804378544883, 'subsample': 0.5559783906982304, 'colsample_bytree': 0.8635266729360704, 'max_depth': 7, 'min_child_weight': 10, 'eta': 2.1484865462362634e-05, 'gamma': 6.19859079514693e-06, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 2.660163296584394e-05, 'skip_drop': 0.00030441708931062364}. Best is trial 3 with value: 0.0023944920483745095.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:03,925]\u001b[0m Trial 5 finished with value: 1.1883302159509654 and parameters: {'booster': 'gbtree', 'lambda': 0.000386388518038511, 'alpha': 3.0881191155451406e-08, 'subsample': 0.5033492690243677, 'colsample_bytree': 0.9033599131245984, 'max_depth': 7, 'min_child_weight': 10, 'eta': 1.9803477464756456e-05, 'gamma': 0.012637410833563751, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 0.0023944920483745095.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:05,259]\u001b[0m Trial 6 finished with value: 1.1878934693920558 and parameters: {'booster': 'dart', 'lambda': 0.8775460153767928, 'alpha': 0.42654036200234824, 'subsample': 0.20460063797067765, 'colsample_bytree': 0.7085409984142457, 'max_depth': 5, 'min_child_weight': 8, 'eta': 2.347629695632935e-05, 'gamma': 0.0003891038620912861, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.0019022931972968763, 'skip_drop': 0.03487784941360235}. Best is trial 3 with value: 0.0023944920483745095.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:05,351]\u001b[0m Trial 7 finished with value: 0.31239411495294667 and parameters: {'booster': 'gblinear', 'lambda': 0.21943418402841008, 'alpha': 0.1949321974879556, 'subsample': 0.3920210290037576, 'colsample_bytree': 0.42117674046734827}. Best is trial 3 with value: 0.0023944920483745095.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:09:05,606]\u001b[0m Trial 8 finished with value: 1.1927219831545806 and parameters: {'booster': 'gbtree', 'lambda': 9.339612304502443e-08, 'alpha': 0.006254880648124807, 'subsample': 0.806865765646523, 'colsample_bytree': 0.38450801707164584, 'max_depth': 7, 'min_child_weight': 4, 'eta': 3.100603046578492e-07, 'gamma': 0.23173157194548707, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 0.0023944920483745095.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:05,747]\u001b[0m Trial 9 finished with value: 0.1074976008891227 and parameters: {'booster': 'gbtree', 'lambda': 3.7633667363844626e-06, 'alpha': 1.2212013697151895e-07, 'subsample': 0.33395112712419406, 'colsample_bytree': 0.36740982538066974, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.5221112891373043, 'gamma': 2.1051777322185966e-07, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 0.0023944920483745095.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:05,878]\u001b[0m Trial 10 finished with value: 0.001427881091088182 and parameters: {'booster': 'gblinear', 'lambda': 0.002032050370340979, 'alpha': 0.00035297942249774486, 'subsample': 0.7042432884434844, 'colsample_bytree': 0.21632480735901616}. Best is trial 10 with value: 0.001427881091088182.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:06,007]\u001b[0m Trial 11 finished with value: 0.0017414032460936718 and parameters: {'booster': 'gblinear', 'lambda': 0.002402942716329585, 'alpha': 0.00021861615452509347, 'subsample': 0.7459919360911582, 'colsample_bytree': 0.2358556363127892}. Best is trial 10 with value: 0.001427881091088182.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:06,137]\u001b[0m Trial 12 finished with value: 0.0018473549497260375 and parameters: {'booster': 'gblinear', 'lambda': 0.003628716985657607, 'alpha': 0.00019805275460062615, 'subsample': 0.7225400365525728, 'colsample_bytree': 0.2146749605477603}. Best is trial 10 with value: 0.001427881091088182.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:06,267]\u001b[0m Trial 13 finished with value: 0.0016978727144046186 and parameters: {'booster': 'gblinear', 'lambda': 0.0061811333414345995, 'alpha': 0.001129328172589246, 'subsample': 0.9675322504391098, 'colsample_bytree': 0.2197459922717327}. Best is trial 10 with value: 0.001427881091088182.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:06,396]\u001b[0m Trial 14 finished with value: 0.008813857334165572 and parameters: {'booster': 'gblinear', 'lambda': 0.02567775730064202, 'alpha': 0.004103017099993954, 'subsample': 0.9773669525482267, 'colsample_bytree': 0.5161878986679789}. Best is trial 10 with value: 0.001427881091088182.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:06,528]\u001b[0m Trial 15 finished with value: 0.0022287556663953437 and parameters: {'booster': 'gblinear', 'lambda': 9.10483806020974e-05, 'alpha': 6.530032444924781e-06, 'subsample': 0.9011963551771474, 'colsample_bytree': 0.25753111887432184}. Best is trial 10 with value: 0.001427881091088182.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:08,015]\u001b[0m Trial 16 finished with value: 1.1927867761872546 and parameters: {'booster': 'dart', 'lambda': 0.01883603604724489, 'alpha': 0.002759924824709402, 'subsample': 0.6492105169460024, 'colsample_bytree': 0.5340342585206103, 'max_depth': 9, 'min_child_weight': 6, 'eta': 1.0997161749936488e-08, 'gamma': 6.562163925442787e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.8759999836114455e-08, 'skip_drop': 1.1891391142667764e-08}. Best is trial 10 with value: 0.001427881091088182.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:08,146]\u001b[0m Trial 17 finished with value: 0.0016762469490146472 and parameters: {'booster': 'gblinear', 'lambda': 0.0001959928041129895, 'alpha': 1.2131820820378671e-05, 'subsample': 0.8721820102909773, 'colsample_bytree': 0.3066470455272507}. Best is trial 10 with value: 0.001427881091088182.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:08,277]\u001b[0m Trial 18 finished with value: 0.0019293024754170082 and parameters: {'booster': 'gblinear', 'lambda': 0.00034894749986495455, 'alpha': 8.881692552803654e-06, 'subsample': 0.8630682039010182, 'colsample_bytree': 0.3215590609649096}. Best is trial 10 with value: 0.001427881091088182.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:09,330]\u001b[0m Trial 19 finished with value: 0.5341572766306392 and parameters: {'booster': 'dart', 'lambda': 1.053056384810941e-08, 'alpha': 2.274133607481042e-05, 'subsample': 0.6844270903970031, 'colsample_bytree': 0.4748023207261032, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.004477453025871568, 'gamma': 0.7752993436173977, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.4694982343014335, 'skip_drop': 1.009694510523253e-08}. Best is trial 10 with value: 0.001427881091088182.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:09,461]\u001b[0m Trial 20 finished with value: 0.0021174730054124226 and parameters: {'booster': 'gblinear', 'lambda': 2.019482656081067e-05, 'alpha': 7.280805786943004e-07, 'subsample': 0.81472857994554, 'colsample_bytree': 0.2924382984386832}. Best is trial 10 with value: 0.001427881091088182.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:09,594]\u001b[0m Trial 21 finished with value: 0.0007932732691373702 and parameters: {'booster': 'gblinear', 'lambda': 0.0005421934327732714, 'alpha': 0.0009021620143648693, 'subsample': 0.9593196775514297, 'colsample_bytree': 0.2140823551086417}. Best is trial 21 with value: 0.0007932732691373702.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:09,718]\u001b[0m Trial 22 finished with value: 0.0024115023454204243 and parameters: {'booster': 'gblinear', 'lambda': 0.0004833099129056476, 'alpha': 0.0195982606767586, 'subsample': 0.9961251680671218, 'colsample_bytree': 0.31456985351756117}. Best is trial 21 with value: 0.0007932732691373702.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:09,848]\u001b[0m Trial 23 finished with value: 0.0030257054670603297 and parameters: {'booster': 'gblinear', 'lambda': 0.0001593300721725772, 'alpha': 3.374294330332544e-05, 'subsample': 0.8616837296233353, 'colsample_bytree': 0.319162458297266}. Best is trial 21 with value: 0.0007932732691373702.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:09,978]\u001b[0m Trial 24 finished with value: 0.017084509136431968 and parameters: {'booster': 'gblinear', 'lambda': 0.043806917047719704, 'alpha': 0.000718563356227198, 'subsample': 0.7389023616877664, 'colsample_bytree': 0.20872975036143623}. Best is trial 21 with value: 0.0007932732691373702.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:10,098]\u001b[0m Trial 25 finished with value: 0.006694981815875602 and parameters: {'booster': 'gblinear', 'lambda': 0.0014240710896010382, 'alpha': 0.03217696296273199, 'subsample': 0.9153202795246175, 'colsample_bytree': 0.4585224016004378}. Best is trial 21 with value: 0.0007932732691373702.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:10,228]\u001b[0m Trial 26 finished with value: 0.0019428983186116431 and parameters: {'booster': 'gblinear', 'lambda': 3.1221579898570405e-05, 'alpha': 1.6442609186971648e-06, 'subsample': 0.8487127467384337, 'colsample_bytree': 0.5767824253766237}. Best is trial 21 with value: 0.0007932732691373702.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:10,443]\u001b[0m Trial 27 finished with value: 0.6303104135457968 and parameters: {'booster': 'gbtree', 'lambda': 7.183582000459502e-07, 'alpha': 5.41302333968362e-05, 'subsample': 0.7668467851443823, 'colsample_bytree': 0.2841334041299833, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.003997033293353314, 'gamma': 2.671929080429382e-06, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.0007932732691373702.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:10,575]\u001b[0m Trial 28 finished with value: 0.001500178001284864 and parameters: {'booster': 'gblinear', 'lambda': 0.0007104158975864073, 'alpha': 0.0006267704382409029, 'subsample': 0.9339908908850112, 'colsample_bytree': 0.3530055782576544}. Best is trial 21 with value: 0.0007932732691373702.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:11,956]\u001b[0m Trial 29 finished with value: 0.6823406558401306 and parameters: {'booster': 'dart', 'lambda': 0.0009036090546466054, 'alpha': 0.0006818817133353692, 'subsample': 0.47328242436923273, 'colsample_bytree': 0.9704367745382386, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.0031130983297666948, 'gamma': 0.02556087949447546, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.212807690064857e-08, 'skip_drop': 0.9898421984597061}. Best is trial 21 with value: 0.0007932732691373702.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:09:12,079]\u001b[0m Trial 30 finished with value: 0.03933285314840223 and parameters: {'booster': 'gblinear', 'lambda': 0.08871953260378049, 'alpha': 0.016188844784576654, 'subsample': 0.9441231535208486, 'colsample_bytree': 0.3713286248304222}. Best is trial 21 with value: 0.0007932732691373702.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:12,211]\u001b[0m Trial 31 finished with value: 0.0010115762105196407 and parameters: {'booster': 'gblinear', 'lambda': 0.00012953742274107177, 'alpha': 0.0003929189602544125, 'subsample': 0.8771800231994339, 'colsample_bytree': 0.2516940659132393}. Best is trial 21 with value: 0.0007932732691373702.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:12,343]\u001b[0m Trial 32 finished with value: 0.0004874114473187253 and parameters: {'booster': 'gblinear', 'lambda': 6.34819590027755e-05, 'alpha': 0.0010843357633836391, 'subsample': 0.800187013264699, 'colsample_bytree': 0.2580954209389779}. Best is trial 32 with value: 0.0004874114473187253.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:12,473]\u001b[0m Trial 33 finished with value: 0.0003213130022816262 and parameters: {'booster': 'gblinear', 'lambda': 5.025765474992534e-06, 'alpha': 0.0017725988791551196, 'subsample': 0.8141056069381747, 'colsample_bytree': 0.2609155784351244}. Best is trial 33 with value: 0.0003213130022816262.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:12,603]\u001b[0m Trial 34 finished with value: 0.00034395188538090927 and parameters: {'booster': 'gblinear', 'lambda': 3.7746258823558067e-06, 'alpha': 0.0020759892945778546, 'subsample': 0.792032918917977, 'colsample_bytree': 0.4319682330022149}. Best is trial 33 with value: 0.0003213130022816262.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:12,735]\u001b[0m Trial 35 finished with value: 0.00030857672853283787 and parameters: {'booster': 'gblinear', 'lambda': 4.516256943433094e-06, 'alpha': 0.0016364579691896981, 'subsample': 0.803847883691241, 'colsample_bytree': 0.4395815126489126}. Best is trial 35 with value: 0.00030857672853283787.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:12,975]\u001b[0m Trial 36 finished with value: 1.1926939239220868 and parameters: {'booster': 'gbtree', 'lambda': 3.1951975617376516e-06, 'alpha': 0.00615970486363138, 'subsample': 0.6364918398876716, 'colsample_bytree': 0.6434800322492669, 'max_depth': 5, 'min_child_weight': 8, 'eta': 4.1992038904469263e-07, 'gamma': 0.0020801842581566255, 'grow_policy': 'depthwise'}. Best is trial 35 with value: 0.00030857672853283787.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:13,104]\u001b[0m Trial 37 finished with value: 0.00026959137092198607 and parameters: {'booster': 'gblinear', 'lambda': 4.436699592451377e-06, 'alpha': 0.0025833720161811896, 'subsample': 0.7820258193024305, 'colsample_bytree': 0.4124716546653855}. Best is trial 37 with value: 0.00026959137092198607.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:13,218]\u001b[0m Trial 38 finished with value: 0.027491923424800963 and parameters: {'booster': 'gblinear', 'lambda': 3.6444704857816077e-06, 'alpha': 0.0678800877766853, 'subsample': 0.5680435591641326, 'colsample_bytree': 0.4375801186497997}. Best is trial 37 with value: 0.00026959137092198607.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:14,743]\u001b[0m Trial 39 finished with value: 1.192782624909058 and parameters: {'booster': 'dart', 'lambda': 7.87943348696379e-07, 'alpha': 6.9978044553756e-05, 'subsample': 0.7718040384989706, 'colsample_bytree': 0.5275237977800266, 'max_depth': 9, 'min_child_weight': 5, 'eta': 1.4428035753756357e-08, 'gamma': 1.5520673704464285e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.1914577246496401e-05, 'skip_drop': 5.877218419946518e-06}. Best is trial 37 with value: 0.00026959137092198607.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:14,987]\u001b[0m Trial 40 finished with value: 0.01912838832205494 and parameters: {'booster': 'gbtree', 'lambda': 8.347796169042731e-07, 'alpha': 0.7193086953373302, 'subsample': 0.6785402474443708, 'colsample_bytree': 0.639960540908839, 'max_depth': 5, 'min_child_weight': 2, 'eta': 0.05694951030356105, 'gamma': 7.687982950927123e-06, 'grow_policy': 'depthwise'}. Best is trial 37 with value: 0.00026959137092198607.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:15,119]\u001b[0m Trial 41 finished with value: 0.00040949916670257965 and parameters: {'booster': 'gblinear', 'lambda': 8.521157742947013e-06, 'alpha': 0.0018513520135131167, 'subsample': 0.7987963040488926, 'colsample_bytree': 0.39749354107334234}. Best is trial 37 with value: 0.00026959137092198607.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:15,249]\u001b[0m Trial 42 finished with value: 0.0003202801788048603 and parameters: {'booster': 'gblinear', 'lambda': 9.289121436523647e-06, 'alpha': 0.002100835735517506, 'subsample': 0.8228584114967069, 'colsample_bytree': 0.4270791351669021}. Best is trial 37 with value: 0.00026959137092198607.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:15,373]\u001b[0m Trial 43 finished with value: 0.0007669338278887736 and parameters: {'booster': 'gblinear', 'lambda': 7.746472670612875e-06, 'alpha': 0.011097981030652442, 'subsample': 0.8142491064009826, 'colsample_bytree': 0.4842331190516299}. Best is trial 37 with value: 0.00026959137092198607.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:15,488]\u001b[0m Trial 44 finished with value: 0.02009872615702289 and parameters: {'booster': 'gblinear', 'lambda': 2.238418735532379e-07, 'alpha': 0.05804143242657598, 'subsample': 0.8437739362489883, 'colsample_bytree': 0.4151235755836251}. Best is trial 37 with value: 0.00026959137092198607.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:15,616]\u001b[0m Trial 45 finished with value: 0.00030296923728646765 and parameters: {'booster': 'gblinear', 'lambda': 1.5210378443201232e-06, 'alpha': 0.0023256617847015547, 'subsample': 0.7740146225811179, 'colsample_bytree': 0.5648082639518626}. Best is trial 37 with value: 0.00026959137092198607.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:15,742]\u001b[0m Trial 46 finished with value: 0.0005928183263585329 and parameters: {'booster': 'gblinear', 'lambda': 1.3654056681864222e-07, 'alpha': 0.008872057110876658, 'subsample': 0.737834355289718, 'colsample_bytree': 0.7124343771706745}. Best is trial 37 with value: 0.00026959137092198607.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:15,872]\u001b[0m Trial 47 finished with value: 0.0013287026512376692 and parameters: {'booster': 'gblinear', 'lambda': 1.69277073062507e-06, 'alpha': 0.00013659869331932582, 'subsample': 0.6005672407979712, 'colsample_bytree': 0.5766864128806962}. Best is trial 37 with value: 0.00026959137092198607.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:16,085]\u001b[0m Trial 48 finished with value: 1.1154129004876374 and parameters: {'booster': 'gbtree', 'lambda': 3.37868600148184e-07, 'alpha': 0.1272561731551778, 'subsample': 0.22047378163557912, 'colsample_bytree': 0.7892484611707473, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.0003689203405287091, 'gamma': 9.745587504112762e-07, 'grow_policy': 'lossguide'}. Best is trial 37 with value: 0.00026959137092198607.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:16,201]\u001b[0m Trial 49 finished with value: 0.007162372916513255 and parameters: {'booster': 'gblinear', 'lambda': 1.0139132861402487e-05, 'alpha': 0.03463561915446228, 'subsample': 0.7076634965138552, 'colsample_bytree': 0.49885729978028936}. Best is trial 37 with value: 0.00026959137092198607.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:17,231]\u001b[0m Trial 50 finished with value: 1.1926426329148583 and parameters: {'booster': 'dart', 'lambda': 2.630767433607869e-08, 'alpha': 0.002860690390583895, 'subsample': 0.899778555621608, 'colsample_bytree': 0.5530571485311295, 'max_depth': 3, 'min_child_weight': 5, 'eta': 6.910799677962712e-07, 'gamma': 3.136231144536736e-05, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.29855180748768495, 'skip_drop': 9.601940943433638e-06}. Best is trial 37 with value: 0.00026959137092198607.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:17,363]\u001b[0m Trial 51 finished with value: 0.0003138801500448805 and parameters: {'booster': 'gblinear', 'lambda': 1.732298598131391e-06, 'alpha': 0.0019010361505514743, 'subsample': 0.7738595217398119, 'colsample_bytree': 0.3612637560185059}. Best is trial 37 with value: 0.00026959137092198607.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:17,495]\u001b[0m Trial 52 finished with value: 0.0003803583530121224 and parameters: {'booster': 'gblinear', 'lambda': 3.568614388503706e-05, 'alpha': 0.005385078805262262, 'subsample': 0.7689297774222381, 'colsample_bytree': 0.3429725886000534}. Best is trial 37 with value: 0.00026959137092198607.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:09:17,626]\u001b[0m Trial 53 finished with value: 0.00069811833530358 and parameters: {'booster': 'gblinear', 'lambda': 1.913841101474501e-06, 'alpha': 0.0003752867037346379, 'subsample': 0.6625877237739899, 'colsample_bytree': 0.396793245532325}. Best is trial 37 with value: 0.00026959137092198607.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:17,758]\u001b[0m Trial 54 finished with value: 0.0011022100887981047 and parameters: {'booster': 'gblinear', 'lambda': 1.5111829658202421e-05, 'alpha': 0.00018970970130995917, 'subsample': 0.8208531270025355, 'colsample_bytree': 0.4622639283132276}. Best is trial 37 with value: 0.00026959137092198607.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:17,886]\u001b[0m Trial 55 finished with value: 0.0002320957361607484 and parameters: {'booster': 'gblinear', 'lambda': 4.1627875668814847e-07, 'alpha': 0.002913156548437104, 'subsample': 0.7149516908531878, 'colsample_bytree': 0.34494598013141803}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:18,018]\u001b[0m Trial 56 finished with value: 0.002479469068072177 and parameters: {'booster': 'gblinear', 'lambda': 6.67542589912456e-08, 'alpha': 1.2755152667258024e-08, 'subsample': 0.7168102962824529, 'colsample_bytree': 0.35681730636484654}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:18,149]\u001b[0m Trial 57 finished with value: 0.00029118894068585035 and parameters: {'booster': 'gblinear', 'lambda': 1.5541358796918124e-06, 'alpha': 0.0036966237856330174, 'subsample': 0.6255659893965428, 'colsample_bytree': 0.6177212189462509}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:18,271]\u001b[0m Trial 58 finished with value: 0.0020374490909110944 and parameters: {'booster': 'gblinear', 'lambda': 1.3505312536085502e-06, 'alpha': 0.01844670305105108, 'subsample': 0.4834255871107737, 'colsample_bytree': 0.6555270435146737}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:18,400]\u001b[0m Trial 59 finished with value: 0.00041186223623106773 and parameters: {'booster': 'gblinear', 'lambda': 4.992523961043938e-07, 'alpha': 0.0057355544314827075, 'subsample': 0.6297350540751177, 'colsample_bytree': 0.6958903367866931}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:18,505]\u001b[0m Trial 60 finished with value: 0.4091776975994779 and parameters: {'booster': 'gblinear', 'lambda': 2.1304275739423365e-07, 'alpha': 0.2960411760179661, 'subsample': 0.5750292484446341, 'colsample_bytree': 0.6034475052882098}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:18,635]\u001b[0m Trial 61 finished with value: 0.00033952380754951635 and parameters: {'booster': 'gblinear', 'lambda': 1.4053517325959446e-06, 'alpha': 0.003453786074336423, 'subsample': 0.7556057972359793, 'colsample_bytree': 0.5033918706331083}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:18,768]\u001b[0m Trial 62 finished with value: 0.0003699837365029821 and parameters: {'booster': 'gblinear', 'lambda': 2.412203590727382e-06, 'alpha': 0.001768075465537675, 'subsample': 0.7063562709798464, 'colsample_bytree': 0.45009996088822585}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:18,900]\u001b[0m Trial 63 finished with value: 0.0009320564389825083 and parameters: {'booster': 'gblinear', 'lambda': 4.962627961168795e-08, 'alpha': 0.0003205488772885026, 'subsample': 0.6821703691133275, 'colsample_bytree': 0.40132940911401443}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:19,028]\u001b[0m Trial 64 finished with value: 0.0006761228957700393 and parameters: {'booster': 'gblinear', 'lambda': 4.1311754505974915e-07, 'alpha': 0.010140330774529123, 'subsample': 0.7347493394180571, 'colsample_bytree': 0.3357607471985288}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:20,512]\u001b[0m Trial 65 finished with value: 1.122682146130208 and parameters: {'booster': 'dart', 'lambda': 6.857108272854443e-06, 'alpha': 0.0036798246888315993, 'subsample': 0.5233326142526142, 'colsample_bytree': 0.768701870041638, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.0003224779653553798, 'gamma': 0.0007431669774277545, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.0024076008112070835, 'skip_drop': 0.0018511391944012504}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:20,633]\u001b[0m Trial 66 finished with value: 0.004309206967954793 and parameters: {'booster': 'gblinear', 'lambda': 1.988835039380463e-05, 'alpha': 0.026848082060796124, 'subsample': 0.7803401520381295, 'colsample_bytree': 0.5478976850263098}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:20,765]\u001b[0m Trial 67 finished with value: 0.001073733227972697 and parameters: {'booster': 'gblinear', 'lambda': 4.806163056284314e-05, 'alpha': 0.0009257748821586018, 'subsample': 0.8390314384405329, 'colsample_bytree': 0.3790540528570989}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:20,979]\u001b[0m Trial 68 finished with value: 0.036004142563357475 and parameters: {'booster': 'gbtree', 'lambda': 1.124321777113262e-06, 'alpha': 0.0013714265065708769, 'subsample': 0.6277631001109094, 'colsample_bytree': 0.29453352418229956, 'max_depth': 5, 'min_child_weight': 3, 'eta': 0.04063021895817008, 'gamma': 0.019255771981310923, 'grow_policy': 'depthwise'}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:21,110]\u001b[0m Trial 69 finished with value: 0.0008598670272623612 and parameters: {'booster': 'gblinear', 'lambda': 1.2982084259478728e-05, 'alpha': 0.0005147164477611322, 'subsample': 0.8868701146360121, 'colsample_bytree': 0.6072627765662335}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:21,237]\u001b[0m Trial 70 finished with value: 0.0006064240472715244 and parameters: {'booster': 'gblinear', 'lambda': 5.1762389344460404e-06, 'alpha': 0.008751593466036304, 'subsample': 0.7500728414020661, 'colsample_bytree': 0.4134836202356904}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:21,367]\u001b[0m Trial 71 finished with value: 0.0003868305084554415 and parameters: {'booster': 'gblinear', 'lambda': 4.812899258032454e-06, 'alpha': 0.001959841774563915, 'subsample': 0.8203384502542063, 'colsample_bytree': 0.2644584837043523}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:21,497]\u001b[0m Trial 72 finished with value: 0.0004202184493380543 and parameters: {'booster': 'gblinear', 'lambda': 2.4970569114096724e-06, 'alpha': 0.0013407680853049517, 'subsample': 0.855385087340164, 'colsample_bytree': 0.27787917053907046}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:21,628]\u001b[0m Trial 73 finished with value: 0.00024529002592143536 and parameters: {'booster': 'gblinear', 'lambda': 5.26416667947881e-07, 'alpha': 0.0030717070829003436, 'subsample': 0.8328670675267386, 'colsample_bytree': 0.31889102596141616}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:21,758]\u001b[0m Trial 74 finished with value: 0.0004378578325484768 and parameters: {'booster': 'gblinear', 'lambda': 5.597963807431483e-07, 'alpha': 0.002962684562668756, 'subsample': 0.8345150411901101, 'colsample_bytree': 0.3295127120780923}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:21,890]\u001b[0m Trial 75 finished with value: 0.002520254101704932 and parameters: {'booster': 'gblinear', 'lambda': 1.7935943669594766e-07, 'alpha': 0.00024428972612361205, 'subsample': 0.7862601593511142, 'colsample_bytree': 0.3662105252925516}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:22,021]\u001b[0m Trial 76 finished with value: 0.0016141217477361688 and parameters: {'booster': 'gblinear', 'lambda': 3.0112622113830693e-07, 'alpha': 0.00010238702210761018, 'subsample': 0.6894859092447372, 'colsample_bytree': 0.4248170416894682}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:22,145]\u001b[0m Trial 77 finished with value: 0.00105605668063012 and parameters: {'booster': 'gblinear', 'lambda': 1.145939712221492e-07, 'alpha': 0.013126324497949357, 'subsample': 0.7236130024676737, 'colsample_bytree': 0.487860079208349}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:09:23,633]\u001b[0m Trial 78 finished with value: 1.1922068779108508 and parameters: {'booster': 'dart', 'lambda': 9.593637695824089e-07, 'alpha': 0.0048052677016695204, 'subsample': 0.7568513496038739, 'colsample_bytree': 0.375521148256916, 'max_depth': 7, 'min_child_weight': 7, 'eta': 2.7618237785408445e-06, 'gamma': 3.5635758805307067e-07, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 5.599775247610285e-07, 'skip_drop': 9.674466476878904e-07}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:23,769]\u001b[0m Trial 79 finished with value: 0.0009332243343585259 and parameters: {'booster': 'gblinear', 'lambda': 5.418958877251208e-07, 'alpha': 0.000604522799329256, 'subsample': 0.6566999129881826, 'colsample_bytree': 0.31003190724424795}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:23,905]\u001b[0m Trial 80 finished with value: 0.0024162510516898467 and parameters: {'booster': 'gblinear', 'lambda': 2.3821029140984526e-06, 'alpha': 1.5709677676560622e-07, 'subsample': 0.915472658176166, 'colsample_bytree': 0.46796120140634795}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:24,040]\u001b[0m Trial 81 finished with value: 0.0005857706242058912 and parameters: {'booster': 'gblinear', 'lambda': 5.201132911359022e-06, 'alpha': 0.0009510906356990391, 'subsample': 0.7905736733828873, 'colsample_bytree': 0.3452704295726108}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:24,175]\u001b[0m Trial 82 finished with value: 0.00034288507753114895 and parameters: {'booster': 'gblinear', 'lambda': 1.3998971793466637e-06, 'alpha': 0.00283820873202098, 'subsample': 0.8225162994026042, 'colsample_bytree': 0.8394621461364479}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:24,309]\u001b[0m Trial 83 finished with value: 0.0004471201882943114 and parameters: {'booster': 'gblinear', 'lambda': 2.4477413814196383e-05, 'alpha': 0.006057924508000053, 'subsample': 0.8799733282411664, 'colsample_bytree': 0.2423162148537559}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:24,445]\u001b[0m Trial 84 finished with value: 0.0003808007107868717 and parameters: {'booster': 'gblinear', 'lambda': 3.4391045815658746e-06, 'alpha': 0.0016630724786784858, 'subsample': 0.4358253812805979, 'colsample_bytree': 0.43934473509666594}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:24,653]\u001b[0m Trial 85 finished with value: 1.1927670618348833 and parameters: {'booster': 'gbtree', 'lambda': 1.118280367264719e-05, 'alpha': 0.038900668289029466, 'subsample': 0.8619100165118877, 'colsample_bytree': 0.6760689433547318, 'max_depth': 3, 'min_child_weight': 9, 'eta': 9.323451391060591e-08, 'gamma': 1.2173947550534533e-08, 'grow_policy': 'lossguide'}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:24,783]\u001b[0m Trial 86 finished with value: 0.0006194527678460814 and parameters: {'booster': 'gblinear', 'lambda': 8.297892446796853e-05, 'alpha': 0.009255841321001488, 'subsample': 0.7999435613133499, 'colsample_bytree': 0.22682557705305684}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:24,919]\u001b[0m Trial 87 finished with value: 0.0008750998898720064 and parameters: {'booster': 'gblinear', 'lambda': 0.0002475622689946135, 'alpha': 0.00044137043071598134, 'subsample': 0.7718455498731546, 'colsample_bytree': 0.6270270598292925}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:25,055]\u001b[0m Trial 88 finished with value: 0.0006944365929606693 and parameters: {'booster': 'gblinear', 'lambda': 7.520184090097549e-06, 'alpha': 0.0009941723361768988, 'subsample': 0.8382138908804357, 'colsample_bytree': 0.5767020656494036}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:25,181]\u001b[0m Trial 89 finished with value: 0.003181538416160691 and parameters: {'booster': 'gblinear', 'lambda': 2.850817966615102e-07, 'alpha': 0.02307527160807508, 'subsample': 0.7384829742237544, 'colsample_bytree': 0.27756423041736594}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:25,318]\u001b[0m Trial 90 finished with value: 0.00034106219839627277 and parameters: {'booster': 'gblinear', 'lambda': 8.279414175573352e-07, 'alpha': 0.0023707422667006597, 'subsample': 0.8082690711152658, 'colsample_bytree': 0.30699077721029505}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:25,452]\u001b[0m Trial 91 finished with value: 0.00031027369546976523 and parameters: {'booster': 'gblinear', 'lambda': 1.5681997330000382e-06, 'alpha': 0.004635470214480497, 'subsample': 0.7583180432724936, 'colsample_bytree': 0.5034449726085134}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:25,586]\u001b[0m Trial 92 finished with value: 0.00033812244920387353 and parameters: {'booster': 'gblinear', 'lambda': 1.9369163586366663e-06, 'alpha': 0.005020316903969786, 'subsample': 0.7620299851929615, 'colsample_bytree': 0.5229969182317209}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:25,723]\u001b[0m Trial 93 finished with value: 0.00042174833729879973 and parameters: {'booster': 'gblinear', 'lambda': 3.2212049920042285e-06, 'alpha': 0.003962195510511894, 'subsample': 0.6905239966021736, 'colsample_bytree': 0.5045930210066623}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:25,854]\u001b[0m Trial 94 finished with value: 0.000498089415632055 and parameters: {'booster': 'gblinear', 'lambda': 6.729632619643209e-07, 'alpha': 0.007683105223553623, 'subsample': 0.7293989138011013, 'colsample_bytree': 0.40950101050197857}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:25,981]\u001b[0m Trial 95 finished with value: 0.0012657400000600373 and parameters: {'booster': 'gblinear', 'lambda': 1.1189138608726249e-06, 'alpha': 0.014463482725550333, 'subsample': 0.7761706818810803, 'colsample_bytree': 0.5604018785597031}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:27,554]\u001b[0m Trial 96 finished with value: 1.191595826558526 and parameters: {'booster': 'dart', 'lambda': 5.387067824477589e-06, 'alpha': 0.001314292979749029, 'subsample': 0.8969513268210576, 'colsample_bytree': 0.44732950687176404, 'max_depth': 9, 'min_child_weight': 5, 'eta': 5.370236225580969e-06, 'gamma': 4.4773813610086e-05, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.004461795404740425, 'skip_drop': 0.7292291666030104}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:27,689]\u001b[0m Trial 97 finished with value: 0.0003878131482496803 and parameters: {'booster': 'gblinear', 'lambda': 1.7081982888692076e-06, 'alpha': 0.0024577268016857377, 'subsample': 0.5847084965292113, 'colsample_bytree': 0.3853694222314324}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:27,826]\u001b[0m Trial 98 finished with value: 0.0009364777873559828 and parameters: {'booster': 'gblinear', 'lambda': 1.5515898967826743e-05, 'alpha': 0.0006357329837349143, 'subsample': 0.8303863771793806, 'colsample_bytree': 0.4750258460384301}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:28,071]\u001b[0m Trial 99 finished with value: 0.03449140721332412 and parameters: {'booster': 'gbtree', 'lambda': 2.737678319551347e-06, 'alpha': 0.00026986555476160514, 'subsample': 0.5443515359139913, 'colsample_bytree': 0.5453586195255685, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.02705882405242548, 'gamma': 0.0033432191547178246, 'grow_policy': 'depthwise'}. Best is trial 55 with value: 0.0002320957361607484.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:28,224]\u001b[0m A new study created in memory with name: no-name-c4986fee-0b52-443d-8a33-a1987a7c44b6\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:28,344]\u001b[0m Trial 0 finished with value: 0.8397246058466393 and parameters: {'booster': 'gblinear', 'lambda': 2.8225919856258567e-08, 'alpha': 2.0789676604703292e-05, 'subsample': 0.5743613822247707, 'colsample_bytree': 0.8784171521054067}. Best is trial 0 with value: 0.8397246058466393.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:09:29,808]\u001b[0m Trial 1 finished with value: 0.941070226027379 and parameters: {'booster': 'dart', 'lambda': 0.008634753903769384, 'alpha': 4.541337963711105e-06, 'subsample': 0.9759045836879225, 'colsample_bytree': 0.5861480915630919, 'max_depth': 3, 'min_child_weight': 9, 'eta': 6.589921238789988e-05, 'gamma': 0.06930542762728537, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 3.5310336854532616e-07, 'skip_drop': 0.01676629481124774}. Best is trial 0 with value: 0.8397246058466393.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:31,475]\u001b[0m Trial 2 finished with value: 0.7236490334257766 and parameters: {'booster': 'dart', 'lambda': 3.1322711935584997e-06, 'alpha': 0.015868824950339457, 'subsample': 0.8123326643839883, 'colsample_bytree': 0.676765541927902, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.03570532587476928, 'gamma': 1.9514029277997518e-08, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 3.537076063528164e-05, 'skip_drop': 0.7058393634002997}. Best is trial 2 with value: 0.7236490334257766.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:31,597]\u001b[0m Trial 3 finished with value: 0.8392417458180886 and parameters: {'booster': 'gblinear', 'lambda': 2.201283636040839e-07, 'alpha': 1.5987759401860273e-06, 'subsample': 0.4141486727354018, 'colsample_bytree': 0.465860021569163}. Best is trial 2 with value: 0.7236490334257766.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:32,522]\u001b[0m Trial 4 finished with value: 0.9443827751421972 and parameters: {'booster': 'dart', 'lambda': 8.899794348030394e-07, 'alpha': 0.00027824887801512294, 'subsample': 0.6366052335713164, 'colsample_bytree': 0.34732158733538643, 'max_depth': 3, 'min_child_weight': 2, 'eta': 1.1712414128541258e-06, 'gamma': 2.20288928420677e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.3803026239175346, 'skip_drop': 0.0002538729283028277}. Best is trial 2 with value: 0.7236490334257766.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:32,749]\u001b[0m Trial 5 finished with value: 0.7092386026169222 and parameters: {'booster': 'gbtree', 'lambda': 8.447698789849252e-07, 'alpha': 3.694888017084171e-07, 'subsample': 0.7265109289893947, 'colsample_bytree': 0.3607826665795192, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.043559135154305366, 'gamma': 0.08886647786457849, 'grow_policy': 'lossguide'}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:34,178]\u001b[0m Trial 6 finished with value: 0.944435932742511 and parameters: {'booster': 'dart', 'lambda': 0.0002505046722667713, 'alpha': 0.01207407683981802, 'subsample': 0.5307372541757799, 'colsample_bytree': 0.5985077345096711, 'max_depth': 7, 'min_child_weight': 5, 'eta': 1.353543312970354e-07, 'gamma': 2.9586437573453533e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.0113956368567106e-07, 'skip_drop': 0.15246108427472735}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:34,297]\u001b[0m Trial 7 finished with value: 0.8206176243078449 and parameters: {'booster': 'gblinear', 'lambda': 0.0018701300739482104, 'alpha': 0.00023761279606450652, 'subsample': 0.8926731730022981, 'colsample_bytree': 0.8773020064243575}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:35,538]\u001b[0m Trial 8 finished with value: 0.7547939946605687 and parameters: {'booster': 'dart', 'lambda': 0.0010112553430750156, 'alpha': 0.002755159845338393, 'subsample': 0.46052490257690865, 'colsample_bytree': 0.21739330037385518, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.15625819798972973, 'gamma': 3.7006336334165207e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.16127005954627624, 'skip_drop': 1.7034029692659566e-06}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:36,984]\u001b[0m Trial 9 finished with value: 0.9444410374316392 and parameters: {'booster': 'dart', 'lambda': 1.8122347395511218e-07, 'alpha': 0.08107549213648335, 'subsample': 0.9344203996354825, 'colsample_bytree': 0.4118583153495055, 'max_depth': 9, 'min_child_weight': 6, 'eta': 3.774254200129484e-08, 'gamma': 2.0871453699785334e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.00013056575206921715, 'skip_drop': 0.00017825386989140833}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:37,168]\u001b[0m Trial 10 finished with value: 0.9075999992792196 and parameters: {'booster': 'gbtree', 'lambda': 1.65938184005894e-05, 'alpha': 1.5282893219189225e-08, 'subsample': 0.22322425413817049, 'colsample_bytree': 0.2223674707262172, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.0007941150915639132, 'gamma': 0.41377946617087374, 'grow_policy': 'lossguide'}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:37,509]\u001b[0m Trial 11 finished with value: 2.0917960714101764 and parameters: {'booster': 'gbtree', 'lambda': 1.6063642329909455e-05, 'alpha': 0.8957666525865333, 'subsample': 0.7691885556298366, 'colsample_bytree': 0.7512326687759152, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.9472887418972019, 'gamma': 0.001072950020987071, 'grow_policy': 'depthwise'}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:37,814]\u001b[0m Trial 12 finished with value: 0.7650566052759659 and parameters: {'booster': 'gbtree', 'lambda': 0.4605586770444957, 'alpha': 8.020115909884986e-08, 'subsample': 0.7618627075894165, 'colsample_bytree': 0.7230523695439878, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.0057445063017250095, 'gamma': 0.0003674996731049408, 'grow_policy': 'depthwise'}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:38,125]\u001b[0m Trial 13 finished with value: 0.718854179297285 and parameters: {'booster': 'gbtree', 'lambda': 6.0353813150910975e-06, 'alpha': 9.13383172097462e-07, 'subsample': 0.7461361459164545, 'colsample_bytree': 0.6970511093442793, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.023826291746095803, 'gamma': 0.008637465736566803, 'grow_policy': 'depthwise'}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:38,408]\u001b[0m Trial 14 finished with value: 0.9365010699797653 and parameters: {'booster': 'gbtree', 'lambda': 1.866646801214482e-08, 'alpha': 2.759313973511674e-07, 'subsample': 0.6988641848529008, 'colsample_bytree': 0.9966453377517407, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.0001551849902826617, 'gamma': 0.011260263909505139, 'grow_policy': 'lossguide'}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:38,689]\u001b[0m Trial 15 finished with value: 0.7166403416169945 and parameters: {'booster': 'gbtree', 'lambda': 2.412142893223686e-05, 'alpha': 8.54158463198068e-07, 'subsample': 0.6606142171844059, 'colsample_bytree': 0.5248132939667165, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.011745425907679725, 'gamma': 0.007877101747214307, 'grow_policy': 'lossguide'}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:38,914]\u001b[0m Trial 16 finished with value: 0.8322114068511641 and parameters: {'booster': 'gbtree', 'lambda': 0.00012405617186789477, 'alpha': 1.1278174265824933e-08, 'subsample': 0.6528753873152564, 'colsample_bytree': 0.45264467967665273, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.002898344303850017, 'gamma': 0.9753314664065494, 'grow_policy': 'lossguide'}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:39,107]\u001b[0m Trial 17 finished with value: 0.9436897473332745 and parameters: {'booster': 'gbtree', 'lambda': 0.07663922902725244, 'alpha': 1.0097220603300594e-05, 'subsample': 0.3477642555805267, 'colsample_bytree': 0.3480845520159344, 'max_depth': 7, 'min_child_weight': 8, 'eta': 1.48544809500424e-05, 'gamma': 7.527857680666184e-06, 'grow_policy': 'lossguide'}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:39,412]\u001b[0m Trial 18 finished with value: 2.2689269572421598 and parameters: {'booster': 'gbtree', 'lambda': 4.132106830736748e-05, 'alpha': 1.027837070841424e-07, 'subsample': 0.8573379687194158, 'colsample_bytree': 0.5480047572942212, 'max_depth': 7, 'min_child_weight': 6, 'eta': 0.9703926561330449, 'gamma': 0.006578702233204601, 'grow_policy': 'lossguide'}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:09:39,621]\u001b[0m Trial 19 finished with value: 0.7630402714829632 and parameters: {'booster': 'gbtree', 'lambda': 4.1894057723385684e-07, 'alpha': 4.882590301365508e-05, 'subsample': 0.5311764438753994, 'colsample_bytree': 0.32334287390942873, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.06980760932957789, 'gamma': 5.2187643675192486e-05, 'grow_policy': 'lossguide'}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:39,914]\u001b[0m Trial 20 finished with value: 0.8898319601036377 and parameters: {'booster': 'gbtree', 'lambda': 1.8216575370388651e-06, 'alpha': 4.9706917311182e-07, 'subsample': 0.6639051029449033, 'colsample_bytree': 0.5244392758437045, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.001188363707725758, 'gamma': 0.08949870640022249, 'grow_policy': 'lossguide'}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:40,223]\u001b[0m Trial 21 finished with value: 0.7257550836376422 and parameters: {'booster': 'gbtree', 'lambda': 1.5488686379523586e-05, 'alpha': 1.09639706740269e-06, 'subsample': 0.7316179407704242, 'colsample_bytree': 0.6840136173808022, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.02844326886750446, 'gamma': 0.009217749115240322, 'grow_policy': 'depthwise'}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:40,508]\u001b[0m Trial 22 finished with value: 0.728956669249909 and parameters: {'booster': 'gbtree', 'lambda': 5.3796233741821515e-06, 'alpha': 2.7929163510989077e-06, 'subsample': 0.8028584297707352, 'colsample_bytree': 0.4979103957969322, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.009211542382577589, 'gamma': 0.04436968206095817, 'grow_policy': 'depthwise'}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:40,826]\u001b[0m Trial 23 finished with value: 0.9428140213056868 and parameters: {'booster': 'gbtree', 'lambda': 0.00022547000016553707, 'alpha': 5.937869451295459e-08, 'subsample': 0.5829160216950625, 'colsample_bytree': 0.818935190120145, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.2754207056134118, 'gamma': 0.0009399452174553388, 'grow_policy': 'lossguide'}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:41,074]\u001b[0m Trial 24 finished with value: 0.7187196570597462 and parameters: {'booster': 'gbtree', 'lambda': 7.724536569049537e-08, 'alpha': 2.0038959344117805e-07, 'subsample': 0.7157724738285897, 'colsample_bytree': 0.6361129399620271, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.010579934515810232, 'gamma': 0.004047644368886358, 'grow_policy': 'depthwise'}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:41,209]\u001b[0m Trial 25 finished with value: 0.8385144892364653 and parameters: {'booster': 'gblinear', 'lambda': 9.725344658985982e-08, 'alpha': 2.111463975565731e-07, 'subsample': 0.8575849689253131, 'colsample_bytree': 0.4032653338691843}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:41,417]\u001b[0m Trial 26 finished with value: 0.9347638278217876 and parameters: {'booster': 'gbtree', 'lambda': 6.827246884769457e-08, 'alpha': 3.1121797922129575e-08, 'subsample': 0.6897175808827393, 'colsample_bytree': 0.2958454352019734, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.00019042656499238116, 'gamma': 0.0001827617545431214, 'grow_policy': 'lossguide'}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:41,612]\u001b[0m Trial 27 finished with value: 0.8981488252651075 and parameters: {'booster': 'gbtree', 'lambda': 1.1390493294186453e-06, 'alpha': 7.575932260233063e-06, 'subsample': 0.47091120624306937, 'colsample_bytree': 0.6411675019073109, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.000982249930066905, 'gamma': 0.002239644893625697, 'grow_policy': 'depthwise'}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:41,837]\u001b[0m Trial 28 finished with value: 0.9439598826078335 and parameters: {'booster': 'gbtree', 'lambda': 1.793951792464547e-08, 'alpha': 3.4205933499963204e-05, 'subsample': 0.6154925972727557, 'colsample_bytree': 0.5583573641985317, 'max_depth': 5, 'min_child_weight': 9, 'eta': 9.34332646730531e-06, 'gamma': 0.18155321664294974, 'grow_policy': 'lossguide'}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:41,974]\u001b[0m Trial 29 finished with value: 0.8368366602379538 and parameters: {'booster': 'gblinear', 'lambda': 5.227199502603174e-07, 'alpha': 2.810702278346136e-07, 'subsample': 0.5770267458526098, 'colsample_bytree': 0.7872658808379712}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:42,226]\u001b[0m Trial 30 finished with value: 0.7467189026675165 and parameters: {'booster': 'gbtree', 'lambda': 5.2338671070900556e-08, 'alpha': 0.00013266542103081017, 'subsample': 0.8185564382829363, 'colsample_bytree': 0.6216922318737321, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.007942237806816107, 'gamma': 0.037905180313123815, 'grow_policy': 'lossguide'}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:42,528]\u001b[0m Trial 31 finished with value: 0.7183897160762022 and parameters: {'booster': 'gbtree', 'lambda': 5.320626493258426e-06, 'alpha': 8.569229744423026e-07, 'subsample': 0.7222598940952853, 'colsample_bytree': 0.6768063274299063, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.012063890507545697, 'gamma': 0.005825602408479327, 'grow_policy': 'depthwise'}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:42,831]\u001b[0m Trial 32 finished with value: 0.750627291745828 and parameters: {'booster': 'gbtree', 'lambda': 4.714869958571827e-05, 'alpha': 3.020655411117282e-06, 'subsample': 0.7086436557719901, 'colsample_bytree': 0.6279768760482662, 'max_depth': 7, 'min_child_weight': 6, 'eta': 0.07497708836802827, 'gamma': 3.55594095005471e-05, 'grow_policy': 'depthwise'}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:43,161]\u001b[0m Trial 33 finished with value: 0.9406770308325196 and parameters: {'booster': 'gbtree', 'lambda': 3.1322475915515923e-06, 'alpha': 1.703103927019259e-05, 'subsample': 0.6361077253609295, 'colsample_bytree': 0.5786854961727304, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.21985718694299236, 'gamma': 0.0032539293395081915, 'grow_policy': 'depthwise'}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:43,296]\u001b[0m Trial 34 finished with value: 0.8396204978788391 and parameters: {'booster': 'gblinear', 'lambda': 3.206848905589311e-07, 'alpha': 6.876242610423538e-07, 'subsample': 0.9744148475239289, 'colsample_bytree': 0.4772287831155667}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:43,566]\u001b[0m Trial 35 finished with value: 0.8386689937078182 and parameters: {'booster': 'gbtree', 'lambda': 7.224525099350423e-06, 'alpha': 1.3270142984436462e-07, 'subsample': 0.800063550586807, 'colsample_bytree': 0.40994923187158383, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.002619688292559236, 'gamma': 0.030326239894497432, 'grow_policy': 'depthwise'}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:44,991]\u001b[0m Trial 36 finished with value: 0.9252278446043105 and parameters: {'booster': 'dart', 'lambda': 1.0164134791466313e-08, 'alpha': 3.693938207078078e-08, 'subsample': 0.5182600168409115, 'colsample_bytree': 0.8305302093709153, 'max_depth': 3, 'min_child_weight': 9, 'eta': 0.0003890853961445783, 'gamma': 0.22014588505811736, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.0015172242960974163, 'skip_drop': 9.068172702231117e-08}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:45,239]\u001b[0m Trial 37 finished with value: 0.711010108468343 and parameters: {'booster': 'gbtree', 'lambda': 1.0938244926367159e-06, 'alpha': 0.0008109815936876963, 'subsample': 0.682311234496942, 'colsample_bytree': 0.6631404758372277, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.01269969286184235, 'gamma': 0.0006271105011460507, 'grow_policy': 'depthwise'}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:45,371]\u001b[0m Trial 38 finished with value: 0.7624548909346732 and parameters: {'booster': 'gblinear', 'lambda': 0.0006907214709715928, 'alpha': 0.0038861492914509872, 'subsample': 0.6137686703528017, 'colsample_bytree': 0.26708248350169106}. Best is trial 5 with value: 0.7092386026169222.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:09:46,905]\u001b[0m Trial 39 finished with value: 0.7054351529248577 and parameters: {'booster': 'dart', 'lambda': 0.007488255938995198, 'alpha': 0.003577457098089042, 'subsample': 0.6718271248847778, 'colsample_bytree': 0.7468169046412507, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.035872921318223665, 'gamma': 0.00048496477998609427, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.1664433407122757e-08, 'skip_drop': 1.1363177086835385e-08}. Best is trial 39 with value: 0.7054351529248577.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:48,548]\u001b[0m Trial 40 finished with value: 0.7576916721132386 and parameters: {'booster': 'dart', 'lambda': 0.0024533309854526545, 'alpha': 0.0007548613370925494, 'subsample': 0.6756499329960474, 'colsample_bytree': 0.9838006503883422, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.07598949543733574, 'gamma': 0.0003536753039144219, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 2.488456636032936e-06, 'skip_drop': 6.395456728344298e-08}. Best is trial 39 with value: 0.7054351529248577.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:50,085]\u001b[0m Trial 41 finished with value: 0.6999581677459372 and parameters: {'booster': 'dart', 'lambda': 1.7366368184389017e-06, 'alpha': 0.0011189207899492857, 'subsample': 0.7479753882648144, 'colsample_bytree': 0.7277098750441302, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.025189438985514068, 'gamma': 0.0010421459624480444, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.1348626062656878e-08, 'skip_drop': 3.6856262913013986e-06}. Best is trial 41 with value: 0.6999581677459372.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:51,634]\u001b[0m Trial 42 finished with value: 0.7085072807829127 and parameters: {'booster': 'dart', 'lambda': 0.009893109617053272, 'alpha': 0.0009296559463130244, 'subsample': 0.7782962807618143, 'colsample_bytree': 0.7419971372852034, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.02579482213835424, 'gamma': 0.0009724013237748661, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.6189049648864857e-08, 'skip_drop': 2.7094930940079526e-06}. Best is trial 41 with value: 0.6999581677459372.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:53,186]\u001b[0m Trial 43 finished with value: 0.7085139719202954 and parameters: {'booster': 'dart', 'lambda': 0.01953923481386512, 'alpha': 0.0006912636127653753, 'subsample': 0.8673976456614814, 'colsample_bytree': 0.7422274138197533, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.03920782503664849, 'gamma': 1.2872997652965682e-05, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.0559678976810323e-08, 'skip_drop': 4.533103853147355e-06}. Best is trial 41 with value: 0.6999581677459372.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:54,739]\u001b[0m Trial 44 finished with value: 0.9461680239512249 and parameters: {'booster': 'dart', 'lambda': 0.013578865109734974, 'alpha': 0.004963963108470859, 'subsample': 0.8966458820581943, 'colsample_bytree': 0.7422980542845156, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.4546192534389108, 'gamma': 1.089156052008626e-05, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.4926591879230053e-08, 'skip_drop': 3.610324676484042e-06}. Best is trial 41 with value: 0.6999581677459372.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:56,323]\u001b[0m Trial 45 finished with value: 0.7291834105765594 and parameters: {'booster': 'dart', 'lambda': 0.018358016451909716, 'alpha': 0.05840883677861266, 'subsample': 0.8458987628060248, 'colsample_bytree': 0.8701552333071803, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.059252550123554466, 'gamma': 3.8610334903778134e-07, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.0615040581327039e-08, 'skip_drop': 3.289524245226642e-06}. Best is trial 41 with value: 0.6999581677459372.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:57,944]\u001b[0m Trial 46 finished with value: 0.7935343390676912 and parameters: {'booster': 'dart', 'lambda': 0.06580492109769828, 'alpha': 0.000825482663751651, 'subsample': 0.7772244799497398, 'colsample_bytree': 0.9289826421677285, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.12958228688855247, 'gamma': 7.114916399214749e-05, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.0132619034792242e-08, 'skip_drop': 1.507847807360694e-05}. Best is trial 41 with value: 0.6999581677459372.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:09:59,599]\u001b[0m Trial 47 finished with value: 0.7150709719309056 and parameters: {'booster': 'dart', 'lambda': 0.6029365606980807, 'alpha': 0.016373754107180522, 'subsample': 0.9344811365450909, 'colsample_bytree': 0.7832241011726184, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.032217885671719806, 'gamma': 1.1842858096661043e-06, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 3.309741957835843e-07, 'skip_drop': 3.752826151562667e-07}. Best is trial 41 with value: 0.6999581677459372.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:01,301]\u001b[0m Trial 48 finished with value: 0.9444013131989857 and parameters: {'booster': 'dart', 'lambda': 0.0028856451124162218, 'alpha': 0.001720965227372242, 'subsample': 0.918000989726987, 'colsample_bytree': 0.7243419785675625, 'max_depth': 7, 'min_child_weight': 10, 'eta': 8.247247737931695e-07, 'gamma': 1.4274440284933262e-05, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 9.048056576517587e-08, 'skip_drop': 1.291994567698588e-08}. Best is trial 41 with value: 0.6999581677459372.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:03,046]\u001b[0m A new study created in memory with name: no-name-c908463a-b1c3-44a6-9c91-cd101ce5f044\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:03,139]\u001b[0m Trial 0 finished with value: 0.6006936809944066 and parameters: {'booster': 'gblinear', 'lambda': 0.00015679914706310226, 'alpha': 0.3405557477721805, 'subsample': 0.33783152245836345, 'colsample_bytree': 0.8317078232054622}. Best is trial 0 with value: 0.6006936809944066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:03,454]\u001b[0m Trial 1 finished with value: 1.2544529918155651 and parameters: {'booster': 'gbtree', 'lambda': 1.9275197055076272e-06, 'alpha': 0.0001749764111269142, 'subsample': 0.3849801338278247, 'colsample_bytree': 0.9664192436307022, 'max_depth': 9, 'min_child_weight': 10, 'eta': 3.680142481672639e-08, 'gamma': 2.1818946478727858e-05, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.6006936809944066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:03,622]\u001b[0m Trial 2 finished with value: 0.9295868899168451 and parameters: {'booster': 'gbtree', 'lambda': 1.2135819728027093e-08, 'alpha': 1.2885084877622374e-07, 'subsample': 0.25416979238139137, 'colsample_bytree': 0.7561108513411738, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.002871373866741539, 'gamma': 6.845740336831679e-05, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.6006936809944066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:03,891]\u001b[0m Trial 3 finished with value: 1.254456824983355 and parameters: {'booster': 'gbtree', 'lambda': 0.09775632088990811, 'alpha': 0.004732412300073967, 'subsample': 0.6088003143076511, 'colsample_bytree': 0.47559046277711836, 'max_depth': 7, 'min_child_weight': 9, 'eta': 1.607300945009893e-08, 'gamma': 1.679416405793987e-06, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.6006936809944066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:04,235]\u001b[0m Trial 4 finished with value: 1.2544409245730663 and parameters: {'booster': 'gbtree', 'lambda': 0.5119938047691512, 'alpha': 2.3671334539421577e-07, 'subsample': 0.9062573578548614, 'colsample_bytree': 0.7665587672965002, 'max_depth': 7, 'min_child_weight': 6, 'eta': 1.0803702858687842e-07, 'gamma': 3.965980212803898e-06, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.6006936809944066.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:04,358]\u001b[0m Trial 5 finished with value: 0.38811318044990306 and parameters: {'booster': 'gblinear', 'lambda': 0.04607903691687636, 'alpha': 0.000665208830287213, 'subsample': 0.7420634122304823, 'colsample_bytree': 0.42312893143907715}. Best is trial 5 with value: 0.38811318044990306.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:04,567]\u001b[0m Trial 6 finished with value: 0.3925968757199842 and parameters: {'booster': 'gbtree', 'lambda': 0.005782335312121248, 'alpha': 7.783175380952345e-06, 'subsample': 0.9985939783552007, 'colsample_bytree': 0.8930604649542908, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.019932893071454377, 'gamma': 9.306375554184285e-06, 'grow_policy': 'depthwise'}. Best is trial 5 with value: 0.38811318044990306.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:10:04,679]\u001b[0m Trial 7 finished with value: 0.4305619232757105 and parameters: {'booster': 'gblinear', 'lambda': 0.0001616143848380233, 'alpha': 0.039546094320014866, 'subsample': 0.6374539316858288, 'colsample_bytree': 0.3948777632149038}. Best is trial 5 with value: 0.38811318044990306.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:04,801]\u001b[0m Trial 8 finished with value: 0.4422125740089892 and parameters: {'booster': 'gblinear', 'lambda': 0.3945190429647702, 'alpha': 0.0024783595040637372, 'subsample': 0.5740064589481518, 'colsample_bytree': 0.7101160686134633}. Best is trial 5 with value: 0.38811318044990306.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:04,925]\u001b[0m Trial 9 finished with value: 0.4055998848713906 and parameters: {'booster': 'gblinear', 'lambda': 0.000805949483322927, 'alpha': 1.1152266128412777e-07, 'subsample': 0.35852696617972524, 'colsample_bytree': 0.8951394770146841}. Best is trial 5 with value: 0.38811318044990306.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:06,475]\u001b[0m Trial 10 finished with value: 0.9521468305767193 and parameters: {'booster': 'dart', 'lambda': 4.130789178054034e-06, 'alpha': 2.1186334781763865e-05, 'subsample': 0.7973120498910868, 'colsample_bytree': 0.20603775595681312, 'max_depth': 5, 'min_child_weight': 2, 'eta': 0.9450979749786278, 'gamma': 0.8632895605978633, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.4637363964865513e-06, 'skip_drop': 1.0707404408521032e-08}. Best is trial 5 with value: 0.38811318044990306.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:07,775]\u001b[0m Trial 11 finished with value: 1.0304069469383663 and parameters: {'booster': 'dart', 'lambda': 0.006825831273248608, 'alpha': 1.611794079972558e-05, 'subsample': 0.9806657150941331, 'colsample_bytree': 0.5508624974230818, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.001958774272304702, 'gamma': 1.3135924307355133e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.502545968370853, 'skip_drop': 0.4468440037290464}. Best is trial 5 with value: 0.38811318044990306.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:08,006]\u001b[0m Trial 12 finished with value: 0.8636526099010705 and parameters: {'booster': 'gbtree', 'lambda': 0.012052694271100532, 'alpha': 2.7046946034066734e-06, 'subsample': 0.7886138448640972, 'colsample_bytree': 0.3413099475530404, 'max_depth': 5, 'min_child_weight': 5, 'eta': 0.9620393140294321, 'gamma': 0.01572972371443831, 'grow_policy': 'depthwise'}. Best is trial 5 with value: 0.38811318044990306.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:08,166]\u001b[0m Trial 13 finished with value: 0.39290717251003476 and parameters: {'booster': 'gblinear', 'lambda': 0.00795614004471323, 'alpha': 0.00039400327817482717, 'subsample': 0.7907635158666386, 'colsample_bytree': 0.620886830551248}. Best is trial 5 with value: 0.38811318044990306.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:09,598]\u001b[0m Trial 14 finished with value: 1.253198168353419 and parameters: {'booster': 'dart', 'lambda': 0.0018307331325903842, 'alpha': 2.4885042396716868e-06, 'subsample': 0.9843816109159692, 'colsample_bytree': 0.27461198774005297, 'max_depth': 3, 'min_child_weight': 4, 'eta': 1.0324845886527015e-05, 'gamma': 3.411300816045952e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.020015858289193344, 'skip_drop': 7.741072043770102e-06}. Best is trial 5 with value: 0.38811318044990306.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:09,740]\u001b[0m Trial 15 finished with value: 0.3855782678169563 and parameters: {'booster': 'gblinear', 'lambda': 0.036150755667396596, 'alpha': 0.0012691270345441034, 'subsample': 0.7052176198374492, 'colsample_bytree': 0.5935032693742296}. Best is trial 15 with value: 0.3855782678169563.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:09,878]\u001b[0m Trial 16 finished with value: 0.38769639845242126 and parameters: {'booster': 'gblinear', 'lambda': 0.05394793176723297, 'alpha': 0.002898684118982224, 'subsample': 0.5127935579121723, 'colsample_bytree': 0.4739510711282138}. Best is trial 15 with value: 0.3855782678169563.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:10,012]\u001b[0m Trial 17 finished with value: 0.3942254754161718 and parameters: {'booster': 'gblinear', 'lambda': 1.2608333086768501e-05, 'alpha': 0.019094973791231238, 'subsample': 0.4875187637878342, 'colsample_bytree': 0.6007064023823092}. Best is trial 15 with value: 0.3855782678169563.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:10,127]\u001b[0m Trial 18 finished with value: 0.5619651348144752 and parameters: {'booster': 'gblinear', 'lambda': 0.08148464198704855, 'alpha': 0.23359857604989398, 'subsample': 0.48557298385453196, 'colsample_bytree': 0.5059769785886675}. Best is trial 15 with value: 0.3855782678169563.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:10,250]\u001b[0m Trial 19 finished with value: 0.5092894408274783 and parameters: {'booster': 'gblinear', 'lambda': 0.6699854081428729, 'alpha': 0.04807997856286512, 'subsample': 0.6827598146773246, 'colsample_bytree': 0.6252886560417653}. Best is trial 15 with value: 0.3855782678169563.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:10,389]\u001b[0m Trial 20 finished with value: 0.3933594081286344 and parameters: {'booster': 'gblinear', 'lambda': 4.5379377047236245e-08, 'alpha': 0.0015332994364424585, 'subsample': 0.5142309692978474, 'colsample_bytree': 0.6785701963437665}. Best is trial 15 with value: 0.3855782678169563.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:10,531]\u001b[0m Trial 21 finished with value: 0.3894812995675276 and parameters: {'booster': 'gblinear', 'lambda': 0.05389380402940972, 'alpha': 0.0005418350519778088, 'subsample': 0.7064767794731022, 'colsample_bytree': 0.4500249388354657}. Best is trial 15 with value: 0.3855782678169563.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:10,670]\u001b[0m Trial 22 finished with value: 0.3884508921910042 and parameters: {'booster': 'gblinear', 'lambda': 0.03938836934026363, 'alpha': 1.0625838939246274e-08, 'subsample': 0.7187686061882856, 'colsample_bytree': 0.3673176210033062}. Best is trial 15 with value: 0.3855782678169563.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:10,810]\u001b[0m Trial 23 finished with value: 0.40425383487949107 and parameters: {'booster': 'gblinear', 'lambda': 0.0008433373991591001, 'alpha': 9.086777361368386e-05, 'subsample': 0.8463866920327368, 'colsample_bytree': 0.5463452873997254}. Best is trial 15 with value: 0.3855782678169563.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:10,943]\u001b[0m Trial 24 finished with value: 0.41773892143977925 and parameters: {'booster': 'gblinear', 'lambda': 0.19103175658122173, 'alpha': 0.009087517825947999, 'subsample': 0.5472167467172572, 'colsample_bytree': 0.4288350596473724}. Best is trial 15 with value: 0.3855782678169563.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:12,492]\u001b[0m Trial 25 finished with value: 1.2536483914826377 and parameters: {'booster': 'dart', 'lambda': 0.023998220956781613, 'alpha': 7.184364141550872e-05, 'subsample': 0.4213846928173256, 'colsample_bytree': 0.31632526642703723, 'max_depth': 9, 'min_child_weight': 8, 'eta': 5.551479018344263e-06, 'gamma': 0.004660999748832489, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 3.3233901853338025e-08, 'skip_drop': 0.12152252836545573}. Best is trial 15 with value: 0.3855782678169563.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:12,630]\u001b[0m Trial 26 finished with value: 0.39501367000403514 and parameters: {'booster': 'gblinear', 'lambda': 0.0031961459210189543, 'alpha': 0.0010225000061990115, 'subsample': 0.6676811930110806, 'colsample_bytree': 0.5321228470786035}. Best is trial 15 with value: 0.3855782678169563.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:12,763]\u001b[0m Trial 27 finished with value: 0.3769586330639396 and parameters: {'booster': 'gblinear', 'lambda': 3.054107277625885e-05, 'alpha': 0.0066719283418493714, 'subsample': 0.7408168789748855, 'colsample_bytree': 0.44525253695523953}. Best is trial 27 with value: 0.3769586330639396.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:12,883]\u001b[0m Trial 28 finished with value: 0.44428630468150243 and parameters: {'booster': 'gblinear', 'lambda': 1.573806121129178e-05, 'alpha': 0.047953544400874494, 'subsample': 0.8783546307986375, 'colsample_bytree': 0.27384017563889584}. Best is trial 27 with value: 0.3769586330639396.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:12,988]\u001b[0m Trial 29 finished with value: 0.9165846864450526 and parameters: {'booster': 'gblinear', 'lambda': 9.703555978728647e-05, 'alpha': 0.9208155953308813, 'subsample': 0.27387865646082954, 'colsample_bytree': 0.6746464864354834}. Best is trial 27 with value: 0.3769586330639396.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:10:14,516]\u001b[0m Trial 30 finished with value: 1.2542913121100865 and parameters: {'booster': 'dart', 'lambda': 0.00016240937226100896, 'alpha': 0.007342042692771894, 'subsample': 0.6248696329275774, 'colsample_bytree': 0.47669060495833937, 'max_depth': 7, 'min_child_weight': 4, 'eta': 1.0641563202322025e-06, 'gamma': 0.0016078884580663089, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.0004404916759826513, 'skip_drop': 3.4434034649721144e-05}. Best is trial 27 with value: 0.3769586330639396.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:14,649]\u001b[0m Trial 31 finished with value: 0.41096351801151726 and parameters: {'booster': 'gblinear', 'lambda': 8.314396711364203e-07, 'alpha': 0.0002984153697798004, 'subsample': 0.7442035644037517, 'colsample_bytree': 0.425932829736471}. Best is trial 27 with value: 0.3769586330639396.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:14,760]\u001b[0m Trial 32 finished with value: 0.5075401408544059 and parameters: {'booster': 'gblinear', 'lambda': 3.511228766918616e-05, 'alpha': 0.12921648576309147, 'subsample': 0.7436786363736733, 'colsample_bytree': 0.5715380608313438}. Best is trial 27 with value: 0.3769586330639396.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:14,896]\u001b[0m Trial 33 finished with value: 0.3896152525851356 and parameters: {'booster': 'gblinear', 'lambda': 5.870766257449676e-07, 'alpha': 0.0017902742419985155, 'subsample': 0.4398749155149256, 'colsample_bytree': 0.3941220484424023}. Best is trial 27 with value: 0.3769586330639396.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:15,027]\u001b[0m Trial 34 finished with value: 0.37495494259557577 and parameters: {'booster': 'gblinear', 'lambda': 0.0007094094785675093, 'alpha': 0.005522225938191407, 'subsample': 0.5754718385203206, 'colsample_bytree': 0.4965093923878478}. Best is trial 34 with value: 0.37495494259557577.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:15,155]\u001b[0m Trial 35 finished with value: 0.3834240764268987 and parameters: {'booster': 'gblinear', 'lambda': 0.00045694786791781723, 'alpha': 0.013763016995259288, 'subsample': 0.5716726844913472, 'colsample_bytree': 0.48470927644050527}. Best is trial 34 with value: 0.37495494259557577.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:15,397]\u001b[0m Trial 36 finished with value: 1.2308873885443945 and parameters: {'booster': 'gbtree', 'lambda': 0.00044081945162472683, 'alpha': 0.016180327556351994, 'subsample': 0.5792681066697855, 'colsample_bytree': 0.5140934493198325, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.00015610732555078208, 'gamma': 0.3167574740140742, 'grow_policy': 'lossguide'}. Best is trial 34 with value: 0.37495494259557577.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:15,511]\u001b[0m Trial 37 finished with value: 0.4843128074314665 and parameters: {'booster': 'gblinear', 'lambda': 6.67498152457465e-05, 'alpha': 0.0991990657866036, 'subsample': 0.6190023489209449, 'colsample_bytree': 0.7880517266082141}. Best is trial 34 with value: 0.37495494259557577.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:15,860]\u001b[0m Trial 38 finished with value: 0.31240456193960203 and parameters: {'booster': 'gbtree', 'lambda': 0.0003004641199542155, 'alpha': 0.004559845704890631, 'subsample': 0.5521999364649476, 'colsample_bytree': 0.652594005176841, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.03614124916948435, 'gamma': 3.294565532976217e-07, 'grow_policy': 'depthwise'}. Best is trial 38 with value: 0.31240456193960203.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:16,174]\u001b[0m Trial 39 finished with value: 0.31721309486396526 and parameters: {'booster': 'gbtree', 'lambda': 0.0002769032522082457, 'alpha': 0.8437599072277143, 'subsample': 0.2968792385594782, 'colsample_bytree': 0.7125714009769746, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.04084217192916417, 'gamma': 1.3029187366841017e-07, 'grow_policy': 'depthwise'}. Best is trial 38 with value: 0.31240456193960203.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:16,547]\u001b[0m Trial 40 finished with value: 0.32341026449606264 and parameters: {'booster': 'gbtree', 'lambda': 2.1860188554492736e-05, 'alpha': 0.7920772698208953, 'subsample': 0.21153782297945756, 'colsample_bytree': 0.8117031311175555, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.04699042978705884, 'gamma': 2.943491241676188e-07, 'grow_policy': 'depthwise'}. Best is trial 38 with value: 0.31240456193960203.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:16,955]\u001b[0m Trial 41 finished with value: 0.32395835202473544 and parameters: {'booster': 'gbtree', 'lambda': 2.25032786362041e-05, 'alpha': 0.5879834374349145, 'subsample': 0.2015061937600191, 'colsample_bytree': 0.8086198402495871, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.04135531125248748, 'gamma': 1.574432353276917e-07, 'grow_policy': 'depthwise'}. Best is trial 38 with value: 0.31240456193960203.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:17,292]\u001b[0m Trial 42 finished with value: 0.3260396478033509 and parameters: {'booster': 'gbtree', 'lambda': 4.642329650177751e-06, 'alpha': 0.6976954866201615, 'subsample': 0.20705398935790245, 'colsample_bytree': 0.8437715707308624, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.05099969355647521, 'gamma': 2.4498738507211487e-07, 'grow_policy': 'depthwise'}. Best is trial 38 with value: 0.31240456193960203.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:17,567]\u001b[0m Trial 43 finished with value: 0.32916856476024703 and parameters: {'booster': 'gbtree', 'lambda': 3.3338148038248163e-06, 'alpha': 0.8914636286045642, 'subsample': 0.20898472635582288, 'colsample_bytree': 0.8569075176672964, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.04815414675284884, 'gamma': 2.5127102044912905e-07, 'grow_policy': 'depthwise'}. Best is trial 38 with value: 0.31240456193960203.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:17,890]\u001b[0m Trial 44 finished with value: 0.32714646901246736 and parameters: {'booster': 'gbtree', 'lambda': 9.363144742030117e-06, 'alpha': 0.3826002634625983, 'subsample': 0.3013795538095829, 'colsample_bytree': 0.9531159571500453, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.06271302212681681, 'gamma': 1.9437054235380468e-07, 'grow_policy': 'depthwise'}. Best is trial 38 with value: 0.31240456193960203.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:18,158]\u001b[0m Trial 45 finished with value: 0.4730566862870281 and parameters: {'booster': 'gbtree', 'lambda': 2.662747671446029e-07, 'alpha': 0.5475594391420741, 'subsample': 0.21064424059427256, 'colsample_bytree': 0.8012135640311038, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.011759366357017334, 'gamma': 3.207813083686546e-07, 'grow_policy': 'depthwise'}. Best is trial 38 with value: 0.31240456193960203.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:18,465]\u001b[0m Trial 46 finished with value: 0.4186498414817302 and parameters: {'booster': 'gbtree', 'lambda': 0.0002132634214802493, 'alpha': 0.23651088914079846, 'subsample': 0.301405931900049, 'colsample_bytree': 0.7396157378260936, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.1800210321278157, 'gamma': 8.775563987929953e-08, 'grow_policy': 'depthwise'}. Best is trial 38 with value: 0.31240456193960203.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:18,743]\u001b[0m Trial 47 finished with value: 0.7890625084606917 and parameters: {'booster': 'gbtree', 'lambda': 6.152282849644136e-06, 'alpha': 0.15864615510089689, 'subsample': 0.2463526091330575, 'colsample_bytree': 0.8384732079614099, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.0040852573142725074, 'gamma': 6.503830453301025e-07, 'grow_policy': 'depthwise'}. Best is trial 38 with value: 0.31240456193960203.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:19,074]\u001b[0m Trial 48 finished with value: 0.37361423172890973 and parameters: {'booster': 'gbtree', 'lambda': 3.7406298148064547e-05, 'alpha': 0.08363336305927649, 'subsample': 0.34134260186581583, 'colsample_bytree': 0.8952757345331186, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.14583429517512692, 'gamma': 4.938123832307119e-08, 'grow_policy': 'depthwise'}. Best is trial 38 with value: 0.31240456193960203.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:19,362]\u001b[0m Trial 49 finished with value: 1.2121593002356812 and parameters: {'booster': 'gbtree', 'lambda': 1.799084311345828e-06, 'alpha': 0.44189191410062995, 'subsample': 0.3785144373018556, 'colsample_bytree': 0.7407418851539819, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.00027484962607956994, 'gamma': 6.041355741909906e-07, 'grow_policy': 'depthwise'}. Best is trial 38 with value: 0.31240456193960203.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:10:19,659]\u001b[0m Trial 50 finished with value: 0.3826159872091 and parameters: {'booster': 'gbtree', 'lambda': 2.1561356705973284e-05, 'alpha': 0.032888084839539006, 'subsample': 0.24826293500611393, 'colsample_bytree': 0.9809192546276545, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.015863418751911783, 'gamma': 1.3060894650625625e-08, 'grow_policy': 'depthwise'}. Best is trial 38 with value: 0.31240456193960203.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:19,981]\u001b[0m Trial 51 finished with value: 0.3537021675973082 and parameters: {'booster': 'gbtree', 'lambda': 5.612555489183138e-06, 'alpha': 0.3880113732013199, 'subsample': 0.31562878644318915, 'colsample_bytree': 0.9276799451100359, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.10242390525721623, 'gamma': 1.5633074936078473e-07, 'grow_policy': 'depthwise'}. Best is trial 38 with value: 0.31240456193960203.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:20,274]\u001b[0m Trial 52 finished with value: 0.3146510645981623 and parameters: {'booster': 'gbtree', 'lambda': 1.4316493747709927e-05, 'alpha': 0.5625485447083194, 'subsample': 0.27918838759112347, 'colsample_bytree': 0.8018917239663691, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.04931443092862848, 'gamma': 1.5016272996368267e-06, 'grow_policy': 'depthwise'}. Best is trial 38 with value: 0.31240456193960203.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:20,579]\u001b[0m Trial 53 finished with value: 0.5352466138426198 and parameters: {'booster': 'gbtree', 'lambda': 7.599876169821818e-05, 'alpha': 0.17050820212246526, 'subsample': 0.27015855186090915, 'colsample_bytree': 0.8042289587110986, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.24361215716389878, 'gamma': 1.5641293989737985e-06, 'grow_policy': 'depthwise'}. Best is trial 38 with value: 0.31240456193960203.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:20,829]\u001b[0m Trial 54 finished with value: 0.4386318187924958 and parameters: {'booster': 'gbtree', 'lambda': 0.00025019313539198046, 'alpha': 0.9548066855035755, 'subsample': 0.20163967483168888, 'colsample_bytree': 0.6899122444632276, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.0149684796166256, 'gamma': 1.1932538718583357e-06, 'grow_policy': 'depthwise'}. Best is trial 38 with value: 0.31240456193960203.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:21,101]\u001b[0m Trial 55 finished with value: 0.32100843104233434 and parameters: {'booster': 'gbtree', 'lambda': 1.5356171551537215e-06, 'alpha': 0.07705702328602274, 'subsample': 0.22920030825859727, 'colsample_bytree': 0.7663476077765867, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.04167430963577397, 'gamma': 1.1226298475693367e-07, 'grow_policy': 'depthwise'}. Best is trial 38 with value: 0.31240456193960203.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:21,355]\u001b[0m Trial 56 finished with value: 1.1309568095753888 and parameters: {'booster': 'gbtree', 'lambda': 1.363417250441042e-06, 'alpha': 0.07909592225883447, 'subsample': 0.2484335517367902, 'colsample_bytree': 0.7627778345094279, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.000835637792877667, 'gamma': 4.972867080189124e-08, 'grow_policy': 'depthwise'}. Best is trial 38 with value: 0.31240456193960203.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:21,643]\u001b[0m Trial 57 finished with value: 0.6358052399790393 and parameters: {'booster': 'gbtree', 'lambda': 3.754006948377741e-07, 'alpha': 0.031995277972298446, 'subsample': 0.3327944032347497, 'colsample_bytree': 0.637226718366365, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.006465439299616832, 'gamma': 7.340151600351651e-08, 'grow_policy': 'depthwise'}. Best is trial 38 with value: 0.31240456193960203.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:21,948]\u001b[0m Trial 58 finished with value: 0.3118999834164984 and parameters: {'booster': 'gbtree', 'lambda': 0.002430475631278782, 'alpha': 0.06481134812353337, 'subsample': 0.36939499901343814, 'colsample_bytree': 0.7248822546651389, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.03443408461757876, 'gamma': 6.083086874845568e-06, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.3118999834164984.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:22,274]\u001b[0m Trial 59 finished with value: 0.4933717983968074 and parameters: {'booster': 'gbtree', 'lambda': 0.0037562066814974143, 'alpha': 0.1965922579090597, 'subsample': 0.42132736387338565, 'colsample_bytree': 0.7311623254925869, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.3265632379400919, 'gamma': 1.1916376996349703e-05, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.3118999834164984.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:22,573]\u001b[0m Trial 60 finished with value: 1.0867383286506447 and parameters: {'booster': 'gbtree', 'lambda': 0.0018317503536269448, 'alpha': 0.07963621617045519, 'subsample': 0.3810771899933648, 'colsample_bytree': 0.6537589518393206, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.0011637492966076917, 'gamma': 4.460954147071639e-05, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.3118999834164984.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:22,850]\u001b[0m Trial 61 finished with value: 0.3287790029157329 and parameters: {'booster': 'gbtree', 'lambda': 1.754509164832613e-07, 'alpha': 0.30942209071906474, 'subsample': 0.27576636356919604, 'colsample_bytree': 0.7066377765642591, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.038059865176563096, 'gamma': 4.28773755974724e-06, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.3118999834164984.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:23,165]\u001b[0m Trial 62 finished with value: 0.3309904948752577 and parameters: {'booster': 'gbtree', 'lambda': 5.598296805278384e-05, 'alpha': 0.47653487366902036, 'subsample': 0.23274439505206485, 'colsample_bytree': 0.7781234482065065, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.029945979514801983, 'gamma': 7.972201691376158e-07, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.3118999834164984.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:23,467]\u001b[0m Trial 63 finished with value: 0.548357422275274 and parameters: {'booster': 'gbtree', 'lambda': 0.0014987941596700104, 'alpha': 0.049982357198898944, 'subsample': 0.3028757339619803, 'colsample_bytree': 0.710645960516352, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.008486654286998942, 'gamma': 3.1760596929642914e-06, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.3118999834164984.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:23,754]\u001b[0m Trial 64 finished with value: 0.44352588991696495 and parameters: {'booster': 'gbtree', 'lambda': 9.627498967087484e-06, 'alpha': 0.2715320878313112, 'subsample': 0.34422371549340014, 'colsample_bytree': 0.8767512848173802, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.308415646297969, 'gamma': 0.0001376968208420891, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.3118999834164984.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:24,055]\u001b[0m Trial 65 finished with value: 0.3415515260143571 and parameters: {'booster': 'gbtree', 'lambda': 1.0286226068165457e-07, 'alpha': 0.01970721526578125, 'subsample': 0.2771542485081455, 'colsample_bytree': 0.8132837470211176, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.0875346325515875, 'gamma': 3.663398873512527e-07, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.3118999834164984.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:25,601]\u001b[0m Trial 66 finished with value: 0.7829616637941039 and parameters: {'booster': 'dart', 'lambda': 0.012349139384366615, 'alpha': 0.1286556094122799, 'subsample': 0.22645560388889746, 'colsample_bytree': 0.8214122629769137, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.004245833942733095, 'gamma': 3.059067632257044e-08, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 2.3427902346145037e-05, 'skip_drop': 1.4443311716852026e-08}. Best is trial 58 with value: 0.3118999834164984.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:25,874]\u001b[0m Trial 67 finished with value: 0.32556229639205037 and parameters: {'booster': 'gbtree', 'lambda': 2.6317261429030844e-06, 'alpha': 0.5733541224711529, 'subsample': 0.31894504490000347, 'colsample_bytree': 0.7624325263243774, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.029422947140673367, 'gamma': 2.491409724413864e-06, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.3118999834164984.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:26,168]\u001b[0m Trial 68 finished with value: 1.024988044526534 and parameters: {'booster': 'gbtree', 'lambda': 0.00034748095403699833, 'alpha': 0.0643722601246654, 'subsample': 0.35860459057451854, 'colsample_bytree': 0.6535778643069196, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.5200960172723466, 'gamma': 6.780758597492818e-06, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.3118999834164984.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:10:26,519]\u001b[0m Trial 69 finished with value: 0.32960971423532187 and parameters: {'booster': 'gbtree', 'lambda': 0.00011829928152385608, 'alpha': 0.002673545052359346, 'subsample': 0.45580660014144364, 'colsample_bytree': 0.7245319378373886, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.09967864408115368, 'gamma': 1.315761393177819e-07, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.3118999834164984.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:26,874]\u001b[0m Trial 70 finished with value: 0.3434257997820091 and parameters: {'booster': 'gbtree', 'lambda': 1.0259621506355871e-08, 'alpha': 1.0059415923965358e-06, 'subsample': 0.40272519047608213, 'colsample_bytree': 0.914242942621355, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.01922031601646864, 'gamma': 1.2728050598229575e-06, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.3118999834164984.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:27,140]\u001b[0m Trial 71 finished with value: 0.32777570954222174 and parameters: {'booster': 'gbtree', 'lambda': 2.4599363104207545e-06, 'alpha': 0.6236989371191801, 'subsample': 0.28626760132055823, 'colsample_bytree': 0.7591166855133353, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.03262221912495321, 'gamma': 2.6958829126133895e-05, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.3118999834164984.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:27,391]\u001b[0m Trial 72 finished with value: 0.34857957516773513 and parameters: {'booster': 'gbtree', 'lambda': 2.238487297912357e-05, 'alpha': 0.25984404298254105, 'subsample': 0.23374001373921643, 'colsample_bytree': 0.7795910729336051, 'max_depth': 7, 'min_child_weight': 6, 'eta': 0.02013260336994326, 'gamma': 2.5955676068616944e-06, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.3118999834164984.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:27,677]\u001b[0m Trial 73 finished with value: 0.32148215972429256 and parameters: {'booster': 'gbtree', 'lambda': 8.325199264216346e-07, 'alpha': 4.341496481080795e-05, 'subsample': 0.3277789515796229, 'colsample_bytree': 0.683295390815557, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.06983428138752443, 'gamma': 0.00013402796740032784, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.3118999834164984.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:27,953]\u001b[0m Trial 74 finished with value: 0.3438654868221211 and parameters: {'booster': 'gbtree', 'lambda': 2.6879085862293043e-08, 'alpha': 7.7051437373217e-06, 'subsample': 0.2662812963450617, 'colsample_bytree': 0.7003839099243181, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.09740896514893253, 'gamma': 0.00018306752221444955, 'grow_policy': 'lossguide'}. Best is trial 58 with value: 0.3118999834164984.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:29,446]\u001b[0m Trial 75 finished with value: 1.8228471643885746 and parameters: {'booster': 'dart', 'lambda': 8.352551698802381e-07, 'alpha': 3.280787024463243e-05, 'subsample': 0.3624188841203095, 'colsample_bytree': 0.5808528125046245, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.6366332912536194, 'gamma': 0.00042279609971805545, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.542100244331922e-08, 'skip_drop': 0.0019544379258988947}. Best is trial 58 with value: 0.3118999834164984.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:29,700]\u001b[0m Trial 76 finished with value: 1.254444963532757 and parameters: {'booster': 'gbtree', 'lambda': 0.0009328128412690157, 'alpha': 0.00021093648591589232, 'subsample': 0.22808903632805072, 'colsample_bytree': 0.6751354216146326, 'max_depth': 9, 'min_child_weight': 8, 'eta': 9.07153525761218e-08, 'gamma': 1.9881826555494877e-08, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.3118999834164984.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:29,995]\u001b[0m Trial 77 finished with value: 0.5522202435791147 and parameters: {'booster': 'gbtree', 'lambda': 1.2745281847638541e-05, 'alpha': 7.217471549539807e-05, 'subsample': 0.2889984328364675, 'colsample_bytree': 0.8612444657842773, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.00816654108027021, 'gamma': 4.5863128056322837e-07, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.3118999834164984.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:30,264]\u001b[0m Trial 78 finished with value: 0.9376072800201616 and parameters: {'booster': 'gbtree', 'lambda': 4.9102750026343e-05, 'alpha': 2.9338357467422134e-05, 'subsample': 0.2540980556055383, 'colsample_bytree': 0.600083536600751, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.002480525609888421, 'gamma': 0.00044521828063041224, 'grow_policy': 'lossguide'}. Best is trial 58 with value: 0.3118999834164984.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:30,546]\u001b[0m Trial 79 finished with value: 0.32270579413138945 and parameters: {'booster': 'gbtree', 'lambda': 2.0697320998209247e-05, 'alpha': 0.028643252624951078, 'subsample': 0.32542825248064966, 'colsample_bytree': 0.6450728712451986, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.056389267924454395, 'gamma': 1.3170201062471166e-07, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.3118999834164984.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:30,780]\u001b[0m Trial 80 finished with value: 0.33854290567556655 and parameters: {'booster': 'gbtree', 'lambda': 0.00010781729373891454, 'alpha': 0.02322921113831768, 'subsample': 0.4607236968373669, 'colsample_bytree': 0.6185894496556692, 'max_depth': 5, 'min_child_weight': 5, 'eta': 0.07510379351837067, 'gamma': 1.0513490075127994e-07, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.3118999834164984.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:31,061]\u001b[0m Trial 81 finished with value: 0.3096598746267562 and parameters: {'booster': 'gbtree', 'lambda': 1.3022196612148417e-06, 'alpha': 0.009116120994039254, 'subsample': 0.32264386738647755, 'colsample_bytree': 0.6479882205933528, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.049540661968772354, 'gamma': 1.8847909346386234e-07, 'grow_policy': 'depthwise'}. Best is trial 81 with value: 0.3096598746267562.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:31,342]\u001b[0m Trial 82 finished with value: 0.4489612410762394 and parameters: {'booster': 'gbtree', 'lambda': 1.287472181285006e-06, 'alpha': 0.0006639861311358796, 'subsample': 0.3239850966685966, 'colsample_bytree': 0.6566701788053795, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.2123954508200934, 'gamma': 2.2240094203109816e-07, 'grow_policy': 'depthwise'}. Best is trial 81 with value: 0.3096598746267562.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:31,632]\u001b[0m Trial 83 finished with value: 0.3395335139104707 and parameters: {'booster': 'gbtree', 'lambda': 6.275456250457171e-07, 'alpha': 0.012015730168912147, 'subsample': 0.39852778098574304, 'colsample_bytree': 0.6232272456964739, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.06540098082161439, 'gamma': 7.875257150789495e-08, 'grow_policy': 'depthwise'}. Best is trial 81 with value: 0.3096598746267562.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:31,921]\u001b[0m Trial 84 finished with value: 0.3185028879597276 and parameters: {'booster': 'gbtree', 'lambda': 6.404299968081804e-06, 'alpha': 0.00348443586879584, 'subsample': 0.3483693478015166, 'colsample_bytree': 0.6728019839811528, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.04237004561863525, 'gamma': 4.381762380515541e-07, 'grow_policy': 'depthwise'}. Best is trial 81 with value: 0.3096598746267562.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:32,210]\u001b[0m Trial 85 finished with value: 0.37413353294663526 and parameters: {'booster': 'gbtree', 'lambda': 6.35949718653312e-06, 'alpha': 0.004226040428275961, 'subsample': 0.35649150656334616, 'colsample_bytree': 0.6834715358787595, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.15349852116133605, 'gamma': 9.683983375522809e-07, 'grow_policy': 'depthwise'}. Best is trial 81 with value: 0.3096598746267562.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:33,713]\u001b[0m Trial 86 finished with value: 1.2539950119219032 and parameters: {'booster': 'dart', 'lambda': 1.3288275542841254e-06, 'alpha': 0.0037802038908323053, 'subsample': 0.40029858287633646, 'colsample_bytree': 0.6406287770971809, 'max_depth': 9, 'min_child_weight': 8, 'eta': 2.8587772991504707e-06, 'gamma': 4.5224925823320506e-07, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.001969852272553895, 'skip_drop': 8.805739666262713e-07}. Best is trial 81 with value: 0.3096598746267562.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:10:34,033]\u001b[0m Trial 87 finished with value: 1.2458004596700727 and parameters: {'booster': 'gbtree', 'lambda': 3.865300281271408e-07, 'alpha': 0.010683013079661779, 'subsample': 0.511033706176731, 'colsample_bytree': 0.5507116876541475, 'max_depth': 9, 'min_child_weight': 8, 'eta': 5.4343316976679155e-05, 'gamma': 3.0466089986502006e-08, 'grow_policy': 'lossguide'}. Best is trial 81 with value: 0.3096598746267562.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:34,323]\u001b[0m Trial 88 finished with value: 0.3799820094022762 and parameters: {'booster': 'gbtree', 'lambda': 6.865378624003065e-06, 'alpha': 0.00012619628059580294, 'subsample': 0.3103525125365977, 'colsample_bytree': 0.7159261442651775, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.01639588533622005, 'gamma': 1.4000733569616276e-05, 'grow_policy': 'depthwise'}. Best is trial 81 with value: 0.3096598746267562.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:34,708]\u001b[0m Trial 89 finished with value: 0.31086991980762224 and parameters: {'booster': 'gbtree', 'lambda': 2.84942056503867e-06, 'alpha': 0.0010453644824489359, 'subsample': 0.6532567935505496, 'colsample_bytree': 0.7439442121212544, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.05033764197360263, 'gamma': 6.758506904205695e-05, 'grow_policy': 'depthwise'}. Best is trial 81 with value: 0.3096598746267562.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:35,062]\u001b[0m Trial 90 finished with value: 0.6516316914947188 and parameters: {'booster': 'gbtree', 'lambda': 3.6030080525142587e-06, 'alpha': 0.0013425389619821412, 'subsample': 0.5415563538806452, 'colsample_bytree': 0.7367461917022929, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.005786816720243455, 'gamma': 6.107373668739392e-05, 'grow_policy': 'depthwise'}. Best is trial 81 with value: 0.3096598746267562.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:35,264]\u001b[0m Trial 91 finished with value: 0.3308597472595813 and parameters: {'booster': 'gbtree', 'lambda': 1.927545199386363e-06, 'alpha': 0.007060889450131247, 'subsample': 0.6605741418097513, 'colsample_bytree': 0.6644178990697676, 'max_depth': 3, 'min_child_weight': 10, 'eta': 0.054382068200682754, 'gamma': 0.001595301733801942, 'grow_policy': 'depthwise'}. Best is trial 81 with value: 0.3096598746267562.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:35,552]\u001b[0m Trial 92 finished with value: 0.3252188339427222 and parameters: {'booster': 'gbtree', 'lambda': 1.0142012177398543e-05, 'alpha': 0.0020762887253520804, 'subsample': 0.33912571898003546, 'colsample_bytree': 0.6888145952850948, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.03581258571803918, 'gamma': 0.0391224392972026, 'grow_policy': 'depthwise'}. Best is trial 81 with value: 0.3096598746267562.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:35,858]\u001b[0m Trial 93 finished with value: 0.34241840829859993 and parameters: {'booster': 'gbtree', 'lambda': 3.3788383188994444e-06, 'alpha': 0.02638646813122045, 'subsample': 0.37006958549782043, 'colsample_bytree': 0.7425415036985656, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.14184560584819916, 'gamma': 2.19547099836592e-07, 'grow_policy': 'depthwise'}. Best is trial 81 with value: 0.3096598746267562.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:36,207]\u001b[0m Trial 94 finished with value: 0.45483355434448997 and parameters: {'booster': 'gbtree', 'lambda': 8.013073937554317e-07, 'alpha': 0.0009175729793178404, 'subsample': 0.6382665765814655, 'colsample_bytree': 0.6135444980295855, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.011020448155562922, 'gamma': 0.00032017257140832373, 'grow_policy': 'depthwise'}. Best is trial 81 with value: 0.3096598746267562.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:36,560]\u001b[0m A new study created in memory with name: no-name-4766a015-dbfd-4b28-a3a8-e2a55775d976\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:37,031]\u001b[0m Trial 0 finished with value: 0.9775652039315842 and parameters: {'booster': 'gbtree', 'lambda': 0.19231689477299616, 'alpha': 0.10029256084772614, 'subsample': 0.9817280181209955, 'colsample_bytree': 0.8225279182268757, 'max_depth': 3, 'min_child_weight': 4, 'eta': 5.878146691938439e-08, 'gamma': 0.005282423428832082, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.9775652039315842.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:43,471]\u001b[0m Trial 1 finished with value: 0.8700315146904504 and parameters: {'booster': 'dart', 'lambda': 0.05826111477081824, 'alpha': 1.0841102535548996e-05, 'subsample': 0.6616148801180404, 'colsample_bytree': 0.2437017976401756, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.00037150180271440904, 'gamma': 1.0359675250042614e-06, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 2.7915117550610184e-06, 'skip_drop': 0.3770942691072103}. Best is trial 0 with value: 0.9775652039315842.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:43,595]\u001b[0m Trial 2 finished with value: 0.7685013046314416 and parameters: {'booster': 'gblinear', 'lambda': 6.0870163584405846e-05, 'alpha': 0.5771165973878832, 'subsample': 0.8143792888156711, 'colsample_bytree': 0.5926257064564808}. Best is trial 0 with value: 0.9775652039315842.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:43,977]\u001b[0m Trial 3 finished with value: 0.9655533898822652 and parameters: {'booster': 'gbtree', 'lambda': 0.22421976505883126, 'alpha': 5.98633088598307e-08, 'subsample': 0.6781000436037177, 'colsample_bytree': 0.4822057483599383, 'max_depth': 3, 'min_child_weight': 3, 'eta': 3.835885836879828e-07, 'gamma': 0.007907376730177088, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.9775652039315842.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:50,697]\u001b[0m Trial 4 finished with value: 0.9680910845658413 and parameters: {'booster': 'dart', 'lambda': 0.6416073900984294, 'alpha': 4.152794911857439e-07, 'subsample': 0.9129629118827702, 'colsample_bytree': 0.46458937568227177, 'max_depth': 5, 'min_child_weight': 5, 'eta': 4.959434893624845e-07, 'gamma': 7.000097903897701e-05, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 2.9270690560625165e-05, 'skip_drop': 9.535745657275079e-05}. Best is trial 0 with value: 0.9775652039315842.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:51,292]\u001b[0m Trial 5 finished with value: 0.9775652039315842 and parameters: {'booster': 'gbtree', 'lambda': 0.9089079138479488, 'alpha': 1.8419243061704414e-08, 'subsample': 0.9574244060077304, 'colsample_bytree': 0.918952291357346, 'max_depth': 9, 'min_child_weight': 6, 'eta': 2.978698455338474e-07, 'gamma': 7.17684558220172e-08, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9775652039315842.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:51,745]\u001b[0m Trial 6 finished with value: 0.8852571774184725 and parameters: {'booster': 'gblinear', 'lambda': 0.15660818612794003, 'alpha': 1.0256612947426274e-06, 'subsample': 0.2282045271261323, 'colsample_bytree': 0.20178989013355536}. Best is trial 0 with value: 0.9775652039315842.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:52,217]\u001b[0m Trial 7 finished with value: 0.9727833230864025 and parameters: {'booster': 'gblinear', 'lambda': 0.0001293049283846137, 'alpha': 2.6322989200804304e-08, 'subsample': 0.2398513385135731, 'colsample_bytree': 0.4144245253915217}. Best is trial 0 with value: 0.9775652039315842.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:52,982]\u001b[0m Trial 8 finished with value: 0.9775652039315842 and parameters: {'booster': 'gbtree', 'lambda': 5.411026896548486e-08, 'alpha': 9.398075914706493e-07, 'subsample': 0.9128090856212434, 'colsample_bytree': 0.8741126713415035, 'max_depth': 7, 'min_child_weight': 2, 'eta': 7.255946439047084e-05, 'gamma': 0.15489666042464298, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.9775652039315842.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:53,121]\u001b[0m Trial 9 finished with value: 0.7685013046314416 and parameters: {'booster': 'gblinear', 'lambda': 0.053687607259575616, 'alpha': 0.8362402963732061, 'subsample': 0.33315928621123037, 'colsample_bytree': 0.9327061975700319}. Best is trial 0 with value: 0.9775652039315842.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:53,453]\u001b[0m Trial 10 finished with value: 0.9698495175113029 and parameters: {'booster': 'gbtree', 'lambda': 0.0005692627511218572, 'alpha': 0.009105200055903638, 'subsample': 0.4521821979919026, 'colsample_bytree': 0.7656964531048515, 'max_depth': 3, 'min_child_weight': 10, 'eta': 0.4100766109218733, 'gamma': 0.000780242336969575, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9775652039315842.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:10:54,132]\u001b[0m Trial 11 finished with value: 0.9747726009013251 and parameters: {'booster': 'gbtree', 'lambda': 0.0038743742149628412, 'alpha': 0.002130071056402652, 'subsample': 0.9829481971474688, 'colsample_bytree': 0.7539117112887559, 'max_depth': 9, 'min_child_weight': 6, 'eta': 1.7974688698232645e-08, 'gamma': 8.21428125299784e-08, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9775652039315842.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:54,824]\u001b[0m Trial 12 finished with value: 0.7685013046314416 and parameters: {'booster': 'gbtree', 'lambda': 3.0388818130822683e-06, 'alpha': 0.00013890106894622254, 'subsample': 0.7989369324190028, 'colsample_bytree': 0.9659800143699319, 'max_depth': 9, 'min_child_weight': 4, 'eta': 1.1519886166853602e-08, 'gamma': 1.589351070880551e-05, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9775652039315842.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:55,466]\u001b[0m Trial 13 finished with value: 0.9775652039315842 and parameters: {'booster': 'gbtree', 'lambda': 0.0061661845233214226, 'alpha': 0.028660480418101774, 'subsample': 0.9989052058244535, 'colsample_bytree': 0.7778243274899772, 'max_depth': 5, 'min_child_weight': 7, 'eta': 6.623553373961925e-06, 'gamma': 0.9151058392293683, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9775652039315842.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:56,042]\u001b[0m Trial 14 finished with value: 0.9620141636076528 and parameters: {'booster': 'gbtree', 'lambda': 0.008141222182313508, 'alpha': 3.178391575121674e-05, 'subsample': 0.5161676663542819, 'colsample_bytree': 0.8550041281916333, 'max_depth': 9, 'min_child_weight': 7, 'eta': 5.822625668079249e-07, 'gamma': 1.652970859785521e-08, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9775652039315842.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:56,619]\u001b[0m Trial 15 finished with value: 0.9775652039315842 and parameters: {'booster': 'gbtree', 'lambda': 0.832472099337969, 'alpha': 0.0003102467911733371, 'subsample': 0.8049096319336058, 'colsample_bytree': 0.6535285717801333, 'max_depth': 5, 'min_child_weight': 5, 'eta': 0.003956313206387975, 'gamma': 0.002625432810547876, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.9775652039315842.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:58,456]\u001b[0m Trial 16 finished with value: 0.9686600491687615 and parameters: {'booster': 'dart', 'lambda': 4.303699648623942e-06, 'alpha': 0.08216577428767527, 'subsample': 0.7229690169397878, 'colsample_bytree': 0.6574348500410271, 'max_depth': 7, 'min_child_weight': 8, 'eta': 1.259614118248453e-07, 'gamma': 1.8749095297764077e-06, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.8490929990064354, 'skip_drop': 1.4730805665326214e-08}. Best is trial 0 with value: 0.9775652039315842.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:59,020]\u001b[0m Trial 17 finished with value: 0.9775652039315842 and parameters: {'booster': 'gbtree', 'lambda': 0.006633127037287582, 'alpha': 0.01946953590114915, 'subsample': 0.8690319125886775, 'colsample_bytree': 0.7768607223456762, 'max_depth': 3, 'min_child_weight': 4, 'eta': 6.647332102808801e-06, 'gamma': 0.29064765702659645, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9775652039315842.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:10:59,708]\u001b[0m Trial 18 finished with value: 0.9751243484242016 and parameters: {'booster': 'gbtree', 'lambda': 5.1685231984421665e-08, 'alpha': 0.0003511887610756248, 'subsample': 0.7732350884426831, 'colsample_bytree': 0.6466471755700077, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.01334675464408213, 'gamma': 0.005105621435061718, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.9775652039315842.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:06,780]\u001b[0m Trial 19 finished with value: 0.9718544763030484 and parameters: {'booster': 'dart', 'lambda': 0.0007835394979287635, 'alpha': 0.003283962601039799, 'subsample': 0.5716969118372772, 'colsample_bytree': 0.5792682609712443, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.003013868100054261, 'gamma': 0.024826454994976297, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.2872922260893788e-08, 'skip_drop': 0.9758082546867052}. Best is trial 0 with value: 0.9775652039315842.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:07,397]\u001b[0m Trial 20 finished with value: 0.9775652039315842 and parameters: {'booster': 'gbtree', 'lambda': 0.021334866227975695, 'alpha': 0.11321532302748984, 'subsample': 0.8747372262583705, 'colsample_bytree': 0.9965502513361412, 'max_depth': 3, 'min_child_weight': 4, 'eta': 9.807116533055095e-06, 'gamma': 0.08407226035415898, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9775652039315842.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:08,006]\u001b[0m Trial 21 finished with value: 0.9781590963710646 and parameters: {'booster': 'gbtree', 'lambda': 0.1906780086955746, 'alpha': 0.0006795345328522867, 'subsample': 0.8505932672982272, 'colsample_bytree': 0.7013284011206278, 'max_depth': 5, 'min_child_weight': 5, 'eta': 0.022166064843961955, 'gamma': 0.0013000301306274396, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.9781590963710646.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:08,506]\u001b[0m Trial 22 finished with value: 0.9751243484242016 and parameters: {'booster': 'gbtree', 'lambda': 0.8042755089285137, 'alpha': 0.0003771271605259006, 'subsample': 0.8228510680445106, 'colsample_bytree': 0.71325918628431, 'max_depth': 5, 'min_child_weight': 5, 'eta': 0.08780835479209624, 'gamma': 0.0006496943548181632, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.9781590963710646.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:09,126]\u001b[0m Trial 23 finished with value: 0.9775652039315842 and parameters: {'booster': 'gbtree', 'lambda': 0.030670612546874153, 'alpha': 0.14164901064004323, 'subsample': 0.9027414339774184, 'colsample_bytree': 0.995469771472645, 'max_depth': 3, 'min_child_weight': 3, 'eta': 1.6115051687776425e-05, 'gamma': 0.03700387914328735, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.9781590963710646.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:09,672]\u001b[0m Trial 24 finished with value: 0.9775652039315842 and parameters: {'booster': 'gbtree', 'lambda': 0.017548718387225604, 'alpha': 0.10827996366790159, 'subsample': 0.863154692891242, 'colsample_bytree': 0.8519617575397179, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.0002989140141711184, 'gamma': 0.00026881606710740195, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.9781590963710646.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:11:10,684]\u001b[0m A new study created in memory with name: no-name-43523b97-67f7-4df4-b5da-518e1364423d\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:10,858]\u001b[0m Trial 0 finished with value: 0.16284036482935846 and parameters: {'booster': 'gbtree', 'lambda': 0.06903080780425642, 'alpha': 0.11013082606540268, 'subsample': 0.3509707683138661, 'colsample_bytree': 0.8636994799952531, 'max_depth': 3, 'min_child_weight': 9, 'eta': 0.019625962762835552, 'gamma': 5.165781275440173e-05, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.16284036482935846.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:10,983]\u001b[0m Trial 1 finished with value: 0.0009216415433032909 and parameters: {'booster': 'gblinear', 'lambda': 4.057708096274483e-06, 'alpha': 3.051580942998993e-07, 'subsample': 0.6714777887082396, 'colsample_bytree': 0.622572624064414}. Best is trial 1 with value: 0.0009216415433032909.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:12,402]\u001b[0m Trial 2 finished with value: 1.1060141677014694 and parameters: {'booster': 'dart', 'lambda': 0.009837568076212604, 'alpha': 0.0028930430125500063, 'subsample': 0.525597789145969, 'colsample_bytree': 0.7281787285278918, 'max_depth': 3, 'min_child_weight': 10, 'eta': 5.017798982662764e-05, 'gamma': 1.7632588888363673e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 6.965110185000063e-06, 'skip_drop': 4.464735334108053e-06}. Best is trial 1 with value: 0.0009216415433032909.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:11:12,807]\u001b[0m Trial 3 finished with value: 1.0399164434639039 and parameters: {'booster': 'gbtree', 'lambda': 1.956798627387352e-06, 'alpha': 0.00033649734849653095, 'subsample': 0.8001563079954821, 'colsample_bytree': 0.971219984192415, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.0003751176778405428, 'gamma': 1.643327518621459e-08, 'grow_policy': 'lossguide'}. Best is trial 1 with value: 0.0009216415433032909.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:14,223]\u001b[0m Trial 4 finished with value: 1.1139526939313147 and parameters: {'booster': 'dart', 'lambda': 4.037105374356975e-08, 'alpha': 0.0021971749200773417, 'subsample': 0.9382049277870779, 'colsample_bytree': 0.7883967553709847, 'max_depth': 3, 'min_child_weight': 9, 'eta': 2.057801487067516e-06, 'gamma': 9.702065789808156e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.07542637848818103, 'skip_drop': 0.9845732766894634}. Best is trial 1 with value: 0.0009216415433032909.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:14,452]\u001b[0m Trial 5 finished with value: 1.1142963728577695 and parameters: {'booster': 'gbtree', 'lambda': 7.319518074178876e-06, 'alpha': 0.17200123318405955, 'subsample': 0.20858752859385696, 'colsample_bytree': 0.8241301894440898, 'max_depth': 9, 'min_child_weight': 6, 'eta': 1.933808249782797e-08, 'gamma': 0.0024368714108169414, 'grow_policy': 'depthwise'}. Best is trial 1 with value: 0.0009216415433032909.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:14,574]\u001b[0m Trial 6 finished with value: 0.0005541661724689891 and parameters: {'booster': 'gblinear', 'lambda': 0.0009605889882283371, 'alpha': 6.461863069200562e-06, 'subsample': 0.25585825447975274, 'colsample_bytree': 0.6153550740350762}. Best is trial 6 with value: 0.0005541661724689891.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:15,636]\u001b[0m Trial 7 finished with value: 1.114139497173025 and parameters: {'booster': 'dart', 'lambda': 3.559732957560779e-08, 'alpha': 0.0018025484704662737, 'subsample': 0.9194480395040827, 'colsample_bytree': 0.26791212515086915, 'max_depth': 9, 'min_child_weight': 9, 'eta': 1.0578227074345103e-06, 'gamma': 0.0045781193577552216, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.37837026742286056, 'skip_drop': 7.371107762010028e-07}. Best is trial 6 with value: 0.0005541661724689891.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:15,730]\u001b[0m Trial 8 finished with value: 0.12556339541594413 and parameters: {'booster': 'gblinear', 'lambda': 1.4521382418766711e-05, 'alpha': 0.1470282534781156, 'subsample': 0.7469833015498537, 'colsample_bytree': 0.8437503591978124}. Best is trial 6 with value: 0.0005541661724689891.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:15,831]\u001b[0m Trial 9 finished with value: 0.020344352404419383 and parameters: {'booster': 'gblinear', 'lambda': 0.004221619252437466, 'alpha': 0.05626077220471368, 'subsample': 0.9313514303195782, 'colsample_bytree': 0.49201924008252895}. Best is trial 6 with value: 0.0005541661724689891.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:15,965]\u001b[0m Trial 10 finished with value: 0.22208713923735954 and parameters: {'booster': 'gblinear', 'lambda': 0.945471674490326, 'alpha': 1.1421852194300716e-06, 'subsample': 0.4661576673248775, 'colsample_bytree': 0.4316504313027135}. Best is trial 6 with value: 0.0005541661724689891.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:16,099]\u001b[0m Trial 11 finished with value: 0.0012610472832859623 and parameters: {'booster': 'gblinear', 'lambda': 0.00026461799188962824, 'alpha': 9.242769476401197e-08, 'subsample': 0.67048622474978, 'colsample_bytree': 0.5953940466162987}. Best is trial 6 with value: 0.0005541661724689891.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:16,233]\u001b[0m Trial 12 finished with value: 0.0005173208674435153 and parameters: {'booster': 'gblinear', 'lambda': 0.0001641804042610151, 'alpha': 6.305100669364321e-06, 'subsample': 0.2220676949896805, 'colsample_bytree': 0.6193667636892913}. Best is trial 12 with value: 0.0005173208674435153.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:16,369]\u001b[0m Trial 13 finished with value: 0.001041261522264926 and parameters: {'booster': 'gblinear', 'lambda': 0.0003292656493151497, 'alpha': 7.913442878757998e-06, 'subsample': 0.20208837018530806, 'colsample_bytree': 0.6560827947533926}. Best is trial 12 with value: 0.0005173208674435153.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:16,505]\u001b[0m Trial 14 finished with value: 0.0006537471309913797 and parameters: {'booster': 'gblinear', 'lambda': 0.0017676851821047785, 'alpha': 2.1674644590714297e-05, 'subsample': 0.3502156444039576, 'colsample_bytree': 0.4532198598771885}. Best is trial 12 with value: 0.0005173208674435153.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:16,642]\u001b[0m Trial 15 finished with value: 0.0008336844613554962 and parameters: {'booster': 'gblinear', 'lambda': 9.344083027308001e-05, 'alpha': 4.002600463356434e-06, 'subsample': 0.3275850519619989, 'colsample_bytree': 0.31924574759630736}. Best is trial 12 with value: 0.0005173208674435153.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:16,778]\u001b[0m Trial 16 finished with value: 0.0013120597114601703 and parameters: {'booster': 'gblinear', 'lambda': 5.350836201971219e-07, 'alpha': 1.1014921367516602e-08, 'subsample': 0.451307637250433, 'colsample_bytree': 0.5463891775783691}. Best is trial 12 with value: 0.0005173208674435153.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:16,913]\u001b[0m Trial 17 finished with value: 0.004856974779726758 and parameters: {'booster': 'gblinear', 'lambda': 0.02251354880285591, 'alpha': 6.656354154707089e-05, 'subsample': 0.3046789111089996, 'colsample_bytree': 0.7046271304403348}. Best is trial 12 with value: 0.0005173208674435153.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:17,110]\u001b[0m Trial 18 finished with value: 1.0773096987116735 and parameters: {'booster': 'gbtree', 'lambda': 4.015457515423079e-05, 'alpha': 0.00019574344273984553, 'subsample': 0.2669977250058787, 'colsample_bytree': 0.36269397676143605, 'max_depth': 5, 'min_child_weight': 2, 'eta': 0.5874882895744953, 'gamma': 0.1755364029426606, 'grow_policy': 'lossguide'}. Best is trial 12 with value: 0.0005173208674435153.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:18,580]\u001b[0m Trial 19 finished with value: 1.1142984781709486 and parameters: {'booster': 'dart', 'lambda': 0.0008373501164702918, 'alpha': 1.2862850876052604e-06, 'subsample': 0.4298685130098244, 'colsample_bytree': 0.20228040301014832, 'max_depth': 7, 'min_child_weight': 5, 'eta': 1.1204363513521335e-08, 'gamma': 0.5329680967405411, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 2.0148669496580332e-08, 'skip_drop': 0.01170635860823164}. Best is trial 12 with value: 0.0005173208674435153.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:18,718]\u001b[0m Trial 20 finished with value: 0.06453355295975086 and parameters: {'booster': 'gblinear', 'lambda': 0.1896819577326835, 'alpha': 5.821865746636824e-08, 'subsample': 0.3848817610990911, 'colsample_bytree': 0.5146750022491824}. Best is trial 12 with value: 0.0005173208674435153.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:18,854]\u001b[0m Trial 21 finished with value: 0.0005437364101901613 and parameters: {'booster': 'gblinear', 'lambda': 0.0013463593531294726, 'alpha': 2.7783768373436724e-05, 'subsample': 0.26509515561266905, 'colsample_bytree': 0.3984379998031228}. Best is trial 12 with value: 0.0005173208674435153.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:18,989]\u001b[0m Trial 22 finished with value: 0.0006900988799191655 and parameters: {'booster': 'gblinear', 'lambda': 0.0012978476727250868, 'alpha': 2.1200954486331058e-05, 'subsample': 0.2576334323959022, 'colsample_bytree': 0.5727310612931192}. Best is trial 12 with value: 0.0005173208674435153.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:19,125]\u001b[0m Trial 23 finished with value: 0.0006114062845864037 and parameters: {'booster': 'gblinear', 'lambda': 0.00014692399719141256, 'alpha': 2.1885247644184986e-06, 'subsample': 0.5473327800323226, 'colsample_bytree': 0.4030782521714957}. Best is trial 12 with value: 0.0005173208674435153.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:19,261]\u001b[0m Trial 24 finished with value: 0.0006717497969580259 and parameters: {'booster': 'gblinear', 'lambda': 2.9865127717952523e-05, 'alpha': 3.182567169314718e-05, 'subsample': 0.26104613103862356, 'colsample_bytree': 0.6834970573497183}. Best is trial 12 with value: 0.0005173208674435153.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:11:19,397]\u001b[0m Trial 25 finished with value: 0.001485754137778978 and parameters: {'booster': 'gblinear', 'lambda': 0.008355975885989528, 'alpha': 3.530110264429049e-07, 'subsample': 0.20137220143047577, 'colsample_bytree': 0.7437071440840072}. Best is trial 12 with value: 0.0005173208674435153.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:19,531]\u001b[0m Trial 26 finished with value: 0.00034136216704582227 and parameters: {'booster': 'gblinear', 'lambda': 0.0006976641135589037, 'alpha': 0.0005624348917199254, 'subsample': 0.39993837156533557, 'colsample_bytree': 0.4869557236106606}. Best is trial 26 with value: 0.00034136216704582227.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:20,911]\u001b[0m Trial 27 finished with value: 1.1107329121491025 and parameters: {'booster': 'dart', 'lambda': 5.566620842241375e-07, 'alpha': 0.014764275635985187, 'subsample': 0.40581455225277385, 'colsample_bytree': 0.35137028215222205, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.7605794142087551, 'gamma': 6.436731136742883e-06, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.0002983748487255687, 'skip_drop': 2.8040610912996112e-08}. Best is trial 26 with value: 0.00034136216704582227.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:21,180]\u001b[0m Trial 28 finished with value: 0.9066176801717646 and parameters: {'booster': 'gbtree', 'lambda': 0.035593220714021725, 'alpha': 0.0004815049121088962, 'subsample': 0.511418475388856, 'colsample_bytree': 0.493048971273893, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.001302252045065283, 'gamma': 0.0036786693090841414, 'grow_policy': 'lossguide'}. Best is trial 26 with value: 0.00034136216704582227.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:21,311]\u001b[0m Trial 29 finished with value: 0.029447354408343843 and parameters: {'booster': 'gblinear', 'lambda': 0.08803237824436956, 'alpha': 7.757242441331888e-05, 'subsample': 0.36616736835874336, 'colsample_bytree': 0.2837978327335191}. Best is trial 26 with value: 0.00034136216704582227.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:21,555]\u001b[0m Trial 30 finished with value: 1.1130912638015364 and parameters: {'booster': 'gbtree', 'lambda': 5.8668381544082754e-05, 'alpha': 0.02269493425051602, 'subsample': 0.3110415507200274, 'colsample_bytree': 0.9509887153292635, 'max_depth': 5, 'min_child_weight': 7, 'eta': 6.36608542887774e-06, 'gamma': 4.745252350438138e-07, 'grow_policy': 'depthwise'}. Best is trial 26 with value: 0.00034136216704582227.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:21,685]\u001b[0m Trial 31 finished with value: 0.0006467982938989819 and parameters: {'booster': 'gblinear', 'lambda': 0.00043154982671073935, 'alpha': 7.427312456606319e-06, 'subsample': 0.2722143552173195, 'colsample_bytree': 0.6254780942324626}. Best is trial 26 with value: 0.00034136216704582227.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:21,815]\u001b[0m Trial 32 finished with value: 0.0003644526005618868 and parameters: {'booster': 'gblinear', 'lambda': 0.0012264621651372095, 'alpha': 0.0008484483776660789, 'subsample': 0.3144383009799585, 'colsample_bytree': 0.5334351142942865}. Best is trial 26 with value: 0.00034136216704582227.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:21,944]\u001b[0m Trial 33 finished with value: 0.00046953126201087456 and parameters: {'booster': 'gblinear', 'lambda': 0.0029100065073974926, 'alpha': 0.0009023133334120704, 'subsample': 0.5803916443790851, 'colsample_bytree': 0.5381086936580977}. Best is trial 26 with value: 0.00034136216704582227.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:22,044]\u001b[0m Trial 34 finished with value: 0.932801394179033 and parameters: {'booster': 'gblinear', 'lambda': 0.003097179822525483, 'alpha': 0.7834315464253886, 'subsample': 0.5994568092191742, 'colsample_bytree': 0.566204541409944}. Best is trial 26 with value: 0.00034136216704582227.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:22,176]\u001b[0m Trial 35 finished with value: 0.0016576988082483797 and parameters: {'booster': 'gblinear', 'lambda': 0.01182477402550094, 'alpha': 0.0007746383563375327, 'subsample': 0.6213372519495133, 'colsample_bytree': 0.5160413486430677}. Best is trial 26 with value: 0.00034136216704582227.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:23,744]\u001b[0m Trial 36 finished with value: 0.39184725029339473 and parameters: {'booster': 'dart', 'lambda': 0.005486408095262315, 'alpha': 0.012034511564796666, 'subsample': 0.791822299192267, 'colsample_bytree': 0.4791203622174708, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.007320151725384558, 'gamma': 0.00026738271889924816, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 2.787637310046188e-08, 'skip_drop': 0.0009311634997479879}. Best is trial 26 with value: 0.00034136216704582227.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:23,875]\u001b[0m Trial 37 finished with value: 0.0001444658169495687 and parameters: {'booster': 'gblinear', 'lambda': 0.0001285220480850324, 'alpha': 0.004336592864133312, 'subsample': 0.4906164105201497, 'colsample_bytree': 0.6498221018759457}. Best is trial 37 with value: 0.0001444658169495687.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:24,136]\u001b[0m Trial 38 finished with value: 1.1142656092419445 and parameters: {'booster': 'gbtree', 'lambda': 3.3715879898649807e-06, 'alpha': 0.004694807797090432, 'subsample': 0.4923637062907772, 'colsample_bytree': 0.7753391687101855, 'max_depth': 5, 'min_child_weight': 3, 'eta': 1.7816101365159288e-07, 'gamma': 0.05484861593877625, 'grow_policy': 'depthwise'}. Best is trial 37 with value: 0.0001444658169495687.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:24,266]\u001b[0m Trial 39 finished with value: 0.000285573910116273 and parameters: {'booster': 'gblinear', 'lambda': 1.1667067119141573e-05, 'alpha': 0.0010510335298593834, 'subsample': 0.5534643845553239, 'colsample_bytree': 0.6716069807244576}. Best is trial 37 with value: 0.0001444658169495687.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:24,393]\u001b[0m Trial 40 finished with value: 0.00013052179042651055 and parameters: {'booster': 'gblinear', 'lambda': 1.071386436439893e-06, 'alpha': 0.004052642770578576, 'subsample': 0.558826332492039, 'colsample_bytree': 0.9163639197474923}. Best is trial 40 with value: 0.00013052179042651055.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:24,522]\u001b[0m Trial 41 finished with value: 0.00017386849439346183 and parameters: {'booster': 'gblinear', 'lambda': 2.3007900481115172e-07, 'alpha': 0.004834666604686988, 'subsample': 0.5261137459534857, 'colsample_bytree': 0.9140939089316693}. Best is trial 40 with value: 0.00013052179042651055.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:24,651]\u001b[0m Trial 42 finished with value: 0.00023225359049851394 and parameters: {'booster': 'gblinear', 'lambda': 3.3590807543515566e-07, 'alpha': 0.0057298179645092736, 'subsample': 0.6401739928752862, 'colsample_bytree': 0.9111179056052322}. Best is trial 40 with value: 0.00013052179042651055.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:24,781]\u001b[0m Trial 43 finished with value: 0.00016454186414444817 and parameters: {'booster': 'gblinear', 'lambda': 1.5051494517070767e-07, 'alpha': 0.005011471189655884, 'subsample': 0.6577958712271273, 'colsample_bytree': 0.9115909029638976}. Best is trial 40 with value: 0.00013052179042651055.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:24,911]\u001b[0m Trial 44 finished with value: 0.00017614697298524686 and parameters: {'booster': 'gblinear', 'lambda': 1.3704433799993519e-08, 'alpha': 0.004344155896821407, 'subsample': 0.6586006974798071, 'colsample_bytree': 0.901114547356241}. Best is trial 40 with value: 0.00013052179042651055.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:26,448]\u001b[0m Trial 45 finished with value: 1.1066197035282872 and parameters: {'booster': 'dart', 'lambda': 1.92460411417147e-08, 'alpha': 0.0031287343556918043, 'subsample': 0.7076486813413121, 'colsample_bytree': 0.9954451068461381, 'max_depth': 7, 'min_child_weight': 7, 'eta': 3.703467722190467e-05, 'gamma': 2.42794188383446e-07, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.00032041581663864885, 'skip_drop': 0.8534146579580468}. Best is trial 40 with value: 0.00013052179042651055.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:26,564]\u001b[0m Trial 46 finished with value: 0.021606339423823524 and parameters: {'booster': 'gblinear', 'lambda': 1.0381874770890169e-07, 'alpha': 0.060992882714324015, 'subsample': 0.7088977818630792, 'colsample_bytree': 0.8822297998495419}. Best is trial 40 with value: 0.00013052179042651055.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:11:26,682]\u001b[0m Trial 47 finished with value: 0.006941988774045704 and parameters: {'booster': 'gblinear', 'lambda': 1.079845073893427e-08, 'alpha': 0.03457235648517929, 'subsample': 0.8498973610097056, 'colsample_bytree': 0.8146523309978344}. Best is trial 40 with value: 0.00013052179042651055.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:26,809]\u001b[0m Trial 48 finished with value: 0.00038486244927925706 and parameters: {'booster': 'gblinear', 'lambda': 8.705647931585743e-08, 'alpha': 0.008136000907751009, 'subsample': 0.6702449358379621, 'colsample_bytree': 0.9334809563065268}. Best is trial 40 with value: 0.00013052179042651055.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:26,940]\u001b[0m Trial 49 finished with value: 0.00014647574223090477 and parameters: {'booster': 'gblinear', 'lambda': 1.4471873238064223e-06, 'alpha': 0.00203122867331904, 'subsample': 0.9926774161608778, 'colsample_bytree': 0.859764467842826}. Best is trial 40 with value: 0.00013052179042651055.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:27,153]\u001b[0m Trial 50 finished with value: 0.16338420674220858 and parameters: {'booster': 'gbtree', 'lambda': 1.5687149099202872e-06, 'alpha': 0.00024019258148516012, 'subsample': 0.9838791410985624, 'colsample_bytree': 0.8515392078101242, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.020057320183278687, 'gamma': 5.008239956906628e-05, 'grow_policy': 'lossguide'}. Best is trial 40 with value: 0.00013052179042651055.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:27,285]\u001b[0m Trial 51 finished with value: 0.0003204715815461754 and parameters: {'booster': 'gblinear', 'lambda': 1.3345341622465288e-07, 'alpha': 0.0018494455693472908, 'subsample': 0.8716632044115946, 'colsample_bytree': 0.8772396042400714}. Best is trial 40 with value: 0.00013052179042651055.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:27,388]\u001b[0m Trial 52 finished with value: 0.48888613258647795 and parameters: {'booster': 'gblinear', 'lambda': 4.407036276450611e-08, 'alpha': 0.35294509274621655, 'subsample': 0.5679960862287403, 'colsample_bytree': 0.9130013807904291}. Best is trial 40 with value: 0.00013052179042651055.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:27,517]\u001b[0m Trial 53 finished with value: 9.10944283626567e-05 and parameters: {'booster': 'gblinear', 'lambda': 1.202872595334921e-06, 'alpha': 0.002764066171429843, 'subsample': 0.4780579137327514, 'colsample_bytree': 0.9783972883368236}. Best is trial 53 with value: 9.10944283626567e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:27,649]\u001b[0m Trial 54 finished with value: 0.0002153049193330931 and parameters: {'booster': 'gblinear', 'lambda': 1.7821278044480052e-06, 'alpha': 0.0019925726217695696, 'subsample': 0.49194752459534663, 'colsample_bytree': 0.9888862627607939}. Best is trial 53 with value: 9.10944283626567e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:27,758]\u001b[0m Trial 55 finished with value: 0.06825067124081931 and parameters: {'booster': 'gblinear', 'lambda': 8.258219815422952e-07, 'alpha': 0.10840295950328256, 'subsample': 0.4424823613925314, 'colsample_bytree': 0.9489585259480129}. Best is trial 53 with value: 9.10944283626567e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:27,883]\u001b[0m Trial 56 finished with value: 0.0007569369147530323 and parameters: {'booster': 'gblinear', 'lambda': 5.268239704050725e-06, 'alpha': 0.011410363631409287, 'subsample': 0.52538081775586, 'colsample_bytree': 0.8214443802913991}. Best is trial 53 with value: 9.10944283626567e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:29,467]\u001b[0m Trial 57 finished with value: 1.11426422231835 and parameters: {'booster': 'dart', 'lambda': 2.43530177693658e-07, 'alpha': 0.021943975375504368, 'subsample': 0.46730744128638013, 'colsample_bytree': 0.7860995724036243, 'max_depth': 9, 'min_child_weight': 10, 'eta': 1.8918524715202302e-07, 'gamma': 0.04533283106287031, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 4.119995743515678e-06, 'skip_drop': 0.00015586303640486294}. Best is trial 53 with value: 9.10944283626567e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:29,618]\u001b[0m Trial 58 finished with value: 0.0006442726819817559 and parameters: {'booster': 'gblinear', 'lambda': 1.7663888653886487e-05, 'alpha': 0.000144275633795056, 'subsample': 0.5974856023777254, 'colsample_bytree': 0.9708530301889834}. Best is trial 53 with value: 9.10944283626567e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:29,761]\u001b[0m Trial 59 finished with value: 0.00029525105228659005 and parameters: {'booster': 'gblinear', 'lambda': 2.6863076757660213e-07, 'alpha': 0.0003237637888709013, 'subsample': 0.4897183655017308, 'colsample_bytree': 0.8519698642582939}. Best is trial 53 with value: 9.10944283626567e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:29,882]\u001b[0m Trial 60 finished with value: 0.020406945149854975 and parameters: {'booster': 'gblinear', 'lambda': 3.0730275947377644e-06, 'alpha': 0.05927375955397981, 'subsample': 0.5370594901384912, 'colsample_bytree': 0.9262489654095584}. Best is trial 53 with value: 9.10944283626567e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:30,017]\u001b[0m Trial 61 finished with value: 0.00013126690651915312 and parameters: {'booster': 'gblinear', 'lambda': 5.1102755138635764e-08, 'alpha': 0.004351930964473168, 'subsample': 0.6368620835558129, 'colsample_bytree': 0.8922261332821191}. Best is trial 53 with value: 9.10944283626567e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:30,155]\u001b[0m Trial 62 finished with value: 0.00013993186097605056 and parameters: {'booster': 'gblinear', 'lambda': 3.562897167784073e-08, 'alpha': 0.0024328274315637928, 'subsample': 0.7003369186774302, 'colsample_bytree': 0.8783668131241906}. Best is trial 53 with value: 9.10944283626567e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:30,292]\u001b[0m Trial 63 finished with value: 0.00020231410201588265 and parameters: {'booster': 'gblinear', 'lambda': 3.699374052965351e-08, 'alpha': 0.0014830157373546273, 'subsample': 0.7221039474053251, 'colsample_bytree': 0.7300959905686202}. Best is trial 53 with value: 9.10944283626567e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:30,426]\u001b[0m Trial 64 finished with value: 0.00010311382995910715 and parameters: {'booster': 'gblinear', 'lambda': 5.733362545419909e-08, 'alpha': 0.0030173187163882605, 'subsample': 0.7627728194357339, 'colsample_bytree': 0.8867782532735906}. Best is trial 53 with value: 9.10944283626567e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:30,560]\u001b[0m Trial 65 finished with value: 0.001843970551415647 and parameters: {'booster': 'gblinear', 'lambda': 6.254304053678581e-08, 'alpha': 0.00233599090507467, 'subsample': 0.7727749949081872, 'colsample_bytree': 0.8788280138929959}. Best is trial 53 with value: 9.10944283626567e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:30,703]\u001b[0m Trial 66 finished with value: 0.0017469302170824948 and parameters: {'booster': 'gblinear', 'lambda': 7.353518606175797e-07, 'alpha': 0.00042371717163949314, 'subsample': 0.8286446132343053, 'colsample_bytree': 0.9597069509429044}. Best is trial 53 with value: 9.10944283626567e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:30,830]\u001b[0m Trial 67 finished with value: 0.0005896546157650013 and parameters: {'booster': 'gblinear', 'lambda': 2.768221436681213e-08, 'alpha': 0.010075223936195836, 'subsample': 0.7441025783875941, 'colsample_bytree': 0.7537455386337992}. Best is trial 53 with value: 9.10944283626567e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:31,091]\u001b[0m Trial 68 finished with value: 0.04639366552400193 and parameters: {'booster': 'gbtree', 'lambda': 1.0632425597766057e-06, 'alpha': 0.02461770746377711, 'subsample': 0.9070995178646396, 'colsample_bytree': 0.8308389118028626, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.14338414840521535, 'gamma': 5.260042337120925e-06, 'grow_policy': 'lossguide'}. Best is trial 53 with value: 9.10944283626567e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:31,221]\u001b[0m Trial 69 finished with value: 7.500974366538848e-05 and parameters: {'booster': 'gblinear', 'lambda': 8.508642181634848e-06, 'alpha': 0.003064127817878802, 'subsample': 0.999831543422898, 'colsample_bytree': 0.8148332781983088}. Best is trial 69 with value: 7.500974366538848e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:31,351]\u001b[0m Trial 70 finished with value: 0.0003982946879931801 and parameters: {'booster': 'gblinear', 'lambda': 0.00015161698149579626, 'alpha': 0.008146578308704782, 'subsample': 0.6264430782627979, 'colsample_bytree': 0.8152838122024283}. Best is trial 69 with value: 7.500974366538848e-05.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:11:31,484]\u001b[0m Trial 71 finished with value: 9.91677053764071e-05 and parameters: {'booster': 'gblinear', 'lambda': 6.4820969414142906e-06, 'alpha': 0.0031409848756318243, 'subsample': 0.9678617310154979, 'colsample_bytree': 0.8680445945855644}. Best is trial 69 with value: 7.500974366538848e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:31,626]\u001b[0m Trial 72 finished with value: 9.330016919232937e-05 and parameters: {'booster': 'gblinear', 'lambda': 7.108392448155047e-06, 'alpha': 0.0034341518965270022, 'subsample': 0.9583774994284571, 'colsample_bytree': 0.8939529719998184}. Best is trial 69 with value: 7.500974366538848e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:31,760]\u001b[0m Trial 73 finished with value: 0.00013482953272635095 and parameters: {'booster': 'gblinear', 'lambda': 7.650135972754106e-06, 'alpha': 0.0013346778177484768, 'subsample': 0.9601898531594527, 'colsample_bytree': 0.9502872446069093}. Best is trial 69 with value: 7.500974366538848e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:31,892]\u001b[0m Trial 74 finished with value: 0.0003411992495421742 and parameters: {'booster': 'gblinear', 'lambda': 1.10984199904921e-05, 'alpha': 0.0012013886749770717, 'subsample': 0.956776463492676, 'colsample_bytree': 0.9353385458571014}. Best is trial 69 with value: 7.500974366538848e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:33,481]\u001b[0m Trial 75 finished with value: 0.9837004041073881 and parameters: {'booster': 'dart', 'lambda': 7.373390031641093e-06, 'alpha': 0.0007011684467571731, 'subsample': 0.899955911247508, 'colsample_bytree': 0.9754276188873683, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.0006673620103001709, 'gamma': 0.000630248351132338, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.006502670273769838, 'skip_drop': 1.2046477626117918e-08}. Best is trial 69 with value: 7.500974366538848e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:33,607]\u001b[0m Trial 76 finished with value: 0.001575722954880977 and parameters: {'booster': 'gblinear', 'lambda': 2.909297791753027e-05, 'alpha': 0.016447906735386437, 'subsample': 0.9599954558850625, 'colsample_bytree': 0.9482411859878634}. Best is trial 69 with value: 7.500974366538848e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:33,735]\u001b[0m Trial 77 finished with value: 0.00035128407149718127 and parameters: {'booster': 'gblinear', 'lambda': 2.8949177298197427e-06, 'alpha': 0.007387917564278476, 'subsample': 0.9380996721156052, 'colsample_bytree': 0.8960368004639482}. Best is trial 69 with value: 7.500974366538848e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:33,855]\u001b[0m Trial 78 finished with value: 0.006570370908834441 and parameters: {'booster': 'gblinear', 'lambda': 5.90393403253258e-05, 'alpha': 0.033589952420253345, 'subsample': 0.8829931719232184, 'colsample_bytree': 0.9996135141183465}. Best is trial 69 with value: 7.500974366538848e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:33,986]\u001b[0m Trial 79 finished with value: 0.0005355012717396407 and parameters: {'booster': 'gblinear', 'lambda': 5.212591815377773e-06, 'alpha': 0.001271354207849061, 'subsample': 0.9992749396533988, 'colsample_bytree': 0.8377870931015048}. Best is trial 69 with value: 7.500974366538848e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:34,117]\u001b[0m Trial 80 finished with value: 9.137149514910385e-05 and parameters: {'booster': 'gblinear', 'lambda': 5.188046064013931e-07, 'alpha': 0.0029049634772686543, 'subsample': 0.959682186838402, 'colsample_bytree': 0.7660114114993904}. Best is trial 69 with value: 7.500974366538848e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:34,247]\u001b[0m Trial 81 finished with value: 0.00011820416115931301 and parameters: {'booster': 'gblinear', 'lambda': 1.9640873596453723e-05, 'alpha': 0.0029723083677091803, 'subsample': 0.9731950356008402, 'colsample_bytree': 0.8019982595499249}. Best is trial 69 with value: 7.500974366538848e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:34,379]\u001b[0m Trial 82 finished with value: 0.0001462076849219143 and parameters: {'booster': 'gblinear', 'lambda': 5.003278486529961e-07, 'alpha': 0.003071307266488809, 'subsample': 0.9127925832598979, 'colsample_bytree': 0.7981502145846103}. Best is trial 69 with value: 7.500974366538848e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:34,511]\u001b[0m Trial 83 finished with value: 0.0008238173593177511 and parameters: {'booster': 'gblinear', 'lambda': 1.469599657814986e-05, 'alpha': 0.0005700849226258878, 'subsample': 0.9707329405648335, 'colsample_bytree': 0.762300729303356}. Best is trial 69 with value: 7.500974366538848e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:34,654]\u001b[0m Trial 84 finished with value: 0.00012007826850867338 and parameters: {'booster': 'gblinear', 'lambda': 2.485892178119317e-06, 'alpha': 0.004209675094102388, 'subsample': 0.9317750115298262, 'colsample_bytree': 0.7931533129194444}. Best is trial 69 with value: 7.500974366538848e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:34,859]\u001b[0m Trial 85 finished with value: 1.1122609716316678 and parameters: {'booster': 'gbtree', 'lambda': 3.697851166568668e-06, 'alpha': 0.013897125648661158, 'subsample': 0.930514089114755, 'colsample_bytree': 0.697838227223903, 'max_depth': 3, 'min_child_weight': 6, 'eta': 1.2272158047872787e-05, 'gamma': 1.0624339552188321e-07, 'grow_policy': 'lossguide'}. Best is trial 69 with value: 7.500974366538848e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:34,989]\u001b[0m Trial 86 finished with value: 0.00010383372588692307 and parameters: {'booster': 'gblinear', 'lambda': 2.5168590180486198e-05, 'alpha': 0.003120507473486007, 'subsample': 0.9421216341491815, 'colsample_bytree': 0.7877352396181455}. Best is trial 69 with value: 7.500974366538848e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:35,121]\u001b[0m Trial 87 finished with value: 0.0007335765292101693 and parameters: {'booster': 'gblinear', 'lambda': 2.2425846109172224e-05, 'alpha': 5.067500843233022e-05, 'subsample': 0.9449216265133114, 'colsample_bytree': 0.7930289771136447}. Best is trial 69 with value: 7.500974366538848e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:35,250]\u001b[0m Trial 88 finished with value: 0.0003195694084751417 and parameters: {'booster': 'gblinear', 'lambda': 4.990933299451475e-05, 'alpha': 0.007369485623161414, 'subsample': 0.8679505709440025, 'colsample_bytree': 0.7672038300057501}. Best is trial 69 with value: 7.500974366538848e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:36,855]\u001b[0m Trial 89 finished with value: 1.114279921302164 and parameters: {'booster': 'dart', 'lambda': 8.378145349093352e-05, 'alpha': 0.002925125364347335, 'subsample': 0.9752054721437071, 'colsample_bytree': 0.8115791560346762, 'max_depth': 9, 'min_child_weight': 8, 'eta': 9.496593090513441e-08, 'gamma': 6.939548589588669e-06, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.393778297328899e-06, 'skip_drop': 0.006742946138983937}. Best is trial 69 with value: 7.500974366538848e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:36,988]\u001b[0m Trial 90 finished with value: 0.0003270494649959945 and parameters: {'booster': 'gblinear', 'lambda': 2.2412580622165306e-06, 'alpha': 0.0002561907217203198, 'subsample': 0.8427893701448704, 'colsample_bytree': 0.735827634961453}. Best is trial 69 with value: 7.500974366538848e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:37,118]\u001b[0m Trial 91 finished with value: 0.00012943586748894923 and parameters: {'booster': 'gblinear', 'lambda': 1.0203518452699543e-05, 'alpha': 0.0034135362693315753, 'subsample': 0.9248118586322323, 'colsample_bytree': 0.869328901452686}. Best is trial 69 with value: 7.500974366538848e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:37,249]\u001b[0m Trial 92 finished with value: 0.0001767983120610078 and parameters: {'booster': 'gblinear', 'lambda': 1.0431580610387646e-05, 'alpha': 0.0032670846282198845, 'subsample': 0.9244565514636244, 'colsample_bytree': 0.8531347100525069}. Best is trial 69 with value: 7.500974366538848e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:37,382]\u001b[0m Trial 93 finished with value: 0.0005744143928836538 and parameters: {'booster': 'gblinear', 'lambda': 3.218731986910252e-05, 'alpha': 0.0008584916438365829, 'subsample': 0.8979195282560837, 'colsample_bytree': 0.8361655274205548}. Best is trial 69 with value: 7.500974366538848e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:37,511]\u001b[0m Trial 94 finished with value: 0.00024732936520225013 and parameters: {'booster': 'gblinear', 'lambda': 5.929746149789409e-06, 'alpha': 0.006016466768333414, 'subsample': 0.9462356713086598, 'colsample_bytree': 0.7796986821370895}. Best is trial 69 with value: 7.500974366538848e-05.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:11:37,643]\u001b[0m Trial 95 finished with value: 0.0002455550413726987 and parameters: {'booster': 'gblinear', 'lambda': 1.757733108510555e-05, 'alpha': 0.0017420834129102892, 'subsample': 0.9820008379212033, 'colsample_bytree': 0.7167466418961632}. Best is trial 69 with value: 7.500974366538848e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:37,768]\u001b[0m Trial 96 finished with value: 0.0015036328452004751 and parameters: {'booster': 'gblinear', 'lambda': 1.025973915628511e-05, 'alpha': 0.01608156988188928, 'subsample': 0.9200581519324215, 'colsample_bytree': 0.8666553851765946}. Best is trial 69 with value: 7.500974366538848e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:37,889]\u001b[0m Trial 97 finished with value: 0.006008225364877105 and parameters: {'booster': 'gblinear', 'lambda': 0.00027127060128364543, 'alpha': 0.031958453433435216, 'subsample': 0.9981349613148249, 'colsample_bytree': 0.8055427291372776}. Best is trial 69 with value: 7.500974366538848e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:38,023]\u001b[0m Trial 98 finished with value: 0.00042036948231268694 and parameters: {'booster': 'gblinear', 'lambda': 3.950082673347659e-07, 'alpha': 0.00016402722867010048, 'subsample': 0.8904646787113171, 'colsample_bytree': 0.8674856377465885}. Best is trial 69 with value: 7.500974366538848e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:38,158]\u001b[0m Trial 99 finished with value: 0.00016040053176303237 and parameters: {'booster': 'gblinear', 'lambda': 2.6241538954667613e-06, 'alpha': 0.000397940337993798, 'subsample': 0.9657091668365457, 'colsample_bytree': 0.8322058009475919}. Best is trial 69 with value: 7.500974366538848e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:38,302]\u001b[0m A new study created in memory with name: no-name-f20f7377-4ee1-4f7d-a2aa-ee18bdebe6a3\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:38,496]\u001b[0m Trial 0 finished with value: 1.1995777346605483 and parameters: {'booster': 'gbtree', 'lambda': 0.10750817294210205, 'alpha': 2.0378117905431058e-05, 'subsample': 0.7377313482974444, 'colsample_bytree': 0.28218889920681917, 'max_depth': 7, 'min_child_weight': 9, 'eta': 1.040116547539128e-05, 'gamma': 3.43983125182015e-07, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 1.1995777346605483.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:39,907]\u001b[0m Trial 1 finished with value: 1.20011272434065 and parameters: {'booster': 'dart', 'lambda': 0.0003932077371289217, 'alpha': 2.2648270267298335e-07, 'subsample': 0.7271097094243022, 'colsample_bytree': 0.899943787219945, 'max_depth': 9, 'min_child_weight': 7, 'eta': 4.408708197049175e-06, 'gamma': 0.4903640523088516, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 2.297478347273824e-06, 'skip_drop': 0.006911292605121461}. Best is trial 0 with value: 1.1995777346605483.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:40,023]\u001b[0m Trial 2 finished with value: 0.04856350049521361 and parameters: {'booster': 'gblinear', 'lambda': 2.8826347059357205e-07, 'alpha': 0.00010778718679892422, 'subsample': 0.494258137828689, 'colsample_bytree': 0.4850798999361504}. Best is trial 2 with value: 0.04856350049521361.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:40,235]\u001b[0m Trial 3 finished with value: 0.127006955238664 and parameters: {'booster': 'gbtree', 'lambda': 1.9327013706971427e-06, 'alpha': 0.00022869176332370082, 'subsample': 0.6813723407074255, 'colsample_bytree': 0.5892993263741502, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.10302517053488477, 'gamma': 2.315005574424089e-05, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 0.04856350049521361.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:40,352]\u001b[0m Trial 4 finished with value: 0.05161085173999364 and parameters: {'booster': 'gblinear', 'lambda': 0.0021376309904946544, 'alpha': 1.8386723703336628e-05, 'subsample': 0.9424250505483143, 'colsample_bytree': 0.6870360904310273}. Best is trial 2 with value: 0.04856350049521361.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:40,548]\u001b[0m Trial 5 finished with value: 1.2008399776850887 and parameters: {'booster': 'gbtree', 'lambda': 1.405200852979475e-07, 'alpha': 0.005753052564624031, 'subsample': 0.4462533195432496, 'colsample_bytree': 0.4625267176035026, 'max_depth': 7, 'min_child_weight': 7, 'eta': 6.630498915670068e-07, 'gamma': 2.421155338169054e-08, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 0.04856350049521361.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:41,902]\u001b[0m Trial 6 finished with value: 1.198707003539274 and parameters: {'booster': 'dart', 'lambda': 0.06140996159199003, 'alpha': 0.03426980465322682, 'subsample': 0.7277254953188594, 'colsample_bytree': 0.8835419920484218, 'max_depth': 3, 'min_child_weight': 7, 'eta': 1.2270184580991814e-05, 'gamma': 9.364388946342735e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 7.170992270798071e-07, 'skip_drop': 0.0026054752911238844}. Best is trial 2 with value: 0.04856350049521361.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:43,270]\u001b[0m Trial 7 finished with value: 1.1996164461996162 and parameters: {'booster': 'dart', 'lambda': 1.2574630368263739e-07, 'alpha': 0.00018682559436835876, 'subsample': 0.6265008996820152, 'colsample_bytree': 0.6064879044968909, 'max_depth': 3, 'min_child_weight': 8, 'eta': 8.261575070463974e-06, 'gamma': 1.5103694442394884e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 3.5269405416708277e-06, 'skip_drop': 6.4860732329087096e-06}. Best is trial 2 with value: 0.04856350049521361.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:43,389]\u001b[0m Trial 8 finished with value: 0.0707968920482953 and parameters: {'booster': 'gblinear', 'lambda': 0.012165345212856556, 'alpha': 0.0017328121062518932, 'subsample': 0.9968382485213634, 'colsample_bytree': 0.6977716217179035}. Best is trial 2 with value: 0.04856350049521361.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:43,566]\u001b[0m Trial 9 finished with value: 1.0893352811832406 and parameters: {'booster': 'gbtree', 'lambda': 2.0675611098619286e-08, 'alpha': 0.4622247478040408, 'subsample': 0.3301334467804227, 'colsample_bytree': 0.5670684128892903, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.0007388138925509338, 'gamma': 0.00013124815576832428, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 0.04856350049521361.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:43,702]\u001b[0m Trial 10 finished with value: 0.04689654984793311 and parameters: {'booster': 'gblinear', 'lambda': 1.2396263383945728e-05, 'alpha': 9.748157832442213e-08, 'subsample': 0.2089209585590514, 'colsample_bytree': 0.2250355363418221}. Best is trial 10 with value: 0.04689654984793311.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:43,837]\u001b[0m Trial 11 finished with value: 0.04618936362819271 and parameters: {'booster': 'gblinear', 'lambda': 1.121420740606079e-05, 'alpha': 2.259394365153637e-08, 'subsample': 0.2536657988623837, 'colsample_bytree': 0.20920013787131994}. Best is trial 11 with value: 0.04618936362819271.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:43,973]\u001b[0m Trial 12 finished with value: 0.046223819058232696 and parameters: {'booster': 'gblinear', 'lambda': 1.604456040755274e-05, 'alpha': 1.1596067328212343e-08, 'subsample': 0.20097110311344293, 'colsample_bytree': 0.20188631666445475}. Best is trial 11 with value: 0.04618936362819271.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:44,106]\u001b[0m Trial 13 finished with value: 0.0464011351644675 and parameters: {'booster': 'gblinear', 'lambda': 3.439323020000649e-05, 'alpha': 1.3999452940171046e-08, 'subsample': 0.22374920157274208, 'colsample_bytree': 0.3434248877392596}. Best is trial 11 with value: 0.04618936362819271.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:44,242]\u001b[0m Trial 14 finished with value: 0.04577983330309426 and parameters: {'booster': 'gblinear', 'lambda': 0.00013114608373842102, 'alpha': 1.3830851132977054e-06, 'subsample': 0.3439878722065709, 'colsample_bytree': 0.37075097523605893}. Best is trial 14 with value: 0.04577983330309426.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:44,376]\u001b[0m Trial 15 finished with value: 0.048750972388787166 and parameters: {'booster': 'gblinear', 'lambda': 0.0004279191806361923, 'alpha': 1.2490698051545025e-06, 'subsample': 0.36221648241349214, 'colsample_bytree': 0.37465921452973583}. Best is trial 14 with value: 0.04577983330309426.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:44,513]\u001b[0m Trial 16 finished with value: 0.045315544649182096 and parameters: {'booster': 'gblinear', 'lambda': 1.7861184710388192e-06, 'alpha': 1.3972390086220023e-06, 'subsample': 0.342037699677648, 'colsample_bytree': 0.33077990637104937}. Best is trial 16 with value: 0.045315544649182096.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:11:44,647]\u001b[0m Trial 17 finished with value: 0.6588170510102938 and parameters: {'booster': 'gblinear', 'lambda': 0.6632096850236909, 'alpha': 1.9792271799908728e-06, 'subsample': 0.4984082116827292, 'colsample_bytree': 0.37877408333221513}. Best is trial 16 with value: 0.045315544649182096.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:44,783]\u001b[0m Trial 18 finished with value: 0.046106955087956376 and parameters: {'booster': 'gblinear', 'lambda': 3.2312992544145785e-06, 'alpha': 3.1476023158673653e-06, 'subsample': 0.3596472437117258, 'colsample_bytree': 0.4711020991880296}. Best is trial 16 with value: 0.045315544649182096.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:45,624]\u001b[0m Trial 19 finished with value: 1.2009428054875688 and parameters: {'booster': 'dart', 'lambda': 0.00015091132502011693, 'alpha': 3.1928379960326507e-07, 'subsample': 0.5567418290138599, 'colsample_bytree': 0.3149604810489912, 'max_depth': 9, 'min_child_weight': 2, 'eta': 1.426043786134528e-08, 'gamma': 0.20904643150486188, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.5660350959582605, 'skip_drop': 1.002417794734383e-08}. Best is trial 16 with value: 0.045315544649182096.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:45,760]\u001b[0m Trial 20 finished with value: 0.04628826372925709 and parameters: {'booster': 'gblinear', 'lambda': 1.401991362213741e-06, 'alpha': 1.0526474611283858e-05, 'subsample': 0.42554066825714143, 'colsample_bytree': 0.985791276622029}. Best is trial 16 with value: 0.045315544649182096.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:45,894]\u001b[0m Trial 21 finished with value: 0.048796075501855725 and parameters: {'booster': 'gblinear', 'lambda': 1.928942490395806e-06, 'alpha': 2.6796537447994156e-06, 'subsample': 0.31856232990270644, 'colsample_bytree': 0.43640505846205574}. Best is trial 16 with value: 0.045315544649182096.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:46,030]\u001b[0m Trial 22 finished with value: 0.04516292540486396 and parameters: {'booster': 'gblinear', 'lambda': 1.0725847878668808e-08, 'alpha': 5.876494686385813e-07, 'subsample': 0.3888392624046957, 'colsample_bytree': 0.5167415410629767}. Best is trial 22 with value: 0.04516292540486396.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:46,164]\u001b[0m Trial 23 finished with value: 0.04464008137636999 and parameters: {'booster': 'gblinear', 'lambda': 1.0393429956703193e-08, 'alpha': 4.2706528577333957e-07, 'subsample': 0.4020143858506729, 'colsample_bytree': 0.39455228350127713}. Best is trial 23 with value: 0.04464008137636999.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:46,297]\u001b[0m Trial 24 finished with value: 0.04729174614019588 and parameters: {'booster': 'gblinear', 'lambda': 1.0160110866279822e-08, 'alpha': 8.261615134176057e-08, 'subsample': 0.42873903921968376, 'colsample_bytree': 0.5221451332956993}. Best is trial 23 with value: 0.04464008137636999.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:46,431]\u001b[0m Trial 25 finished with value: 0.04617019033951327 and parameters: {'booster': 'gblinear', 'lambda': 4.8762055901495867e-08, 'alpha': 4.3195065721426837e-07, 'subsample': 0.2768878794861648, 'colsample_bytree': 0.6685527875821247}. Best is trial 23 with value: 0.04464008137636999.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:46,565]\u001b[0m Trial 26 finished with value: 0.04511028318143548 and parameters: {'booster': 'gblinear', 'lambda': 4.648848840925569e-08, 'alpha': 6.083852094295417e-08, 'subsample': 0.5631176669344035, 'colsample_bytree': 0.41158030521383926}. Best is trial 23 with value: 0.04464008137636999.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:46,758]\u001b[0m Trial 27 finished with value: 0.39613179808241444 and parameters: {'booster': 'gbtree', 'lambda': 3.352922726425971e-08, 'alpha': 5.64553628944821e-08, 'subsample': 0.563242733233778, 'colsample_bytree': 0.5309046401342078, 'max_depth': 3, 'min_child_weight': 10, 'eta': 0.8767094242754413, 'gamma': 0.004991356464616543, 'grow_policy': 'depthwise'}. Best is trial 23 with value: 0.04464008137636999.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:46,894]\u001b[0m Trial 28 finished with value: 0.04600898020125655 and parameters: {'booster': 'gblinear', 'lambda': 4.2205987438821466e-07, 'alpha': 1.0221888184712253e-05, 'subsample': 0.6209458417865313, 'colsample_bytree': 0.41913099978636065}. Best is trial 23 with value: 0.04464008137636999.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:48,374]\u001b[0m Trial 29 finished with value: 0.840314179036492 and parameters: {'booster': 'dart', 'lambda': 5.343945320418643e-08, 'alpha': 3.372587694162613e-05, 'subsample': 0.5049416898810306, 'colsample_bytree': 0.252562205436609, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.0035263822192143526, 'gamma': 0.008636393150308848, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.02116513635517353, 'skip_drop': 0.9967606980926964}. Best is trial 23 with value: 0.04464008137636999.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:48,643]\u001b[0m Trial 30 finished with value: 1.200942437451533 and parameters: {'booster': 'gbtree', 'lambda': 1.1245287677986545e-08, 'alpha': 3.288200154403245e-07, 'subsample': 0.8401477522394052, 'colsample_bytree': 0.7679694606860085, 'max_depth': 5, 'min_child_weight': 4, 'eta': 1.236925065389795e-08, 'gamma': 7.889191611464477e-07, 'grow_policy': 'depthwise'}. Best is trial 23 with value: 0.04464008137636999.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:48,781]\u001b[0m Trial 31 finished with value: 0.05078732022298466 and parameters: {'booster': 'gblinear', 'lambda': 5.094537501991035e-07, 'alpha': 4.096696976702784e-08, 'subsample': 0.39348538880934575, 'colsample_bytree': 0.29338272042310864}. Best is trial 23 with value: 0.04464008137636999.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:48,914]\u001b[0m Trial 32 finished with value: 0.04526789562780958 and parameters: {'booster': 'gblinear', 'lambda': 8.052056138745583e-08, 'alpha': 1.653123659703856e-07, 'subsample': 0.2829820318663473, 'colsample_bytree': 0.41073031654131364}. Best is trial 23 with value: 0.04464008137636999.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:49,049]\u001b[0m Trial 33 finished with value: 0.046173725740950494 and parameters: {'booster': 'gblinear', 'lambda': 1.0467667678568102e-07, 'alpha': 1.4228408599122064e-07, 'subsample': 0.2932465246346069, 'colsample_bytree': 0.41854513608354643}. Best is trial 23 with value: 0.04464008137636999.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:49,184]\u001b[0m Trial 34 finished with value: 0.04445062329514247 and parameters: {'booster': 'gblinear', 'lambda': 2.5037506615861946e-08, 'alpha': 3.883152145030666e-07, 'subsample': 0.4688447634090015, 'colsample_bytree': 0.5189786475001359}. Best is trial 34 with value: 0.04445062329514247.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:49,318]\u001b[0m Trial 35 finished with value: 0.047855224225935626 and parameters: {'booster': 'gblinear', 'lambda': 1.017549100047748e-08, 'alpha': 5.229830994667825e-07, 'subsample': 0.46874766713294547, 'colsample_bytree': 0.5225414475593203}. Best is trial 34 with value: 0.04445062329514247.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:49,454]\u001b[0m Trial 36 finished with value: 0.045766296627324815 and parameters: {'booster': 'gblinear', 'lambda': 2.9053718747886464e-07, 'alpha': 5.754516535084292e-06, 'subsample': 0.6676102524691532, 'colsample_bytree': 0.6263049732442343}. Best is trial 34 with value: 0.04445062329514247.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:51,023]\u001b[0m Trial 37 finished with value: 0.39535835950633563 and parameters: {'booster': 'dart', 'lambda': 4.527839858277528e-08, 'alpha': 5.776689524423968e-05, 'subsample': 0.5266537960454801, 'colsample_bytree': 0.4975447846877519, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.010954229771404948, 'gamma': 0.0015416778011356324, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.0009764685552421696, 'skip_drop': 3.238502094095024e-08}. Best is trial 34 with value: 0.04445062329514247.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:51,238]\u001b[0m Trial 38 finished with value: 1.2009249050924484 and parameters: {'booster': 'gbtree', 'lambda': 2.1008371857829735e-07, 'alpha': 3.1260228979592746e-08, 'subsample': 0.39986395719095263, 'colsample_bytree': 0.5539176225116905, 'max_depth': 5, 'min_child_weight': 10, 'eta': 1.2410541917230116e-07, 'gamma': 3.0290007298299874e-06, 'grow_policy': 'lossguide'}. Best is trial 34 with value: 0.04445062329514247.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:11:51,373]\u001b[0m Trial 39 finished with value: 0.04375384693344071 and parameters: {'booster': 'gblinear', 'lambda': 2.5222505504489605e-08, 'alpha': 0.000513162563137067, 'subsample': 0.5766006933389692, 'colsample_bytree': 0.7459047827410318}. Best is trial 39 with value: 0.04375384693344071.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:52,869]\u001b[0m Trial 40 finished with value: 1.1569383957316959 and parameters: {'booster': 'dart', 'lambda': 6.500793190160434e-07, 'alpha': 0.0009875752305015968, 'subsample': 0.6684583197886665, 'colsample_bytree': 0.7440970055556729, 'max_depth': 7, 'min_child_weight': 5, 'eta': 0.0002493441892976646, 'gamma': 0.0004347728613348875, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.00024921560457637774, 'skip_drop': 3.5004124492478822e-06}. Best is trial 39 with value: 0.04375384693344071.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:53,004]\u001b[0m Trial 41 finished with value: 0.04093071171648905 and parameters: {'booster': 'gblinear', 'lambda': 3.7378609675583736e-08, 'alpha': 0.0008849745048008631, 'subsample': 0.5766843226844224, 'colsample_bytree': 0.7902148210420212}. Best is trial 41 with value: 0.04093071171648905.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:53,141]\u001b[0m Trial 42 finished with value: 0.04219084162603672 and parameters: {'booster': 'gblinear', 'lambda': 2.4711236575443573e-08, 'alpha': 0.0006809250977293078, 'subsample': 0.5904096656100145, 'colsample_bytree': 0.8373634853443864}. Best is trial 41 with value: 0.04093071171648905.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:53,275]\u001b[0m Trial 43 finished with value: 0.04172515881266443 and parameters: {'booster': 'gblinear', 'lambda': 2.3840015582722105e-08, 'alpha': 0.000655580318622078, 'subsample': 0.7772498572519616, 'colsample_bytree': 0.8414106721597825}. Best is trial 41 with value: 0.04093071171648905.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:53,410]\u001b[0m Trial 44 finished with value: 0.041832978905902964 and parameters: {'booster': 'gblinear', 'lambda': 1.2735777070168618e-07, 'alpha': 0.0006419238554654968, 'subsample': 0.8005422008880232, 'colsample_bytree': 0.8342774479533361}. Best is trial 41 with value: 0.04093071171648905.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:53,544]\u001b[0m Trial 45 finished with value: 0.03988500723313228 and parameters: {'booster': 'gblinear', 'lambda': 1.2746672646634023e-07, 'alpha': 0.0007999357017158389, 'subsample': 0.7914354036172635, 'colsample_bytree': 0.8375573223317083}. Best is trial 45 with value: 0.03988500723313228.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:53,677]\u001b[0m Trial 46 finished with value: 0.04040936502443877 and parameters: {'booster': 'gblinear', 'lambda': 1.8702153570100277e-07, 'alpha': 0.008026159823151427, 'subsample': 0.7866534326102155, 'colsample_bytree': 0.8484371921402104}. Best is trial 45 with value: 0.03988500723313228.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:53,895]\u001b[0m Trial 47 finished with value: 0.5455828083244845 and parameters: {'booster': 'gbtree', 'lambda': 4.524172419876335e-06, 'alpha': 0.007114540877014524, 'subsample': 0.7941894220823142, 'colsample_bytree': 0.8476947513121237, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.9583473536678252, 'gamma': 0.07780665861451774, 'grow_policy': 'lossguide'}. Best is trial 45 with value: 0.03988500723313228.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:54,026]\u001b[0m Trial 48 finished with value: 0.036629650151820285 and parameters: {'booster': 'gblinear', 'lambda': 1.5291964777613763e-07, 'alpha': 0.0049296042875300265, 'subsample': 0.8611197130217363, 'colsample_bytree': 0.9484569507959983}. Best is trial 48 with value: 0.036629650151820285.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:54,144]\u001b[0m Trial 49 finished with value: 0.13675490343492183 and parameters: {'booster': 'gblinear', 'lambda': 6.965718362720519e-07, 'alpha': 0.03770248072973418, 'subsample': 0.9092776053192284, 'colsample_bytree': 0.9590288423171791}. Best is trial 48 with value: 0.036629650151820285.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:54,277]\u001b[0m Trial 50 finished with value: 0.03644033492862859 and parameters: {'booster': 'gblinear', 'lambda': 2.054022205245876e-07, 'alpha': 0.005069158146005374, 'subsample': 0.8916225443281611, 'colsample_bytree': 0.9265109607774262}. Best is trial 50 with value: 0.03644033492862859.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:54,411]\u001b[0m Trial 51 finished with value: 0.036227975775569896 and parameters: {'booster': 'gblinear', 'lambda': 2.4225431515236765e-07, 'alpha': 0.005192792857692161, 'subsample': 0.8853244977491428, 'colsample_bytree': 0.8853182621341196}. Best is trial 51 with value: 0.036227975775569896.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:54,543]\u001b[0m Trial 52 finished with value: 0.037455308300374704 and parameters: {'booster': 'gblinear', 'lambda': 2.0253137247062622e-07, 'alpha': 0.00529758217845014, 'subsample': 0.8824262234798056, 'colsample_bytree': 0.9156197181224088}. Best is trial 51 with value: 0.036227975775569896.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:54,673]\u001b[0m Trial 53 finished with value: 0.04191792425868961 and parameters: {'booster': 'gblinear', 'lambda': 8.477197606268303e-07, 'alpha': 0.009043474422335515, 'subsample': 0.8972549258699152, 'colsample_bytree': 0.9356578061684957}. Best is trial 51 with value: 0.036227975775569896.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:54,808]\u001b[0m Trial 54 finished with value: 0.03595767074880136 and parameters: {'booster': 'gblinear', 'lambda': 1.9638728840813185e-07, 'alpha': 0.00291771908380656, 'subsample': 0.992075292765128, 'colsample_bytree': 0.9003529681706647}. Best is trial 54 with value: 0.03595767074880136.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:54,942]\u001b[0m Trial 55 finished with value: 0.03550163408388959 and parameters: {'booster': 'gblinear', 'lambda': 7.104494681283822e-06, 'alpha': 0.0026963969812204883, 'subsample': 0.9937165285731322, 'colsample_bytree': 0.8990713030936066}. Best is trial 55 with value: 0.03550163408388959.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:55,076]\u001b[0m Trial 56 finished with value: 0.035289459296685394 and parameters: {'booster': 'gblinear', 'lambda': 6.137426153540208e-06, 'alpha': 0.002738818453459447, 'subsample': 0.9977670341688513, 'colsample_bytree': 0.9087581256555333}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:56,625]\u001b[0m Trial 57 finished with value: 0.22413277692854675 and parameters: {'booster': 'dart', 'lambda': 5.373430207894463e-06, 'alpha': 0.032532043802485935, 'subsample': 0.995444682652991, 'colsample_bytree': 0.8849358745457698, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.031223546720442055, 'gamma': 1.4906930781703288e-08, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 1.4217531350848524e-08, 'skip_drop': 0.054780844103273434}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:56,760]\u001b[0m Trial 58 finished with value: 0.03596026004881706 and parameters: {'booster': 'gblinear', 'lambda': 7.383789322707692e-05, 'alpha': 0.002751216370873812, 'subsample': 0.9465756578943938, 'colsample_bytree': 0.9945269973194717}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:56,875]\u001b[0m Trial 59 finished with value: 0.40298590503540616 and parameters: {'booster': 'gblinear', 'lambda': 6.0470305858102946e-05, 'alpha': 0.07803165971576896, 'subsample': 0.9575553923134449, 'colsample_bytree': 0.9950132314955602}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:57,010]\u001b[0m Trial 60 finished with value: 0.0371353814350268 and parameters: {'booster': 'gblinear', 'lambda': 0.0003158726488749415, 'alpha': 0.0032046153720088266, 'subsample': 0.9469512060416596, 'colsample_bytree': 0.8990835279368057}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:57,142]\u001b[0m Trial 61 finished with value: 0.041122622191654745 and parameters: {'booster': 'gblinear', 'lambda': 0.0012836253353398657, 'alpha': 0.0020633173594505737, 'subsample': 0.976370937086455, 'colsample_bytree': 0.9594735230124042}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:57,278]\u001b[0m Trial 62 finished with value: 0.04652536800678818 and parameters: {'booster': 'gblinear', 'lambda': 3.4558423537756594e-05, 'alpha': 0.00019367438333737065, 'subsample': 0.9262077689736625, 'colsample_bytree': 0.9291999068052836}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:11:57,408]\u001b[0m Trial 63 finished with value: 0.059511531116368775 and parameters: {'booster': 'gblinear', 'lambda': 9.912245343203191e-06, 'alpha': 0.016006024799861834, 'subsample': 0.8638197211074559, 'colsample_bytree': 0.9588475320503509}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:57,512]\u001b[0m Trial 64 finished with value: 0.9357158496632322 and parameters: {'booster': 'gblinear', 'lambda': 2.1871458608731565e-05, 'alpha': 0.3527847056542069, 'subsample': 0.9990157676611627, 'colsample_bytree': 0.8698583959275996}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:57,645]\u001b[0m Trial 65 finished with value: 0.035899921259648034 and parameters: {'booster': 'gblinear', 'lambda': 1.2794782713314851e-06, 'alpha': 0.0035469444176669538, 'subsample': 0.844779633483219, 'colsample_bytree': 0.7977452783227615}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:57,914]\u001b[0m Trial 66 finished with value: 1.185327428550332 and parameters: {'booster': 'gbtree', 'lambda': 1.2492301179818557e-06, 'alpha': 0.0003280319151163091, 'subsample': 0.9274066417342692, 'colsample_bytree': 0.8081022465158783, 'max_depth': 5, 'min_child_weight': 6, 'eta': 8.583511931989502e-05, 'gamma': 0.023958110803200754, 'grow_policy': 'lossguide'}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:58,048]\u001b[0m Trial 67 finished with value: 0.038789347879074544 and parameters: {'booster': 'gblinear', 'lambda': 3.6380721167094337e-06, 'alpha': 0.0018009268290914483, 'subsample': 0.973628060790867, 'colsample_bytree': 0.9149952492284715}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:58,177]\u001b[0m Trial 68 finished with value: 0.06599736460311685 and parameters: {'booster': 'gblinear', 'lambda': 6.574884840695504e-06, 'alpha': 0.018735923851752663, 'subsample': 0.829614485411472, 'colsample_bytree': 0.8727396513552782}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:58,311]\u001b[0m Trial 69 finished with value: 0.03540030835435054 and parameters: {'booster': 'gblinear', 'lambda': 6.462999545256018e-05, 'alpha': 0.003118310655896442, 'subsample': 0.9638020987799719, 'colsample_bytree': 0.9856146976533846}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:58,423]\u001b[0m Trial 70 finished with value: 0.6213663564274505 and parameters: {'booster': 'gblinear', 'lambda': 0.0001963126173725554, 'alpha': 0.10405854275272225, 'subsample': 0.9634160725419872, 'colsample_bytree': 0.9749389362538897}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:58,552]\u001b[0m Trial 71 finished with value: 0.05410603518922022 and parameters: {'booster': 'gblinear', 'lambda': 7.718277464538329e-05, 'alpha': 0.013786250882125296, 'subsample': 0.9266594520855206, 'colsample_bytree': 0.9946094773947759}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:58,687]\u001b[0m Trial 72 finished with value: 0.035923720369523494 and parameters: {'booster': 'gblinear', 'lambda': 3.557132098691722e-05, 'alpha': 0.002936338248949032, 'subsample': 0.8978665630779478, 'colsample_bytree': 0.9140391114924632}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:58,819]\u001b[0m Trial 73 finished with value: 0.03837975949166506 and parameters: {'booster': 'gblinear', 'lambda': 2.928341528896734e-05, 'alpha': 0.0025799193103724465, 'subsample': 0.9389065195146136, 'colsample_bytree': 0.8968105762630533}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:58,954]\u001b[0m Trial 74 finished with value: 0.03572256570001064 and parameters: {'booster': 'gblinear', 'lambda': 4.2576814370899045e-05, 'alpha': 0.0031192521723583345, 'subsample': 0.9814945879356217, 'colsample_bytree': 0.8788871018685461}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:11:59,090]\u001b[0m Trial 75 finished with value: 0.044498311195440086 and parameters: {'booster': 'gblinear', 'lambda': 5.900418410133925e-05, 'alpha': 0.0003315827069502267, 'subsample': 0.9794284035495369, 'colsample_bytree': 0.9709512109590827}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:00,665]\u001b[0m Trial 76 finished with value: 1.2009074481596107 and parameters: {'booster': 'dart', 'lambda': 1.4761585843596343e-05, 'alpha': 0.00011810945396457176, 'subsample': 0.9995337205503732, 'colsample_bytree': 0.8085110585617348, 'max_depth': 7, 'min_child_weight': 5, 'eta': 1.924342138410902e-07, 'gamma': 0.9926102161275985, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.2713913013127867e-08, 'skip_drop': 7.595204574355252e-05}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:00,807]\u001b[0m Trial 77 finished with value: 0.043631489145959476 and parameters: {'booster': 'gblinear', 'lambda': 0.0009149832401869118, 'alpha': 0.0012110558001784913, 'subsample': 0.9499268555468758, 'colsample_bytree': 0.9453654025411885}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:00,947]\u001b[0m Trial 78 finished with value: 0.03707016970487992 and parameters: {'booster': 'gblinear', 'lambda': 0.00011884268400665683, 'alpha': 0.002922933983710053, 'subsample': 0.8581376358028566, 'colsample_bytree': 0.863956737362657}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:01,184]\u001b[0m Trial 79 finished with value: 1.0346105294262353 and parameters: {'booster': 'gbtree', 'lambda': 0.00835595652177503, 'alpha': 0.0013567858477272743, 'subsample': 0.9140692454413422, 'colsample_bytree': 0.9162944455187287, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.001025419622864672, 'gamma': 3.611110291695034e-06, 'grow_policy': 'lossguide'}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:01,322]\u001b[0m Trial 80 finished with value: 0.03619004898919104 and parameters: {'booster': 'gblinear', 'lambda': 4.0801751943567136e-05, 'alpha': 0.0035052284658196094, 'subsample': 0.743171595547407, 'colsample_bytree': 0.9977813112803178}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:01,463]\u001b[0m Trial 81 finished with value: 0.036660186915664174 and parameters: {'booster': 'gblinear', 'lambda': 8.059436219848656e-06, 'alpha': 0.003389948387003673, 'subsample': 0.975779899613936, 'colsample_bytree': 0.9989344301880329}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:01,599]\u001b[0m Trial 82 finished with value: 0.046535227926952125 and parameters: {'booster': 'gblinear', 'lambda': 2.837162517193035e-06, 'alpha': 0.01100310358704084, 'subsample': 0.9452079965846717, 'colsample_bytree': 0.9752306956139435}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:01,741]\u001b[0m Trial 83 finished with value: 0.04504677830362551 and parameters: {'booster': 'gblinear', 'lambda': 4.6137228464146685e-05, 'alpha': 0.00035543632066862413, 'subsample': 0.8370540182706951, 'colsample_bytree': 0.9036015252861089}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:01,882]\u001b[0m Trial 84 finished with value: 0.03973988510999419 and parameters: {'booster': 'gblinear', 'lambda': 1.9801627186018475e-05, 'alpha': 0.0014564994856680934, 'subsample': 0.9132215340106028, 'colsample_bytree': 0.942446328761923}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:02,009]\u001b[0m Trial 85 finished with value: 0.1446240184456069 and parameters: {'booster': 'gblinear', 'lambda': 1.3924107731703254e-05, 'alpha': 0.039341834483535704, 'subsample': 0.7160059215448829, 'colsample_bytree': 0.8100876099907837}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:02,150]\u001b[0m Trial 86 finished with value: 0.03750733019448024 and parameters: {'booster': 'gblinear', 'lambda': 0.00018433450175695781, 'alpha': 0.002132434157382234, 'subsample': 0.7415598589518215, 'colsample_bytree': 0.9784264599414785}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:12:02,308]\u001b[0m Trial 87 finished with value: 0.03775142766590809 and parameters: {'booster': 'gblinear', 'lambda': 0.00033417444072197645, 'alpha': 0.0039659056900778625, 'subsample': 0.8206173881203422, 'colsample_bytree': 0.7071744164592174}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:02,455]\u001b[0m Trial 88 finished with value: 0.0860971774599718 and parameters: {'booster': 'gblinear', 'lambda': 9.604598840584323e-05, 'alpha': 0.02493127239301942, 'subsample': 0.9664544218928455, 'colsample_bytree': 0.9331647048920478}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:04,234]\u001b[0m Trial 89 finished with value: 0.1549135768602137 and parameters: {'booster': 'dart', 'lambda': 2.4686954535458154e-06, 'alpha': 0.01098800674505557, 'subsample': 0.8716064681553014, 'colsample_bytree': 0.8584263041620416, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.13610722433059666, 'gamma': 0.0005830126936493933, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.026658235188203663, 'skip_drop': 1.626355440397729e-06}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:04,468]\u001b[0m Trial 90 finished with value: 0.046282134922091066 and parameters: {'booster': 'gblinear', 'lambda': 3.132120441719081e-05, 'alpha': 0.00010835647465195556, 'subsample': 0.9841780075504052, 'colsample_bytree': 0.8883193482099897}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:04,725]\u001b[0m Trial 91 finished with value: 0.03645803131693786 and parameters: {'booster': 'gblinear', 'lambda': 1.7287148339699086e-06, 'alpha': 0.005575762149163877, 'subsample': 0.9001287403249432, 'colsample_bytree': 0.9051416878639309}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:04,891]\u001b[0m Trial 92 finished with value: 0.03859515096733789 and parameters: {'booster': 'gblinear', 'lambda': 4.970007237743957e-05, 'alpha': 0.00713477870310865, 'subsample': 0.9315655869835513, 'colsample_bytree': 0.8788229932376777}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:05,033]\u001b[0m Trial 93 finished with value: 0.040364714435502956 and parameters: {'booster': 'gblinear', 'lambda': 1.0728935088807934e-06, 'alpha': 0.00112941970495761, 'subsample': 0.7661719865534619, 'colsample_bytree': 0.8227728567126726}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:05,175]\u001b[0m Trial 94 finished with value: 0.04494632146330236 and parameters: {'booster': 'gblinear', 'lambda': 3.576490445904653e-07, 'alpha': 0.00046408447502102026, 'subsample': 0.9569798519232189, 'colsample_bytree': 0.9567949936306211}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:05,315]\u001b[0m Trial 95 finished with value: 0.03945284329234017 and parameters: {'booster': 'gblinear', 'lambda': 0.0006114935694592647, 'alpha': 0.0038065682277835136, 'subsample': 0.8742625651948799, 'colsample_bytree': 0.7639643135674427}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:05,457]\u001b[0m Trial 96 finished with value: 0.038482965729888415 and parameters: {'booster': 'gblinear', 'lambda': 1.075903796560385e-05, 'alpha': 0.0020990507279131853, 'subsample': 0.8147362452472251, 'colsample_bytree': 0.9842773813447969}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:05,709]\u001b[0m Trial 97 finished with value: 0.30420530798808704 and parameters: {'booster': 'gblinear', 'lambda': 2.4212677370965662e-05, 'alpha': 0.06557673416157214, 'subsample': 0.8461398384662377, 'colsample_bytree': 0.9275966795716653}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:06,204]\u001b[0m Trial 98 finished with value: 1.1870267588310346 and parameters: {'booster': 'gbtree', 'lambda': 5.094000447862364e-06, 'alpha': 0.019209496979622688, 'subsample': 0.8928723122044177, 'colsample_bytree': 0.8860090933358743, 'max_depth': 7, 'min_child_weight': 9, 'eta': 7.521528642165539e-05, 'gamma': 5.073335794365328e-05, 'grow_policy': 'depthwise'}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:06,404]\u001b[0m Trial 99 finished with value: 0.03983996882439828 and parameters: {'booster': 'gblinear', 'lambda': 8.472488839624063e-05, 'alpha': 0.007784967675403039, 'subsample': 0.9920487137104036, 'colsample_bytree': 0.7819653636166815}. Best is trial 56 with value: 0.035289459296685394.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:06,608]\u001b[0m A new study created in memory with name: no-name-d002a1de-fd9b-47b5-a030-25be1152f1bb\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:06,764]\u001b[0m Trial 0 finished with value: 0.4583695538859126 and parameters: {'booster': 'gblinear', 'lambda': 4.386657179448069e-08, 'alpha': 0.011141506957976404, 'subsample': 0.44234170191455197, 'colsample_bytree': 0.9333961786989118}. Best is trial 0 with value: 0.4583695538859126.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:06,877]\u001b[0m Trial 1 finished with value: 0.511972010598072 and parameters: {'booster': 'gblinear', 'lambda': 0.6848394769697131, 'alpha': 0.041660903928205734, 'subsample': 0.9355094131446466, 'colsample_bytree': 0.5838789268482963}. Best is trial 0 with value: 0.4583695538859126.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:07,036]\u001b[0m Trial 2 finished with value: 0.467728789904917 and parameters: {'booster': 'gblinear', 'lambda': 2.935165041716433e-07, 'alpha': 1.155530878781503e-08, 'subsample': 0.3473721204905291, 'colsample_bytree': 0.8685310875256138}. Best is trial 0 with value: 0.4583695538859126.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:08,812]\u001b[0m Trial 3 finished with value: 1.2368040167327266 and parameters: {'booster': 'dart', 'lambda': 4.074721989715718e-06, 'alpha': 5.176149731678228e-05, 'subsample': 0.21906908558272242, 'colsample_bytree': 0.9983081340270297, 'max_depth': 5, 'min_child_weight': 10, 'eta': 2.1881089322445805e-05, 'gamma': 6.646818143595027e-08, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 2.946754865438707e-07, 'skip_drop': 2.4217280353126357e-05}. Best is trial 0 with value: 0.4583695538859126.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:09,097]\u001b[0m Trial 4 finished with value: 1.2400804903258353 and parameters: {'booster': 'gbtree', 'lambda': 0.04718709713805392, 'alpha': 2.853403311273616e-05, 'subsample': 0.3224764992905833, 'colsample_bytree': 0.48797856733531914, 'max_depth': 9, 'min_child_weight': 8, 'eta': 1.0598827796033653e-08, 'gamma': 7.673483223445491e-08, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.4583695538859126.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:09,222]\u001b[0m Trial 5 finished with value: 0.4589291019002832 and parameters: {'booster': 'gblinear', 'lambda': 0.0024330643969732455, 'alpha': 1.0323945329764364e-05, 'subsample': 0.8135630587264162, 'colsample_bytree': 0.672649240168151}. Best is trial 0 with value: 0.4583695538859126.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:09,317]\u001b[0m Trial 6 finished with value: 0.6183933846049644 and parameters: {'booster': 'gblinear', 'lambda': 0.0005901382906502524, 'alpha': 0.2680818984458262, 'subsample': 0.3459090743715632, 'colsample_bytree': 0.5509320305452913}. Best is trial 0 with value: 0.4583695538859126.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:09,412]\u001b[0m Trial 7 finished with value: 0.6167386493104772 and parameters: {'booster': 'gblinear', 'lambda': 5.323415376319629e-05, 'alpha': 0.26485621018301503, 'subsample': 0.3608309382760202, 'colsample_bytree': 0.21074274864517728}. Best is trial 0 with value: 0.4583695538859126.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:09,539]\u001b[0m Trial 8 finished with value: 0.4547492921121717 and parameters: {'booster': 'gblinear', 'lambda': 1.960705055907721e-07, 'alpha': 0.0008835940312880487, 'subsample': 0.33821283776473854, 'colsample_bytree': 0.5608128951254497}. Best is trial 8 with value: 0.4547492921121717.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:09,759]\u001b[0m Trial 9 finished with value: 1.2400693153656563 and parameters: {'booster': 'gbtree', 'lambda': 7.088527523457438e-06, 'alpha': 0.043741046094952676, 'subsample': 0.21993807528650466, 'colsample_bytree': 0.3230515862327515, 'max_depth': 7, 'min_child_weight': 2, 'eta': 8.196299102659722e-08, 'gamma': 9.142202446699968e-08, 'grow_policy': 'depthwise'}. Best is trial 8 with value: 0.4547492921121717.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:12:11,188]\u001b[0m Trial 10 finished with value: 0.44355576883314907 and parameters: {'booster': 'dart', 'lambda': 1.1741750407893017e-08, 'alpha': 0.0013662414489859296, 'subsample': 0.5985504311634745, 'colsample_bytree': 0.7517510896871189, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.9250776689529686, 'gamma': 0.18113722576361296, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.1429241854501943, 'skip_drop': 0.18812649258841674}. Best is trial 10 with value: 0.44355576883314907.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:12,437]\u001b[0m Trial 11 finished with value: 0.38920688293195255 and parameters: {'booster': 'dart', 'lambda': 1.5927029951322437e-08, 'alpha': 0.0011024879860730393, 'subsample': 0.6022819433806127, 'colsample_bytree': 0.760683163756857, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.4060516340020286, 'gamma': 0.9525235635707129, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.5428137747350041, 'skip_drop': 0.5679410579811496}. Best is trial 11 with value: 0.38920688293195255.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:13,810]\u001b[0m Trial 12 finished with value: 0.4715905342860958 and parameters: {'booster': 'dart', 'lambda': 1.1447977344165623e-08, 'alpha': 0.0010890964593570681, 'subsample': 0.6082627773852897, 'colsample_bytree': 0.7703078056908579, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.6605486660315852, 'gamma': 0.8374497960899104, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.5975587040290234, 'skip_drop': 0.8109951777549562}. Best is trial 11 with value: 0.38920688293195255.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:15,112]\u001b[0m Trial 13 finished with value: 0.5203775909600673 and parameters: {'booster': 'dart', 'lambda': 1.1918669244008436e-06, 'alpha': 2.3502716562416905e-06, 'subsample': 0.6272794015285194, 'colsample_bytree': 0.7730862537944085, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.9514872809835676, 'gamma': 0.5064232717008449, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.9299153633504484, 'skip_drop': 0.9340171261834734}. Best is trial 11 with value: 0.38920688293195255.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:16,528]\u001b[0m Trial 14 finished with value: 0.6442565094640151 and parameters: {'booster': 'dart', 'lambda': 1.4477777494762146e-08, 'alpha': 0.0009444140330455336, 'subsample': 0.7373672256600172, 'colsample_bytree': 0.7188870744590324, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.007128845418834298, 'gamma': 0.0029285389668023748, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.0035676369649825772, 'skip_drop': 0.009130637857719913}. Best is trial 11 with value: 0.38920688293195255.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:18,019]\u001b[0m Trial 15 finished with value: 0.46073456281949876 and parameters: {'booster': 'dart', 'lambda': 1.9532553935306925e-07, 'alpha': 7.679487808801098e-07, 'subsample': 0.5004985328536513, 'colsample_bytree': 0.8559837210006058, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.013414723728140805, 'gamma': 0.00544911447903932, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.003505887433396118, 'skip_drop': 7.1803995210109e-08}. Best is trial 11 with value: 0.38920688293195255.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:19,432]\u001b[0m Trial 16 finished with value: 0.6207771042836704 and parameters: {'booster': 'dart', 'lambda': 9.319526662847265e-06, 'alpha': 0.0031292395860028108, 'subsample': 0.7182608696970799, 'colsample_bytree': 0.6990576166436389, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.007640941137746467, 'gamma': 0.015732241348775423, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.008358165190234119, 'skip_drop': 0.0037917239259224406}. Best is trial 11 with value: 0.38920688293195255.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:20,874]\u001b[0m Trial 17 finished with value: 1.225443719292382 and parameters: {'booster': 'dart', 'lambda': 5.871004647749027e-05, 'alpha': 0.000297648038085249, 'subsample': 0.5496440614667903, 'colsample_bytree': 0.3984195976959093, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.00010904367174852447, 'gamma': 5.543150487799546e-05, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 6.6701274186208184e-06, 'skip_drop': 0.01615962428771181}. Best is trial 11 with value: 0.38920688293195255.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:21,223]\u001b[0m Trial 18 finished with value: 0.4118366771492473 and parameters: {'booster': 'gbtree', 'lambda': 7.582010364094761e-08, 'alpha': 0.0001349521066045021, 'subsample': 0.6914722870262542, 'colsample_bytree': 0.8407130577284508, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.09065024096560034, 'gamma': 2.278863119404439e-05, 'grow_policy': 'depthwise'}. Best is trial 11 with value: 0.38920688293195255.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:21,585]\u001b[0m Trial 19 finished with value: 0.38231869617904013 and parameters: {'booster': 'gbtree', 'lambda': 8.058137814981204e-07, 'alpha': 2.8228639040221143e-07, 'subsample': 0.8732131075895717, 'colsample_bytree': 0.8485884509514796, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.03573290893406419, 'gamma': 1.338581095581942e-05, 'grow_policy': 'depthwise'}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:22,042]\u001b[0m Trial 20 finished with value: 1.2080477366568492 and parameters: {'booster': 'gbtree', 'lambda': 1.10766202216169e-06, 'alpha': 2.628771519158569e-08, 'subsample': 0.9599708278235755, 'colsample_bytree': 0.9989770789094395, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.0001941961131482307, 'gamma': 2.273821005940277e-06, 'grow_policy': 'depthwise'}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:22,399]\u001b[0m Trial 21 finished with value: 0.3997137492681714 and parameters: {'booster': 'gbtree', 'lambda': 6.615848361356284e-08, 'alpha': 1.6934914298478592e-07, 'subsample': 0.8496613564360802, 'colsample_bytree': 0.847887250159516, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.055129377188294186, 'gamma': 3.727137865903683e-05, 'grow_policy': 'depthwise'}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:22,768]\u001b[0m Trial 22 finished with value: 0.40258513006649477 and parameters: {'booster': 'gbtree', 'lambda': 8.402368894841279e-07, 'alpha': 1.463110099089904e-07, 'subsample': 0.8713743945415844, 'colsample_bytree': 0.9131908465150521, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.04169315403949942, 'gamma': 3.802527467964961e-06, 'grow_policy': 'depthwise'}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:23,125]\u001b[0m Trial 23 finished with value: 1.1023991884021893 and parameters: {'booster': 'gbtree', 'lambda': 6.138406722914505e-08, 'alpha': 1.4397686074579198e-07, 'subsample': 0.8408736702349426, 'colsample_bytree': 0.819100823362259, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.0009147335778654769, 'gamma': 0.00029049176760966776, 'grow_policy': 'depthwise'}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:23,518]\u001b[0m Trial 24 finished with value: 0.40045015711949505 and parameters: {'booster': 'gbtree', 'lambda': 5.7558980140897776e-08, 'alpha': 3.794748694029344e-06, 'subsample': 0.9997362617219621, 'colsample_bytree': 0.6470796486696317, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.08624013462735919, 'gamma': 0.0004627419438817766, 'grow_policy': 'depthwise'}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:23,887]\u001b[0m Trial 25 finished with value: 1.0485127608436147 and parameters: {'booster': 'gbtree', 'lambda': 5.82331594417991e-07, 'alpha': 3.055642458903126e-07, 'subsample': 0.78180815547942, 'colsample_bytree': 0.917079674957238, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.0013143686358862959, 'gamma': 2.486805187580442e-06, 'grow_policy': 'depthwise'}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:24,171]\u001b[0m Trial 26 finished with value: 1.2385651816694199 and parameters: {'booster': 'gbtree', 'lambda': 4.480307891893585e-06, 'alpha': 1.0666720150419827e-06, 'subsample': 0.8772585844683306, 'colsample_bytree': 0.7991612532642149, 'max_depth': 5, 'min_child_weight': 6, 'eta': 9.356961194521484e-06, 'gamma': 2.2810909802510392e-05, 'grow_policy': 'depthwise'}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:12:24,483]\u001b[0m Trial 27 finished with value: 0.4485699056384886 and parameters: {'booster': 'gbtree', 'lambda': 0.0002959608197200561, 'alpha': 5.6545555708103665e-08, 'subsample': 0.9123151441176073, 'colsample_bytree': 0.6387212336190338, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.14768164587771831, 'gamma': 0.0005980448139434869, 'grow_policy': 'depthwise'}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:24,770]\u001b[0m Trial 28 finished with value: 1.0149545397528044 and parameters: {'booster': 'gbtree', 'lambda': 3.3376595076265584e-08, 'alpha': 1.157702007346058e-05, 'subsample': 0.6597483543524603, 'colsample_bytree': 0.8913573170372167, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.0016199565354885661, 'gamma': 0.04615854349345635, 'grow_policy': 'depthwise'}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:25,135]\u001b[0m Trial 29 finished with value: 0.4046990034911487 and parameters: {'booster': 'gbtree', 'lambda': 1.9812506663618154e-05, 'alpha': 0.023002653956406584, 'subsample': 0.458130039711863, 'colsample_bytree': 0.9454294714091069, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.028122600197200545, 'gamma': 8.399051087857845e-07, 'grow_policy': 'depthwise'}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:26,703]\u001b[0m Trial 30 finished with value: 1.2398657101507709 and parameters: {'booster': 'dart', 'lambda': 1.1533869806156749e-07, 'alpha': 0.0045067780335438954, 'subsample': 0.7804349096290335, 'colsample_bytree': 0.7186229091174645, 'max_depth': 7, 'min_child_weight': 5, 'eta': 1.3378047160681771e-06, 'gamma': 4.303837490727871e-07, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 2.4127656982656295e-08, 'skip_drop': 1.3570293836386155e-05}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:27,091]\u001b[0m Trial 31 finished with value: 0.4187934214611846 and parameters: {'booster': 'gbtree', 'lambda': 3.9638440376922225e-08, 'alpha': 3.0934700261789273e-06, 'subsample': 0.989614751646976, 'colsample_bytree': 0.6359224097379585, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.17880281385638414, 'gamma': 0.0005352824140775364, 'grow_policy': 'depthwise'}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:27,491]\u001b[0m Trial 32 finished with value: 0.4671178751681878 and parameters: {'booster': 'gbtree', 'lambda': 2.6560166021814004e-08, 'alpha': 4.26866600048864e-07, 'subsample': 0.9219624248700713, 'colsample_bytree': 0.63172911225204, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.2287748637068735, 'gamma': 1.1751183078593452e-05, 'grow_policy': 'depthwise'}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:27,844]\u001b[0m Trial 33 finished with value: 0.397605992336443 and parameters: {'booster': 'gbtree', 'lambda': 3.3031978786054194e-07, 'alpha': 4.245829974074278e-06, 'subsample': 0.9950361200501187, 'colsample_bytree': 0.4870465790631092, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.04230389418728828, 'gamma': 0.00010675257510619961, 'grow_policy': 'depthwise'}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:28,152]\u001b[0m Trial 34 finished with value: 0.7925698996845475 and parameters: {'booster': 'gbtree', 'lambda': 4.375523939512173e-07, 'alpha': 1.539157077444503e-08, 'subsample': 0.8969297698273905, 'colsample_bytree': 0.4766068654341819, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.004335011667067537, 'gamma': 0.00010145468901353424, 'grow_policy': 'depthwise'}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:28,398]\u001b[0m Trial 35 finished with value: 0.39302996631535314 and parameters: {'booster': 'gbtree', 'lambda': 1.9469325405846766e-06, 'alpha': 2.4749473119859326e-05, 'subsample': 0.9607331304501457, 'colsample_bytree': 0.5078724765548145, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.035121356473716225, 'gamma': 0.0001077996701857321, 'grow_policy': 'depthwise'}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:28,644]\u001b[0m Trial 36 finished with value: 0.40904426288703793 and parameters: {'booster': 'gbtree', 'lambda': 2.47978949656749e-06, 'alpha': 7.77552862371458e-05, 'subsample': 0.9483364090814095, 'colsample_bytree': 0.4925137221815841, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.022995783388014095, 'gamma': 0.0018701395047874885, 'grow_policy': 'depthwise'}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:28,779]\u001b[0m Trial 37 finished with value: 0.4674450006180808 and parameters: {'booster': 'gblinear', 'lambda': 2.1722972096463068e-06, 'alpha': 1.2226224542610101e-05, 'subsample': 0.9626367451093, 'colsample_bytree': 0.4094648041744126}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:29,017]\u001b[0m Trial 38 finished with value: 1.183120187121863 and parameters: {'booster': 'gbtree', 'lambda': 0.03275421411167708, 'alpha': 0.00030285449543377725, 'subsample': 0.7880309046384425, 'colsample_bytree': 0.4335457555094369, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.00041709273822078613, 'gamma': 5.84222045938145e-06, 'grow_policy': 'depthwise'}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:30,427]\u001b[0m Trial 39 finished with value: 0.402943731641738 and parameters: {'booster': 'dart', 'lambda': 1.881475226302425e-05, 'alpha': 3.063738437959354e-05, 'subsample': 0.8282837940721967, 'colsample_bytree': 0.5124810208159944, 'max_depth': 3, 'min_child_weight': 8, 'eta': 0.3000541362785522, 'gamma': 0.0539869418449439, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 6.517909107435393e-05, 'skip_drop': 8.422242660330388e-08}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:30,562]\u001b[0m Trial 40 finished with value: 0.4663507121256637 and parameters: {'booster': 'gblinear', 'lambda': 2.4591751436964905e-07, 'alpha': 2.9377221826026216e-05, 'subsample': 0.3956368213179252, 'colsample_bytree': 0.33795317986524137}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:30,872]\u001b[0m Trial 41 finished with value: 0.3873282623965062 and parameters: {'booster': 'gbtree', 'lambda': 1.2674041149105244e-07, 'alpha': 6.696786393502515e-08, 'subsample': 0.8586987126337574, 'colsample_bytree': 0.5867542626038954, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.04611427879478517, 'gamma': 1.4156647509745732e-08, 'grow_policy': 'depthwise'}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:31,265]\u001b[0m Trial 42 finished with value: 0.8295434217322909 and parameters: {'booster': 'gbtree', 'lambda': 3.578942884843472e-07, 'alpha': 1.5069213068744672e-06, 'subsample': 0.9351490221782836, 'colsample_bytree': 0.5923683053776102, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.0035675967009418954, 'gamma': 2.09007130348465e-07, 'grow_policy': 'depthwise'}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:31,576]\u001b[0m Trial 43 finished with value: 0.40458501182102263 and parameters: {'booster': 'gbtree', 'lambda': 1.2480562071821505e-07, 'alpha': 4.42348735894523e-08, 'subsample': 0.9978479612668671, 'colsample_bytree': 0.5326849707680144, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.021434453928947966, 'gamma': 1.0207637427446268e-08, 'grow_policy': 'depthwise'}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:31,827]\u001b[0m Trial 44 finished with value: 0.4689137694780017 and parameters: {'booster': 'gbtree', 'lambda': 2.2125878275479403e-06, 'alpha': 6.479303818518287e-06, 'subsample': 0.9017715897035421, 'colsample_bytree': 0.5895619548193761, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.31937072202260874, 'gamma': 9.742223929596861e-05, 'grow_policy': 'lossguide'}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:32,006]\u001b[0m Trial 45 finished with value: 1.2357000259262267 and parameters: {'booster': 'gbtree', 'lambda': 2.261961115220277e-08, 'alpha': 0.0001928109465178192, 'subsample': 0.29338964953604085, 'colsample_bytree': 0.4445994562495545, 'max_depth': 3, 'min_child_weight': 8, 'eta': 3.302399645146531e-05, 'gamma': 1.1796882904157584e-08, 'grow_policy': 'depthwise'}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:12:32,141]\u001b[0m Trial 46 finished with value: 0.47049363008026895 and parameters: {'booster': 'gblinear', 'lambda': 2.0760320029487784e-07, 'alpha': 7.188500662427275e-08, 'subsample': 0.7500527737700996, 'colsample_bytree': 0.5523860383508412}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:33,643]\u001b[0m Trial 47 finished with value: 0.4211966846190035 and parameters: {'booster': 'dart', 'lambda': 0.6640391051019788, 'alpha': 0.9517083137337833, 'subsample': 0.8675876594131022, 'colsample_bytree': 0.33983518907761273, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.056578051911800924, 'gamma': 4.14428877854054e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.0002633279174037596, 'skip_drop': 0.0003270210582496725}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:33,979]\u001b[0m Trial 48 finished with value: 0.5554420908837493 and parameters: {'booster': 'gbtree', 'lambda': 0.0002525563572573683, 'alpha': 4.648522637277567e-07, 'subsample': 0.8075874380632193, 'colsample_bytree': 0.4669482665607058, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.4591459335983356, 'gamma': 4.110942803166201e-08, 'grow_policy': 'depthwise'}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:35,370]\u001b[0m Trial 49 finished with value: 0.5569860971744246 and parameters: {'booster': 'dart', 'lambda': 1.0344104752185713e-08, 'alpha': 6.028311008731923e-06, 'subsample': 0.5762020129144533, 'colsample_bytree': 0.6746870196362601, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.00988960692479286, 'gamma': 1.0424064986046602e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.029828183159963436, 'skip_drop': 0.00026945606947537814}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:35,586]\u001b[0m Trial 50 finished with value: 0.8257375495698562 and parameters: {'booster': 'gbtree', 'lambda': 9.562832194298584e-06, 'alpha': 0.0004747707179398074, 'subsample': 0.973780482172304, 'colsample_bytree': 0.2746869898505269, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.9307856860345737, 'gamma': 0.3176247820825698, 'grow_policy': 'lossguide'}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:35,967]\u001b[0m Trial 51 finished with value: 0.3937016544374887 and parameters: {'booster': 'gbtree', 'lambda': 1.0447279592813273e-07, 'alpha': 1.782160132477868e-07, 'subsample': 0.8493182024027853, 'colsample_bytree': 0.9669116668610432, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.05536258557190087, 'gamma': 0.00014494136959594065, 'grow_policy': 'depthwise'}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:36,346]\u001b[0m Trial 52 finished with value: 1.240074137453204 and parameters: {'booster': 'gbtree', 'lambda': 6.170893092965863e-07, 'alpha': 2.1647032178758156e-08, 'subsample': 0.9310841365063853, 'colsample_bytree': 0.9592406092167532, 'max_depth': 7, 'min_child_weight': 8, 'eta': 3.439815918323427e-08, 'gamma': 0.00020906573483828704, 'grow_policy': 'depthwise'}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:36,731]\u001b[0m Trial 53 finished with value: 0.4104875733325256 and parameters: {'booster': 'gbtree', 'lambda': 1.336319361842155e-07, 'alpha': 6.392305110468203e-07, 'subsample': 0.8876690596619207, 'colsample_bytree': 0.9723607949528675, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.09702719129593582, 'gamma': 0.007532870055886153, 'grow_policy': 'depthwise'}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:37,092]\u001b[0m Trial 54 finished with value: 0.46634199532380716 and parameters: {'booster': 'gbtree', 'lambda': 1.0461256095441412e-06, 'alpha': 1.1142682321773009e-08, 'subsample': 0.685568070910227, 'colsample_bytree': 0.7548886189359882, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.012270061524134953, 'gamma': 0.001926147430261155, 'grow_policy': 'depthwise'}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:38,526]\u001b[0m Trial 55 finished with value: 0.7137322155252056 and parameters: {'booster': 'dart', 'lambda': 0.0021547136987152085, 'alpha': 2.2684998614421985e-07, 'subsample': 0.5279564350210616, 'colsample_bytree': 0.8914154236233423, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.0054003624045668615, 'gamma': 9.233051324188038e-05, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.00023447703672580634, 'skip_drop': 1.3328292391729114e-06}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:38,872]\u001b[0m Trial 56 finished with value: 0.3977794450146683 and parameters: {'booster': 'gbtree', 'lambda': 1.8269324350645353e-08, 'alpha': 8.382315332170043e-08, 'subsample': 0.8548719081697288, 'colsample_bytree': 0.5259373073198551, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.04432124914680885, 'gamma': 1.047157822701733e-05, 'grow_policy': 'lossguide'}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:39,047]\u001b[0m Trial 57 finished with value: 0.4719104023437323 and parameters: {'booster': 'gblinear', 'lambda': 3.681142128350082e-07, 'alpha': 1.7360357653259063e-06, 'subsample': 0.7515368083957376, 'colsample_bytree': 0.7995571890254358}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:39,348]\u001b[0m Trial 58 finished with value: 0.42800439492469416 and parameters: {'booster': 'gbtree', 'lambda': 6.828709227122467e-08, 'alpha': 8.017520771000613e-05, 'subsample': 0.9552759343191749, 'colsample_bytree': 0.38500595385993297, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.1455825372246815, 'gamma': 0.0008027327391595784, 'grow_policy': 'depthwise'}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:40,976]\u001b[0m Trial 59 finished with value: 0.4250302602866285 and parameters: {'booster': 'dart', 'lambda': 1.5828068960390818e-06, 'alpha': 1.648266741683411e-05, 'subsample': 0.8047120702666613, 'colsample_bytree': 0.5694263961894237, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.018331637796841743, 'gamma': 0.14089802640522012, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 5.747331958457424e-06, 'skip_drop': 1.0126970156855626e-08}. Best is trial 19 with value: 0.38231869617904013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:41,403]\u001b[0m A new study created in memory with name: no-name-044ad5a8-ba65-4a72-b5cf-b989878ef237\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:42,886]\u001b[0m Trial 0 finished with value: 1.3244778538307278 and parameters: {'booster': 'dart', 'lambda': 0.025602789716487547, 'alpha': 0.00015971699934845754, 'subsample': 0.9049200484428506, 'colsample_bytree': 0.6850639143990037, 'max_depth': 7, 'min_child_weight': 6, 'eta': 4.9697044602616924e-05, 'gamma': 5.324300244419841e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.02394292021162262, 'skip_drop': 8.318158938726283e-08}. Best is trial 0 with value: 1.3244778538307278.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:43,009]\u001b[0m Trial 1 finished with value: 1.0419572629468614 and parameters: {'booster': 'gblinear', 'lambda': 0.0020116440358557215, 'alpha': 5.0849920494848436e-08, 'subsample': 0.5442897244964746, 'colsample_bytree': 0.7554478379932601}. Best is trial 1 with value: 1.0419572629468614.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:43,135]\u001b[0m Trial 2 finished with value: 1.017823590394736 and parameters: {'booster': 'gblinear', 'lambda': 0.15271390113605332, 'alpha': 5.118822828399026e-06, 'subsample': 0.5602831539669619, 'colsample_bytree': 0.48430596742431686}. Best is trial 2 with value: 1.017823590394736.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:43,258]\u001b[0m Trial 3 finished with value: 1.0363902949085864 and parameters: {'booster': 'gblinear', 'lambda': 6.278814774364677e-06, 'alpha': 0.000550453466904618, 'subsample': 0.9722014444949534, 'colsample_bytree': 0.23225382915429363}. Best is trial 2 with value: 1.017823590394736.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:44,678]\u001b[0m Trial 4 finished with value: 1.3281825103606388 and parameters: {'booster': 'dart', 'lambda': 0.002581748777537279, 'alpha': 4.174742007656599e-06, 'subsample': 0.3238540655190941, 'colsample_bytree': 0.6651348266333099, 'max_depth': 5, 'min_child_weight': 2, 'eta': 4.04892643130621e-06, 'gamma': 0.0001320190988780217, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.00031784864840280613, 'skip_drop': 5.14638229448891e-08}. Best is trial 2 with value: 1.017823590394736.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:12:44,800]\u001b[0m Trial 5 finished with value: 1.0394255824508571 and parameters: {'booster': 'gblinear', 'lambda': 1.7492513727926061e-06, 'alpha': 0.0004671474800562277, 'subsample': 0.6072623604306018, 'colsample_bytree': 0.42626107910010785}. Best is trial 2 with value: 1.017823590394736.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:44,924]\u001b[0m Trial 6 finished with value: 1.051225962738503 and parameters: {'booster': 'gblinear', 'lambda': 2.8823598263141326e-06, 'alpha': 0.00013896579405210104, 'subsample': 0.5427460871718692, 'colsample_bytree': 0.8254303136750183}. Best is trial 2 with value: 1.017823590394736.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:46,382]\u001b[0m Trial 7 finished with value: 1.3284268435737496 and parameters: {'booster': 'dart', 'lambda': 2.1326196944919686e-07, 'alpha': 0.20596217130813568, 'subsample': 0.4516589972501634, 'colsample_bytree': 0.6300940900001231, 'max_depth': 3, 'min_child_weight': 6, 'eta': 1.4434800932011797e-07, 'gamma': 1.679374811658845e-06, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.012219079439892536, 'skip_drop': 1.573133629331014e-05}. Best is trial 2 with value: 1.017823590394736.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:47,872]\u001b[0m Trial 8 finished with value: 1.2711080052560098 and parameters: {'booster': 'dart', 'lambda': 2.9364289933794518e-05, 'alpha': 1.1524255329891797e-05, 'subsample': 0.412410192431112, 'colsample_bytree': 0.9954877108324109, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.0009253213156487475, 'gamma': 0.07032062461742848, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.0014086614481766135, 'skip_drop': 3.550850693683135e-06}. Best is trial 2 with value: 1.017823590394736.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:47,995]\u001b[0m Trial 9 finished with value: 1.0175681545612416 and parameters: {'booster': 'gblinear', 'lambda': 0.15043510551956474, 'alpha': 1.6471235548438047e-07, 'subsample': 0.21951763365226853, 'colsample_bytree': 0.8370878067959915}. Best is trial 9 with value: 1.0175681545612416.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:48,291]\u001b[0m Trial 10 finished with value: 57.15567082622952 and parameters: {'booster': 'gbtree', 'lambda': 0.6094374601423541, 'alpha': 1.1441310014953246e-08, 'subsample': 0.2350933677006035, 'colsample_bytree': 0.9500415386963452, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.7573588690337009, 'gamma': 1.0442448900904778e-08, 'grow_policy': 'lossguide'}. Best is trial 9 with value: 1.0175681545612416.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:48,429]\u001b[0m Trial 11 finished with value: 1.0432599081513483 and parameters: {'booster': 'gblinear', 'lambda': 0.7316057921061991, 'alpha': 5.695000829536583e-07, 'subsample': 0.7442899160524632, 'colsample_bytree': 0.46725781216612616}. Best is trial 9 with value: 1.0175681545612416.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:48,827]\u001b[0m Trial 12 finished with value: 1.3018735621417814 and parameters: {'booster': 'gbtree', 'lambda': 0.014176072503141892, 'alpha': 3.4556700714070486e-07, 'subsample': 0.7914534863187779, 'colsample_bytree': 0.5205292669042838, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.44801768992548535, 'gamma': 0.22583927444567983, 'grow_policy': 'lossguide'}. Best is trial 9 with value: 1.0175681545612416.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:48,961]\u001b[0m Trial 13 finished with value: 1.0273630613730955 and parameters: {'booster': 'gblinear', 'lambda': 1.147422085597595e-08, 'alpha': 0.010098872995716395, 'subsample': 0.2187453734316743, 'colsample_bytree': 0.2967694898067904}. Best is trial 9 with value: 1.0175681545612416.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:49,100]\u001b[0m Trial 14 finished with value: 1.0141717374272226 and parameters: {'booster': 'gblinear', 'lambda': 0.08126272149659473, 'alpha': 6.439068110884124e-06, 'subsample': 0.6767816458794387, 'colsample_bytree': 0.8309142938545897}. Best is trial 14 with value: 1.0141717374272226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:49,237]\u001b[0m Trial 15 finished with value: 1.050029269332545 and parameters: {'booster': 'gblinear', 'lambda': 0.0002522481452962622, 'alpha': 2.402177136676945e-07, 'subsample': 0.7078095572565016, 'colsample_bytree': 0.8513393657553789}. Best is trial 14 with value: 1.0141717374272226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:49,455]\u001b[0m Trial 16 finished with value: 1.3284353373852862 and parameters: {'booster': 'gbtree', 'lambda': 0.05349713887152953, 'alpha': 1.6493126844997338e-05, 'subsample': 0.6713664237956847, 'colsample_bytree': 0.8938571599755327, 'max_depth': 3, 'min_child_weight': 10, 'eta': 1.0824680881090635e-08, 'gamma': 0.0018427171950097852, 'grow_policy': 'depthwise'}. Best is trial 14 with value: 1.0141717374272226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:49,595]\u001b[0m Trial 17 finished with value: 1.0418329658265515 and parameters: {'booster': 'gblinear', 'lambda': 0.0011092131587440701, 'alpha': 1.0244933483992378e-08, 'subsample': 0.8306544044204638, 'colsample_bytree': 0.769995991383853}. Best is trial 14 with value: 1.0141717374272226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:49,734]\u001b[0m Trial 18 finished with value: 1.0325813065212814 and parameters: {'booster': 'gblinear', 'lambda': 0.0074118849812056685, 'alpha': 1.2698865016486345e-06, 'subsample': 0.44409801303702146, 'colsample_bytree': 0.7316437357335808}. Best is trial 14 with value: 1.0141717374272226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:49,983]\u001b[0m Trial 19 finished with value: 1.0797396422509349 and parameters: {'booster': 'gbtree', 'lambda': 0.19095473183074482, 'alpha': 0.003234885333603563, 'subsample': 0.35882058818247026, 'colsample_bytree': 0.5673648127194493, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.006726909867041341, 'gamma': 2.8020436094675528e-08, 'grow_policy': 'lossguide'}. Best is trial 14 with value: 1.0141717374272226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:50,123]\u001b[0m Trial 20 finished with value: 1.0504088170207244 and parameters: {'booster': 'gblinear', 'lambda': 0.0003692840688216763, 'alpha': 6.403050749111595e-08, 'subsample': 0.6420338026190896, 'colsample_bytree': 0.9107738767247366}. Best is trial 14 with value: 1.0141717374272226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:50,262]\u001b[0m Trial 21 finished with value: 1.0150450550180314 and parameters: {'booster': 'gblinear', 'lambda': 0.11034627975276019, 'alpha': 1.3734983587889524e-05, 'subsample': 0.5258127630754497, 'colsample_bytree': 0.3898081672890875}. Best is trial 14 with value: 1.0141717374272226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:50,402]\u001b[0m Trial 22 finished with value: 1.0137271461388253 and parameters: {'booster': 'gblinear', 'lambda': 0.06891942299184199, 'alpha': 2.9015803884642426e-05, 'subsample': 0.28262826454939666, 'colsample_bytree': 0.3852816271016294}. Best is trial 22 with value: 1.0137271461388253.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:50,545]\u001b[0m Trial 23 finished with value: 1.016759526884384 and parameters: {'booster': 'gblinear', 'lambda': 0.04002280837212522, 'alpha': 3.035578030015017e-05, 'subsample': 0.49833527140031453, 'colsample_bytree': 0.3873647212148358}. Best is trial 22 with value: 1.0137271461388253.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:50,690]\u001b[0m Trial 24 finished with value: 1.0354755819601171 and parameters: {'booster': 'gblinear', 'lambda': 0.00630864433814615, 'alpha': 1.7725917301473203e-06, 'subsample': 0.31412350791346505, 'colsample_bytree': 0.3499686011644208}. Best is trial 22 with value: 1.0137271461388253.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:50,830]\u001b[0m Trial 25 finished with value: 1.0479142084861535 and parameters: {'booster': 'gblinear', 'lambda': 0.9524852784266258, 'alpha': 4.874817904523992e-05, 'subsample': 0.831069015626769, 'colsample_bytree': 0.28413777323816897}. Best is trial 22 with value: 1.0137271461388253.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:50,965]\u001b[0m Trial 26 finished with value: 1.0231128846804376 and parameters: {'booster': 'gblinear', 'lambda': 0.12062368543301222, 'alpha': 0.00471509462623565, 'subsample': 0.3726268676350854, 'colsample_bytree': 0.5648696127836854}. Best is trial 22 with value: 1.0137271461388253.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:52,351]\u001b[0m Trial 27 finished with value: 1.3283149060092807 and parameters: {'booster': 'dart', 'lambda': 5.9038214954246554e-05, 'alpha': 0.00043430982723288865, 'subsample': 0.612891515081208, 'colsample_bytree': 0.20353953822326287, 'max_depth': 3, 'min_child_weight': 4, 'eta': 2.1730147525580574e-06, 'gamma': 0.002520700321663715, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 6.485329454211533e-08, 'skip_drop': 0.18176538518062}. Best is trial 22 with value: 1.0137271461388253.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:12:52,491]\u001b[0m Trial 28 finished with value: 1.048692689476357 and parameters: {'booster': 'gblinear', 'lambda': 0.0005044046344845135, 'alpha': 7.893946025398203e-06, 'subsample': 0.2730395183846192, 'colsample_bytree': 0.34569357369777454}. Best is trial 22 with value: 1.0137271461388253.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:52,766]\u001b[0m Trial 29 finished with value: 1.0030856884682755 and parameters: {'booster': 'gbtree', 'lambda': 0.024804839179196535, 'alpha': 5.373583695200226e-05, 'subsample': 0.9438164617739222, 'colsample_bytree': 0.41591136339709445, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.012142195180409779, 'gamma': 4.154174675263124e-07, 'grow_policy': 'lossguide'}. Best is trial 29 with value: 1.0030856884682755.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:53,063]\u001b[0m Trial 30 finished with value: 0.99576912968169 and parameters: {'booster': 'gbtree', 'lambda': 0.0164262556707798, 'alpha': 7.662294132006696e-05, 'subsample': 0.9193877258860779, 'colsample_bytree': 0.4598434472445041, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.012919862137906614, 'gamma': 3.0630874985217026e-07, 'grow_policy': 'lossguide'}. Best is trial 30 with value: 0.99576912968169.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:53,353]\u001b[0m Trial 31 finished with value: 0.9800718657702708 and parameters: {'booster': 'gbtree', 'lambda': 0.009904656214939371, 'alpha': 0.00010917746610461012, 'subsample': 0.9944771008918829, 'colsample_bytree': 0.4623493217649247, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.01398572578886289, 'gamma': 3.4807263341146975e-07, 'grow_policy': 'lossguide'}. Best is trial 31 with value: 0.9800718657702708.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:53,642]\u001b[0m Trial 32 finished with value: 0.9634013789791687 and parameters: {'booster': 'gbtree', 'lambda': 0.013496139821153032, 'alpha': 7.585781243088234e-05, 'subsample': 0.9900163964408066, 'colsample_bytree': 0.45653677059557973, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.021140536947853603, 'gamma': 5.8063591129827e-07, 'grow_policy': 'lossguide'}. Best is trial 32 with value: 0.9634013789791687.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:53,931]\u001b[0m Trial 33 finished with value: 0.9780213316172275 and parameters: {'booster': 'gbtree', 'lambda': 0.005813638708975489, 'alpha': 8.221478341749545e-05, 'subsample': 0.9897038739216757, 'colsample_bytree': 0.48951365467425323, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.013567045066293365, 'gamma': 5.036996737527094e-07, 'grow_policy': 'lossguide'}. Best is trial 32 with value: 0.9634013789791687.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:54,222]\u001b[0m Trial 34 finished with value: 0.9581614433229525 and parameters: {'booster': 'gbtree', 'lambda': 0.003323462400387469, 'alpha': 0.001362525507723505, 'subsample': 0.9026920893911403, 'colsample_bytree': 0.4955657655112175, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.02980291346524406, 'gamma': 2.6950661388356106e-07, 'grow_policy': 'lossguide'}. Best is trial 34 with value: 0.9581614433229525.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:54,521]\u001b[0m Trial 35 finished with value: 0.9685547754578636 and parameters: {'booster': 'gbtree', 'lambda': 0.002429216975469315, 'alpha': 0.035111851856076265, 'subsample': 0.9995146994550432, 'colsample_bytree': 0.5191536749417485, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.05096988677788917, 'gamma': 1.1655994727928712e-05, 'grow_policy': 'lossguide'}. Best is trial 34 with value: 0.9581614433229525.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:54,819]\u001b[0m Trial 36 finished with value: 1.0383173915808244 and parameters: {'booster': 'gbtree', 'lambda': 0.0022197503552386943, 'alpha': 0.353975326651276, 'subsample': 0.8825343490208508, 'colsample_bytree': 0.5154568080986657, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.12331819535820894, 'gamma': 1.6208510156691344e-05, 'grow_policy': 'lossguide'}. Best is trial 34 with value: 0.9581614433229525.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:55,071]\u001b[0m Trial 37 finished with value: 1.276634796783677 and parameters: {'booster': 'gbtree', 'lambda': 0.003480178352478608, 'alpha': 0.058682845268756924, 'subsample': 0.8779986593862761, 'colsample_bytree': 0.6069475228420921, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.0007422052859104243, 'gamma': 4.256285274371455e-05, 'grow_policy': 'lossguide'}. Best is trial 34 with value: 0.9581614433229525.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:55,432]\u001b[0m Trial 38 finished with value: 0.9969279236110735 and parameters: {'booster': 'gbtree', 'lambda': 0.0008642792941391264, 'alpha': 0.0012117228513329724, 'subsample': 0.9460149909287046, 'colsample_bytree': 0.5561675147861993, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.08621993079863732, 'gamma': 1.1683608268421839e-07, 'grow_policy': 'lossguide'}. Best is trial 34 with value: 0.9581614433229525.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:55,718]\u001b[0m Trial 39 finished with value: 1.2713329801685058 and parameters: {'booster': 'gbtree', 'lambda': 0.00013410206840268384, 'alpha': 0.01842291818471686, 'subsample': 0.9866858022990541, 'colsample_bytree': 0.5262886847450634, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.0008786936879557981, 'gamma': 2.815273798559057e-06, 'grow_policy': 'lossguide'}. Best is trial 34 with value: 0.9581614433229525.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:56,039]\u001b[0m Trial 40 finished with value: 0.9615195082462171 and parameters: {'booster': 'gbtree', 'lambda': 1.7679550192402185e-05, 'alpha': 0.00028387391316853354, 'subsample': 0.8472360675453038, 'colsample_bytree': 0.6828177712676323, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.0703252006131752, 'gamma': 1.6219015581342315e-06, 'grow_policy': 'lossguide'}. Best is trial 34 with value: 0.9581614433229525.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:56,362]\u001b[0m Trial 41 finished with value: 0.9865935447041626 and parameters: {'booster': 'gbtree', 'lambda': 2.010616697735866e-05, 'alpha': 0.0010448993516987465, 'subsample': 0.912126177408377, 'colsample_bytree': 0.6640554727446937, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.08934840675355676, 'gamma': 1.4319210868087312e-06, 'grow_policy': 'lossguide'}. Best is trial 34 with value: 0.9581614433229525.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:56,675]\u001b[0m Trial 42 finished with value: 0.9378759866835668 and parameters: {'booster': 'gbtree', 'lambda': 9.94397610143954e-06, 'alpha': 0.00028899045934842994, 'subsample': 0.8442257038604077, 'colsample_bytree': 0.6421359419467266, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.051384885885334665, 'gamma': 1.0936716956461719e-07, 'grow_policy': 'lossguide'}. Best is trial 42 with value: 0.9378759866835668.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:56,985]\u001b[0m Trial 43 finished with value: 1.0088635991361126 and parameters: {'booster': 'gbtree', 'lambda': 1.0251375025244657e-06, 'alpha': 0.0003249103614147107, 'subsample': 0.8454555690306454, 'colsample_bytree': 0.6375375305144451, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.10067473713140943, 'gamma': 5.242347580242188e-08, 'grow_policy': 'lossguide'}. Best is trial 42 with value: 0.9378759866835668.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:57,250]\u001b[0m Trial 44 finished with value: 1.1545151566378993 and parameters: {'booster': 'gbtree', 'lambda': 7.292139466591204e-06, 'alpha': 0.11699552640568095, 'subsample': 0.8694959605260942, 'colsample_bytree': 0.7277782508290385, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.0028786471355517888, 'gamma': 1.0287250921184673e-05, 'grow_policy': 'lossguide'}. Best is trial 42 with value: 0.9378759866835668.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:57,631]\u001b[0m Trial 45 finished with value: 0.945914392120201 and parameters: {'booster': 'gbtree', 'lambda': 3.7918887661929146e-07, 'alpha': 0.0016624300631215645, 'subsample': 0.7768870091054214, 'colsample_bytree': 0.6931446728171702, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.04531964473304774, 'gamma': 1.125573907836121e-07, 'grow_policy': 'lossguide'}. Best is trial 42 with value: 0.9378759866835668.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:12:59,258]\u001b[0m Trial 46 finished with value: 1.376034818043462 and parameters: {'booster': 'dart', 'lambda': 2.1887886610291967e-07, 'alpha': 0.00021035424311850078, 'subsample': 0.7711263517908968, 'colsample_bytree': 0.6796668463113708, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.39885843874429294, 'gamma': 9.708593879317444e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.6635820463181634e-07, 'skip_drop': 0.10184824804243033}. Best is trial 42 with value: 0.9378759866835668.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:12:59,663]\u001b[0m Trial 47 finished with value: 1.042505159766195 and parameters: {'booster': 'gbtree', 'lambda': 2.1731349277173656e-07, 'alpha': 0.0015796029735776905, 'subsample': 0.7930170052704318, 'colsample_bytree': 0.7599458753278571, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.05184885064767731, 'gamma': 1.621518496600873e-08, 'grow_policy': 'lossguide'}. Best is trial 42 with value: 0.9378759866835668.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:00,019]\u001b[0m Trial 48 finished with value: 1.107448391204984 and parameters: {'booster': 'gbtree', 'lambda': 9.01527955791827e-07, 'alpha': 0.004485461810568154, 'subsample': 0.7307470837676929, 'colsample_bytree': 0.7104352763803066, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.004214093519294776, 'gamma': 1.4270886371719925e-07, 'grow_policy': 'lossguide'}. Best is trial 42 with value: 0.9378759866835668.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:00,275]\u001b[0m Trial 49 finished with value: 0.9359893933835185 and parameters: {'booster': 'gbtree', 'lambda': 1.875320156889733e-08, 'alpha': 0.0006462577173756949, 'subsample': 0.9481588675008168, 'colsample_bytree': 0.6047913476111626, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.03583180490633973, 'gamma': 9.846584365438787e-07, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.9359893933835185.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:00,533]\u001b[0m Trial 50 finished with value: 1.0490717858944205 and parameters: {'booster': 'gbtree', 'lambda': 1.044885377498124e-08, 'alpha': 0.000775335958840595, 'subsample': 0.8017277417161031, 'colsample_bytree': 0.6286602297372615, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.306201996727026, 'gamma': 5.45634463235996e-08, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.9359893933835185.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:00,786]\u001b[0m Trial 51 finished with value: 0.9289231071119112 and parameters: {'booster': 'gbtree', 'lambda': 2.5093419611140604e-08, 'alpha': 0.00023071656731128923, 'subsample': 0.94528088670442, 'colsample_bytree': 0.5902150347180188, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.03171864240400185, 'gamma': 1.026210456466015e-06, 'grow_policy': 'lossguide'}. Best is trial 51 with value: 0.9289231071119112.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:01,058]\u001b[0m Trial 52 finished with value: 1.317847902120119 and parameters: {'booster': 'gbtree', 'lambda': 3.3741308315123914e-08, 'alpha': 0.00019932194936745075, 'subsample': 0.9442007477684893, 'colsample_bytree': 0.787061003242591, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.00013138797629168392, 'gamma': 1.455191293124502e-06, 'grow_policy': 'lossguide'}. Best is trial 51 with value: 0.9289231071119112.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:01,313]\u001b[0m Trial 53 finished with value: 0.9182581032435726 and parameters: {'booster': 'gbtree', 'lambda': 3.683967436641241e-08, 'alpha': 0.0024316914535492226, 'subsample': 0.8477475623182403, 'colsample_bytree': 0.6069135255097758, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.03423878750951646, 'gamma': 1.811435959737162e-07, 'grow_policy': 'lossguide'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:01,565]\u001b[0m Trial 54 finished with value: 1.1890933984789283 and parameters: {'booster': 'gbtree', 'lambda': 6.224105657716031e-08, 'alpha': 0.0022735222022400234, 'subsample': 0.9007732156056547, 'colsample_bytree': 0.5914832180818219, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.0023055516548577916, 'gamma': 1.9420534800919992e-07, 'grow_policy': 'lossguide'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:02,656]\u001b[0m Trial 55 finished with value: 1.0933510101726027 and parameters: {'booster': 'dart', 'lambda': 4.795262326803828e-08, 'alpha': 0.009640694354489557, 'subsample': 0.9469182404813598, 'colsample_bytree': 0.6516366122045425, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.03215850385215021, 'gamma': 3.9449580276953785e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.41762794970616474, 'skip_drop': 0.0021362546192870836}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:02,909]\u001b[0m Trial 56 finished with value: 1.1019932588141497 and parameters: {'booster': 'gbtree', 'lambda': 2.3641645240965667e-08, 'alpha': 0.0005879958019855721, 'subsample': 0.7563269120571072, 'colsample_bytree': 0.6140968348625686, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.2099761643506951, 'gamma': 8.288604581738124e-07, 'grow_policy': 'depthwise'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:03,159]\u001b[0m Trial 57 finished with value: 1.3202408445037752 and parameters: {'booster': 'gbtree', 'lambda': 9.394749851700778e-08, 'alpha': 0.0021842038482594263, 'subsample': 0.8613761024367647, 'colsample_bytree': 0.5841227267144379, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.00011382528353302748, 'gamma': 3.986596746519159e-06, 'grow_policy': 'lossguide'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:03,409]\u001b[0m Trial 58 finished with value: 1.649831522846124 and parameters: {'booster': 'gbtree', 'lambda': 1.384152333878487e-07, 'alpha': 0.009045950872642726, 'subsample': 0.8157024737929544, 'colsample_bytree': 0.5433970162880852, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.905245674663175, 'gamma': 0.0002414937395954041, 'grow_policy': 'lossguide'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:03,606]\u001b[0m Trial 59 finished with value: 0.9378341284741853 and parameters: {'booster': 'gbtree', 'lambda': 4.1843147964895163e-07, 'alpha': 0.9187373188809563, 'subsample': 0.9000197635402241, 'colsample_bytree': 0.4959072424168542, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.02899919890711546, 'gamma': 1.2283386766167114e-08, 'grow_policy': 'depthwise'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:03,824]\u001b[0m Trial 60 finished with value: 1.3279593787151034 and parameters: {'booster': 'gbtree', 'lambda': 4.770651348637759e-07, 'alpha': 0.3428591858189355, 'subsample': 0.9587015116941031, 'colsample_bytree': 0.7941317433301996, 'max_depth': 3, 'min_child_weight': 5, 'eta': 6.9346148584941116e-06, 'gamma': 1.0892321508275996e-08, 'grow_policy': 'depthwise'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:04,037]\u001b[0m Trial 61 finished with value: 0.954709696976207 and parameters: {'booster': 'gbtree', 'lambda': 3.3464418821399793e-06, 'alpha': 0.0007766128811536668, 'subsample': 0.9085421250498275, 'colsample_bytree': 0.7010066979430541, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.020028556025502933, 'gamma': 8.281239509236525e-08, 'grow_policy': 'depthwise'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:04,250]\u001b[0m Trial 62 finished with value: 1.0976967896476724 and parameters: {'booster': 'gbtree', 'lambda': 4.07981730175573e-06, 'alpha': 0.0006753092490672828, 'subsample': 0.9114974157894415, 'colsample_bytree': 0.7154857496007271, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.005330167812607965, 'gamma': 8.30713256335208e-08, 'grow_policy': 'depthwise'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:04,458]\u001b[0m Trial 63 finished with value: 0.9998507956100536 and parameters: {'booster': 'gbtree', 'lambda': 4.2208266136722774e-07, 'alpha': 0.9198353573429623, 'subsample': 0.7160559665556333, 'colsample_bytree': 0.6422049757937214, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.17581360238688903, 'gamma': 3.187324239690848e-08, 'grow_policy': 'depthwise'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:05,895]\u001b[0m Trial 64 finished with value: 0.9642650869470385 and parameters: {'booster': 'dart', 'lambda': 2.1496795871068174e-08, 'alpha': 0.005494830997974996, 'subsample': 0.9239493905492763, 'colsample_bytree': 0.7047172395887669, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.033351514904323226, 'gamma': 2.1530410719729063e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 7.505340558439187e-06, 'skip_drop': 0.0011358419652824068}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:13:06,100]\u001b[0m Trial 65 finished with value: 1.0415477160607878 and parameters: {'booster': 'gbtree', 'lambda': 2.218120407957328e-06, 'alpha': 0.00015479097627821894, 'subsample': 0.8810610979609923, 'colsample_bytree': 0.5820632787478051, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.007822168275883038, 'gamma': 1.155808082522047e-07, 'grow_policy': 'depthwise'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:06,305]\u001b[0m Trial 66 finished with value: 1.2198844195661136 and parameters: {'booster': 'gbtree', 'lambda': 4.814034535984461e-07, 'alpha': 2.3898414966507917e-05, 'subsample': 0.8267747513130305, 'colsample_bytree': 0.6143734868613387, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.0019039643406927858, 'gamma': 4.276983768584074e-08, 'grow_policy': 'depthwise'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:06,513]\u001b[0m Trial 67 finished with value: 0.9629704231703189 and parameters: {'booster': 'gbtree', 'lambda': 8.391006280988162e-06, 'alpha': 0.00042917899282948806, 'subsample': 0.6781967719102954, 'colsample_bytree': 0.6833537876470128, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.020573784883624463, 'gamma': 0.024003330566625604, 'grow_policy': 'depthwise'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:06,773]\u001b[0m Trial 68 finished with value: 1.136716710504369 and parameters: {'booster': 'gbtree', 'lambda': 1.0069022969516291e-06, 'alpha': 0.0027288618494730075, 'subsample': 0.7832103790737754, 'colsample_bytree': 0.6519357920209973, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.2422957441950317, 'gamma': 2.1522582841617636e-07, 'grow_policy': 'depthwise'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:07,044]\u001b[0m Trial 69 finished with value: 1.297672578933817 and parameters: {'booster': 'gbtree', 'lambda': 1.095830911624643e-07, 'alpha': 0.01332852020469001, 'subsample': 0.8524926685946402, 'colsample_bytree': 0.7413375020353541, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.00040097892807804987, 'gamma': 7.210407899519812e-07, 'grow_policy': 'depthwise'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:07,245]\u001b[0m Trial 70 finished with value: 1.0389622838552155 and parameters: {'booster': 'gbtree', 'lambda': 1.7371507044654978e-08, 'alpha': 4.572565707587388e-05, 'subsample': 0.9627055752446473, 'colsample_bytree': 0.5495376905763227, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.009088781385732056, 'gamma': 1.8262122668046208e-08, 'grow_policy': 'depthwise'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:07,499]\u001b[0m Trial 71 finished with value: 0.9293302922098913 and parameters: {'booster': 'gbtree', 'lambda': 6.017067463377412e-08, 'alpha': 0.0016829464649170595, 'subsample': 0.9111663573783712, 'colsample_bytree': 0.5777050364253241, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.03157811157880525, 'gamma': 2.901756493770478e-07, 'grow_policy': 'lossguide'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:07,750]\u001b[0m Trial 72 finished with value: 0.9411303591125748 and parameters: {'booster': 'gbtree', 'lambda': 5.546674649677668e-08, 'alpha': 0.025634788329205665, 'subsample': 0.9281678014864948, 'colsample_bytree': 0.5748674471871241, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.031165106778212066, 'gamma': 3.113203013965449e-07, 'grow_policy': 'lossguide'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:08,002]\u001b[0m Trial 73 finished with value: 0.9338875411121174 and parameters: {'booster': 'gbtree', 'lambda': 5.693965589784418e-08, 'alpha': 0.04733539612182657, 'subsample': 0.8883033716455112, 'colsample_bytree': 0.577551943039242, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.03663831339016034, 'gamma': 3.010248841359314e-07, 'grow_policy': 'lossguide'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:08,256]\u001b[0m Trial 74 finished with value: 1.3284321041492475 and parameters: {'booster': 'gbtree', 'lambda': 3.849305510288018e-08, 'alpha': 0.04885495091547029, 'subsample': 0.969451187082618, 'colsample_bytree': 0.5753530395073064, 'max_depth': 5, 'min_child_weight': 8, 'eta': 3.585557179449768e-08, 'gamma': 4.1185699115147053e-07, 'grow_policy': 'lossguide'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:08,498]\u001b[0m Trial 75 finished with value: 0.9786130379436668 and parameters: {'booster': 'gbtree', 'lambda': 7.961943751995245e-08, 'alpha': 0.02384542760614482, 'subsample': 0.9337582299611463, 'colsample_bytree': 0.4961282483805516, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.012841927146736563, 'gamma': 8.264080379672662e-07, 'grow_policy': 'lossguide'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:09,979]\u001b[0m Trial 76 finished with value: 1.0016041098455868 and parameters: {'booster': 'dart', 'lambda': 1.4911400754308445e-08, 'alpha': 0.6253018483229092, 'subsample': 0.8752719620011714, 'colsample_bytree': 0.5427487505699133, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.1270129555928649, 'gamma': 2.5365572806572214e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 5.313048588778757e-06, 'skip_drop': 0.835314738512449}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:10,237]\u001b[0m Trial 77 finished with value: 1.2241203030685264 and parameters: {'booster': 'gbtree', 'lambda': 1.3716173175937708e-07, 'alpha': 0.0867134863337819, 'subsample': 0.8998584199126282, 'colsample_bytree': 0.5966262618536045, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.5681645897635605, 'gamma': 2.817490532781071e-07, 'grow_policy': 'lossguide'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:10,493]\u001b[0m Trial 78 finished with value: 0.9289803121626922 and parameters: {'booster': 'gbtree', 'lambda': 3.1722913530019195e-08, 'alpha': 0.17877836809441383, 'subsample': 0.9676246205718119, 'colsample_bytree': 0.6141738761954948, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.02009628039134104, 'gamma': 5.967666896486009e-06, 'grow_policy': 'lossguide'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:10,739]\u001b[0m Trial 79 finished with value: 0.9497918580566919 and parameters: {'booster': 'gbtree', 'lambda': 2.9179566551413093e-08, 'alpha': 0.3072947140616648, 'subsample': 0.971643929654021, 'colsample_bytree': 0.6265123444599511, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.06290873368923808, 'gamma': 7.099063335397338e-06, 'grow_policy': 'lossguide'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:10,963]\u001b[0m Trial 80 finished with value: 1.069252117969525 and parameters: {'booster': 'gbtree', 'lambda': 1.1028134277959752e-08, 'alpha': 0.14799586468361228, 'subsample': 0.8888237010613025, 'colsample_bytree': 0.4455130273714142, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.006695582153027009, 'gamma': 4.1073072225202555e-05, 'grow_policy': 'lossguide'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:11,201]\u001b[0m Trial 81 finished with value: 0.9302934777615913 and parameters: {'booster': 'gbtree', 'lambda': 4.7240649650800245e-08, 'alpha': 0.19856497034223097, 'subsample': 0.9340323421968324, 'colsample_bytree': 0.5704428338028937, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.0250045684116403, 'gamma': 7.320579721306081e-07, 'grow_policy': 'lossguide'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:11,434]\u001b[0m Trial 82 finished with value: 0.9359745960585804 and parameters: {'booster': 'gbtree', 'lambda': 4.332957602743e-08, 'alpha': 0.1944088951747848, 'subsample': 0.9340591911233236, 'colsample_bytree': 0.5262413719001998, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.02039435307230079, 'gamma': 1.223377296951313e-06, 'grow_policy': 'lossguide'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:11,668]\u001b[0m Trial 83 finished with value: 0.9557010910060186 and parameters: {'booster': 'gbtree', 'lambda': 4.056953574478116e-08, 'alpha': 0.1939910284183459, 'subsample': 0.9681586052307445, 'colsample_bytree': 0.5304462062777558, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.015775367436794595, 'gamma': 9.618271670509995e-07, 'grow_policy': 'lossguide'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:13:11,900]\u001b[0m Trial 84 finished with value: 0.9269410405619675 and parameters: {'booster': 'gbtree', 'lambda': 1.9663225542877578e-08, 'alpha': 0.07722445879263919, 'subsample': 0.9264620037240563, 'colsample_bytree': 0.5105765282618367, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.026225306038565138, 'gamma': 2.5468640510696653e-06, 'grow_policy': 'lossguide'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:12,140]\u001b[0m Trial 85 finished with value: 0.9898449968826804 and parameters: {'booster': 'gbtree', 'lambda': 1.950889287144751e-08, 'alpha': 0.07058253058285911, 'subsample': 0.9343897025822949, 'colsample_bytree': 0.5607538133226114, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.09241728505021375, 'gamma': 3.334115330392012e-06, 'grow_policy': 'lossguide'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:12,375]\u001b[0m Trial 86 finished with value: 1.1106310261811605 and parameters: {'booster': 'gbtree', 'lambda': 7.069445954736296e-08, 'alpha': 0.12052865981346703, 'subsample': 0.9771304256533057, 'colsample_bytree': 0.5125870696510977, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.004595284521265298, 'gamma': 5.6450392649048754e-06, 'grow_policy': 'lossguide'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:12,607]\u001b[0m Trial 87 finished with value: 1.0006252597116883 and parameters: {'booster': 'gbtree', 'lambda': 1.6575148456030575e-07, 'alpha': 0.4564988031061781, 'subsample': 0.5716650777983796, 'colsample_bytree': 0.6041504940690361, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.011293264086872984, 'gamma': 2.1225563511585734e-06, 'grow_policy': 'lossguide'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:12,834]\u001b[0m Trial 88 finished with value: 1.3277537736436436 and parameters: {'booster': 'gbtree', 'lambda': 3.1807414969252696e-08, 'alpha': 0.04422090444248818, 'subsample': 0.9989465042302447, 'colsample_bytree': 0.47680072157239684, 'max_depth': 5, 'min_child_weight': 7, 'eta': 1.0327280947272043e-05, 'gamma': 5.507530367108333e-07, 'grow_policy': 'lossguide'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:13,054]\u001b[0m Trial 89 finished with value: 1.3283905559455615 and parameters: {'booster': 'gbtree', 'lambda': 5.472768331231063e-08, 'alpha': 0.2122603804222752, 'subsample': 0.9533204427171694, 'colsample_bytree': 0.4253432028385955, 'max_depth': 5, 'min_child_weight': 9, 'eta': 6.853225348257295e-07, 'gamma': 1.996196215081791e-05, 'grow_policy': 'lossguide'}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:14,466]\u001b[0m Trial 90 finished with value: 1.0422115971822745 and parameters: {'booster': 'dart', 'lambda': 1.498869480815651e-08, 'alpha': 0.08266214348494612, 'subsample': 0.9243371955002448, 'colsample_bytree': 0.5333870251340419, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.14065287375988436, 'gamma': 1.3346178079903465e-06, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 5.263308772836628e-06, 'skip_drop': 2.3994742501768038e-06}. Best is trial 53 with value: 0.9182581032435726.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:14,735]\u001b[0m A new study created in memory with name: no-name-31f7b152-3b28-471f-aa8b-06757a79109a\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:16,168]\u001b[0m Trial 0 finished with value: 1.0891199387439845 and parameters: {'booster': 'dart', 'lambda': 8.013718780067236e-07, 'alpha': 0.0004511895917826572, 'subsample': 0.3480927846358607, 'colsample_bytree': 0.5023956401168307, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.00030553720785303376, 'gamma': 0.0005621569100864785, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.0020679969914371875, 'skip_drop': 0.006134205584528284}. Best is trial 0 with value: 1.0891199387439845.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:16,520]\u001b[0m Trial 1 finished with value: 1.1353427736723964 and parameters: {'booster': 'gbtree', 'lambda': 0.000963846809052747, 'alpha': 3.2887385390729624e-08, 'subsample': 0.77239169329649, 'colsample_bytree': 0.9622982812680119, 'max_depth': 7, 'min_child_weight': 8, 'eta': 2.8212086682981228e-05, 'gamma': 6.188553054936541e-06, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 1.0891199387439845.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:16,637]\u001b[0m Trial 2 finished with value: 0.0011229798011972811 and parameters: {'booster': 'gblinear', 'lambda': 1.589472588299625e-05, 'alpha': 3.082763708637292e-08, 'subsample': 0.6404983659681905, 'colsample_bytree': 0.20884522416862775}. Best is trial 2 with value: 0.0011229798011972811.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:17,947]\u001b[0m Trial 3 finished with value: 1.10410205757883 and parameters: {'booster': 'dart', 'lambda': 1.961205483792667e-05, 'alpha': 9.297258216491237e-07, 'subsample': 0.3701021286195883, 'colsample_bytree': 0.5716359103433897, 'max_depth': 3, 'min_child_weight': 9, 'eta': 0.00023760142455581622, 'gamma': 2.3889311345194285e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.3819619538957067e-08, 'skip_drop': 0.00046626439760169796}. Best is trial 2 with value: 0.0011229798011972811.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:19,271]\u001b[0m Trial 4 finished with value: 0.05391467469281062 and parameters: {'booster': 'dart', 'lambda': 1.0218614004857572e-08, 'alpha': 2.2707018959087586e-08, 'subsample': 0.44179445469853373, 'colsample_bytree': 0.6738947597866674, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.041583954144280885, 'gamma': 0.06448341758932563, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.003329628129574976, 'skip_drop': 0.8675905611054981}. Best is trial 2 with value: 0.0011229798011972811.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:19,390]\u001b[0m Trial 5 finished with value: 0.0007439731647725326 and parameters: {'booster': 'gblinear', 'lambda': 7.521402906773134e-07, 'alpha': 1.9976392838902992e-07, 'subsample': 0.944370144088184, 'colsample_bytree': 0.5729695995794868}. Best is trial 5 with value: 0.0007439731647725326.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:19,625]\u001b[0m Trial 6 finished with value: 1.1412453888043126 and parameters: {'booster': 'gbtree', 'lambda': 2.2722321744990405e-07, 'alpha': 1.0168024159804302e-06, 'subsample': 0.7208591310723922, 'colsample_bytree': 0.6775097298065402, 'max_depth': 5, 'min_child_weight': 2, 'eta': 2.085741534035051e-08, 'gamma': 1.9187461244979334e-06, 'grow_policy': 'lossguide'}. Best is trial 5 with value: 0.0007439731647725326.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:19,740]\u001b[0m Trial 7 finished with value: 0.060720985212587536 and parameters: {'booster': 'gblinear', 'lambda': 0.15117351409827978, 'alpha': 0.00012737019565809711, 'subsample': 0.9116802585782062, 'colsample_bytree': 0.8883389143152125}. Best is trial 5 with value: 0.0007439731647725326.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:21,186]\u001b[0m Trial 8 finished with value: 1.1410291572222349 and parameters: {'booster': 'dart', 'lambda': 0.0005032082590371859, 'alpha': 0.01833798159061061, 'subsample': 0.4048100222829284, 'colsample_bytree': 0.6338039703389922, 'max_depth': 9, 'min_child_weight': 9, 'eta': 1.20672221258103e-06, 'gamma': 0.3651659184308234, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 2.075610716232733e-06, 'skip_drop': 0.44462445731153066}. Best is trial 5 with value: 0.0007439731647725326.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:22,562]\u001b[0m Trial 9 finished with value: 0.2604511241470627 and parameters: {'booster': 'dart', 'lambda': 0.14404102416640474, 'alpha': 1.9814676749583759e-07, 'subsample': 0.37762067947369166, 'colsample_bytree': 0.585929167748622, 'max_depth': 5, 'min_child_weight': 2, 'eta': 0.010863276880263046, 'gamma': 0.00045471468516352026, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 3.8119342704771886e-08, 'skip_drop': 0.25574195126042804}. Best is trial 5 with value: 0.0007439731647725326.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:22,661]\u001b[0m Trial 10 finished with value: 0.8532998796289429 and parameters: {'booster': 'gblinear', 'lambda': 3.011101916963949e-08, 'alpha': 0.5263419789975377, 'subsample': 0.9512614356887945, 'colsample_bytree': 0.3502094763963413}. Best is trial 5 with value: 0.0007439731647725326.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:13:22,793]\u001b[0m Trial 11 finished with value: 0.0010961571916720198 and parameters: {'booster': 'gblinear', 'lambda': 9.60052407291919e-06, 'alpha': 6.219900190951584e-06, 'subsample': 0.6156189903889183, 'colsample_bytree': 0.29125151246655284}. Best is trial 5 with value: 0.0007439731647725326.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:22,924]\u001b[0m Trial 12 finished with value: 0.0012891623438320667 and parameters: {'booster': 'gblinear', 'lambda': 1.4738021397683167e-06, 'alpha': 6.939522370363623e-06, 'subsample': 0.5189187158200752, 'colsample_bytree': 0.4134772627172558}. Best is trial 5 with value: 0.0007439731647725326.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:23,054]\u001b[0m Trial 13 finished with value: 0.0011729966849066877 and parameters: {'booster': 'gblinear', 'lambda': 1.424161197065769e-05, 'alpha': 8.482826735560876e-06, 'subsample': 0.2394290827173738, 'colsample_bytree': 0.2020576614387556}. Best is trial 5 with value: 0.0007439731647725326.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:23,185]\u001b[0m Trial 14 finished with value: 0.0004653908534863247 and parameters: {'booster': 'gblinear', 'lambda': 0.004815009584605216, 'alpha': 0.0015688783333886564, 'subsample': 0.8376279199444547, 'colsample_bytree': 0.7662523339244622}. Best is trial 14 with value: 0.0004653908534863247.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:23,313]\u001b[0m Trial 15 finished with value: 0.000881183401580291 and parameters: {'booster': 'gblinear', 'lambda': 0.008980942168873409, 'alpha': 0.002847180440386965, 'subsample': 0.8522125259628646, 'colsample_bytree': 0.8158684620489782}. Best is trial 14 with value: 0.0004653908534863247.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:23,434]\u001b[0m Trial 16 finished with value: 0.008803125070323495 and parameters: {'booster': 'gblinear', 'lambda': 0.01136823857173964, 'alpha': 0.03507190419431061, 'subsample': 0.9911795095237659, 'colsample_bytree': 0.7554027435668612}. Best is trial 14 with value: 0.0004653908534863247.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:23,753]\u001b[0m Trial 17 finished with value: 0.1271375979251256 and parameters: {'booster': 'gbtree', 'lambda': 0.00021498238245494392, 'alpha': 0.0011753237080735844, 'subsample': 0.823512403656223, 'colsample_bytree': 0.4761711912360145, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.3714135797185835, 'gamma': 1.0205662803585615e-08, 'grow_policy': 'depthwise'}. Best is trial 14 with value: 0.0004653908534863247.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:23,883]\u001b[0m Trial 18 finished with value: 0.00063804435369859 and parameters: {'booster': 'gblinear', 'lambda': 0.00354894233209121, 'alpha': 5.151580145856375e-05, 'subsample': 0.6978587202675716, 'colsample_bytree': 0.7858281080405056}. Best is trial 14 with value: 0.0004653908534863247.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:24,015]\u001b[0m Trial 19 finished with value: 0.0009284227602779092 and parameters: {'booster': 'gblinear', 'lambda': 0.006477020640781613, 'alpha': 0.00013184708048913344, 'subsample': 0.7007860274357389, 'colsample_bytree': 0.7957861938129436}. Best is trial 14 with value: 0.0004653908534863247.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:24,230]\u001b[0m Trial 20 finished with value: 1.1412460661589934 and parameters: {'booster': 'gbtree', 'lambda': 0.9261522175675847, 'alpha': 0.008750214504678841, 'subsample': 0.5267775012085595, 'colsample_bytree': 0.9452591692544102, 'max_depth': 3, 'min_child_weight': 6, 'eta': 1.680352003536653e-08, 'gamma': 0.01026493901457481, 'grow_policy': 'depthwise'}. Best is trial 14 with value: 0.0004653908534863247.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:24,362]\u001b[0m Trial 21 finished with value: 0.000806695575586962 and parameters: {'booster': 'gblinear', 'lambda': 0.003267103148845077, 'alpha': 1.9817070290690335e-05, 'subsample': 0.8759720719616707, 'colsample_bytree': 0.714750156704393}. Best is trial 14 with value: 0.0004653908534863247.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:24,469]\u001b[0m Trial 22 finished with value: 0.1888876720863731 and parameters: {'booster': 'gblinear', 'lambda': 0.038696180847776075, 'alpha': 0.18652850534244253, 'subsample': 0.7769489961426808, 'colsample_bytree': 0.8796576066935626}. Best is trial 14 with value: 0.0004653908534863247.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:24,599]\u001b[0m Trial 23 finished with value: 0.0009959794087152018 and parameters: {'booster': 'gblinear', 'lambda': 0.00015091591024851762, 'alpha': 4.109243511693342e-05, 'subsample': 0.9212463118075215, 'colsample_bytree': 0.8419381084838955}. Best is trial 14 with value: 0.0004653908534863247.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:24,730]\u001b[0m Trial 24 finished with value: 0.0007346786837351912 and parameters: {'booster': 'gblinear', 'lambda': 0.0020331117025653217, 'alpha': 2.591763590488765e-07, 'subsample': 0.691742136107766, 'colsample_bytree': 0.749982229538551}. Best is trial 14 with value: 0.0004653908534863247.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:24,860]\u001b[0m Trial 25 finished with value: 0.00045930088121903556 and parameters: {'booster': 'gblinear', 'lambda': 0.0014655994496502798, 'alpha': 0.0003882136011381214, 'subsample': 0.6614469583508297, 'colsample_bytree': 0.7502212930272564}. Best is trial 25 with value: 0.00045930088121903556.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:24,990]\u001b[0m Trial 26 finished with value: 0.006556721240989086 and parameters: {'booster': 'gblinear', 'lambda': 0.026737954683714742, 'alpha': 0.0004751453612105932, 'subsample': 0.5739820755629966, 'colsample_bytree': 0.8855814559817674}. Best is trial 25 with value: 0.00045930088121903556.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:25,119]\u001b[0m Trial 27 finished with value: 7.098037345746466e-05 and parameters: {'booster': 'gblinear', 'lambda': 5.365132183075918e-05, 'alpha': 0.0024400621597055502, 'subsample': 0.758032642001714, 'colsample_bytree': 0.7707010487360323}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:25,249]\u001b[0m Trial 28 finished with value: 0.00014456452839303584 and parameters: {'booster': 'gblinear', 'lambda': 0.0004657275698642955, 'alpha': 0.0025163873057069547, 'subsample': 0.7866711279482503, 'colsample_bytree': 0.9956182177475595}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:25,648]\u001b[0m Trial 29 finished with value: 1.1409419669974241 and parameters: {'booster': 'gbtree', 'lambda': 6.156025075645416e-05, 'alpha': 0.0003763784639334133, 'subsample': 0.76076276613985, 'colsample_bytree': 0.9815624275783525, 'max_depth': 7, 'min_child_weight': 5, 'eta': 1.447639725656935e-06, 'gamma': 1.368550226369751e-06, 'grow_policy': 'depthwise'}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:26,965]\u001b[0m Trial 30 finished with value: 0.0377143682298059 and parameters: {'booster': 'dart', 'lambda': 8.032350759846063e-05, 'alpha': 0.06546877072747115, 'subsample': 0.6664916517830693, 'colsample_bytree': 0.94245196867979, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.8261568023000306, 'gamma': 3.7136405875409546e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.13185471984248845, 'skip_drop': 1.4580058467959211e-08}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:27,100]\u001b[0m Trial 31 finished with value: 8.997816108148222e-05 and parameters: {'booster': 'gblinear', 'lambda': 0.0004848675270722473, 'alpha': 0.0032837825015704695, 'subsample': 0.8219956610141895, 'colsample_bytree': 0.5190299918797288}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:27,233]\u001b[0m Trial 32 finished with value: 0.0002625336606039137 and parameters: {'booster': 'gblinear', 'lambda': 0.00043571083168649475, 'alpha': 0.006354679127462312, 'subsample': 0.7626697236328608, 'colsample_bytree': 0.49944704705821596}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:27,366]\u001b[0m Trial 33 finished with value: 0.00014079906074973013 and parameters: {'booster': 'gblinear', 'lambda': 0.0004041530767753243, 'alpha': 0.004482147789291514, 'subsample': 0.7810666255496376, 'colsample_bytree': 0.5150977195758967}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:27,498]\u001b[0m Trial 34 finished with value: 0.00023231080375993215 and parameters: {'booster': 'gblinear', 'lambda': 3.865801218123426e-05, 'alpha': 0.005900560843364161, 'subsample': 0.8197160437799262, 'colsample_bytree': 0.4332981324993578}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:13:27,616]\u001b[0m Trial 35 finished with value: 0.01401451177523664 and parameters: {'booster': 'gblinear', 'lambda': 4.820041654147322e-06, 'alpha': 0.05559909666471863, 'subsample': 0.7954709188882654, 'colsample_bytree': 0.5313178183999205}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:27,753]\u001b[0m Trial 36 finished with value: 0.000425353008498397 and parameters: {'booster': 'gblinear', 'lambda': 0.0006629184195058956, 'alpha': 0.001096025128596661, 'subsample': 0.8716120241237714, 'colsample_bytree': 0.6129116135686404}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:28,204]\u001b[0m Trial 37 finished with value: 0.4437024821498714 and parameters: {'booster': 'gbtree', 'lambda': 0.00027263809460903313, 'alpha': 0.014624283879447923, 'subsample': 0.7412933544640258, 'colsample_bytree': 0.6538322940783501, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.005717850834763751, 'gamma': 0.0042456225033627604, 'grow_policy': 'depthwise'}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:29,768]\u001b[0m Trial 38 finished with value: 1.1411426356213936 and parameters: {'booster': 'dart', 'lambda': 3.4288218674180132e-06, 'alpha': 0.0029550502638519237, 'subsample': 0.5944640869957943, 'colsample_bytree': 0.5290647255726817, 'max_depth': 5, 'min_child_weight': 7, 'eta': 6.071015778967726e-07, 'gamma': 2.3437161702202046e-07, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.6508738377927765e-05, 'skip_drop': 2.1719948533051056e-07}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:29,896]\u001b[0m Trial 39 finished with value: 0.07681115229256348 and parameters: {'booster': 'gblinear', 'lambda': 3.883192032784979e-05, 'alpha': 0.13014877021870594, 'subsample': 0.8991629316628095, 'colsample_bytree': 0.44127374550176895}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:30,046]\u001b[0m Trial 40 finished with value: 0.00034067289792363386 and parameters: {'booster': 'gblinear', 'lambda': 0.000997920807829179, 'alpha': 0.00027478924713307974, 'subsample': 0.8024142915720816, 'colsample_bytree': 0.3729966091340946}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:30,200]\u001b[0m Trial 41 finished with value: 0.00016301013550463692 and parameters: {'booster': 'gblinear', 'lambda': 3.497845317751262e-05, 'alpha': 0.005559683820227874, 'subsample': 0.8346917738893608, 'colsample_bytree': 0.4575834811643811}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:30,349]\u001b[0m Trial 42 finished with value: 8.051148540631049e-05 and parameters: {'booster': 'gblinear', 'lambda': 0.0001100757161366517, 'alpha': 0.0035090382421810147, 'subsample': 0.965034992941715, 'colsample_bytree': 0.545163501769405}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:30,519]\u001b[0m Trial 43 finished with value: 0.00012451460393518376 and parameters: {'booster': 'gblinear', 'lambda': 0.00013153103594825425, 'alpha': 0.002271899633409856, 'subsample': 0.952676980250754, 'colsample_bytree': 0.5287402612835376}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:31,060]\u001b[0m Trial 44 finished with value: 1.1382360763521786 and parameters: {'booster': 'dart', 'lambda': 0.00015935790898374163, 'alpha': 0.023368750882534272, 'subsample': 0.9944154462794739, 'colsample_bytree': 0.5406153717669651, 'max_depth': 7, 'min_child_weight': 10, 'eta': 1.640121320338093e-05, 'gamma': 0.3280581673500269, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.9023938477997097, 'skip_drop': 9.154565045485928e-06}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:31,207]\u001b[0m Trial 45 finished with value: 0.0004962484347146241 and parameters: {'booster': 'gblinear', 'lambda': 8.147428663889995e-06, 'alpha': 0.0007547635481406739, 'subsample': 0.9617130506923236, 'colsample_bytree': 0.5709735680293881}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:31,356]\u001b[0m Trial 46 finished with value: 0.000718620988876946 and parameters: {'booster': 'gblinear', 'lambda': 2.0379601804360003e-07, 'alpha': 0.012590730864480313, 'subsample': 0.9292860026233407, 'colsample_bytree': 0.6194884517517985}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:31,469]\u001b[0m Trial 47 finished with value: 0.3817998366886912 and parameters: {'booster': 'gblinear', 'lambda': 2.0397449851455706e-05, 'alpha': 0.2915340002308098, 'subsample': 0.9002110348822802, 'colsample_bytree': 0.6838197504058325}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:31,603]\u001b[0m Trial 48 finished with value: 0.0013368096324165193 and parameters: {'booster': 'gblinear', 'lambda': 0.00012432769855677366, 'alpha': 1.1297229317975974e-08, 'subsample': 0.9605624910104682, 'colsample_bytree': 0.3674805524184098}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:31,797]\u001b[0m Trial 49 finished with value: 0.836780101448075 and parameters: {'booster': 'gbtree', 'lambda': 0.0003245548625510102, 'alpha': 0.00014705897818756536, 'subsample': 0.8629415828353212, 'colsample_bytree': 0.49451199757590575, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.002298127685499614, 'gamma': 5.2107675748348514e-05, 'grow_policy': 'lossguide'}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:33,312]\u001b[0m Trial 50 finished with value: 1.1412250922080465 and parameters: {'booster': 'dart', 'lambda': 7.669329539421814e-05, 'alpha': 0.003946192367609835, 'subsample': 0.2654828741915849, 'colsample_bytree': 0.5773635484514961, 'max_depth': 9, 'min_child_weight': 7, 'eta': 1.3839149081273e-07, 'gamma': 2.2274614635433053e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 8.568336338729406e-07, 'skip_drop': 9.25609941111974e-06}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:33,447]\u001b[0m Trial 51 finished with value: 0.00015026317764432824 and parameters: {'booster': 'gblinear', 'lambda': 0.00114711023380697, 'alpha': 0.0020644073303730825, 'subsample': 0.7276130453522585, 'colsample_bytree': 0.5448383136262727}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:33,582]\u001b[0m Trial 52 finished with value: 0.00029411740705951255 and parameters: {'booster': 'gblinear', 'lambda': 0.0006265058791850932, 'alpha': 0.0009776556961356012, 'subsample': 0.8949411330405863, 'colsample_bytree': 0.2786930149772323}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:33,707]\u001b[0m Trial 53 finished with value: 0.0026108646604418727 and parameters: {'booster': 'gblinear', 'lambda': 0.0003006584661797086, 'alpha': 0.023749755532883093, 'subsample': 0.9710670412626923, 'colsample_bytree': 0.39190895506118195}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:33,843]\u001b[0m Trial 54 finished with value: 0.00034080156959486824 and parameters: {'booster': 'gblinear', 'lambda': 1.788715484396663e-05, 'alpha': 0.0015623646849377598, 'subsample': 0.9357976223347074, 'colsample_bytree': 0.6418003953558984}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:33,979]\u001b[0m Trial 55 finished with value: 8.70329664719267e-05 and parameters: {'booster': 'gblinear', 'lambda': 9.987286608373848e-05, 'alpha': 0.0029739705939727263, 'subsample': 0.7943378317268577, 'colsample_bytree': 0.4741194517599807}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:34,099]\u001b[0m Trial 56 finished with value: 0.013051921978337174 and parameters: {'booster': 'gblinear', 'lambda': 2.7667291005705705e-06, 'alpha': 0.053657145560898706, 'subsample': 0.8487924272227254, 'colsample_bytree': 0.481573627943206}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:34,230]\u001b[0m Trial 57 finished with value: 0.0005724181405139669 and parameters: {'booster': 'gblinear', 'lambda': 0.0023868041437958933, 'alpha': 0.009190489663200987, 'subsample': 0.6284071444917626, 'colsample_bytree': 0.3083791328342656}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:13:34,366]\u001b[0m Trial 58 finished with value: 0.00039112753618617034 and parameters: {'booster': 'gblinear', 'lambda': 8.564673727636932e-07, 'alpha': 0.0006674970341664915, 'subsample': 0.7447765659938829, 'colsample_bytree': 0.5947606275549807}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:34,503]\u001b[0m Trial 59 finished with value: 0.0003528969995171141 and parameters: {'booster': 'gblinear', 'lambda': 0.00013245327712280196, 'alpha': 0.00022789006060198192, 'subsample': 0.4544680041415171, 'colsample_bytree': 0.5116293936336647}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:34,650]\u001b[0m Trial 60 finished with value: 9.927304653781876e-05 and parameters: {'booster': 'gblinear', 'lambda': 9.095584744521696e-06, 'alpha': 0.0041604536968068775, 'subsample': 0.8244548271842083, 'colsample_bytree': 0.4102199281125498}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:34,780]\u001b[0m Trial 61 finished with value: 0.000701997639643928 and parameters: {'booster': 'gblinear', 'lambda': 7.828968157903553e-06, 'alpha': 0.012437720373378914, 'subsample': 0.8040079105516802, 'colsample_bytree': 0.41208562220675354}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:34,915]\u001b[0m Trial 62 finished with value: 9.305829026346431e-05 and parameters: {'booster': 'gblinear', 'lambda': 2.940515313556907e-05, 'alpha': 0.0033006904868937287, 'subsample': 0.7094898837769698, 'colsample_bytree': 0.5621490554968256}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:35,050]\u001b[0m Trial 63 finished with value: 0.0002244257971125486 and parameters: {'booster': 'gblinear', 'lambda': 2.4448476116735024e-05, 'alpha': 0.0017382534451364025, 'subsample': 0.7214057485494911, 'colsample_bytree': 0.5628314723309962}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:35,186]\u001b[0m Trial 64 finished with value: 0.0007292069516443786 and parameters: {'booster': 'gblinear', 'lambda': 5.654771169093828e-05, 'alpha': 6.053991605827059e-05, 'subsample': 0.6643077414700126, 'colsample_bytree': 0.4724322992807952}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:35,448]\u001b[0m Trial 65 finished with value: 1.1395282056850322 and parameters: {'booster': 'gbtree', 'lambda': 1.2879499251547159e-05, 'alpha': 0.0033447241428300064, 'subsample': 0.7004682644330822, 'colsample_bytree': 0.44959600216844764, 'max_depth': 5, 'min_child_weight': 8, 'eta': 1.0128302029358675e-05, 'gamma': 0.008301104611733607, 'grow_policy': 'lossguide'}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:35,572]\u001b[0m Trial 66 finished with value: 0.005079502022407153 and parameters: {'booster': 'gblinear', 'lambda': 1.7321203961307994e-06, 'alpha': 0.03347339420867278, 'subsample': 0.8905074610604633, 'colsample_bytree': 0.41508729514996356}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:35,708]\u001b[0m Trial 67 finished with value: 0.00026542898098725373 and parameters: {'booster': 'gblinear', 'lambda': 3.4921020412190465e-07, 'alpha': 0.00145952166743872, 'subsample': 0.8275872075593456, 'colsample_bytree': 0.3219333287255745}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:35,844]\u001b[0m Trial 68 finished with value: 0.0005445421905138307 and parameters: {'booster': 'gblinear', 'lambda': 8.788525251286114e-05, 'alpha': 0.0005885093823919348, 'subsample': 0.7561804413233749, 'colsample_bytree': 0.6962273906044014}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:37,386]\u001b[0m Trial 69 finished with value: 0.0475191955160367 and parameters: {'booster': 'dart', 'lambda': 0.00019268143628051868, 'alpha': 0.008423692908557299, 'subsample': 0.9160878172883248, 'colsample_bytree': 0.549917547024703, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.128790752531462, 'gamma': 0.0004050337739748773, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.0005862099835774443, 'skip_drop': 0.004962634911010282}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:37,521]\u001b[0m Trial 70 finished with value: 0.00012485786992707016 and parameters: {'booster': 'gblinear', 'lambda': 6.569499366601374e-06, 'alpha': 0.0025314458728947697, 'subsample': 0.8570480978629078, 'colsample_bytree': 0.7194859256026938}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:37,655]\u001b[0m Trial 71 finished with value: 0.00010737595487278769 and parameters: {'booster': 'gblinear', 'lambda': 6.593926735231109e-06, 'alpha': 0.003749737698090551, 'subsample': 0.8691336358952054, 'colsample_bytree': 0.8062780594982567}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:37,792]\u001b[0m Trial 72 finished with value: 0.00015071102492699356 and parameters: {'booster': 'gblinear', 'lambda': 2.4840545193197082e-05, 'alpha': 0.004925020821943065, 'subsample': 0.8074164856475106, 'colsample_bytree': 0.9068623708231099}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:37,928]\u001b[0m Trial 73 finished with value: 0.0005730664157975996 and parameters: {'booster': 'gblinear', 'lambda': 5.5773378540803964e-05, 'alpha': 0.0009270692627705065, 'subsample': 0.9428331905935851, 'colsample_bytree': 0.8305301133112369}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:38,063]\u001b[0m Trial 74 finished with value: 0.0008773664834899956 and parameters: {'booster': 'gblinear', 'lambda': 1.1708888991780603e-05, 'alpha': 2.165635677692098e-06, 'subsample': 0.8761835437574709, 'colsample_bytree': 0.7807313561702606}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:38,166]\u001b[0m Trial 75 finished with value: 0.8532998796289429 and parameters: {'booster': 'gblinear', 'lambda': 3.4856970449640935e-05, 'alpha': 0.975154143362921, 'subsample': 0.7738502615217052, 'colsample_bytree': 0.8583133737014705}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:38,295]\u001b[0m Trial 76 finished with value: 0.001816364200385607 and parameters: {'booster': 'gblinear', 'lambda': 3.0904078458713357e-06, 'alpha': 0.0200148524737641, 'subsample': 0.8409039707834118, 'colsample_bytree': 0.6027387990361623}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:38,427]\u001b[0m Trial 77 finished with value: 0.00029340785727204017 and parameters: {'booster': 'gblinear', 'lambda': 4.8997959392905466e-06, 'alpha': 0.008039879157951332, 'subsample': 0.9756858746423118, 'colsample_bytree': 0.6626463202514015}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:38,626]\u001b[0m Trial 78 finished with value: 1.0764569519347709 and parameters: {'booster': 'gbtree', 'lambda': 0.0002111205193451378, 'alpha': 0.00027203679180571997, 'subsample': 0.8792500884244853, 'colsample_bytree': 0.5198061475163175, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.0004140412734485971, 'gamma': 0.04098544499158644, 'grow_policy': 'lossguide'}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:38,763]\u001b[0m Trial 79 finished with value: 9.141453921731217e-05 and parameters: {'booster': 'gblinear', 'lambda': 4.2106005371715496e-05, 'alpha': 0.00333643259858443, 'subsample': 0.8184256182109185, 'colsample_bytree': 0.4642286196488076}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:38,897]\u001b[0m Trial 80 finished with value: 8.539371998323322e-05 and parameters: {'booster': 'gblinear', 'lambda': 4.20934778329105e-05, 'alpha': 0.0033431135108573317, 'subsample': 0.8157511576125794, 'colsample_bytree': 0.42772867670794423}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:39,030]\u001b[0m Trial 81 finished with value: 0.00016468464222910771 and parameters: {'booster': 'gblinear', 'lambda': 5.4761013678476144e-05, 'alpha': 0.005211650032245795, 'subsample': 0.8229247035892029, 'colsample_bytree': 0.4313432395271359}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:13:39,164]\u001b[0m Trial 82 finished with value: 9.048938795735348e-05 and parameters: {'booster': 'gblinear', 'lambda': 1.5541133085631517e-05, 'alpha': 0.003344313992522688, 'subsample': 0.787809829891238, 'colsample_bytree': 0.4743871920904087}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:39,294]\u001b[0m Trial 83 finished with value: 0.000754862797949964 and parameters: {'booster': 'gblinear', 'lambda': 2.9837188293006918e-05, 'alpha': 0.012879058342765096, 'subsample': 0.6802352513920037, 'colsample_bytree': 0.46483347042168327}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:39,430]\u001b[0m Trial 84 finished with value: 0.000343686463171666 and parameters: {'booster': 'gblinear', 'lambda': 1.7308241864209397e-05, 'alpha': 0.0012283783772511138, 'subsample': 0.7415794676248907, 'colsample_bytree': 0.49655528444717634}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:39,555]\u001b[0m Trial 85 finished with value: 0.0049511746311490575 and parameters: {'booster': 'gblinear', 'lambda': 9.973899930122219e-05, 'alpha': 0.03296829889541276, 'subsample': 0.7789286108351785, 'colsample_bytree': 0.4056406197973825}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:39,689]\u001b[0m Trial 86 finished with value: 7.569409659114547e-05 and parameters: {'booster': 'gblinear', 'lambda': 4.437480576815436e-05, 'alpha': 0.002664873592808103, 'subsample': 0.7144042408863643, 'colsample_bytree': 0.3816128782212729}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:39,803]\u001b[0m Trial 87 finished with value: 0.04552441247527063 and parameters: {'booster': 'gblinear', 'lambda': 4.5271655550184815e-05, 'alpha': 0.10018373882576372, 'subsample': 0.7020093880944187, 'colsample_bytree': 0.3535131785329723}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:41,313]\u001b[0m Trial 88 finished with value: 1.1412383828312422 and parameters: {'booster': 'dart', 'lambda': 0.0006026132733722195, 'alpha': 0.0020916949228663045, 'subsample': 0.6474097903198343, 'colsample_bytree': 0.38771849138192793, 'max_depth': 9, 'min_child_weight': 7, 'eta': 1.2362797805605937e-07, 'gamma': 7.085422796733318e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.05428548779740594, 'skip_drop': 1.9573965042925255e-06}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:41,449]\u001b[0m Trial 89 finished with value: 0.0003194998219076845 and parameters: {'booster': 'gblinear', 'lambda': 9.248628563722951e-05, 'alpha': 0.0005011267203354342, 'subsample': 0.7151220695449715, 'colsample_bytree': 0.4882603731804679}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:41,584]\u001b[0m Trial 90 finished with value: 0.00038161851923108935 and parameters: {'booster': 'gblinear', 'lambda': 1.5722005551949433e-05, 'alpha': 0.0009565964940975264, 'subsample': 0.6027532239193943, 'colsample_bytree': 0.4295479648243894}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:41,718]\u001b[0m Trial 91 finished with value: 9.042550080276032e-05 and parameters: {'booster': 'gblinear', 'lambda': 1.0658815197868253e-05, 'alpha': 0.003028417943370538, 'subsample': 0.7926676997872826, 'colsample_bytree': 0.467402368601744}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:41,851]\u001b[0m Trial 92 finished with value: 0.00020904376194172882 and parameters: {'booster': 'gblinear', 'lambda': 2.676315106565704e-05, 'alpha': 0.006437513937286772, 'subsample': 0.7668239773564153, 'colsample_bytree': 0.4622082374573041}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:41,985]\u001b[0m Trial 93 finished with value: 0.00012305288333413027 and parameters: {'booster': 'gblinear', 'lambda': 0.00022572422342719814, 'alpha': 0.002454915834663297, 'subsample': 0.7920874626554939, 'colsample_bytree': 0.5119423774465632}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:42,117]\u001b[0m Trial 94 finished with value: 0.00048443395134738817 and parameters: {'booster': 'gblinear', 'lambda': 7.774001982945448e-05, 'alpha': 0.010271041048042159, 'subsample': 0.5512288781966781, 'colsample_bytree': 0.5577881149644649}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:42,254]\u001b[0m Trial 95 finished with value: 0.00023441421656188318 and parameters: {'booster': 'gblinear', 'lambda': 3.724125169922904e-05, 'alpha': 0.0014714021800852199, 'subsample': 0.7531546048462335, 'colsample_bytree': 0.4436112442951401}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:42,389]\u001b[0m Trial 96 finished with value: 8.019812973544693e-05 and parameters: {'booster': 'gblinear', 'lambda': 1.3152120506443903e-05, 'alpha': 0.0029799657700952014, 'subsample': 0.7331056389398041, 'colsample_bytree': 0.33353817216310166}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:42,612]\u001b[0m Trial 97 finished with value: 1.0249767121032292 and parameters: {'booster': 'gbtree', 'lambda': 1.1430217832398316e-05, 'alpha': 0.015924110381973795, 'subsample': 0.7284147286003948, 'colsample_bytree': 0.22609648636534696, 'max_depth': 5, 'min_child_weight': 3, 'eta': 0.0009006868103424125, 'gamma': 1.596157725343818e-05, 'grow_policy': 'depthwise'}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:42,747]\u001b[0m Trial 98 finished with value: 0.000883741946031461 and parameters: {'booster': 'gblinear', 'lambda': 0.00033852025401174244, 'alpha': 8.949122370480058e-08, 'subsample': 0.8025444944680447, 'colsample_bytree': 0.3326215516648311}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:42,879]\u001b[0m Trial 99 finished with value: 0.0002094876910171533 and parameters: {'booster': 'gblinear', 'lambda': 2.0679571828516597e-06, 'alpha': 0.006786808900786336, 'subsample': 0.7820140809534096, 'colsample_bytree': 0.37976882791296096}. Best is trial 27 with value: 7.098037345746466e-05.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:43,033]\u001b[0m A new study created in memory with name: no-name-c0d7ef88-7ecc-4d3f-9998-238f866f2a23\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:43,155]\u001b[0m Trial 0 finished with value: 0.9300870265914586 and parameters: {'booster': 'gblinear', 'lambda': 1.143807587357499e-08, 'alpha': 4.675436810183748e-08, 'subsample': 0.7650656982318702, 'colsample_bytree': 0.45571344756323584}. Best is trial 0 with value: 0.9300870265914586.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:43,339]\u001b[0m Trial 1 finished with value: 0.9024874849625519 and parameters: {'booster': 'gbtree', 'lambda': 4.190540178907287e-07, 'alpha': 1.1307107039358937e-06, 'subsample': 0.4977157776837639, 'colsample_bytree': 0.4602910483024141, 'max_depth': 9, 'min_child_weight': 8, 'eta': 8.013701442666034e-05, 'gamma': 0.15164689195130268, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.9300870265914586.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:43,459]\u001b[0m Trial 2 finished with value: 0.9300088798998019 and parameters: {'booster': 'gblinear', 'lambda': 0.027943148876902264, 'alpha': 1.7685087788199386e-08, 'subsample': 0.5668853039950958, 'colsample_bytree': 0.9524938609617}. Best is trial 0 with value: 0.9300870265914586.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:44,898]\u001b[0m Trial 3 finished with value: 0.9090278830273 and parameters: {'booster': 'dart', 'lambda': 5.039657065333936e-05, 'alpha': 5.4144290037751766e-05, 'subsample': 0.7214104640150425, 'colsample_bytree': 0.4163899077254259, 'max_depth': 5, 'min_child_weight': 4, 'eta': 8.178024532136125e-08, 'gamma': 0.030284093266817486, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 8.308668729448194e-07, 'skip_drop': 0.16388344673752814}. Best is trial 0 with value: 0.9300870265914586.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:46,028]\u001b[0m Trial 4 finished with value: 0.9024874849625519 and parameters: {'booster': 'dart', 'lambda': 1.256845412914728e-05, 'alpha': 0.0013714091412141546, 'subsample': 0.21605056006620843, 'colsample_bytree': 0.436662550519917, 'max_depth': 3, 'min_child_weight': 2, 'eta': 2.444654833156108e-06, 'gamma': 0.35988239344593653, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.2203726135159637, 'skip_drop': 2.3735909944286514e-06}. Best is trial 0 with value: 0.9300870265914586.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:13:46,200]\u001b[0m Trial 5 finished with value: 0.9362018668443741 and parameters: {'booster': 'gbtree', 'lambda': 1.9145422077998838e-07, 'alpha': 0.21581932940608572, 'subsample': 0.42268757660636913, 'colsample_bytree': 0.7994070559046622, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.4617808991092956, 'gamma': 5.344216845892122e-07, 'grow_policy': 'depthwise'}. Best is trial 5 with value: 0.9362018668443741.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:47,644]\u001b[0m Trial 6 finished with value: 0.9024874849625519 and parameters: {'booster': 'dart', 'lambda': 0.014142458334932407, 'alpha': 0.415217601708812, 'subsample': 0.6805346137859976, 'colsample_bytree': 0.7492092995611355, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.0007887189197055573, 'gamma': 0.009250527949240252, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 2.448235768193112e-05, 'skip_drop': 0.0017362527800076305}. Best is trial 5 with value: 0.9362018668443741.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:47,863]\u001b[0m Trial 7 finished with value: 0.9294716242661448 and parameters: {'booster': 'gbtree', 'lambda': 9.001288984880838e-07, 'alpha': 3.763625193860703e-05, 'subsample': 0.5294286822638903, 'colsample_bytree': 0.5395190927557934, 'max_depth': 5, 'min_child_weight': 2, 'eta': 0.012274230432950587, 'gamma': 9.416647797516532e-08, 'grow_policy': 'lossguide'}. Best is trial 5 with value: 0.9362018668443741.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:48,018]\u001b[0m Trial 8 finished with value: 0.9366747008617254 and parameters: {'booster': 'gbtree', 'lambda': 4.1291806376186874e-07, 'alpha': 7.149597296431932e-05, 'subsample': 0.9414685774234897, 'colsample_bytree': 0.23600044672347922, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.052667787201424045, 'gamma': 0.2886512280171089, 'grow_policy': 'depthwise'}. Best is trial 8 with value: 0.9366747008617254.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:48,145]\u001b[0m Trial 9 finished with value: 0.9342465753424658 and parameters: {'booster': 'gblinear', 'lambda': 8.778857645131406e-05, 'alpha': 7.139712846686086e-06, 'subsample': 0.44765288188479374, 'colsample_bytree': 0.5000606197025077}. Best is trial 8 with value: 0.9366747008617254.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:48,320]\u001b[0m Trial 10 finished with value: 0.9218690314580726 and parameters: {'booster': 'gbtree', 'lambda': 0.6910569819605713, 'alpha': 0.0026651130181223276, 'subsample': 0.926152619195652, 'colsample_bytree': 0.20608799103958253, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.6001802698517162, 'gamma': 0.00010191231715305571, 'grow_policy': 'depthwise'}. Best is trial 8 with value: 0.9366747008617254.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:48,504]\u001b[0m Trial 11 finished with value: 0.9260699059391293 and parameters: {'booster': 'gbtree', 'lambda': 1.1500731292639658e-08, 'alpha': 0.04071951624482823, 'subsample': 0.32220436617152787, 'colsample_bytree': 0.7701733005565997, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.5470290833700521, 'gamma': 8.847577556557745e-08, 'grow_policy': 'depthwise'}. Best is trial 8 with value: 0.9366747008617254.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:48,746]\u001b[0m Trial 12 finished with value: 0.9151672813487881 and parameters: {'booster': 'gbtree', 'lambda': 5.412440718193051e-07, 'alpha': 0.006490075181631161, 'subsample': 0.9930225738638826, 'colsample_bytree': 0.25390482321076596, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.017823822719546856, 'gamma': 8.133474993831441e-06, 'grow_policy': 'depthwise'}. Best is trial 8 with value: 0.9366747008617254.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:48,991]\u001b[0m Trial 13 finished with value: 0.9253483534168073 and parameters: {'booster': 'gbtree', 'lambda': 3.821850786376542e-06, 'alpha': 0.7405026464014238, 'subsample': 0.8418783699993686, 'colsample_bytree': 0.7010107583135154, 'max_depth': 7, 'min_child_weight': 6, 'eta': 0.028416036835775555, 'gamma': 2.012265268184359e-05, 'grow_policy': 'depthwise'}. Best is trial 8 with value: 0.9366747008617254.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:49,183]\u001b[0m Trial 14 finished with value: 0.9260699059391293 and parameters: {'booster': 'gbtree', 'lambda': 7.80406091407995e-08, 'alpha': 0.0003323591905677596, 'subsample': 0.36907800274830294, 'colsample_bytree': 0.911673454056962, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.860923705464164, 'gamma': 0.0007558042853788812, 'grow_policy': 'lossguide'}. Best is trial 8 with value: 0.9366747008617254.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:49,440]\u001b[0m Trial 15 finished with value: 0.9090278830273 and parameters: {'booster': 'gbtree', 'lambda': 0.0013652466501180708, 'alpha': 0.04855872547143406, 'subsample': 0.6024941608462253, 'colsample_bytree': 0.6423611875677748, 'max_depth': 7, 'min_child_weight': 5, 'eta': 0.00042454363895280255, 'gamma': 7.142564268077021e-07, 'grow_policy': 'depthwise'}. Best is trial 8 with value: 0.9366747008617254.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:49,653]\u001b[0m Trial 16 finished with value: 0.9209506550530343 and parameters: {'booster': 'gbtree', 'lambda': 1.167218633928183e-07, 'alpha': 9.558409571172849e-07, 'subsample': 0.3893373695659703, 'colsample_bytree': 0.8736455717228508, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.03614120346756365, 'gamma': 0.0011541215348095024, 'grow_policy': 'depthwise'}. Best is trial 8 with value: 0.9366747008617254.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:49,868]\u001b[0m Trial 17 finished with value: 0.9024874849625519 and parameters: {'booster': 'gbtree', 'lambda': 6.008402487492142e-06, 'alpha': 0.0004399809606392432, 'subsample': 0.23855015693325596, 'colsample_bytree': 0.8149571898748482, 'max_depth': 5, 'min_child_weight': 3, 'eta': 1.8905387842925496e-05, 'gamma': 1.4771455467270202e-08, 'grow_policy': 'depthwise'}. Best is trial 8 with value: 0.9366747008617254.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:51,358]\u001b[0m Trial 18 finished with value: 0.9024874849625519 and parameters: {'booster': 'dart', 'lambda': 0.00034915068749852263, 'alpha': 0.029262942252750758, 'subsample': 0.8449752948309912, 'colsample_bytree': 0.33006858913546494, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.0009755801014398586, 'gamma': 2.1422859073263415e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.0161848567624932e-08, 'skip_drop': 2.015065755539764e-08}. Best is trial 8 with value: 0.9366747008617254.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:51,496]\u001b[0m Trial 19 finished with value: 0.9280396468713173 and parameters: {'booster': 'gblinear', 'lambda': 6.516096134954004e-08, 'alpha': 4.38300421104544e-06, 'subsample': 0.6055488964706506, 'colsample_bytree': 0.5904109853750454}. Best is trial 8 with value: 0.9366747008617254.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:51,699]\u001b[0m Trial 20 finished with value: 0.9224187866927592 and parameters: {'booster': 'gbtree', 'lambda': 2.6862438421966364e-06, 'alpha': 2.1368993339095242e-07, 'subsample': 0.29811910752446036, 'colsample_bytree': 0.9989231780812355, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.09228256880798016, 'gamma': 0.0001946184401123812, 'grow_policy': 'depthwise'}. Best is trial 8 with value: 0.9366747008617254.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:51,837]\u001b[0m Trial 21 finished with value: 0.9342465753424658 and parameters: {'booster': 'gblinear', 'lambda': 5.871171984511245e-05, 'alpha': 5.0047206936313285e-06, 'subsample': 0.4494735385854584, 'colsample_bytree': 0.3362748460747463}. Best is trial 8 with value: 0.9366747008617254.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:51,973]\u001b[0m Trial 22 finished with value: 0.9428745702159176 and parameters: {'booster': 'gblinear', 'lambda': 0.0018293033089059024, 'alpha': 1.964654137808809e-05, 'subsample': 0.4707877432136317, 'colsample_bytree': 0.32352291462485094}. Best is trial 22 with value: 0.9428745702159176.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:52,110]\u001b[0m Trial 23 finished with value: 0.9415305147226142 and parameters: {'booster': 'gblinear', 'lambda': 0.00281540527861241, 'alpha': 0.00014732909799357931, 'subsample': 0.44458052741306175, 'colsample_bytree': 0.3306238935528271}. Best is trial 22 with value: 0.9428745702159176.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:52,246]\u001b[0m Trial 24 finished with value: 0.9437659327982031 and parameters: {'booster': 'gblinear', 'lambda': 0.0031813204681302057, 'alpha': 0.00012937429198314377, 'subsample': 0.49828487254937437, 'colsample_bytree': 0.32182660833070925}. Best is trial 24 with value: 0.9437659327982031.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:13:52,382]\u001b[0m Trial 25 finished with value: 0.946039309112567 and parameters: {'booster': 'gblinear', 'lambda': 0.006305830681513785, 'alpha': 1.6698783921441255e-05, 'subsample': 0.5029501599008774, 'colsample_bytree': 0.3379032455485782}. Best is trial 25 with value: 0.946039309112567.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:52,518]\u001b[0m Trial 26 finished with value: 0.9190582122088973 and parameters: {'booster': 'gblinear', 'lambda': 0.1272123764395852, 'alpha': 2.317617870874187e-05, 'subsample': 0.6658754082501754, 'colsample_bytree': 0.3736576016111076}. Best is trial 25 with value: 0.946039309112567.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:52,654]\u001b[0m Trial 27 finished with value: 0.9415305147226142 and parameters: {'booster': 'gblinear', 'lambda': 0.0034872513482003737, 'alpha': 1.1366731321975667e-05, 'subsample': 0.5013068253514876, 'colsample_bytree': 0.2765916637318068}. Best is trial 25 with value: 0.946039309112567.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:52,791]\u001b[0m Trial 28 finished with value: 0.9440944031709213 and parameters: {'booster': 'gblinear', 'lambda': 0.0007108747104748179, 'alpha': 1.7963062566732265e-06, 'subsample': 0.5522711795879965, 'colsample_bytree': 0.38645635153065866}. Best is trial 25 with value: 0.946039309112567.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:52,928]\u001b[0m Trial 29 finished with value: 0.9406739326067394 and parameters: {'booster': 'gblinear', 'lambda': 0.0003534711377672816, 'alpha': 3.0724167418832965e-07, 'subsample': 0.547592801346914, 'colsample_bytree': 0.5344180161115215}. Best is trial 25 with value: 0.946039309112567.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:53,065]\u001b[0m Trial 30 finished with value: 0.9300088798998019 and parameters: {'booster': 'gblinear', 'lambda': 0.017730190147063025, 'alpha': 1.2770339535827844e-07, 'subsample': 0.6408795482858354, 'colsample_bytree': 0.42451433135518474}. Best is trial 25 with value: 0.946039309112567.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:53,198]\u001b[0m Trial 31 finished with value: 0.9463240342632403 and parameters: {'booster': 'gblinear', 'lambda': 0.0005079096995852067, 'alpha': 0.00023764491433464073, 'subsample': 0.4936536315479938, 'colsample_bytree': 0.2750182687152485}. Best is trial 31 with value: 0.9463240342632403.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:53,331]\u001b[0m Trial 32 finished with value: 0.9463240342632403 and parameters: {'booster': 'gblinear', 'lambda': 0.00048419253803051883, 'alpha': 0.00023450160894016245, 'subsample': 0.5621644028607944, 'colsample_bytree': 0.27789362059741585}. Best is trial 31 with value: 0.9463240342632403.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:53,466]\u001b[0m Trial 33 finished with value: 0.9406739326067394 and parameters: {'booster': 'gblinear', 'lambda': 0.00031617369391403625, 'alpha': 9.92876322601106e-07, 'subsample': 0.5710772682102403, 'colsample_bytree': 0.2773378155295262}. Best is trial 31 with value: 0.9463240342632403.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:53,598]\u001b[0m Trial 34 finished with value: 0.9190582122088973 and parameters: {'booster': 'gblinear', 'lambda': 0.07013258773871421, 'alpha': 0.0006581954012173101, 'subsample': 0.7321433206202433, 'colsample_bytree': 0.37878868897926743}. Best is trial 31 with value: 0.9463240342632403.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:53,731]\u001b[0m Trial 35 finished with value: 0.9440944031709213 and parameters: {'booster': 'gblinear', 'lambda': 0.0007536563170852731, 'alpha': 2.290971240024757e-06, 'subsample': 0.6213972470338799, 'colsample_bytree': 0.3820079454985851}. Best is trial 31 with value: 0.9463240342632403.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:53,865]\u001b[0m Trial 36 finished with value: 0.9383915882826076 and parameters: {'booster': 'gblinear', 'lambda': 0.008703025864848564, 'alpha': 3.8308994434167596e-08, 'subsample': 0.6342887120295014, 'colsample_bytree': 0.4752275875473948}. Best is trial 31 with value: 0.9463240342632403.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:53,995]\u001b[0m Trial 37 finished with value: 0.9544299048888388 and parameters: {'booster': 'gblinear', 'lambda': 2.3680737305304515e-05, 'alpha': 0.0028633339333816636, 'subsample': 0.558121186356859, 'colsample_bytree': 0.206192295621321}. Best is trial 37 with value: 0.9544299048888388.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:55,032]\u001b[0m Trial 38 finished with value: 0.9024874849625519 and parameters: {'booster': 'dart', 'lambda': 1.8473767276522436e-05, 'alpha': 0.0019271951373223772, 'subsample': 0.37918754432669544, 'colsample_bytree': 0.21162115856505775, 'max_depth': 5, 'min_child_weight': 10, 'eta': 2.6550078780733248e-08, 'gamma': 0.008859592609376838, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.3989281727583205, 'skip_drop': 0.3218213894534854}. Best is trial 37 with value: 0.9544299048888388.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:55,159]\u001b[0m Trial 39 finished with value: 0.9344753489492159 and parameters: {'booster': 'gblinear', 'lambda': 0.00016100771069481044, 'alpha': 0.006936973071294157, 'subsample': 0.7117071018070296, 'colsample_bytree': 0.26114986308514987}. Best is trial 37 with value: 0.9544299048888388.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:55,292]\u001b[0m Trial 40 finished with value: 0.9440944031709213 and parameters: {'booster': 'gblinear', 'lambda': 2.2423128352822466e-05, 'alpha': 0.00021426097693934086, 'subsample': 0.5746089687197127, 'colsample_bytree': 0.2923417051812222}. Best is trial 37 with value: 0.9544299048888388.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:55,425]\u001b[0m Trial 41 finished with value: 0.9440944031709213 and parameters: {'booster': 'gblinear', 'lambda': 1.4343878688683697e-05, 'alpha': 0.00019604322738367568, 'subsample': 0.5169613845553565, 'colsample_bytree': 0.29302602086857055}. Best is trial 37 with value: 0.9544299048888388.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:55,558]\u001b[0m Trial 42 finished with value: 0.954299656172734 and parameters: {'booster': 'gblinear', 'lambda': 4.282505500837353e-05, 'alpha': 0.000787993773662121, 'subsample': 0.48736142722672776, 'colsample_bytree': 0.20757098625340026}. Best is trial 37 with value: 0.9544299048888388.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:55,690]\u001b[0m Trial 43 finished with value: 0.9566643619988566 and parameters: {'booster': 'gblinear', 'lambda': 0.0001396077837785275, 'alpha': 0.0009373237432971739, 'subsample': 0.40433080680688055, 'colsample_bytree': 0.2211701226674784}. Best is trial 43 with value: 0.9566643619988566.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:57,041]\u001b[0m Trial 44 finished with value: 0.9024874849625519 and parameters: {'booster': 'dart', 'lambda': 0.00016145456998712537, 'alpha': 0.000799383262171251, 'subsample': 0.4189435789516397, 'colsample_bytree': 0.2017969218307577, 'max_depth': 7, 'min_child_weight': 8, 'eta': 4.949757415137285e-07, 'gamma': 3.5658491505295105e-05, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.001938956123223544, 'skip_drop': 7.471413348948412e-05}. Best is trial 43 with value: 0.9566643619988566.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:57,166]\u001b[0m Trial 45 finished with value: 0.9344753489492159 and parameters: {'booster': 'gblinear', 'lambda': 4.176900200911336e-05, 'alpha': 0.007413588017559625, 'subsample': 0.3341108357151614, 'colsample_bytree': 0.22478391037046572}. Best is trial 43 with value: 0.9566643619988566.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:57,294]\u001b[0m Trial 46 finished with value: 0.9507132706260862 and parameters: {'booster': 'gblinear', 'lambda': 1.5821194612077613e-06, 'alpha': 0.003563570311309279, 'subsample': 0.41151894914473536, 'colsample_bytree': 0.24289648484801274}. Best is trial 43 with value: 0.9566643619988566.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:57,412]\u001b[0m Trial 47 finished with value: 0.9253483534168073 and parameters: {'booster': 'gblinear', 'lambda': 2.4956693273306485e-06, 'alpha': 0.014648481940402918, 'subsample': 0.4186820017796388, 'colsample_bytree': 0.23612896325958344}. Best is trial 43 with value: 0.9566643619988566.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:57,516]\u001b[0m Trial 48 finished with value: 0.9024874849625519 and parameters: {'booster': 'gblinear', 'lambda': 3.104452151547337e-05, 'alpha': 0.1562157802670782, 'subsample': 0.3468521728698576, 'colsample_bytree': 0.24209871154051893}. Best is trial 43 with value: 0.9566643619988566.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:58,850]\u001b[0m Trial 49 finished with value: 0.9024874849625519 and parameters: {'booster': 'dart', 'lambda': 1.0555009031202008e-05, 'alpha': 0.0029593937566748697, 'subsample': 0.2659233199012475, 'colsample_bytree': 0.20586422260095996, 'max_depth': 3, 'min_child_weight': 7, 'eta': 5.417323858032055e-06, 'gamma': 0.0008363767580000231, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.0022834064398060913, 'skip_drop': 3.5767331684075655e-08}. Best is trial 43 with value: 0.9566643619988566.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:13:58,983]\u001b[0m Trial 50 finished with value: 0.9566643619988566 and parameters: {'booster': 'gblinear', 'lambda': 0.00010349943338349717, 'alpha': 0.0009838172048317218, 'subsample': 0.47025925937019325, 'colsample_bytree': 0.2458842460959556}. Best is trial 43 with value: 0.9566643619988566.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:59,113]\u001b[0m Trial 51 finished with value: 0.95907136030583 and parameters: {'booster': 'gblinear', 'lambda': 0.00010912520797112877, 'alpha': 0.0010506895558792658, 'subsample': 0.46948173715779823, 'colsample_bytree': 0.24619912713396772}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:59,244]\u001b[0m Trial 52 finished with value: 0.9580305737542189 and parameters: {'booster': 'gblinear', 'lambda': 9.181888776320345e-05, 'alpha': 0.0014103471696136811, 'subsample': 0.4065187487652549, 'colsample_bytree': 0.2404063696228722}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:59,376]\u001b[0m Trial 53 finished with value: 0.9566643619988566 and parameters: {'booster': 'gblinear', 'lambda': 0.00012946555922057476, 'alpha': 0.000988600268922699, 'subsample': 0.46596370462105025, 'colsample_bytree': 0.2435051967181996}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:59,509]\u001b[0m Trial 54 finished with value: 0.9385038434880132 and parameters: {'booster': 'gblinear', 'lambda': 0.00010569393972300505, 'alpha': 5.274977902252938e-05, 'subsample': 0.4576694123584091, 'colsample_bytree': 0.2975564364354167}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:59,644]\u001b[0m Trial 55 finished with value: 0.9580305737542189 and parameters: {'booster': 'gblinear', 'lambda': 0.00010955171947073698, 'alpha': 0.0012753234754428187, 'subsample': 0.3637134797063211, 'colsample_bytree': 0.2446558119543739}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:59,814]\u001b[0m Trial 56 finished with value: 0.9580305737542189 and parameters: {'booster': 'gblinear', 'lambda': 0.00015906545406921504, 'alpha': 0.0012096269256687796, 'subsample': 0.3106513988149197, 'colsample_bytree': 0.2477615876662048}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:13:59,950]\u001b[0m Trial 57 finished with value: 0.9580305737542189 and parameters: {'booster': 'gblinear', 'lambda': 6.505579896037563e-06, 'alpha': 0.0012921236622967856, 'subsample': 0.29409908899850584, 'colsample_bytree': 0.35011892448483367}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:01,334]\u001b[0m Trial 58 finished with value: 0.9024874849625519 and parameters: {'booster': 'dart', 'lambda': 5.765009815752439e-06, 'alpha': 0.015565501555741315, 'subsample': 0.3006433548806311, 'colsample_bytree': 0.46816920508541515, 'max_depth': 5, 'min_child_weight': 9, 'eta': 1.9326065566900276e-07, 'gamma': 1.228181721843151e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.1577799273990505e-08, 'skip_drop': 0.001910325534276098}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:01,467]\u001b[0m Trial 59 finished with value: 0.9385038434880132 and parameters: {'booster': 'gblinear', 'lambda': 7.552349738473593e-05, 'alpha': 7.552484991383295e-05, 'subsample': 0.2525359456677644, 'colsample_bytree': 0.3519031200965463}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:01,599]\u001b[0m Trial 60 finished with value: 0.948587113194326 and parameters: {'booster': 'gblinear', 'lambda': 7.070395352175139e-06, 'alpha': 0.00046379811405998956, 'subsample': 0.2944275349723569, 'colsample_bytree': 0.4121355909493134}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:01,733]\u001b[0m Trial 61 finished with value: 0.9580305737542189 and parameters: {'booster': 'gblinear', 'lambda': 0.000168135823158851, 'alpha': 0.001337384981374696, 'subsample': 0.3601618934660306, 'colsample_bytree': 0.305288948094862}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:01,865]\u001b[0m Trial 62 finished with value: 0.9580305737542189 and parameters: {'booster': 'gblinear', 'lambda': 0.00022042037410326346, 'alpha': 0.0014013882662203465, 'subsample': 0.35434417463057777, 'colsample_bytree': 0.31196776643953483}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:01,996]\u001b[0m Trial 63 finished with value: 0.9520349414333928 and parameters: {'booster': 'gblinear', 'lambda': 0.00022501711384246192, 'alpha': 0.001699065132617117, 'subsample': 0.35266327827473143, 'colsample_bytree': 0.31654727788005954}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:02,127]\u001b[0m Trial 64 finished with value: 0.9344753489492159 and parameters: {'booster': 'gblinear', 'lambda': 0.0010974098875949116, 'alpha': 0.004261346493499876, 'subsample': 0.2205774804256096, 'colsample_bytree': 0.35084789882955497}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:02,247]\u001b[0m Trial 65 finished with value: 0.9300088798998019 and parameters: {'booster': 'gblinear', 'lambda': 6.316775533284748e-05, 'alpha': 0.013190382885386466, 'subsample': 0.3168889890123048, 'colsample_bytree': 0.310979200618933}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:02,379]\u001b[0m Trial 66 finished with value: 0.9473774632503528 and parameters: {'booster': 'gblinear', 'lambda': 0.0011565717638751145, 'alpha': 0.00047068240957033467, 'subsample': 0.3695769822554944, 'colsample_bytree': 0.6762714916244477}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:02,510]\u001b[0m Trial 67 finished with value: 0.9520349414333928 and parameters: {'booster': 'gblinear', 'lambda': 0.0002448663676960736, 'alpha': 0.0015616456180660274, 'subsample': 0.27906128925668267, 'colsample_bytree': 0.2637028651466813}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:02,701]\u001b[0m Trial 68 finished with value: 0.9024874849625519 and parameters: {'booster': 'gbtree', 'lambda': 1.0606054901703548e-05, 'alpha': 0.030261201619865324, 'subsample': 0.39017758497823235, 'colsample_bytree': 0.4030898379903576, 'max_depth': 7, 'min_child_weight': 6, 'eta': 1.5563363967831752e-08, 'gamma': 0.04804983734780876, 'grow_policy': 'lossguide'}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:02,828]\u001b[0m Trial 69 finished with value: 0.9387647298990554 and parameters: {'booster': 'gblinear', 'lambda': 3.7208335223940573e-07, 'alpha': 0.005450313180369278, 'subsample': 0.3212767296928332, 'colsample_bytree': 0.30299119691072074}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:02,961]\u001b[0m Trial 70 finished with value: 0.9451081918652182 and parameters: {'booster': 'gblinear', 'lambda': 0.0020419548218377154, 'alpha': 0.00012094335967347785, 'subsample': 0.20397986275133972, 'colsample_bytree': 0.347541578245525}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:03,093]\u001b[0m Trial 71 finished with value: 0.9556046837880549 and parameters: {'booster': 'gblinear', 'lambda': 6.10963794242399e-05, 'alpha': 0.0013766406841706953, 'subsample': 0.43841858540817313, 'colsample_bytree': 0.2572354445036699}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:03,227]\u001b[0m Trial 72 finished with value: 0.9415305147226142 and parameters: {'booster': 'gblinear', 'lambda': 0.0005831328664468441, 'alpha': 0.0004573693026032236, 'subsample': 0.40193017722928726, 'colsample_bytree': 0.22630080557920418}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:03,352]\u001b[0m Trial 73 finished with value: 0.9300088798998019 and parameters: {'booster': 'gblinear', 'lambda': 3.297169862898876e-05, 'alpha': 0.00969157827304433, 'subsample': 0.3500282817036292, 'colsample_bytree': 0.27659400698892433}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:03,484]\u001b[0m Trial 74 finished with value: 0.9520349414333928 and parameters: {'booster': 'gblinear', 'lambda': 0.00027766554381980426, 'alpha': 0.0021491410830788696, 'subsample': 0.23037227031788332, 'colsample_bytree': 0.44031568670759297}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:14:03,622]\u001b[0m Trial 75 finished with value: 0.948587113194326 and parameters: {'booster': 'gblinear', 'lambda': 0.00013748111658667237, 'alpha': 0.0003298611143074916, 'subsample': 0.36181427332138005, 'colsample_bytree': 0.361307768511307}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:03,755]\u001b[0m Trial 76 finished with value: 0.9544299048888388 and parameters: {'booster': 'gblinear', 'lambda': 0.0004659957836273662, 'alpha': 0.001142071902697758, 'subsample': 0.3869118275919786, 'colsample_bytree': 0.2928593702358812}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:03,887]\u001b[0m Trial 77 finished with value: 0.9463240342632403 and parameters: {'booster': 'gblinear', 'lambda': 0.000826003171056618, 'alpha': 3.503288344298155e-05, 'subsample': 0.2742935635945088, 'colsample_bytree': 0.5879988315410386}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:04,050]\u001b[0m Trial 78 finished with value: 0.9024874849625519 and parameters: {'booster': 'gbtree', 'lambda': 8.664225402153357e-05, 'alpha': 0.004202605890796687, 'subsample': 0.33195068895753077, 'colsample_bytree': 0.2597736928375682, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.004122392363047957, 'gamma': 4.357546846562917e-06, 'grow_policy': 'lossguide'}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:05,401]\u001b[0m Trial 79 finished with value: 0.9024874849625519 and parameters: {'booster': 'dart', 'lambda': 0.000223428534603381, 'alpha': 0.0006234175929225889, 'subsample': 0.3043498098490393, 'colsample_bytree': 0.32278744209718535, 'max_depth': 9, 'min_child_weight': 9, 'eta': 7.223065444735154e-05, 'gamma': 0.7490428977777005, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.6547478230964004e-06, 'skip_drop': 3.940704466895765e-06}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:05,537]\u001b[0m Trial 80 finished with value: 0.9520349414333928 and parameters: {'booster': 'gblinear', 'lambda': 1.2180913700230635e-08, 'alpha': 0.0023492752279977215, 'subsample': 0.43521700662821033, 'colsample_bytree': 0.24579956256648988}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:05,670]\u001b[0m Trial 81 finished with value: 0.9566643619988566 and parameters: {'booster': 'gblinear', 'lambda': 0.00010315081952796868, 'alpha': 0.0009658644732411328, 'subsample': 0.3795493626079165, 'colsample_bytree': 0.225136353972104}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:05,803]\u001b[0m Trial 82 finished with value: 0.9519741359197413 and parameters: {'booster': 'gblinear', 'lambda': 0.0001642154760458087, 'alpha': 0.00027719394493637173, 'subsample': 0.5268870093774617, 'colsample_bytree': 0.27969244919825204}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:05,935]\u001b[0m Trial 83 finished with value: 0.9556046837880549 and parameters: {'booster': 'gblinear', 'lambda': 3.609461233760145e-05, 'alpha': 0.0014883029133802394, 'subsample': 0.3398525426936668, 'colsample_bytree': 0.23066326785819352}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:06,069]\u001b[0m Trial 84 finished with value: 0.955275522536737 and parameters: {'booster': 'gblinear', 'lambda': 5.382387270288135e-05, 'alpha': 0.0006932924393119479, 'subsample': 0.3960768863545732, 'colsample_bytree': 0.21783732002267606}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:06,175]\u001b[0m Trial 85 finished with value: 0.9024874849625519 and parameters: {'booster': 'gblinear', 'lambda': 1.9057402992343398e-05, 'alpha': 0.08686652346845611, 'subsample': 0.3681260689515014, 'colsample_bytree': 0.25931052212558303}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:06,305]\u001b[0m Trial 86 finished with value: 0.9544299048888388 and parameters: {'booster': 'gblinear', 'lambda': 0.00035128689727571057, 'alpha': 0.0026157093238246528, 'subsample': 0.47365048376515034, 'colsample_bytree': 0.3067611431897841}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:06,439]\u001b[0m Trial 87 finished with value: 0.9463240342632403 and parameters: {'booster': 'gblinear', 'lambda': 7.246473318277891e-05, 'alpha': 0.0001506185775364926, 'subsample': 0.25223394807161714, 'colsample_bytree': 0.20036262884416567}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:06,567]\u001b[0m Trial 88 finished with value: 0.9387647298990554 and parameters: {'booster': 'gblinear', 'lambda': 0.00012002214062141, 'alpha': 0.00496376736491939, 'subsample': 0.4616032682867192, 'colsample_bytree': 0.3289910626206368}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:06,689]\u001b[0m Trial 89 finished with value: 0.9253483534168073 and parameters: {'booster': 'gblinear', 'lambda': 0.0056893424467969545, 'alpha': 0.009607988859901934, 'subsample': 0.42702807118556035, 'colsample_bytree': 0.281168860673459}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:06,822]\u001b[0m Trial 90 finished with value: 0.9566643619988566 and parameters: {'booster': 'gblinear', 'lambda': 1.1055967927713678e-06, 'alpha': 0.0011146695290155644, 'subsample': 0.7989685727414283, 'colsample_bytree': 0.23893808912096784}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:06,956]\u001b[0m Trial 91 finished with value: 0.9566643619988566 and parameters: {'booster': 'gblinear', 'lambda': 0.00016730767781158494, 'alpha': 0.0009317727507021697, 'subsample': 0.47457972747076893, 'colsample_bytree': 0.2514679454643081}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:07,090]\u001b[0m Trial 92 finished with value: 0.948587113194326 and parameters: {'booster': 'gblinear', 'lambda': 7.34313109978932e-07, 'alpha': 0.0003540833363099996, 'subsample': 0.8022107780343186, 'colsample_bytree': 0.2600291340430588}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:07,225]\u001b[0m Trial 93 finished with value: 0.9428745702159176 and parameters: {'booster': 'gblinear', 'lambda': 0.00047845270332923213, 'alpha': 1.0676627197092565e-08, 'subsample': 0.48085839136311453, 'colsample_bytree': 0.24448867490244255}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:07,357]\u001b[0m Trial 94 finished with value: 0.9519741359197413 and parameters: {'booster': 'gblinear', 'lambda': 0.00020158734717923572, 'alpha': 0.00072856464883609, 'subsample': 0.5170485248785226, 'colsample_bytree': 0.2923888804151465}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:07,490]\u001b[0m Trial 95 finished with value: 0.9580305737542189 and parameters: {'booster': 'gblinear', 'lambda': 1.127266940078137e-06, 'alpha': 0.001250406056234702, 'subsample': 0.28757057099445305, 'colsample_bytree': 0.23222617991282557}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:07,679]\u001b[0m Trial 96 finished with value: 0.9024874849625519 and parameters: {'booster': 'gbtree', 'lambda': 1.295970986814741e-06, 'alpha': 0.0020177558143609563, 'subsample': 0.891989607357776, 'colsample_bytree': 0.2308948398184229, 'max_depth': 5, 'min_child_weight': 8, 'eta': 1.0330833520839302e-06, 'gamma': 0.005498600550930228, 'grow_policy': 'lossguide'}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:09,035]\u001b[0m Trial 97 finished with value: 0.9024874849625519 and parameters: {'booster': 'dart', 'lambda': 1.911793247712716e-07, 'alpha': 0.00048828063644268296, 'subsample': 0.28328243883598764, 'colsample_bytree': 0.27378500996672606, 'max_depth': 7, 'min_child_weight': 5, 'eta': 8.659617944282557e-06, 'gamma': 1.0812332233469984e-07, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.004311363540711668, 'skip_drop': 0.006189639248387637}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:09,172]\u001b[0m Trial 98 finished with value: 0.9556046837880549 and parameters: {'booster': 'gblinear', 'lambda': 2.808110168348734e-06, 'alpha': 0.0014399083921302373, 'subsample': 0.31424515651995377, 'colsample_bytree': 0.37098355437656244}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:14:09,308]\u001b[0m Trial 99 finished with value: 0.9342465753424658 and parameters: {'booster': 'gblinear', 'lambda': 4.9678765240299e-06, 'alpha': 9.000933521950387e-05, 'subsample': 0.246847931075378, 'colsample_bytree': 0.8131737644115514}. Best is trial 51 with value: 0.95907136030583.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:14:09,629]\u001b[0m A new study created in memory with name: no-name-92ec5bd0-a696-4d44-a8a6-1d54ba0dc255\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:21,058]\u001b[0m Trial 0 finished with value: 0.8112798090615536 and parameters: {'booster': 'dart', 'lambda': 0.0019281343629574412, 'alpha': 1.2345849206892965e-06, 'subsample': 0.6880476524452628, 'colsample_bytree': 0.5449542439745247, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.04635832783809468, 'gamma': 1.145312782299387e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 2.4205019395424356e-06, 'skip_drop': 7.122114167704006e-08}. Best is trial 0 with value: 0.8112798090615536.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:21,459]\u001b[0m Trial 1 finished with value: 0.8044126560795247 and parameters: {'booster': 'gbtree', 'lambda': 0.0006019473808655007, 'alpha': 3.0191302166765253e-07, 'subsample': 0.24884758367341206, 'colsample_bytree': 0.4854021762557918, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.19111832131444997, 'gamma': 6.00085807674535e-07, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.8112798090615536.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:22,269]\u001b[0m Trial 2 finished with value: 0.8112798090615536 and parameters: {'booster': 'gblinear', 'lambda': 0.7901934983980768, 'alpha': 0.0007700188800674846, 'subsample': 0.3277570774574426, 'colsample_bytree': 0.9527606600835428}. Best is trial 0 with value: 0.8112798090615536.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:23,052]\u001b[0m Trial 3 finished with value: 0.8112798090615536 and parameters: {'booster': 'gblinear', 'lambda': 0.4386590349409415, 'alpha': 0.0009750698891032662, 'subsample': 0.924982460035249, 'colsample_bytree': 0.29646128407502453}. Best is trial 0 with value: 0.8112798090615536.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:23,548]\u001b[0m Trial 4 finished with value: 0.8112798090615536 and parameters: {'booster': 'gbtree', 'lambda': 0.5179504238715347, 'alpha': 7.005834008544428e-07, 'subsample': 0.8212817249313229, 'colsample_bytree': 0.32973814264791135, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.026794677956709794, 'gamma': 4.252916937777572e-06, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.8112798090615536.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:24,014]\u001b[0m Trial 5 finished with value: 0.8099144337765637 and parameters: {'booster': 'gbtree', 'lambda': 0.0286130698159951, 'alpha': 0.0471517321729032, 'subsample': 0.3353496601019626, 'colsample_bytree': 0.6672202226187488, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.09656932180421814, 'gamma': 3.4573927175904954e-07, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.8112798090615536.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:36,023]\u001b[0m Trial 6 finished with value: 0.8099144337765637 and parameters: {'booster': 'dart', 'lambda': 1.1721374904310211e-07, 'alpha': 0.5630119537587585, 'subsample': 0.750938249629167, 'colsample_bytree': 0.8672541040332042, 'max_depth': 5, 'min_child_weight': 5, 'eta': 0.05784618566014045, 'gamma': 0.3234826765207987, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.00011405117620363105, 'skip_drop': 0.00012467140733418998}. Best is trial 0 with value: 0.8112798090615536.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:36,841]\u001b[0m Trial 7 finished with value: 0.8112798090615536 and parameters: {'booster': 'gbtree', 'lambda': 0.0021732579434113213, 'alpha': 1.6256305500694282e-08, 'subsample': 0.8761026581370188, 'colsample_bytree': 0.5104124945523327, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.00016657023193410555, 'gamma': 0.014954169774343728, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.8112798090615536.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:14:48,720]\u001b[0m Trial 8 finished with value: 0.805600857934886 and parameters: {'booster': 'dart', 'lambda': 1.2324179294049942e-08, 'alpha': 0.0026675165348090777, 'subsample': 0.9179497265171286, 'colsample_bytree': 0.2855413816097967, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.2990713586065105, 'gamma': 2.351982091483268e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 6.732942291957918e-06, 'skip_drop': 1.2661384224735298e-08}. Best is trial 0 with value: 0.8112798090615536.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:15:02,094]\u001b[0m A new study created in memory with name: no-name-9369d33a-8c2b-4a02-9eac-59403cb7a11f\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:02,356]\u001b[0m Trial 0 finished with value: 0.9754105804889125 and parameters: {'booster': 'gbtree', 'lambda': 0.022260232091557614, 'alpha': 2.8858825652703096e-08, 'subsample': 0.20626340102057628, 'colsample_bytree': 0.4709605976486628, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.00018034100326570464, 'gamma': 0.16850251958216705, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9754105804889125.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:02,662]\u001b[0m Trial 1 finished with value: 0.9754105804889125 and parameters: {'booster': 'gbtree', 'lambda': 1.0881957558936136e-08, 'alpha': 0.03527276993342669, 'subsample': 0.9767150037105969, 'colsample_bytree': 0.20121361744250824, 'max_depth': 5, 'min_child_weight': 6, 'eta': 1.0807655280042798e-06, 'gamma': 0.16301555444685334, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.9754105804889125.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:03,338]\u001b[0m Trial 2 finished with value: 0.9754105804889125 and parameters: {'booster': 'gblinear', 'lambda': 1.0359309270170474e-08, 'alpha': 7.075696168661727e-07, 'subsample': 0.5922790873508925, 'colsample_bytree': 0.3778319102692813}. Best is trial 0 with value: 0.9754105804889125.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:04,056]\u001b[0m Trial 3 finished with value: 0.9754105804889125 and parameters: {'booster': 'gblinear', 'lambda': 0.07079545808673354, 'alpha': 2.3180776056047742e-08, 'subsample': 0.41596556787849526, 'colsample_bytree': 0.45098273514362647}. Best is trial 0 with value: 0.9754105804889125.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:04,380]\u001b[0m Trial 4 finished with value: 0.9754105804889125 and parameters: {'booster': 'gbtree', 'lambda': 0.00023865212866397965, 'alpha': 4.735320019827101e-07, 'subsample': 0.5099084384193034, 'colsample_bytree': 0.3824811477201759, 'max_depth': 3, 'min_child_weight': 5, 'eta': 1.0782418016293129e-05, 'gamma': 0.013291932805999693, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.9754105804889125.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:05,102]\u001b[0m Trial 5 finished with value: 0.9754105804889125 and parameters: {'booster': 'gblinear', 'lambda': 6.14573861500385e-05, 'alpha': 3.3758443269334934e-06, 'subsample': 0.8977810149500991, 'colsample_bytree': 0.39869260066289675}. Best is trial 0 with value: 0.9754105804889125.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:13,807]\u001b[0m Trial 6 finished with value: 0.9754105804889125 and parameters: {'booster': 'dart', 'lambda': 0.4646955877454504, 'alpha': 0.002584952505942233, 'subsample': 0.9303280031127084, 'colsample_bytree': 0.5728319090131883, 'max_depth': 7, 'min_child_weight': 2, 'eta': 2.0374321524460394e-07, 'gamma': 0.08693886177283733, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.005464345890128314, 'skip_drop': 1.6165435467153385e-06}. Best is trial 0 with value: 0.9754105804889125.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:15:22,544]\u001b[0m Trial 7 finished with value: 0.9754105804889125 and parameters: {'booster': 'dart', 'lambda': 0.8445500625143612, 'alpha': 0.0037498824339141593, 'subsample': 0.7053937710223215, 'colsample_bytree': 0.7119641496455564, 'max_depth': 5, 'min_child_weight': 6, 'eta': 2.9694359660737464e-08, 'gamma': 0.47435313535884827, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 4.844608381303359e-06, 'skip_drop': 1.6254723880589547e-06}. Best is trial 0 with value: 0.9754105804889125.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:31,658]\u001b[0m Trial 8 finished with value: 0.9754105804889125 and parameters: {'booster': 'dart', 'lambda': 0.00025766254256251724, 'alpha': 0.001297107051884716, 'subsample': 0.41683115786876296, 'colsample_bytree': 0.6990102544407355, 'max_depth': 3, 'min_child_weight': 4, 'eta': 2.9067548962317533e-05, 'gamma': 9.265044966738109e-06, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 2.1754116140013732e-05, 'skip_drop': 1.4920622796596597e-06}. Best is trial 0 with value: 0.9754105804889125.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:32,100]\u001b[0m Trial 9 finished with value: 0.9754105804889125 and parameters: {'booster': 'gbtree', 'lambda': 0.16237010726042855, 'alpha': 0.0017492693211707759, 'subsample': 0.8162284992324005, 'colsample_bytree': 0.7126730355986144, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.0006611708343586079, 'gamma': 6.54098234793028e-08, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9754105804889125.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:32,402]\u001b[0m Trial 10 finished with value: 0.9754105804889125 and parameters: {'booster': 'gbtree', 'lambda': 0.004773508673264163, 'alpha': 0.9518450632194884, 'subsample': 0.2042690219043479, 'colsample_bytree': 0.9797231264522135, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.1826606725722593, 'gamma': 0.00043733119634991056, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9754105804889125.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:32,652]\u001b[0m Trial 11 finished with value: 0.9754105804889125 and parameters: {'booster': 'gbtree', 'lambda': 1.200707674316886e-08, 'alpha': 0.28917740248906126, 'subsample': 0.30641740798421857, 'colsample_bytree': 0.22284302988117244, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.002402158026178648, 'gamma': 0.0042604875716712514, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9754105804889125.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:33,020]\u001b[0m Trial 12 finished with value: 0.9754105804889125 and parameters: {'booster': 'gbtree', 'lambda': 8.680897830683629e-07, 'alpha': 4.7392201212496287e-05, 'subsample': 0.7437473193493149, 'colsample_bytree': 0.20201939288004428, 'max_depth': 5, 'min_child_weight': 2, 'eta': 1.584503243817065e-06, 'gamma': 0.9617206988851156, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9754105804889125.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:33,789]\u001b[0m Trial 13 finished with value: 0.9754105804889125 and parameters: {'booster': 'gbtree', 'lambda': 5.844286504439367e-07, 'alpha': 1.2987179778718668e-08, 'subsample': 0.9814822799186222, 'colsample_bytree': 0.5240107797483186, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.011273754799987915, 'gamma': 3.002029170431002e-05, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9754105804889125.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:34,125]\u001b[0m Trial 14 finished with value: 0.9754105804889125 and parameters: {'booster': 'gbtree', 'lambda': 0.005178278290441727, 'alpha': 0.047648196919420585, 'subsample': 0.649261193016881, 'colsample_bytree': 0.2869671332439323, 'max_depth': 7, 'min_child_weight': 7, 'eta': 8.629118963325259e-05, 'gamma': 0.004969116384270996, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.9754105804889125.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:34,468]\u001b[0m Trial 15 finished with value: 0.9754105804889125 and parameters: {'booster': 'gbtree', 'lambda': 4.835265188902571e-06, 'alpha': 5.7598330408187314e-05, 'subsample': 0.21389856243722316, 'colsample_bytree': 0.8923587485267908, 'max_depth': 5, 'min_child_weight': 3, 'eta': 2.1906506316748796e-06, 'gamma': 0.047533992585268636, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.9754105804889125.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:34,850]\u001b[0m Trial 16 finished with value: 0.9754105804889125 and parameters: {'booster': 'gbtree', 'lambda': 0.00854562283746471, 'alpha': 0.027513790913633738, 'subsample': 0.8249965361643611, 'colsample_bytree': 0.29327294999480497, 'max_depth': 7, 'min_child_weight': 10, 'eta': 1.1304647275674603e-08, 'gamma': 0.0005289494195836258, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9754105804889125.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:35,262]\u001b[0m Trial 17 finished with value: 0.9754105804889125 and parameters: {'booster': 'gbtree', 'lambda': 0.0038909755843721397, 'alpha': 6.829727149500766e-06, 'subsample': 0.6172890982722843, 'colsample_bytree': 0.48356958205071937, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.00017824590236490052, 'gamma': 0.004948303879072391, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9754105804889125.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:15:36,075]\u001b[0m A new study created in memory with name: no-name-643013e6-155f-4c33-a0f9-dbcac707d88e\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:36,192]\u001b[0m Trial 0 finished with value: 0.7509052662599808 and parameters: {'booster': 'gblinear', 'lambda': 0.00028788752999248335, 'alpha': 0.0027767637016176136, 'subsample': 0.512284898113655, 'colsample_bytree': 0.24885937427454552}. Best is trial 0 with value: 0.7509052662599808.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:36,347]\u001b[0m Trial 1 finished with value: 1.1556349261019394 and parameters: {'booster': 'gbtree', 'lambda': 9.558354549328357e-08, 'alpha': 6.077429163398151e-07, 'subsample': 0.20069547261913379, 'colsample_bytree': 0.23636866444324423, 'max_depth': 7, 'min_child_weight': 10, 'eta': 1.830594791505834e-06, 'gamma': 0.0005049823149640635, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.7509052662599808.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:37,773]\u001b[0m Trial 2 finished with value: 0.9593023779262005 and parameters: {'booster': 'dart', 'lambda': 6.830070670748098e-05, 'alpha': 3.3015031650558428e-06, 'subsample': 0.38586983113197715, 'colsample_bytree': 0.7939320802166117, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.002649916168713057, 'gamma': 4.0183196319909984e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 2.1947212463603928e-07, 'skip_drop': 0.09763668004717017}. Best is trial 0 with value: 0.7509052662599808.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:37,957]\u001b[0m Trial 3 finished with value: 0.7087101778394759 and parameters: {'booster': 'gbtree', 'lambda': 0.5211983493324881, 'alpha': 1.4334145660057045e-07, 'subsample': 0.8164268227264746, 'colsample_bytree': 0.7819729714884611, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.10075476728840693, 'gamma': 9.711174777121497e-06, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 0.7087101778394759.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:39,315]\u001b[0m Trial 4 finished with value: 1.1557725022499457 and parameters: {'booster': 'dart', 'lambda': 0.000286291291467658, 'alpha': 0.06461243897918625, 'subsample': 0.5188304295924926, 'colsample_bytree': 0.38811846162963826, 'max_depth': 3, 'min_child_weight': 6, 'eta': 1.6072983999452273e-08, 'gamma': 0.0037026971106876136, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 2.237258531381665e-05, 'skip_drop': 0.032625571748531694}. Best is trial 3 with value: 0.7087101778394759.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:40,709]\u001b[0m Trial 5 finished with value: 1.155502661223623 and parameters: {'booster': 'dart', 'lambda': 0.3610487552265455, 'alpha': 0.0011387646884089, 'subsample': 0.5970488900561933, 'colsample_bytree': 0.9091337440124361, 'max_depth': 3, 'min_child_weight': 5, 'eta': 2.8305003729891464e-06, 'gamma': 2.137966551261386e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.0019137169236398126, 'skip_drop': 0.2508378256884606}. Best is trial 3 with value: 0.7087101778394759.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:15:40,829]\u001b[0m Trial 6 finished with value: 0.827352940460488 and parameters: {'booster': 'gblinear', 'lambda': 0.00018794219064104817, 'alpha': 2.1134297614544993e-08, 'subsample': 0.9391469141433326, 'colsample_bytree': 0.6925156421240938}. Best is trial 3 with value: 0.7087101778394759.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:42,189]\u001b[0m Trial 7 finished with value: 1.1060818385077376 and parameters: {'booster': 'dart', 'lambda': 1.0958419013641951e-07, 'alpha': 0.00037030765743002346, 'subsample': 0.4243326389179206, 'colsample_bytree': 0.42798033559319093, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.000639408817535966, 'gamma': 0.10157007537166858, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 7.671474732481881e-08, 'skip_drop': 5.37643330260735e-07}. Best is trial 3 with value: 0.7087101778394759.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:43,385]\u001b[0m Trial 8 finished with value: 1.150385307315849 and parameters: {'booster': 'dart', 'lambda': 4.884020476404657e-08, 'alpha': 0.0054918871720334205, 'subsample': 0.7590679728312764, 'colsample_bytree': 0.28612613388024766, 'max_depth': 9, 'min_child_weight': 5, 'eta': 6.59643336700251e-05, 'gamma': 0.0005296399020764552, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.24391317957497208, 'skip_drop': 0.00015980837941835722}. Best is trial 3 with value: 0.7087101778394759.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:43,538]\u001b[0m Trial 9 finished with value: 0.8313957434957642 and parameters: {'booster': 'gbtree', 'lambda': 1.1830290349126136e-08, 'alpha': 0.03917863023713183, 'subsample': 0.2512586278722908, 'colsample_bytree': 0.6387930991540798, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.006082097771502055, 'gamma': 1.9553373899577136e-06, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 0.7087101778394759.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:43,831]\u001b[0m Trial 10 finished with value: 0.9750756501839933 and parameters: {'booster': 'gbtree', 'lambda': 0.3526287730140487, 'alpha': 1.1614723344491462e-08, 'subsample': 0.7976666914943338, 'colsample_bytree': 0.9789406455188483, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.37110687633007367, 'gamma': 4.485867715107193e-06, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 0.7087101778394759.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:43,970]\u001b[0m Trial 11 finished with value: 0.7712501843256927 and parameters: {'booster': 'gblinear', 'lambda': 0.013413073243724876, 'alpha': 1.0304462398008304e-05, 'subsample': 0.735147132763221, 'colsample_bytree': 0.5211340958968687}. Best is trial 3 with value: 0.7087101778394759.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:44,075]\u001b[0m Trial 12 finished with value: 0.8840423408793217 and parameters: {'booster': 'gblinear', 'lambda': 3.649061949705828e-06, 'alpha': 0.468351347353155, 'subsample': 0.903019792732628, 'colsample_bytree': 0.7784978596628602}. Best is trial 3 with value: 0.7087101778394759.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:44,376]\u001b[0m Trial 13 finished with value: 2.4331838118619826 and parameters: {'booster': 'gbtree', 'lambda': 0.016714490776704456, 'alpha': 3.500556924219899e-05, 'subsample': 0.6335514368688981, 'colsample_bytree': 0.5363097380578921, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.8141836433560216, 'gamma': 1.7478634124881594e-08, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 0.7087101778394759.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:44,566]\u001b[0m Trial 14 finished with value: 0.7909123933215095 and parameters: {'booster': 'gblinear', 'lambda': 0.003879677588903541, 'alpha': 3.6370221993194616e-07, 'subsample': 0.989994743028399, 'colsample_bytree': 0.8123976027900344}. Best is trial 3 with value: 0.7087101778394759.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:44,791]\u001b[0m Trial 15 finished with value: 0.7359635380111469 and parameters: {'booster': 'gbtree', 'lambda': 4.026863593965163e-06, 'alpha': 0.00016187305946609238, 'subsample': 0.6441888287563078, 'colsample_bytree': 0.38301631537533126, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.06519140913928538, 'gamma': 0.17154379412251794, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 0.7087101778394759.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:45,016]\u001b[0m Trial 16 finished with value: 0.6914328652638189 and parameters: {'booster': 'gbtree', 'lambda': 3.794405997239241e-06, 'alpha': 0.00021666868286198294, 'subsample': 0.8468600916351284, 'colsample_bytree': 0.3856040200370367, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.04111125041499216, 'gamma': 0.7842163512823891, 'grow_policy': 'lossguide'}. Best is trial 16 with value: 0.6914328652638189.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:45,260]\u001b[0m Trial 17 finished with value: 0.7062437875193697 and parameters: {'booster': 'gbtree', 'lambda': 3.915712292905849e-06, 'alpha': 2.0786977443468944e-07, 'subsample': 0.8533940873326575, 'colsample_bytree': 0.5500988627120414, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.016303516220197562, 'gamma': 0.8555591371861783, 'grow_policy': 'lossguide'}. Best is trial 16 with value: 0.6914328652638189.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:45,545]\u001b[0m Trial 18 finished with value: 0.7413975782584028 and parameters: {'booster': 'gbtree', 'lambda': 2.16074031814364e-06, 'alpha': 3.974915178970237e-06, 'subsample': 0.8723120114313478, 'colsample_bytree': 0.47935391229682656, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.012135411582592789, 'gamma': 0.6818056299354296, 'grow_policy': 'lossguide'}. Best is trial 16 with value: 0.6914328652638189.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:45,794]\u001b[0m Trial 19 finished with value: 1.1430393756204469 and parameters: {'booster': 'gbtree', 'lambda': 2.2253748939027815e-05, 'alpha': 2.3557444866331125e-05, 'subsample': 0.7134549560629008, 'colsample_bytree': 0.598253456884004, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.00014293388671853978, 'gamma': 0.011271487689530707, 'grow_policy': 'lossguide'}. Best is trial 16 with value: 0.6914328652638189.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:46,155]\u001b[0m Trial 20 finished with value: 0.7248145894808568 and parameters: {'booster': 'gbtree', 'lambda': 6.902043412740071e-07, 'alpha': 1.096032766996003e-07, 'subsample': 0.8376963562783264, 'colsample_bytree': 0.3260162255353095, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.02304280700471395, 'gamma': 0.02560533282091068, 'grow_policy': 'lossguide'}. Best is trial 16 with value: 0.6914328652638189.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:46,421]\u001b[0m Trial 21 finished with value: 0.7773720102287648 and parameters: {'booster': 'gbtree', 'lambda': 3.3840284222022174e-05, 'alpha': 1.031849466281837e-07, 'subsample': 0.9708929719520187, 'colsample_bytree': 0.7156250796488756, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.15389179015516163, 'gamma': 2.1419637873523363e-05, 'grow_policy': 'lossguide'}. Best is trial 16 with value: 0.6914328652638189.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:46,623]\u001b[0m Trial 22 finished with value: 0.6722999862857821 and parameters: {'booster': 'gbtree', 'lambda': 5.237945929315347e-07, 'alpha': 1.0379902690123921e-06, 'subsample': 0.824806370928014, 'colsample_bytree': 0.5736166325415522, 'max_depth': 3, 'min_child_weight': 8, 'eta': 0.05339827106824607, 'gamma': 0.6400022562561613, 'grow_policy': 'lossguide'}. Best is trial 22 with value: 0.6722999862857821.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:46,878]\u001b[0m Trial 23 finished with value: 1.0627644900977526 and parameters: {'booster': 'gbtree', 'lambda': 4.913490597559241e-07, 'alpha': 1.190068369249712e-06, 'subsample': 0.8714491210675765, 'colsample_bytree': 0.5899953852421889, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.0011467867991189098, 'gamma': 0.660372912659489, 'grow_policy': 'lossguide'}. Best is trial 22 with value: 0.6722999862857821.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:47,155]\u001b[0m Trial 24 finished with value: 0.7076490501564414 and parameters: {'booster': 'gbtree', 'lambda': 1.1068487302836224e-05, 'alpha': 8.10766246622309e-05, 'subsample': 0.6995086665752885, 'colsample_bytree': 0.4821884945643369, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.019093387233052823, 'gamma': 0.0722583707824959, 'grow_policy': 'lossguide'}. Best is trial 22 with value: 0.6722999862857821.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:47,343]\u001b[0m Trial 25 finished with value: 1.088032404540487 and parameters: {'booster': 'gbtree', 'lambda': 5.994276544500009e-07, 'alpha': 2.4532027653525273e-06, 'subsample': 0.9237151321447096, 'colsample_bytree': 0.42300610102328384, 'max_depth': 3, 'min_child_weight': 9, 'eta': 0.9224400778873871, 'gamma': 0.90540922692875, 'grow_policy': 'lossguide'}. Best is trial 22 with value: 0.6722999862857821.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:15:47,589]\u001b[0m Trial 26 finished with value: 1.1470839901899073 and parameters: {'booster': 'gbtree', 'lambda': 2.3419182266211967e-07, 'alpha': 1.1211144247555527e-05, 'subsample': 0.7794181938137582, 'colsample_bytree': 0.5427939485515093, 'max_depth': 5, 'min_child_weight': 8, 'eta': 9.922525426183088e-05, 'gamma': 0.003026939344108458, 'grow_policy': 'lossguide'}. Best is trial 22 with value: 0.6722999862857821.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:47,808]\u001b[0m Trial 27 finished with value: 0.6913599058224371 and parameters: {'booster': 'gbtree', 'lambda': 1.2767944679245128e-08, 'alpha': 0.0003517222349520123, 'subsample': 0.8582165023559758, 'colsample_bytree': 0.32755281257618585, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.043015400277099665, 'gamma': 0.24609709765599994, 'grow_policy': 'depthwise'}. Best is trial 22 with value: 0.6722999862857821.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:47,990]\u001b[0m Trial 28 finished with value: 1.1116436402153729 and parameters: {'booster': 'gbtree', 'lambda': 1.1359833010405446e-08, 'alpha': 0.0006250698899869187, 'subsample': 0.9965614124331887, 'colsample_bytree': 0.3326949383346629, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.0005882106862883141, 'gamma': 0.05159284748579033, 'grow_policy': 'depthwise'}. Best is trial 22 with value: 0.6722999862857821.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:48,242]\u001b[0m Trial 29 finished with value: 0.752965725737642 and parameters: {'booster': 'gbtree', 'lambda': 3.301442682964511e-08, 'alpha': 0.005040977122304168, 'subsample': 0.9130049261868081, 'colsample_bytree': 0.20489580462181917, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.07297796017331463, 'gamma': 0.1721650445881742, 'grow_policy': 'depthwise'}. Best is trial 22 with value: 0.6722999862857821.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:48,378]\u001b[0m Trial 30 finished with value: 0.7999106452907141 and parameters: {'booster': 'gblinear', 'lambda': 0.0015837308488241115, 'alpha': 0.00015822528931011434, 'subsample': 0.5643920953127264, 'colsample_bytree': 0.2901380062549134}. Best is trial 22 with value: 0.6722999862857821.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:48,617]\u001b[0m Trial 31 finished with value: 0.6846596086589878 and parameters: {'booster': 'gbtree', 'lambda': 1.6050405268463468e-06, 'alpha': 0.0012226288393036061, 'subsample': 0.854541702452376, 'colsample_bytree': 0.4520573376523065, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.030304577738269615, 'gamma': 0.9306863522028176, 'grow_policy': 'depthwise'}. Best is trial 22 with value: 0.6722999862857821.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:48,854]\u001b[0m Trial 32 finished with value: 0.9469430220830225 and parameters: {'booster': 'gbtree', 'lambda': 9.822871614769367e-07, 'alpha': 0.0017648730414568455, 'subsample': 0.6862324166548348, 'colsample_bytree': 0.47281010192847717, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.0031757589261760615, 'gamma': 0.2700585827483173, 'grow_policy': 'depthwise'}. Best is trial 22 with value: 0.6722999862857821.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:49,075]\u001b[0m Trial 33 finished with value: 0.7161697132282921 and parameters: {'booster': 'gbtree', 'lambda': 1.486153979566781e-07, 'alpha': 0.03654538808618803, 'subsample': 0.8246893014973311, 'colsample_bytree': 0.3550916166187027, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.23430876432618175, 'gamma': 0.013655192373406965, 'grow_policy': 'depthwise'}. Best is trial 22 with value: 0.6722999862857821.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:49,303]\u001b[0m Trial 34 finished with value: 0.7050813760391611 and parameters: {'booster': 'gbtree', 'lambda': 4.490202756901817e-08, 'alpha': 0.006503101478530948, 'subsample': 0.7796470481822908, 'colsample_bytree': 0.4275171743140451, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.03910632199483814, 'gamma': 0.2509049225985458, 'grow_policy': 'depthwise'}. Best is trial 22 with value: 0.6722999862857821.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:49,478]\u001b[0m Trial 35 finished with value: 0.9337783848555425 and parameters: {'booster': 'gbtree', 'lambda': 1.115935386163367e-05, 'alpha': 0.00029686554502198907, 'subsample': 0.8820181069352113, 'colsample_bytree': 0.24814080006629102, 'max_depth': 3, 'min_child_weight': 9, 'eta': 0.004035828757801605, 'gamma': 0.040114743275757404, 'grow_policy': 'depthwise'}. Best is trial 22 with value: 0.6722999862857821.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:50,410]\u001b[0m Trial 36 finished with value: 0.7376332681166134 and parameters: {'booster': 'dart', 'lambda': 7.356327253944154e-05, 'alpha': 5.994759134061854e-05, 'subsample': 0.9564847409967145, 'colsample_bytree': 0.653536924471734, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.2909213505330905, 'gamma': 0.00025309078793154995, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.5213370191365506, 'skip_drop': 1.6033754486057655e-08}. Best is trial 22 with value: 0.6722999862857821.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:50,638]\u001b[0m Trial 37 finished with value: 1.1554463023797155 and parameters: {'booster': 'gbtree', 'lambda': 3.0842862572413594e-07, 'alpha': 0.0010737195650650905, 'subsample': 0.836329252782227, 'colsample_bytree': 0.3870056529780459, 'max_depth': 5, 'min_child_weight': 6, 'eta': 3.966006186512654e-06, 'gamma': 0.004508649214024019, 'grow_policy': 'depthwise'}. Best is trial 22 with value: 0.6722999862857821.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:50,944]\u001b[0m Trial 38 finished with value: 0.7801417889472646 and parameters: {'booster': 'gbtree', 'lambda': 1.4383744571392665e-06, 'alpha': 0.013246927240443603, 'subsample': 0.7544705845320004, 'colsample_bytree': 0.4676054123281825, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.009120802536962838, 'gamma': 4.327447191374143e-07, 'grow_policy': 'depthwise'}. Best is trial 22 with value: 0.6722999862857821.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:52,384]\u001b[0m Trial 39 finished with value: 1.1540583416717796 and parameters: {'booster': 'dart', 'lambda': 0.000724341122555441, 'alpha': 0.0022942119706415597, 'subsample': 0.6669697612770739, 'colsample_bytree': 0.2892677504240111, 'max_depth': 3, 'min_child_weight': 6, 'eta': 2.19471597707708e-05, 'gamma': 0.001233448695760051, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 9.311947115189457e-05, 'skip_drop': 8.447508342319665e-05}. Best is trial 22 with value: 0.6722999862857821.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:52,594]\u001b[0m Trial 40 finished with value: 1.1557675786977588 and parameters: {'booster': 'gbtree', 'lambda': 9.459738605263633e-08, 'alpha': 0.2400258301260292, 'subsample': 0.4471189730214198, 'colsample_bytree': 0.20360301412974086, 'max_depth': 5, 'min_child_weight': 8, 'eta': 6.10838891425091e-08, 'gamma': 0.31035088760268914, 'grow_policy': 'depthwise'}. Best is trial 22 with value: 0.6722999862857821.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:52,844]\u001b[0m Trial 41 finished with value: 0.7079514762957791 and parameters: {'booster': 'gbtree', 'lambda': 2.787798614344147e-08, 'alpha': 0.008302116032010275, 'subsample': 0.7917558273560482, 'colsample_bytree': 0.45097535905059216, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.046597944505948646, 'gamma': 0.3713502605790755, 'grow_policy': 'depthwise'}. Best is trial 22 with value: 0.6722999862857821.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:53,089]\u001b[0m Trial 42 finished with value: 0.6987004668991735 and parameters: {'booster': 'gbtree', 'lambda': 7.405414318243122e-08, 'alpha': 0.0007138048708450568, 'subsample': 0.8060070362535665, 'colsample_bytree': 0.4245949619392969, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.03915526017997475, 'gamma': 0.11360122746872967, 'grow_policy': 'depthwise'}. Best is trial 22 with value: 0.6722999862857821.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:53,337]\u001b[0m Trial 43 finished with value: 1.0298067354270146 and parameters: {'booster': 'gbtree', 'lambda': 8.396613650012061e-08, 'alpha': 0.000583782159312453, 'subsample': 0.9406000404759395, 'colsample_bytree': 0.3674795001112252, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.00176904599255754, 'gamma': 0.10839030220950499, 'grow_policy': 'depthwise'}. Best is trial 22 with value: 0.6722999862857821.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:54,777]\u001b[0m Trial 44 finished with value: 0.7728579718400357 and parameters: {'booster': 'dart', 'lambda': 2.556832284656849e-07, 'alpha': 0.00028688565424350395, 'subsample': 0.7322126907144135, 'colsample_bytree': 0.5054292454238885, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.11926283542831315, 'gamma': 0.017847234475272936, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.004646939144377912, 'skip_drop': 0.00023729526406538517}. Best is trial 22 with value: 0.6722999862857821.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:15:54,974]\u001b[0m Trial 45 finished with value: 0.6786085671499961 and parameters: {'booster': 'gbtree', 'lambda': 2.1528889105205146e-08, 'alpha': 0.0009976812747128766, 'subsample': 0.8162524601241082, 'colsample_bytree': 0.416231993077537, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.03362392745300257, 'gamma': 0.07839648581847897, 'grow_policy': 'depthwise'}. Best is trial 22 with value: 0.6722999862857821.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:55,110]\u001b[0m Trial 46 finished with value: 0.8311698613058789 and parameters: {'booster': 'gblinear', 'lambda': 2.3147970537921932e-08, 'alpha': 2.1363598862018716e-05, 'subsample': 0.8991443669857433, 'colsample_bytree': 0.5642896034954902}. Best is trial 22 with value: 0.6722999862857821.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:55,287]\u001b[0m Trial 47 finished with value: 0.8373726531523783 and parameters: {'booster': 'gbtree', 'lambda': 1.492015729618082e-08, 'alpha': 0.019850104551166196, 'subsample': 0.24987795795851697, 'colsample_bytree': 0.32985093394632525, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.007163384530975748, 'gamma': 0.9269298701513283, 'grow_policy': 'depthwise'}. Best is trial 22 with value: 0.6722999862857821.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:55,495]\u001b[0m Trial 48 finished with value: 1.1320368955461486 and parameters: {'booster': 'gbtree', 'lambda': 7.358004498349446e-06, 'alpha': 0.0026843138111575567, 'subsample': 0.5940094258171356, 'colsample_bytree': 0.6502407441741996, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.0002692970879410259, 'gamma': 0.03854670457001128, 'grow_policy': 'lossguide'}. Best is trial 22 with value: 0.6722999862857821.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:55,632]\u001b[0m Trial 49 finished with value: 0.8235624513013229 and parameters: {'booster': 'gblinear', 'lambda': 0.00016192783295847248, 'alpha': 3.671549379976214e-08, 'subsample': 0.8504401819902343, 'colsample_bytree': 0.5090146410457741}. Best is trial 22 with value: 0.6722999862857821.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:57,037]\u001b[0m Trial 50 finished with value: 1.097428000286716 and parameters: {'booster': 'dart', 'lambda': 2.035089839155262e-06, 'alpha': 4.530489358799202e-05, 'subsample': 0.7544438861318794, 'colsample_bytree': 0.4154178751750298, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.5347452755707742, 'gamma': 6.420402926113418e-05, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.0257106459148381e-08, 'skip_drop': 1.1407041625437354e-06}. Best is trial 22 with value: 0.6722999862857821.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:57,278]\u001b[0m Trial 51 finished with value: 0.7013259140703276 and parameters: {'booster': 'gbtree', 'lambda': 6.093907193389139e-08, 'alpha': 0.0008518488347085246, 'subsample': 0.8106355889348672, 'colsample_bytree': 0.40781991070150614, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.03257122402322649, 'gamma': 0.11160792226110093, 'grow_policy': 'depthwise'}. Best is trial 22 with value: 0.6722999862857821.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:57,464]\u001b[0m Trial 52 finished with value: 0.6689889439729156 and parameters: {'booster': 'gbtree', 'lambda': 1.2628944930955135e-07, 'alpha': 0.00014816617652086566, 'subsample': 0.811202140112109, 'colsample_bytree': 0.30234828902929267, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.056468193937996354, 'gamma': 0.3653933982364181, 'grow_policy': 'depthwise'}. Best is trial 52 with value: 0.6689889439729156.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:57,650]\u001b[0m Trial 53 finished with value: 0.7132536498833562 and parameters: {'booster': 'gbtree', 'lambda': 1.6947448338202933e-07, 'alpha': 0.00012197941974484432, 'subsample': 0.8759664799618146, 'colsample_bytree': 0.3058342893268664, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.12910396487974304, 'gamma': 0.2789124127308127, 'grow_policy': 'depthwise'}. Best is trial 52 with value: 0.6689889439729156.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:57,832]\u001b[0m Trial 54 finished with value: 0.7687155892207012 and parameters: {'booster': 'gbtree', 'lambda': 4.940075100391691e-07, 'alpha': 0.00036412828273213774, 'subsample': 0.8477733887628159, 'colsample_bytree': 0.2696050712008379, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.010907705564887892, 'gamma': 0.4364292977551794, 'grow_policy': 'depthwise'}. Best is trial 52 with value: 0.6689889439729156.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:58,025]\u001b[0m Trial 55 finished with value: 0.6825159715535587 and parameters: {'booster': 'gbtree', 'lambda': 1.0724124076833414e-08, 'alpha': 1.2703472748789963e-05, 'subsample': 0.9001553175335582, 'colsample_bytree': 0.3537466928341639, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.11416987564877308, 'gamma': 0.9409937319635999, 'grow_policy': 'lossguide'}. Best is trial 52 with value: 0.6689889439729156.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:58,217]\u001b[0m Trial 56 finished with value: 0.7012172175471932 and parameters: {'booster': 'gbtree', 'lambda': 1.0280416527276756e-08, 'alpha': 4.01679401646659e-06, 'subsample': 0.9308729573005488, 'colsample_bytree': 0.35007128910494567, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.09448989898960691, 'gamma': 0.06841804917888018, 'grow_policy': 'lossguide'}. Best is trial 52 with value: 0.6689889439729156.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:58,396]\u001b[0m Trial 57 finished with value: 1.0097026128943083 and parameters: {'booster': 'gbtree', 'lambda': 2.0644123226830876e-08, 'alpha': 8.873592975704818e-07, 'subsample': 0.9655564007836143, 'colsample_bytree': 0.23270079334971686, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.442514050523945, 'gamma': 0.16722586417784305, 'grow_policy': 'depthwise'}. Best is trial 52 with value: 0.6689889439729156.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:58,614]\u001b[0m Trial 58 finished with value: 0.7988922295440019 and parameters: {'booster': 'gbtree', 'lambda': 4.56758881290611e-08, 'alpha': 7.74877121411204e-06, 'subsample': 0.727236277420392, 'colsample_bytree': 0.7417826608181269, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.254943489781961, 'gamma': 0.4858681474546945, 'grow_policy': 'lossguide'}. Best is trial 52 with value: 0.6689889439729156.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:58,841]\u001b[0m Trial 59 finished with value: 0.6766492473795731 and parameters: {'booster': 'gbtree', 'lambda': 1.352596296801209e-07, 'alpha': 1.935674990622731e-05, 'subsample': 0.8915310068068985, 'colsample_bytree': 0.8381810647052796, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.016588607051420887, 'gamma': 4.1738535976459965e-07, 'grow_policy': 'depthwise'}. Best is trial 52 with value: 0.6689889439729156.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:58,980]\u001b[0m Trial 60 finished with value: 0.7305385826775629 and parameters: {'booster': 'gblinear', 'lambda': 0.16480850584746606, 'alpha': 1.5680619141639303e-05, 'subsample': 0.8985636192328147, 'colsample_bytree': 0.9496144418727895}. Best is trial 52 with value: 0.6689889439729156.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:59,205]\u001b[0m Trial 61 finished with value: 0.6610339486725613 and parameters: {'booster': 'gbtree', 'lambda': 2.4652146595448417e-08, 'alpha': 9.645785834639825e-05, 'subsample': 0.872106033734559, 'colsample_bytree': 0.8102497372119157, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.021307709057432362, 'gamma': 1.416298496483532e-06, 'grow_policy': 'depthwise'}. Best is trial 61 with value: 0.6610339486725613.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:59,432]\u001b[0m Trial 62 finished with value: 0.6767808093045959 and parameters: {'booster': 'gbtree', 'lambda': 1.3013808998879376e-07, 'alpha': 9.36154887967822e-05, 'subsample': 0.8908427727671013, 'colsample_bytree': 0.8493310126200188, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.017279789435838057, 'gamma': 2.382652988355287e-07, 'grow_policy': 'depthwise'}. Best is trial 61 with value: 0.6610339486725613.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:59,661]\u001b[0m Trial 63 finished with value: 0.6819990856193854 and parameters: {'booster': 'gbtree', 'lambda': 3.019220849745976e-08, 'alpha': 2.8858580643518334e-05, 'subsample': 0.8913470051604341, 'colsample_bytree': 0.8272498892139443, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.014747235348536293, 'gamma': 3.600435370496527e-07, 'grow_policy': 'depthwise'}. Best is trial 61 with value: 0.6610339486725613.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:15:59,891]\u001b[0m Trial 64 finished with value: 0.819498718194518 and parameters: {'booster': 'gbtree', 'lambda': 1.1360601696415042e-07, 'alpha': 7.901859722399614e-05, 'subsample': 0.8122564333820892, 'colsample_bytree': 0.8953586669190909, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.005832199539619541, 'gamma': 1.0130819481807288e-07, 'grow_policy': 'depthwise'}. Best is trial 61 with value: 0.6610339486725613.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:16:00,121]\u001b[0m Trial 65 finished with value: 0.6843234453225018 and parameters: {'booster': 'gbtree', 'lambda': 3.162641001036985e-07, 'alpha': 3.1757118934739425e-05, 'subsample': 0.9342725405706771, 'colsample_bytree': 0.8240118587522858, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.014080240519363638, 'gamma': 4.7457027909254973e-07, 'grow_policy': 'depthwise'}. Best is trial 61 with value: 0.6610339486725613.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:16:00,348]\u001b[0m Trial 66 finished with value: 1.0200793572109104 and parameters: {'booster': 'gbtree', 'lambda': 3.356706193810731e-08, 'alpha': 3.7038538861412347e-07, 'subsample': 0.7666346937480925, 'colsample_bytree': 0.84467072927344, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.001641745974147869, 'gamma': 1.0512573827007806e-07, 'grow_policy': 'depthwise'}. Best is trial 61 with value: 0.6610339486725613.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:16:00,578]\u001b[0m Trial 67 finished with value: 0.6723843102760442 and parameters: {'booster': 'gbtree', 'lambda': 1.4662565903722928e-07, 'alpha': 5.1436498917411216e-05, 'subsample': 0.986102509959788, 'colsample_bytree': 0.8793309075192931, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.017457710564266583, 'gamma': 1.2393938710625507e-06, 'grow_policy': 'depthwise'}. Best is trial 61 with value: 0.6610339486725613.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:16:00,809]\u001b[0m Trial 68 finished with value: 0.6668141839079632 and parameters: {'booster': 'gbtree', 'lambda': 1.5309486677375703e-07, 'alpha': 0.00011750100013805512, 'subsample': 0.9761566839583046, 'colsample_bytree': 0.8605371330273414, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.021191666065268594, 'gamma': 1.6658207057927138e-06, 'grow_policy': 'depthwise'}. Best is trial 61 with value: 0.6610339486725613.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:16:01,036]\u001b[0m Trial 69 finished with value: 1.0902115007849922 and parameters: {'booster': 'gbtree', 'lambda': 1.6646669109564386e-07, 'alpha': 6.64730104414157e-06, 'subsample': 0.9848019702137862, 'colsample_bytree': 0.8556538598883605, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.000713023302796797, 'gamma': 1.925751399369441e-06, 'grow_policy': 'depthwise'}. Best is trial 61 with value: 0.6610339486725613.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:16:01,552]\u001b[0m Trial 70 finished with value: 0.8812522721859054 and parameters: {'booster': 'gbtree', 'lambda': 9.97503473500953e-07, 'alpha': 0.00012324361096012558, 'subsample': 0.9764097191339409, 'colsample_bytree': 0.9004727723361866, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.004541036949862606, 'gamma': 9.828330627016874e-07, 'grow_policy': 'depthwise'}. Best is trial 61 with value: 0.6610339486725613.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:16:01,775]\u001b[0m Trial 71 finished with value: 0.6809103074973231 and parameters: {'booster': 'gbtree', 'lambda': 3.921637790417938e-07, 'alpha': 1.7109909182207432e-06, 'subsample': 0.9552182494467192, 'colsample_bytree': 0.7743776037177822, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.07322570163911597, 'gamma': 4.549568391950436e-06, 'grow_policy': 'depthwise'}. Best is trial 61 with value: 0.6610339486725613.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:16:02,008]\u001b[0m Trial 72 finished with value: 0.6614516366090005 and parameters: {'booster': 'gbtree', 'lambda': 5.7956780468626864e-08, 'alpha': 5.7385573397940444e-05, 'subsample': 0.9956307870497682, 'colsample_bytree': 0.8701212695723847, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.021926761291726906, 'gamma': 1.8532740068571547e-07, 'grow_policy': 'depthwise'}. Best is trial 61 with value: 0.6610339486725613.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:16:02,239]\u001b[0m Trial 73 finished with value: 0.6653962994153718 and parameters: {'booster': 'gbtree', 'lambda': 1.6597256752607423e-07, 'alpha': 5.37738736693546e-05, 'subsample': 0.9438222432957091, 'colsample_bytree': 0.8706332844087182, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.018137024612367842, 'gamma': 1.0276108888892833e-07, 'grow_policy': 'depthwise'}. Best is trial 61 with value: 0.6610339486725613.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:16:02,476]\u001b[0m Trial 74 finished with value: 0.654559230070367 and parameters: {'booster': 'gbtree', 'lambda': 5.655237675074985e-08, 'alpha': 4.922614782292701e-05, 'subsample': 0.9921703264243105, 'colsample_bytree': 0.931036417680233, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.021023574170419317, 'gamma': 1.2702813054670914e-08, 'grow_policy': 'depthwise'}. Best is trial 74 with value: 0.654559230070367.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:16:02,714]\u001b[0m Trial 75 finished with value: 0.9220760270955987 and parameters: {'booster': 'gbtree', 'lambda': 5.705754521002282e-08, 'alpha': 5.1484559409812056e-05, 'subsample': 0.9929933514869564, 'colsample_bytree': 0.9913910344066873, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.003315610829327013, 'gamma': 2.175479677020823e-08, 'grow_policy': 'depthwise'}. Best is trial 74 with value: 0.654559230070367.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:16:04,208]\u001b[0m Trial 76 finished with value: 0.6618195266530662 and parameters: {'booster': 'dart', 'lambda': 8.628772169720718e-07, 'alpha': 0.00017454263128255295, 'subsample': 0.9506522358750624, 'colsample_bytree': 0.9309939979687865, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.057047779214003336, 'gamma': 3.0424471316199745e-08, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 2.618615424119977e-06, 'skip_drop': 0.0037784422199714034}. Best is trial 74 with value: 0.654559230070367.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:16:05,676]\u001b[0m Trial 77 finished with value: 0.7525248185238277 and parameters: {'booster': 'dart', 'lambda': 8.296451955246491e-07, 'alpha': 0.00016967178560152668, 'subsample': 0.9497023952673647, 'colsample_bytree': 0.927519675499615, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.18865878867821187, 'gamma': 5.2605694875873185e-08, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 6.242447162122509e-06, 'skip_drop': 0.00473768400343403}. Best is trial 74 with value: 0.654559230070367.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:16:07,130]\u001b[0m Trial 78 finished with value: 0.6759929815363671 and parameters: {'booster': 'dart', 'lambda': 2.0713965850143558e-07, 'alpha': 0.00021071472870146557, 'subsample': 0.9173532287282852, 'colsample_bytree': 0.9593173440062568, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.0650226948439464, 'gamma': 1.1767953722021121e-08, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.6124739113426646e-06, 'skip_drop': 0.0026887386903172057}. Best is trial 74 with value: 0.654559230070367.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:16:08,578]\u001b[0m Trial 79 finished with value: 0.7541598306303021 and parameters: {'booster': 'dart', 'lambda': 5.483642687574621e-07, 'alpha': 0.0005167098052914527, 'subsample': 0.965524107971179, 'colsample_bytree': 0.8640704016451343, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.008637679952541109, 'gamma': 3.740463245498427e-08, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.002555467900534495, 'skip_drop': 8.317782757223739e-06}. Best is trial 74 with value: 0.654559230070367.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:16:10,025]\u001b[0m Trial 80 finished with value: 0.66623723743448 and parameters: {'booster': 'dart', 'lambda': 7.911220866901161e-08, 'alpha': 5.035932884880894e-06, 'subsample': 0.9238638636458807, 'colsample_bytree': 0.7961527441624019, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.06189620759910902, 'gamma': 1.3730105801725186e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 5.827997804644766e-07, 'skip_drop': 0.006245196831861768}. Best is trial 74 with value: 0.654559230070367.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:16:10,312]\u001b[0m A new study created in memory with name: no-name-4b7fd20e-a764-4746-a55f-22050c5b56a2\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:16:16,880]\u001b[0m Trial 0 finished with value: 0.8191180881911808 and parameters: {'booster': 'dart', 'lambda': 8.582155244880478e-05, 'alpha': 0.08343959498010736, 'subsample': 0.3676874241636048, 'colsample_bytree': 0.6418711166899468, 'max_depth': 7, 'min_child_weight': 3, 'eta': 1.4606459862575505e-08, 'gamma': 2.286501911507469e-06, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.3671019475734902e-06, 'skip_drop': 1.0926848582266155e-06}. Best is trial 0 with value: 0.8191180881911808.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:16:17,425]\u001b[0m Trial 1 finished with value: 0.8191180881911808 and parameters: {'booster': 'gbtree', 'lambda': 1.8097627090835812e-07, 'alpha': 1.6200441545731878e-08, 'subsample': 0.6073981012841096, 'colsample_bytree': 0.4260234439684869, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.0002324590306762423, 'gamma': 3.122562067090672e-06, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.8191180881911808.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:16:17,844]\u001b[0m Trial 2 finished with value: 0.8129373874026989 and parameters: {'booster': 'gblinear', 'lambda': 2.8858466469125454e-06, 'alpha': 4.7366853023308745e-08, 'subsample': 0.5738784871617858, 'colsample_bytree': 0.5486854350707704}. Best is trial 0 with value: 0.8191180881911808.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:16:24,529]\u001b[0m Trial 3 finished with value: 0.831427133500112 and parameters: {'booster': 'dart', 'lambda': 0.558560226723916, 'alpha': 0.010157047626196581, 'subsample': 0.7116742657579118, 'colsample_bytree': 0.8775844544784037, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.04289591235913079, 'gamma': 0.0015494059805113095, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 2.8424586698495925e-08, 'skip_drop': 0.07013301648665882}. Best is trial 3 with value: 0.831427133500112.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:16:31,410]\u001b[0m Trial 4 finished with value: 0.8191180881911808 and parameters: {'booster': 'dart', 'lambda': 0.0002235701052921082, 'alpha': 0.003708901764822463, 'subsample': 0.9291353176365627, 'colsample_bytree': 0.43138047413723996, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.0026834813161461216, 'gamma': 2.4082663355677218e-08, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 2.4601117283439995e-08, 'skip_drop': 1.7323782806371995e-07}. Best is trial 3 with value: 0.831427133500112.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:16:38,162]\u001b[0m Trial 5 finished with value: 0.8191180881911808 and parameters: {'booster': 'dart', 'lambda': 4.721748024418248e-05, 'alpha': 0.00014683989333548182, 'subsample': 0.7435740006507734, 'colsample_bytree': 0.5017104979763776, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.0001829047416787233, 'gamma': 0.00029014558400757587, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 3.448712411251379e-05, 'skip_drop': 0.02437595011084294}. Best is trial 3 with value: 0.831427133500112.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:16:44,794]\u001b[0m Trial 6 finished with value: 0.8191180881911808 and parameters: {'booster': 'dart', 'lambda': 5.802051213332442e-07, 'alpha': 2.100072576761427e-07, 'subsample': 0.4684121117065996, 'colsample_bytree': 0.4393178629931722, 'max_depth': 5, 'min_child_weight': 7, 'eta': 1.2919924465729646e-06, 'gamma': 2.8899969033907083e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.865139463489617e-07, 'skip_drop': 3.415627471250157e-06}. Best is trial 3 with value: 0.831427133500112.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:16:52,227]\u001b[0m A new study created in memory with name: no-name-e149bbbf-43ae-4075-9daa-aab222497e7a\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:16:57,619]\u001b[0m Trial 0 finished with value: 0.8769655231761281 and parameters: {'booster': 'dart', 'lambda': 0.0049613287764022984, 'alpha': 5.0568988923671286e-05, 'subsample': 0.45907659482094776, 'colsample_bytree': 0.3906674112721182, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.00016729311634714738, 'gamma': 1.923171609874026e-06, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 4.236211935022759e-08, 'skip_drop': 7.860053725506345e-08}. Best is trial 0 with value: 0.8769655231761281.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:16:57,942]\u001b[0m Trial 1 finished with value: 0.8954192931765291 and parameters: {'booster': 'gbtree', 'lambda': 0.028356537522966855, 'alpha': 0.20108218709629694, 'subsample': 0.6780604476538297, 'colsample_bytree': 0.4980776747967981, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.27049667183620707, 'gamma': 1.823759615760352e-07, 'grow_policy': 'lossguide'}. Best is trial 1 with value: 0.8954192931765291.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:16:58,257]\u001b[0m Trial 2 finished with value: 0.8776661461083253 and parameters: {'booster': 'gblinear', 'lambda': 4.962010913460652e-07, 'alpha': 1.846582473328064e-05, 'subsample': 0.33052677827049814, 'colsample_bytree': 0.8192313687397561}. Best is trial 1 with value: 0.8954192931765291.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:03,686]\u001b[0m Trial 3 finished with value: 0.8491200906073705 and parameters: {'booster': 'dart', 'lambda': 3.684114973604506e-06, 'alpha': 4.2479167159143277e-07, 'subsample': 0.42462625724458525, 'colsample_bytree': 0.9173756658444514, 'max_depth': 9, 'min_child_weight': 10, 'eta': 6.444601330628749e-08, 'gamma': 0.9756995014353462, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 9.177778661062683e-06, 'skip_drop': 0.00017203669304340777}. Best is trial 1 with value: 0.8954192931765291.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:04,022]\u001b[0m Trial 4 finished with value: 0.8833498244611065 and parameters: {'booster': 'gbtree', 'lambda': 5.622004167766182e-05, 'alpha': 5.462623430179279e-06, 'subsample': 0.2217027591187115, 'colsample_bytree': 0.9224769589802775, 'max_depth': 7, 'min_child_weight': 6, 'eta': 0.13255501505384817, 'gamma': 0.038757833949073034, 'grow_policy': 'lossguide'}. Best is trial 1 with value: 0.8954192931765291.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:04,331]\u001b[0m Trial 5 finished with value: 0.9082212248740633 and parameters: {'booster': 'gblinear', 'lambda': 2.7723097068214552e-05, 'alpha': 0.0006297345083312435, 'subsample': 0.3606572902805984, 'colsample_bytree': 0.3597500839298873}. Best is trial 5 with value: 0.9082212248740633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:04,969]\u001b[0m Trial 6 finished with value: 0.8729006964623403 and parameters: {'booster': 'gbtree', 'lambda': 0.0028601754598075965, 'alpha': 0.003169592173093411, 'subsample': 0.6155503985814395, 'colsample_bytree': 0.823950674501214, 'max_depth': 7, 'min_child_weight': 10, 'eta': 4.740915755062607e-06, 'gamma': 1.615076414525649e-05, 'grow_policy': 'lossguide'}. Best is trial 5 with value: 0.9082212248740633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:05,259]\u001b[0m Trial 7 finished with value: 0.9039584757614526 and parameters: {'booster': 'gblinear', 'lambda': 0.00022710647869745096, 'alpha': 0.0018076926195091164, 'subsample': 0.39015286497442575, 'colsample_bytree': 0.2431350377939137}. Best is trial 5 with value: 0.9082212248740633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:05,718]\u001b[0m Trial 8 finished with value: 0.8902398126246438 and parameters: {'booster': 'gbtree', 'lambda': 5.72437726241632e-07, 'alpha': 2.319256703534032e-07, 'subsample': 0.9391665828526126, 'colsample_bytree': 0.8516214837600462, 'max_depth': 3, 'min_child_weight': 9, 'eta': 0.005384282023062909, 'gamma': 0.03778140792571564, 'grow_policy': 'depthwise'}. Best is trial 5 with value: 0.9082212248740633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:06,213]\u001b[0m Trial 9 finished with value: 0.9008680121072618 and parameters: {'booster': 'gbtree', 'lambda': 0.057874338467277034, 'alpha': 0.028848914426820065, 'subsample': 0.7410664070040651, 'colsample_bytree': 0.5262089360595452, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.04560313042473915, 'gamma': 0.025135651448203004, 'grow_policy': 'lossguide'}. Best is trial 5 with value: 0.9082212248740633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:06,545]\u001b[0m Trial 10 finished with value: 0.881932485035836 and parameters: {'booster': 'gblinear', 'lambda': 1.3236704196506386e-08, 'alpha': 1.004180131056127e-08, 'subsample': 0.21706428019854007, 'colsample_bytree': 0.2035034363883448}. Best is trial 5 with value: 0.9082212248740633.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:17:06,864]\u001b[0m Trial 11 finished with value: 0.9110333580982475 and parameters: {'booster': 'gblinear', 'lambda': 0.00017421386664041128, 'alpha': 0.001003612218187796, 'subsample': 0.47791455392306265, 'colsample_bytree': 0.20630202457676358}. Best is trial 11 with value: 0.9110333580982475.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:07,185]\u001b[0m Trial 12 finished with value: 0.9082212248740633 and parameters: {'booster': 'gblinear', 'lambda': 4.977233914220537e-05, 'alpha': 0.0007028873577699971, 'subsample': 0.5079690900182304, 'colsample_bytree': 0.36088384622174274}. Best is trial 11 with value: 0.9110333580982475.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:07,315]\u001b[0m Trial 13 finished with value: 0.44001603282012597 and parameters: {'booster': 'gblinear', 'lambda': 0.0005576309327624853, 'alpha': 0.9443916926315187, 'subsample': 0.5123913222897605, 'colsample_bytree': 0.33897896960226753}. Best is trial 11 with value: 0.9110333580982475.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:07,645]\u001b[0m Trial 14 finished with value: 0.8857298654393336 and parameters: {'booster': 'gblinear', 'lambda': 1.1089154374044044e-05, 'alpha': 0.0002073579474849491, 'subsample': 0.28768702188778905, 'colsample_bytree': 0.6447972638644828}. Best is trial 11 with value: 0.9110333580982475.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:07,907]\u001b[0m Trial 15 finished with value: 0.8534340006853184 and parameters: {'booster': 'gblinear', 'lambda': 0.7920947151957406, 'alpha': 0.01961933333054567, 'subsample': 0.8481966387345861, 'colsample_bytree': 0.6606790785846974}. Best is trial 11 with value: 0.9110333580982475.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:08,132]\u001b[0m Trial 16 finished with value: 0.8906550965579172 and parameters: {'booster': 'gblinear', 'lambda': 3.0145701742957787e-06, 'alpha': 0.012191049572500536, 'subsample': 0.598020376036758, 'colsample_bytree': 0.2936090712325209}. Best is trial 11 with value: 0.9110333580982475.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:12,305]\u001b[0m Trial 17 finished with value: 0.002092947203953344 and parameters: {'booster': 'dart', 'lambda': 0.0005846227171759123, 'alpha': 3.4855349617994932e-06, 'subsample': 0.5328428625268944, 'colsample_bytree': 0.4500747510569465, 'max_depth': 5, 'min_child_weight': 2, 'eta': 1.1252492771542759e-08, 'gamma': 3.2770470812300235e-08, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.5857792696144556, 'skip_drop': 0.11492166753697994}. Best is trial 11 with value: 0.9110333580982475.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:12,614]\u001b[0m Trial 18 finished with value: 0.8832652162065587 and parameters: {'booster': 'gblinear', 'lambda': 1.501381871910425e-08, 'alpha': 0.00018748510585274856, 'subsample': 0.3356647883560152, 'colsample_bytree': 0.2670136517151685}. Best is trial 11 with value: 0.9110333580982475.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:12,919]\u001b[0m Trial 19 finished with value: 0.9082212248740633 and parameters: {'booster': 'gblinear', 'lambda': 2.22138744943639e-07, 'alpha': 0.0007236897543478233, 'subsample': 0.754749428133412, 'colsample_bytree': 0.5902122831947523}. Best is trial 11 with value: 0.9110333580982475.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:17,127]\u001b[0m Trial 20 finished with value: 0.8927626841521167 and parameters: {'booster': 'dart', 'lambda': 1.5364510613850626e-07, 'alpha': 0.11233650475455251, 'subsample': 0.7881722694380436, 'colsample_bytree': 0.5887210877352671, 'max_depth': 5, 'min_child_weight': 4, 'eta': 4.046515355651579e-06, 'gamma': 0.000441341852112445, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.35527693018004014, 'skip_drop': 1.2993467972368622e-08}. Best is trial 11 with value: 0.9110333580982475.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:17,432]\u001b[0m Trial 21 finished with value: 0.9082212248740633 and parameters: {'booster': 'gblinear', 'lambda': 1.2769688297299873e-05, 'alpha': 0.00062007087174811, 'subsample': 0.9501822383728805, 'colsample_bytree': 0.7055599814244558}. Best is trial 11 with value: 0.9110333580982475.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:17,696]\u001b[0m Trial 22 finished with value: 0.8952736222294854 and parameters: {'booster': 'gblinear', 'lambda': 1.2187023765587853e-07, 'alpha': 0.0043669297317788704, 'subsample': 0.9981334311988161, 'colsample_bytree': 0.7470602603358523}. Best is trial 11 with value: 0.9110333580982475.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:18,007]\u001b[0m Trial 23 finished with value: 0.8775714494070659 and parameters: {'booster': 'gblinear', 'lambda': 9.668798652468728e-05, 'alpha': 5.9999927743111934e-05, 'subsample': 0.642228772301317, 'colsample_bytree': 0.41786559059238715}. Best is trial 11 with value: 0.9110333580982475.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:18,313]\u001b[0m Trial 24 finished with value: 0.9082212248740633 and parameters: {'booster': 'gblinear', 'lambda': 2.338515694542303e-06, 'alpha': 0.000775635953880114, 'subsample': 0.8721009284222766, 'colsample_bytree': 0.7221269811367603}. Best is trial 11 with value: 0.9110333580982475.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:18,630]\u001b[0m Trial 25 finished with value: 0.8866526418926154 and parameters: {'booster': 'gblinear', 'lambda': 2.7318651537690283e-05, 'alpha': 1.4832878771476654e-05, 'subsample': 0.5401882562515512, 'colsample_bytree': 0.3205116045193479}. Best is trial 11 with value: 0.9110333580982475.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:18,881]\u001b[0m Trial 26 finished with value: 0.8906550965579172 and parameters: {'booster': 'gblinear', 'lambda': 0.0024553034970052675, 'alpha': 0.006800080645670076, 'subsample': 0.4809269588426558, 'colsample_bytree': 0.2225226358975565}. Best is trial 11 with value: 0.9110333580982475.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:19,198]\u001b[0m Trial 27 finished with value: 0.8857298654393336 and parameters: {'booster': 'gblinear', 'lambda': 3.5093983077044084e-06, 'alpha': 0.00025836239771820585, 'subsample': 0.867947827073214, 'colsample_bytree': 0.7308471161338195}. Best is trial 11 with value: 0.9110333580982475.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:19,360]\u001b[0m Trial 28 finished with value: 0.8318528692770745 and parameters: {'booster': 'gblinear', 'lambda': 6.972938788914757e-08, 'alpha': 0.0733304303214487, 'subsample': 0.7312286376152057, 'colsample_bytree': 0.9829220973394535}. Best is trial 11 with value: 0.9110333580982475.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:24,714]\u001b[0m Trial 29 finished with value: 0.8897506762886991 and parameters: {'booster': 'dart', 'lambda': 5.598141934021518e-07, 'alpha': 4.8477386775750875e-05, 'subsample': 0.9957656552432544, 'colsample_bytree': 0.5496013976376387, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.0008431513458986696, 'gamma': 0.0011734755872025075, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.000378774460856734, 'skip_drop': 0.03309966508923356}. Best is trial 11 with value: 0.9110333580982475.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:30,148]\u001b[0m Trial 30 finished with value: 0.8518915381189155 and parameters: {'booster': 'dart', 'lambda': 1.9637819154905777e-05, 'alpha': 0.0016672597726265902, 'subsample': 0.40323947113935465, 'colsample_bytree': 0.40071923335873005, 'max_depth': 5, 'min_child_weight': 8, 'eta': 3.606139829739277e-06, 'gamma': 1.8921378981124214e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 2.0404699521009052e-08, 'skip_drop': 1.2358224889404758e-05}. Best is trial 11 with value: 0.9110333580982475.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:17:30,827]\u001b[0m A new study created in memory with name: no-name-468860cb-7b9f-4926-8139-0725e35e856a\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:32,481]\u001b[0m Trial 0 finished with value: 0.7567524480763156 and parameters: {'booster': 'gblinear', 'lambda': 0.01615442266000323, 'alpha': 1.1644609915576937e-08, 'subsample': 0.3017934956861398, 'colsample_bytree': 0.323536570415481}. Best is trial 0 with value: 0.7567524480763156.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:17:33,264]\u001b[0m Trial 1 finished with value: 0.7181241961407938 and parameters: {'booster': 'gbtree', 'lambda': 7.11433663778741e-07, 'alpha': 0.00026342291065507953, 'subsample': 0.3167924024907744, 'colsample_bytree': 0.7138086750442509, 'max_depth': 3, 'min_child_weight': 4, 'eta': 1.2559141414543115e-08, 'gamma': 1.6174238970647545e-05, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.7567524480763156.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:33,549]\u001b[0m Trial 2 finished with value: 0.6603751579509884 and parameters: {'booster': 'gblinear', 'lambda': 1.2800030350485432e-08, 'alpha': 0.04969155545760789, 'subsample': 0.5314406972604417, 'colsample_bytree': 0.8488108055823995}. Best is trial 0 with value: 0.7567524480763156.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:35,222]\u001b[0m Trial 3 finished with value: 0.7196842238745539 and parameters: {'booster': 'gblinear', 'lambda': 0.03468610530136394, 'alpha': 3.3220269211197627e-07, 'subsample': 0.843988438964494, 'colsample_bytree': 0.48979281722621065}. Best is trial 0 with value: 0.7567524480763156.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:35,428]\u001b[0m Trial 4 finished with value: 0.19717242704587254 and parameters: {'booster': 'gblinear', 'lambda': 0.0012583834637691607, 'alpha': 0.6143704247500458, 'subsample': 0.7753247477561045, 'colsample_bytree': 0.5948713021469811}. Best is trial 0 with value: 0.7567524480763156.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:17:53,810]\u001b[0m Trial 5 finished with value: 0.7482089990896253 and parameters: {'booster': 'dart', 'lambda': 0.0003307196408650489, 'alpha': 0.00011410737070120188, 'subsample': 0.7233815482855563, 'colsample_bytree': 0.6312287309387236, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.0016406865647893506, 'gamma': 6.571270069363841e-07, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.059464360626231345, 'skip_drop': 4.5298533865315e-08}. Best is trial 0 with value: 0.7567524480763156.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:18:14,139]\u001b[0m Trial 6 finished with value: 0.8400970395231556 and parameters: {'booster': 'dart', 'lambda': 1.1450598125999475e-08, 'alpha': 0.5554719539219802, 'subsample': 0.8345218414101181, 'colsample_bytree': 0.9372264477727286, 'max_depth': 7, 'min_child_weight': 3, 'eta': 7.920038329119983e-05, 'gamma': 0.8129329918217876, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 2.871330240654372e-06, 'skip_drop': 1.0387158010793576e-05}. Best is trial 6 with value: 0.8400970395231556.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:18:36,984]\u001b[0m A new study created in memory with name: no-name-c4e1a49a-f2e9-4c55-9d70-695f06b6b9d7\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:18:38,538]\u001b[0m Trial 0 finished with value: 0.8824775512879334 and parameters: {'booster': 'gblinear', 'lambda': 5.461903245174092e-06, 'alpha': 0.0005152409490318844, 'subsample': 0.765948707790268, 'colsample_bytree': 0.7240911618216792}. Best is trial 0 with value: 0.8824775512879334.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:18:39,982]\u001b[0m Trial 1 finished with value: 0.8548885031958677 and parameters: {'booster': 'gbtree', 'lambda': 0.042300260473745056, 'alpha': 0.008213015998606858, 'subsample': 0.8465216439246153, 'colsample_bytree': 0.9277520692465917, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.8508161971044713, 'gamma': 0.6128671030831422, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.8824775512879334.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:18:41,257]\u001b[0m Trial 2 finished with value: 0.855041916838289 and parameters: {'booster': 'gbtree', 'lambda': 7.466516420475804e-08, 'alpha': 0.06113158219778319, 'subsample': 0.7322928159922031, 'colsample_bytree': 0.934679165649043, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.18355695169136502, 'gamma': 0.00019955624614285378, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.8824775512879334.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:18:41,479]\u001b[0m Trial 3 finished with value: 0.17717266969840692 and parameters: {'booster': 'gblinear', 'lambda': 1.3842404001618522e-07, 'alpha': 0.27972272512475654, 'subsample': 0.28534641459929544, 'colsample_bytree': 0.8995023413594667}. Best is trial 0 with value: 0.8824775512879334.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:18:42,121]\u001b[0m Trial 4 finished with value: 0.7237700000049939 and parameters: {'booster': 'gbtree', 'lambda': 2.6346396465558263e-08, 'alpha': 0.0011465585809411103, 'subsample': 0.2344751547329212, 'colsample_bytree': 0.49926755960212327, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.00497165584822676, 'gamma': 2.9093746236370594e-06, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.8824775512879334.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:18:43,506]\u001b[0m Trial 5 finished with value: 0.8544105181050179 and parameters: {'booster': 'gbtree', 'lambda': 0.014495037602143797, 'alpha': 0.007749993391784523, 'subsample': 0.7069335917004416, 'colsample_bytree': 0.4954055658859788, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.012210603075068186, 'gamma': 1.3662556960859814e-08, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.8824775512879334.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:03,734]\u001b[0m Trial 6 finished with value: 0.8324469703983883 and parameters: {'booster': 'dart', 'lambda': 0.019673081302743853, 'alpha': 4.1097479755230277e-07, 'subsample': 0.6061822943827531, 'colsample_bytree': 0.5780680071568527, 'max_depth': 3, 'min_child_weight': 2, 'eta': 3.7301070623957014e-08, 'gamma': 2.4859470099288395e-07, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.0044772707004982135, 'skip_drop': 0.00016634322402193637}. Best is trial 0 with value: 0.8824775512879334.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:04,989]\u001b[0m Trial 7 finished with value: 0.8791859319469641 and parameters: {'booster': 'gbtree', 'lambda': 6.491754493056658e-07, 'alpha': 0.05169131351021069, 'subsample': 0.9395071096393519, 'colsample_bytree': 0.7153398149500123, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.028837911466660027, 'gamma': 0.0025015326768422753, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.8824775512879334.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:23,143]\u001b[0m Trial 8 finished with value: 0.7895689298012435 and parameters: {'booster': 'dart', 'lambda': 0.03071509660752935, 'alpha': 0.00011267492481223641, 'subsample': 0.6529134511423111, 'colsample_bytree': 0.8405207177786951, 'max_depth': 3, 'min_child_weight': 6, 'eta': 1.475282861239922e-07, 'gamma': 0.0002790521074181946, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.15522660703982297, 'skip_drop': 0.09199098543317175}. Best is trial 0 with value: 0.8824775512879334.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:19:26,028]\u001b[0m A new study created in memory with name: no-name-59724283-cb81-47ba-81e9-22c19d21eb0a\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:26,143]\u001b[0m Trial 0 finished with value: 0.2230442955299459 and parameters: {'booster': 'gblinear', 'lambda': 1.7762774932857975e-07, 'alpha': 3.0718845942575327e-06, 'subsample': 0.20792100055830504, 'colsample_bytree': 0.6661840769265128}. Best is trial 0 with value: 0.2230442955299459.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:27,529]\u001b[0m Trial 1 finished with value: 1.2817324013622267 and parameters: {'booster': 'dart', 'lambda': 0.7133031146687893, 'alpha': 0.00025703940901112426, 'subsample': 0.9193097104685282, 'colsample_bytree': 0.704870535633418, 'max_depth': 5, 'min_child_weight': 10, 'eta': 8.984337575034404e-07, 'gamma': 3.561266160880683e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 4.836321470848739e-05, 'skip_drop': 2.2546747192755069e-07}. Best is trial 0 with value: 0.2230442955299459.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:19:28,966]\u001b[0m Trial 2 finished with value: 1.2818103191066113 and parameters: {'booster': 'dart', 'lambda': 0.0006793301079046571, 'alpha': 0.7986414131234396, 'subsample': 0.35886780784789585, 'colsample_bytree': 0.7423710801728138, 'max_depth': 5, 'min_child_weight': 4, 'eta': 5.305537404683322e-07, 'gamma': 1.8425197975655893e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 4.998571765691882e-06, 'skip_drop': 3.754905637277861e-05}. Best is trial 0 with value: 0.2230442955299459.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:30,439]\u001b[0m Trial 3 finished with value: 0.41253575264839154 and parameters: {'booster': 'dart', 'lambda': 0.013195654898818951, 'alpha': 0.3675223834026761, 'subsample': 0.43885784856025645, 'colsample_bytree': 0.6880171667766539, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.008711652510861893, 'gamma': 2.922059651476362e-07, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.0017590464520017115, 'skip_drop': 0.09068878449995633}. Best is trial 0 with value: 0.2230442955299459.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:30,668]\u001b[0m Trial 4 finished with value: 0.2287093542330352 and parameters: {'booster': 'gbtree', 'lambda': 0.12237873991879859, 'alpha': 6.568358265523258e-06, 'subsample': 0.25829121110740466, 'colsample_bytree': 0.34894051194667053, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.032427691103772784, 'gamma': 0.000498049820720531, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.2230442955299459.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:30,794]\u001b[0m Trial 5 finished with value: 0.21799435193095199 and parameters: {'booster': 'gblinear', 'lambda': 0.0002672077045829654, 'alpha': 0.00012619152348384037, 'subsample': 0.5366579871412582, 'colsample_bytree': 0.4120788908947197}. Best is trial 5 with value: 0.21799435193095199.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:30,911]\u001b[0m Trial 6 finished with value: 0.22870578991257268 and parameters: {'booster': 'gblinear', 'lambda': 1.589961716246646e-08, 'alpha': 6.142186444267084e-06, 'subsample': 0.38670429648476223, 'colsample_bytree': 0.23335937076536598}. Best is trial 5 with value: 0.21799435193095199.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:31,027]\u001b[0m Trial 7 finished with value: 0.22349251139842263 and parameters: {'booster': 'gblinear', 'lambda': 1.0428851700507337e-05, 'alpha': 1.1988870511718444e-08, 'subsample': 0.22925372106204264, 'colsample_bytree': 0.42072488076654013}. Best is trial 5 with value: 0.21799435193095199.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:31,147]\u001b[0m Trial 8 finished with value: 0.22483015296293712 and parameters: {'booster': 'gblinear', 'lambda': 3.834954583366146e-07, 'alpha': 4.400271714530605e-07, 'subsample': 0.640426969170099, 'colsample_bytree': 0.2549633165948444}. Best is trial 5 with value: 0.21799435193095199.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:31,438]\u001b[0m Trial 9 finished with value: 1.2694833150640494 and parameters: {'booster': 'gbtree', 'lambda': 1.715724228256799e-07, 'alpha': 0.2650154440933031, 'subsample': 0.8749384092512711, 'colsample_bytree': 0.422491833519719, 'max_depth': 9, 'min_child_weight': 8, 'eta': 6.808901146200991e-05, 'gamma': 2.482838065700234e-06, 'grow_policy': 'lossguide'}. Best is trial 5 with value: 0.21799435193095199.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:31,570]\u001b[0m Trial 10 finished with value: 0.19980358210792717 and parameters: {'booster': 'gblinear', 'lambda': 0.0001162977542511601, 'alpha': 0.004346320611982841, 'subsample': 0.571200377551099, 'colsample_bytree': 0.85594927881354}. Best is trial 10 with value: 0.19980358210792717.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:31,703]\u001b[0m Trial 11 finished with value: 0.20165548834889122 and parameters: {'booster': 'gblinear', 'lambda': 0.00022525130968389202, 'alpha': 0.0023808179066958425, 'subsample': 0.6222829850055215, 'colsample_bytree': 0.9705754562197324}. Best is trial 10 with value: 0.19980358210792717.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:31,831]\u001b[0m Trial 12 finished with value: 0.20155206190368422 and parameters: {'booster': 'gblinear', 'lambda': 3.140016622594405e-05, 'alpha': 0.006569698463947315, 'subsample': 0.7037551971614929, 'colsample_bytree': 0.990216255081833}. Best is trial 10 with value: 0.19980358210792717.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:31,958]\u001b[0m Trial 13 finished with value: 0.20106401441506 and parameters: {'booster': 'gblinear', 'lambda': 9.045467255924147e-06, 'alpha': 0.005607433637497094, 'subsample': 0.7694405085899525, 'colsample_bytree': 0.9703695521354707}. Best is trial 10 with value: 0.19980358210792717.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:32,085]\u001b[0m Trial 14 finished with value: 0.20363307215838272 and parameters: {'booster': 'gblinear', 'lambda': 4.720817089313474e-06, 'alpha': 0.0091414224625961, 'subsample': 0.8008443552075759, 'colsample_bytree': 0.8614674873587677}. Best is trial 10 with value: 0.19980358210792717.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:32,296]\u001b[0m Trial 15 finished with value: 0.263433859582516 and parameters: {'booster': 'gbtree', 'lambda': 0.0029929149895693333, 'alpha': 0.02391074034276423, 'subsample': 0.7714355719745354, 'colsample_bytree': 0.8354223498874516, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.8570395314398963, 'gamma': 0.6207860492389796, 'grow_policy': 'lossguide'}. Best is trial 10 with value: 0.19980358210792717.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:32,427]\u001b[0m Trial 16 finished with value: 0.21019984324683183 and parameters: {'booster': 'gblinear', 'lambda': 3.7354501492428824e-06, 'alpha': 0.000766951917049684, 'subsample': 0.5370719584877129, 'colsample_bytree': 0.8697819849856497}. Best is trial 10 with value: 0.19980358210792717.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:32,544]\u001b[0m Trial 17 finished with value: 0.2607987909862273 and parameters: {'booster': 'gblinear', 'lambda': 0.0040433701846533925, 'alpha': 0.07501651496642536, 'subsample': 0.9806181394702107, 'colsample_bytree': 0.5676556434649902}. Best is trial 10 with value: 0.19980358210792717.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:33,253]\u001b[0m Trial 18 finished with value: 1.281917226974608 and parameters: {'booster': 'dart', 'lambda': 3.743440652700293e-05, 'alpha': 4.445018999411384e-05, 'subsample': 0.7445424257535804, 'colsample_bytree': 0.914968240859544, 'max_depth': 3, 'min_child_weight': 10, 'eta': 1.1952798301643719e-08, 'gamma': 0.44271385378870354, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.9462938745100284, 'skip_drop': 0.3468284684790723}. Best is trial 10 with value: 0.19980358210792717.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:33,526]\u001b[0m Trial 19 finished with value: 1.2638504688710022 and parameters: {'booster': 'gbtree', 'lambda': 1.6248658268270652e-06, 'alpha': 0.0011059895130569512, 'subsample': 0.5074350032798387, 'colsample_bytree': 0.7779591733640105, 'max_depth': 7, 'min_child_weight': 5, 'eta': 8.687048447209765e-05, 'gamma': 0.0034959906289726075, 'grow_policy': 'depthwise'}. Best is trial 10 with value: 0.19980358210792717.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:33,647]\u001b[0m Trial 20 finished with value: 0.213166752047806 and parameters: {'booster': 'gblinear', 'lambda': 1.2728767143426836e-08, 'alpha': 0.030715530323725652, 'subsample': 0.6659897543098184, 'colsample_bytree': 0.5588052866680238}. Best is trial 10 with value: 0.19980358210792717.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:33,775]\u001b[0m Trial 21 finished with value: 0.20033196632624892 and parameters: {'booster': 'gblinear', 'lambda': 6.153969183039174e-05, 'alpha': 0.004895442894110502, 'subsample': 0.7194444293214183, 'colsample_bytree': 0.996223969728137}. Best is trial 10 with value: 0.19980358210792717.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:33,904]\u001b[0m Trial 22 finished with value: 0.2004653556876433 and parameters: {'booster': 'gblinear', 'lambda': 5.752869294710402e-05, 'alpha': 0.0033404693690948536, 'subsample': 0.833841559842539, 'colsample_bytree': 0.9257293965835102}. Best is trial 10 with value: 0.19980358210792717.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:34,034]\u001b[0m Trial 23 finished with value: 0.210967970293312 and parameters: {'booster': 'gblinear', 'lambda': 7.078511727868006e-05, 'alpha': 0.0005707240202930233, 'subsample': 0.853836836533661, 'colsample_bytree': 0.9136938452520041}. Best is trial 10 with value: 0.19980358210792717.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:19:34,145]\u001b[0m Trial 24 finished with value: 0.27419582011470905 and parameters: {'booster': 'gblinear', 'lambda': 0.0009304998577842068, 'alpha': 0.08812448398193008, 'subsample': 0.6999847166494692, 'colsample_bytree': 0.799417906207103}. Best is trial 10 with value: 0.19980358210792717.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:34,274]\u001b[0m Trial 25 finished with value: 0.21579103815336517 and parameters: {'booster': 'gblinear', 'lambda': 0.02999494065964721, 'alpha': 8.708393902413767e-05, 'subsample': 0.578086219638656, 'colsample_bytree': 0.9066635611202426}. Best is trial 10 with value: 0.19980358210792717.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:34,404]\u001b[0m Trial 26 finished with value: 0.19944447581224597 and parameters: {'booster': 'gblinear', 'lambda': 0.0001837408090175405, 'alpha': 0.003687265394724989, 'subsample': 0.9992392796809779, 'colsample_bytree': 0.9995848705446633}. Best is trial 26 with value: 0.19944447581224597.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:35,804]\u001b[0m Trial 27 finished with value: 0.8143474111688205 and parameters: {'booster': 'dart', 'lambda': 0.0011628096150219272, 'alpha': 0.02362533121492346, 'subsample': 0.9990850078940408, 'colsample_bytree': 0.9964156132794132, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.002875024070145061, 'gamma': 1.790916577443377e-05, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.3092366586321834e-08, 'skip_drop': 1.3869595144128578e-08}. Best is trial 26 with value: 0.19944447581224597.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:35,934]\u001b[0m Trial 28 finished with value: 0.22222133074564027 and parameters: {'booster': 'gblinear', 'lambda': 0.00022689195942093745, 'alpha': 4.350443492057216e-05, 'subsample': 0.9305294070876796, 'colsample_bytree': 0.8081958786659219}. Best is trial 26 with value: 0.19944447581224597.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:36,215]\u001b[0m Trial 29 finished with value: 1.3295392222532316 and parameters: {'booster': 'gbtree', 'lambda': 1.8981335497102572e-05, 'alpha': 7.256762518758945e-07, 'subsample': 0.47596854590813453, 'colsample_bytree': 0.6510537890327037, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.9527152380804182, 'gamma': 0.014232516158269988, 'grow_policy': 'lossguide'}. Best is trial 26 with value: 0.19944447581224597.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:36,328]\u001b[0m Trial 30 finished with value: 0.25696730958670383 and parameters: {'booster': 'gblinear', 'lambda': 8.443849755515668e-07, 'alpha': 0.07460221912876391, 'subsample': 0.5909934074643656, 'colsample_bytree': 0.6293617534143429}. Best is trial 26 with value: 0.19944447581224597.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:36,456]\u001b[0m Trial 31 finished with value: 0.19935850980316422 and parameters: {'booster': 'gblinear', 'lambda': 0.0001636751807023814, 'alpha': 0.0040806853144846715, 'subsample': 0.8349656918420393, 'colsample_bytree': 0.9348489388521712}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:36,587]\u001b[0m Trial 32 finished with value: 0.21670709817606046 and parameters: {'booster': 'gblinear', 'lambda': 0.00014874702541214577, 'alpha': 0.00030504174017615185, 'subsample': 0.9084847612134785, 'colsample_bytree': 0.9405286363035187}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:36,716]\u001b[0m Trial 33 finished with value: 0.20467258892825782 and parameters: {'booster': 'gblinear', 'lambda': 0.0004352532235713533, 'alpha': 0.001568438509598604, 'subsample': 0.9459131895012066, 'colsample_bytree': 0.8767236996800296}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:37,755]\u001b[0m Trial 34 finished with value: 1.2818412932480743 and parameters: {'booster': 'dart', 'lambda': 0.005512720495936372, 'alpha': 0.013117754577994682, 'subsample': 0.8240021841548462, 'colsample_bytree': 0.7632888353411076, 'max_depth': 5, 'min_child_weight': 6, 'eta': 2.8568328252254347e-06, 'gamma': 0.00013483382193223584, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.4620266692526328, 'skip_drop': 0.000401233830706999}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:37,885]\u001b[0m Trial 35 finished with value: 0.21500727669198516 and parameters: {'booster': 'gblinear', 'lambda': 0.001471745390425588, 'alpha': 0.0002799164391637596, 'subsample': 0.6927908891013106, 'colsample_bytree': 0.7212218494209908}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:37,986]\u001b[0m Trial 36 finished with value: 1.072434056305355 and parameters: {'booster': 'gblinear', 'lambda': 9.0697808581664e-05, 'alpha': 0.7202757046372008, 'subsample': 0.8797247114326099, 'colsample_bytree': 0.9549435406986203}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:39,411]\u001b[0m Trial 37 finished with value: 1.281917232589977 and parameters: {'booster': 'dart', 'lambda': 0.0006148266343137316, 'alpha': 0.17965345073766967, 'subsample': 0.3382827839660881, 'colsample_bytree': 0.8222755417389251, 'max_depth': 9, 'min_child_weight': 9, 'eta': 1.3095677698936325e-08, 'gamma': 1.1473968357027447e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.185877803978885e-08, 'skip_drop': 0.00047563260163524263}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:39,540]\u001b[0m Trial 38 finished with value: 0.20968167061577225 and parameters: {'booster': 'gblinear', 'lambda': 0.021830549543733518, 'alpha': 0.0027465431665011013, 'subsample': 0.7253967128233353, 'colsample_bytree': 0.996136407822021}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:39,670]\u001b[0m Trial 39 finished with value: 0.22100537719392738 and parameters: {'booster': 'gblinear', 'lambda': 1.5602477386819393e-05, 'alpha': 0.0001327568548120131, 'subsample': 0.4313091582913523, 'colsample_bytree': 0.878578375923958}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:39,902]\u001b[0m Trial 40 finished with value: 1.0764038874212294 and parameters: {'booster': 'gbtree', 'lambda': 0.00014691888496906028, 'alpha': 1.532974351335738e-05, 'subsample': 0.652167088809932, 'colsample_bytree': 0.4846906696335088, 'max_depth': 5, 'min_child_weight': 3, 'eta': 0.0011953205520828557, 'gamma': 5.9252075177485345e-06, 'grow_policy': 'lossguide'}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:40,032]\u001b[0m Trial 41 finished with value: 0.19992240344228798 and parameters: {'booster': 'gblinear', 'lambda': 6.0545442287558666e-05, 'alpha': 0.002610693977572596, 'subsample': 0.8338181978621421, 'colsample_bytree': 0.9195652103502603}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:40,162]\u001b[0m Trial 42 finished with value: 0.21121106206169296 and parameters: {'booster': 'gblinear', 'lambda': 0.000434233749355031, 'alpha': 0.0007383619237518106, 'subsample': 0.8966259691732115, 'colsample_bytree': 0.9531574087562159}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:40,289]\u001b[0m Trial 43 finished with value: 0.20015468024264815 and parameters: {'booster': 'gblinear', 'lambda': 3.174277390602163e-05, 'alpha': 0.003656729463187467, 'subsample': 0.7803675569520911, 'colsample_bytree': 0.8961408862786121}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:40,415]\u001b[0m Trial 44 finished with value: 0.45979757483873607 and parameters: {'booster': 'gblinear', 'lambda': 0.9244547962891748, 'alpha': 0.013484329111085751, 'subsample': 0.9504753917653419, 'colsample_bytree': 0.8422579367740415}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:40,545]\u001b[0m Trial 45 finished with value: 0.20284873636119716 and parameters: {'booster': 'gblinear', 'lambda': 4.218189073640851e-06, 'alpha': 0.0018263357068147475, 'subsample': 0.7925430117072961, 'colsample_bytree': 0.7345972090692964}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:40,665]\u001b[0m Trial 46 finished with value: 0.21962740893875937 and parameters: {'booster': 'gblinear', 'lambda': 6.705303568266224e-08, 'alpha': 0.03955272641185104, 'subsample': 0.8312558302203586, 'colsample_bytree': 0.9027294061236162}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:19:40,796]\u001b[0m Trial 47 finished with value: 0.2243102306793067 and parameters: {'booster': 'gblinear', 'lambda': 2.207671748968975e-05, 'alpha': 2.1710829376129947e-08, 'subsample': 0.5524989927264067, 'colsample_bytree': 0.6861579396849099}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:40,924]\u001b[0m Trial 48 finished with value: 0.20196160940217192 and parameters: {'booster': 'gblinear', 'lambda': 9.22049648616841e-06, 'alpha': 0.007082982230455207, 'subsample': 0.6130744368707373, 'colsample_bytree': 0.8852410200427122}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:42,426]\u001b[0m Trial 49 finished with value: 1.2784973959500359 and parameters: {'booster': 'dart', 'lambda': 0.002279109742039043, 'alpha': 0.0006264164114276261, 'subsample': 0.7594518625724697, 'colsample_bytree': 0.9537882934258102, 'max_depth': 7, 'min_child_weight': 6, 'eta': 1.5871833782908748e-05, 'gamma': 0.03240642855648901, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.004905054799260901, 'skip_drop': 2.046233358142885e-06}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:42,638]\u001b[0m Trial 50 finished with value: 0.20574248708786405 and parameters: {'booster': 'gbtree', 'lambda': 0.1096113174479951, 'alpha': 0.01292893976786052, 'subsample': 0.8628737808751201, 'colsample_bytree': 0.8448844958636891, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.06814027231734385, 'gamma': 0.000853022113224873, 'grow_policy': 'depthwise'}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:42,766]\u001b[0m Trial 51 finished with value: 0.20033253112157826 and parameters: {'booster': 'gblinear', 'lambda': 4.862086731713461e-05, 'alpha': 0.003873243084752447, 'subsample': 0.7421283254234478, 'colsample_bytree': 0.980752238113816}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:42,894]\u001b[0m Trial 52 finished with value: 0.19963277141529548 and parameters: {'booster': 'gblinear', 'lambda': 9.869540412750823e-05, 'alpha': 0.004870167874744478, 'subsample': 0.6613966454039962, 'colsample_bytree': 0.926749535480125}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:43,025]\u001b[0m Trial 53 finished with value: 0.20479056733768108 and parameters: {'booster': 'gblinear', 'lambda': 0.00014257802972454862, 'alpha': 0.0016854986093815874, 'subsample': 0.7973635793372622, 'colsample_bytree': 0.9393714626221753}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:43,154]\u001b[0m Trial 54 finished with value: 0.20264237555335246 and parameters: {'booster': 'gblinear', 'lambda': 0.0002682634430985842, 'alpha': 0.00762045332406223, 'subsample': 0.6315521429709718, 'colsample_bytree': 0.7801809527898487}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:43,285]\u001b[0m Trial 55 finished with value: 0.21459234911777314 and parameters: {'booster': 'gblinear', 'lambda': 3.188948187537112e-05, 'alpha': 0.0003896759732828836, 'subsample': 0.6642708299718425, 'colsample_bytree': 0.9018006201942688}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:43,402]\u001b[0m Trial 56 finished with value: 0.22580481637452995 and parameters: {'booster': 'gblinear', 'lambda': 2.5647548091485737e-06, 'alpha': 0.04646610103627182, 'subsample': 0.9643067030646965, 'colsample_bytree': 0.8563627036476024}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:43,533]\u001b[0m Trial 57 finished with value: 0.20683475324801992 and parameters: {'booster': 'gblinear', 'lambda': 8.013215622365882e-06, 'alpha': 0.001187252378877527, 'subsample': 0.68698630370019, 'colsample_bytree': 0.2683741312678452}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:43,663]\u001b[0m Trial 58 finished with value: 0.20059385632289847 and parameters: {'booster': 'gblinear', 'lambda': 8.759239387508593e-05, 'alpha': 0.003740794855990362, 'subsample': 0.4938240779672812, 'colsample_bytree': 0.9312612976817483}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:43,793]\u001b[0m Trial 59 finished with value: 0.2121269601418511 and parameters: {'booster': 'gblinear', 'lambda': 0.007209398147907456, 'alpha': 0.00017401373628807696, 'subsample': 0.5699314228056839, 'colsample_bytree': 0.9619593407583198}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:44,147]\u001b[0m Trial 60 finished with value: 1.233823230788056 and parameters: {'booster': 'gbtree', 'lambda': 0.0002890891465081571, 'alpha': 0.1433451489217513, 'subsample': 0.8104840819652379, 'colsample_bytree': 0.8965846053870968, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.00022898069005851168, 'gamma': 0.09943349179686202, 'grow_policy': 'lossguide'}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:44,271]\u001b[0m Trial 61 finished with value: 0.20658181081615304 and parameters: {'booster': 'gblinear', 'lambda': 3.823270390143912e-05, 'alpha': 0.020680754823938188, 'subsample': 0.7293266214096079, 'colsample_bytree': 0.9813894582019282}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:44,398]\u001b[0m Trial 62 finished with value: 0.20101337200002972 and parameters: {'booster': 'gblinear', 'lambda': 9.145557077812447e-05, 'alpha': 0.006309715635516329, 'subsample': 0.7763072514989394, 'colsample_bytree': 0.9191258192277959}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:44,526]\u001b[0m Trial 63 finished with value: 0.1998849183934655 and parameters: {'booster': 'gblinear', 'lambda': 0.0006555169075756005, 'alpha': 0.004496352394892558, 'subsample': 0.7134181394049647, 'colsample_bytree': 0.9785899746425699}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:44,651]\u001b[0m Trial 64 finished with value: 0.20302027478606266 and parameters: {'booster': 'gblinear', 'lambda': 0.0007182388377206329, 'alpha': 0.002086971896480394, 'subsample': 0.8421367461605777, 'colsample_bytree': 0.8642146859814431}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:44,772]\u001b[0m Trial 65 finished with value: 0.20619292467684078 and parameters: {'booster': 'gblinear', 'lambda': 0.0018319097416671763, 'alpha': 0.015345529251569807, 'subsample': 0.6757743404253225, 'colsample_bytree': 0.9262406448495131}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:44,902]\u001b[0m Trial 66 finished with value: 0.20745213554214015 and parameters: {'booster': 'gblinear', 'lambda': 0.00018871846247347333, 'alpha': 0.0010742666127114447, 'subsample': 0.8787681690867043, 'colsample_bytree': 0.810190507090612}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:46,301]\u001b[0m Trial 67 finished with value: 1.281890299986799 and parameters: {'booster': 'dart', 'lambda': 0.0005365859165472753, 'alpha': 0.0032321288896527854, 'subsample': 0.6151923049912922, 'colsample_bytree': 0.9580053212954576, 'max_depth': 5, 'min_child_weight': 5, 'eta': 1.4690530294638204e-07, 'gamma': 2.717181144602887e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 4.0154882340506874e-07, 'skip_drop': 0.02466982249954156}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:46,437]\u001b[0m Trial 68 finished with value: 0.2223012397193483 and parameters: {'booster': 'gblinear', 'lambda': 1.9156704837270313e-05, 'alpha': 6.713223163760351e-05, 'subsample': 0.7795286220168026, 'colsample_bytree': 0.9740282515842597}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:46,572]\u001b[0m Trial 69 finished with value: 0.21320339009810302 and parameters: {'booster': 'gblinear', 'lambda': 0.00034152991027460133, 'alpha': 0.00042999199766939134, 'subsample': 0.7530366601668663, 'colsample_bytree': 0.8314703940787815}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:46,692]\u001b[0m Trial 70 finished with value: 0.2173100051840595 and parameters: {'booster': 'gblinear', 'lambda': 0.0008619243317598029, 'alpha': 0.03601222429188691, 'subsample': 0.903934609914554, 'colsample_bytree': 0.99974199049767}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:19:46,824]\u001b[0m Trial 71 finished with value: 0.2033838599984519 and parameters: {'booster': 'gblinear', 'lambda': 5.586636292183335e-05, 'alpha': 0.009321327041720128, 'subsample': 0.715891599137218, 'colsample_bytree': 0.9267309939736375}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:46,951]\u001b[0m Trial 72 finished with value: 0.20074837894899542 and parameters: {'booster': 'gblinear', 'lambda': 0.00013798225804672156, 'alpha': 0.00555872642905188, 'subsample': 0.6477851915466338, 'colsample_bytree': 0.9991074504264119}. Best is trial 31 with value: 0.19935850980316422.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:47,077]\u001b[0m Trial 73 finished with value: 0.19872817452427796 and parameters: {'booster': 'gblinear', 'lambda': 1.2188704828584415e-05, 'alpha': 0.0037252997421683056, 'subsample': 0.7189039701561741, 'colsample_bytree': 0.8850109542076964}. Best is trial 73 with value: 0.19872817452427796.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:47,206]\u001b[0m Trial 74 finished with value: 0.20805358291212844 and parameters: {'booster': 'gblinear', 'lambda': 2.5393268245398075e-05, 'alpha': 0.0009799048516035767, 'subsample': 0.8167696441732394, 'colsample_bytree': 0.88391328332774}. Best is trial 73 with value: 0.19872817452427796.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:47,333]\u001b[0m Trial 75 finished with value: 0.2008025229837467 and parameters: {'booster': 'gblinear', 'lambda': 5.7454576067873375e-06, 'alpha': 0.0027230134265192204, 'subsample': 0.5932131727255057, 'colsample_bytree': 0.9410707035445253}. Best is trial 73 with value: 0.19872817452427796.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:47,445]\u001b[0m Trial 76 finished with value: 0.24327638548800137 and parameters: {'booster': 'gblinear', 'lambda': 1.5791706847995413e-06, 'alpha': 0.06277301346653795, 'subsample': 0.5181767526334612, 'colsample_bytree': 0.8656639138343319}. Best is trial 73 with value: 0.19872817452427796.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:47,566]\u001b[0m Trial 77 finished with value: 0.20707830919334694 and parameters: {'booster': 'gblinear', 'lambda': 3.899966959309971e-05, 'alpha': 0.02103142389624673, 'subsample': 0.7142870018656687, 'colsample_bytree': 0.8979268647350616}. Best is trial 73 with value: 0.19872817452427796.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:47,818]\u001b[0m Trial 78 finished with value: 1.280846808504317 and parameters: {'booster': 'gbtree', 'lambda': 7.533848910042931e-05, 'alpha': 0.00974730127086734, 'subsample': 0.6929389125033623, 'colsample_bytree': 0.4969196021271627, 'max_depth': 7, 'min_child_weight': 8, 'eta': 5.547147549494794e-06, 'gamma': 3.8165817306818883e-07, 'grow_policy': 'depthwise'}. Best is trial 73 with value: 0.19872817452427796.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:49,143]\u001b[0m Trial 79 finished with value: 1.2819039532158192 and parameters: {'booster': 'dart', 'lambda': 1.4079721132475573e-05, 'alpha': 0.00019399046916353303, 'subsample': 0.931742443716617, 'colsample_bytree': 0.7622880721221285, 'max_depth': 3, 'min_child_weight': 3, 'eta': 8.284766565981378e-08, 'gamma': 0.00395826895571848, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.010141177211237602, 'skip_drop': 1.1602448012184502e-05}. Best is trial 73 with value: 0.19872817452427796.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:49,275]\u001b[0m Trial 80 finished with value: 0.20382766225216828 and parameters: {'booster': 'gblinear', 'lambda': 1.1779017814825055e-05, 'alpha': 0.0015652689947693043, 'subsample': 0.994355467198216, 'colsample_bytree': 0.9760436372814961}. Best is trial 73 with value: 0.19872817452427796.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:49,405]\u001b[0m Trial 81 finished with value: 0.20008548250624747 and parameters: {'booster': 'gblinear', 'lambda': 0.00011123686650175287, 'alpha': 0.003724216743977734, 'subsample': 0.7391390583298487, 'colsample_bytree': 0.9498977862318371}. Best is trial 73 with value: 0.19872817452427796.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:49,530]\u001b[0m Trial 82 finished with value: 0.19976454855185216 and parameters: {'booster': 'gblinear', 'lambda': 0.00016702693752003602, 'alpha': 0.004282615723354295, 'subsample': 0.7405021550731175, 'colsample_bytree': 0.9470159743412617}. Best is trial 73 with value: 0.19872817452427796.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:49,655]\u001b[0m Trial 83 finished with value: 0.20039805283600462 and parameters: {'booster': 'gblinear', 'lambda': 0.00011899522345824915, 'alpha': 0.0056428230579461695, 'subsample': 0.7365705089663026, 'colsample_bytree': 0.9448082194157917}. Best is trial 73 with value: 0.19872817452427796.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:49,782]\u001b[0m Trial 84 finished with value: 0.20157713817905612 and parameters: {'booster': 'gblinear', 'lambda': 0.00022740796515426182, 'alpha': 0.0021298255675043566, 'subsample': 0.6725190217821739, 'colsample_bytree': 0.9205459824377025}. Best is trial 73 with value: 0.19872817452427796.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:49,911]\u001b[0m Trial 85 finished with value: 0.2115363134640518 and parameters: {'booster': 'gblinear', 'lambda': 0.0012690209281690946, 'alpha': 0.000732840449161093, 'subsample': 0.7535343997831631, 'colsample_bytree': 0.9681463000755816}. Best is trial 73 with value: 0.19872817452427796.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:50,036]\u001b[0m Trial 86 finished with value: 0.20028684890534088 and parameters: {'booster': 'gblinear', 'lambda': 0.0002983792812193977, 'alpha': 0.004769796496481526, 'subsample': 0.6377809375432335, 'colsample_bytree': 0.9140595915422168}. Best is trial 73 with value: 0.19872817452427796.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:50,157]\u001b[0m Trial 87 finished with value: 0.20665494634803344 and parameters: {'booster': 'gblinear', 'lambda': 0.00046261983842755237, 'alpha': 0.019950278537468304, 'subsample': 0.7045437712773, 'colsample_bytree': 0.9628493116171524}. Best is trial 73 with value: 0.19872817452427796.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:50,280]\u001b[0m Trial 88 finished with value: 0.206226402012342 and parameters: {'booster': 'gblinear', 'lambda': 0.0036405031892144833, 'alpha': 0.01227478868654814, 'subsample': 0.27092988652901806, 'colsample_bytree': 0.8500098294838059}. Best is trial 73 with value: 0.19872817452427796.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:50,407]\u001b[0m Trial 89 finished with value: 0.20773367186761804 and parameters: {'booster': 'gblinear', 'lambda': 5.382759106045801e-05, 'alpha': 0.001198903947248333, 'subsample': 0.6090889298663441, 'colsample_bytree': 0.9420592684528322}. Best is trial 73 with value: 0.19872817452427796.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:50,535]\u001b[0m Trial 90 finished with value: 0.21397666712186636 and parameters: {'booster': 'gblinear', 'lambda': 0.00016485748044661126, 'alpha': 0.00047151860896043734, 'subsample': 0.5644827787228235, 'colsample_bytree': 0.8778810277420711}. Best is trial 73 with value: 0.19872817452427796.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:50,662]\u001b[0m Trial 91 finished with value: 0.19942120886347398 and parameters: {'booster': 'gblinear', 'lambda': 2.6423745895116947e-05, 'alpha': 0.003804707768517797, 'subsample': 0.7931624085675893, 'colsample_bytree': 0.8926676746768745}. Best is trial 73 with value: 0.19872817452427796.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:50,788]\u001b[0m Trial 92 finished with value: 0.20156987231309836 and parameters: {'booster': 'gblinear', 'lambda': 9.46838874982479e-05, 'alpha': 0.0023447506453564805, 'subsample': 0.8547477968581622, 'colsample_bytree': 0.9111484914139966}. Best is trial 73 with value: 0.19872817452427796.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:50,916]\u001b[0m Trial 93 finished with value: 0.20005210392285527 and parameters: {'booster': 'gblinear', 'lambda': 6.212758254107614e-05, 'alpha': 0.004016977001555392, 'subsample': 0.7862790642251193, 'colsample_bytree': 0.9789881535800928}. Best is trial 73 with value: 0.19872817452427796.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:51,040]\u001b[0m Trial 94 finished with value: 0.20312690275671405 and parameters: {'booster': 'gblinear', 'lambda': 6.473428883000957e-06, 'alpha': 0.008524515579665416, 'subsample': 0.7652331773732738, 'colsample_bytree': 0.9821305057952341}. Best is trial 73 with value: 0.19872817452427796.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:51,166]\u001b[0m Trial 95 finished with value: 0.20038774517316132 and parameters: {'booster': 'gblinear', 'lambda': 2.796305667583297e-05, 'alpha': 0.00546919283915055, 'subsample': 0.8055752227335781, 'colsample_bytree': 0.8246744860075601}. Best is trial 73 with value: 0.19872817452427796.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:19:51,533]\u001b[0m Trial 96 finished with value: 0.21442232569265454 and parameters: {'booster': 'gbtree', 'lambda': 5.448750802314228e-05, 'alpha': 0.028923646761300707, 'subsample': 0.8409567896751811, 'colsample_bytree': 0.8945432364282948, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.13178731523051523, 'gamma': 1.7356159603679802e-06, 'grow_policy': 'lossguide'}. Best is trial 73 with value: 0.19872817452427796.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:51,661]\u001b[0m Trial 97 finished with value: 0.20529027858889018 and parameters: {'booster': 'gblinear', 'lambda': 0.00020798034304415403, 'alpha': 0.0014238731098981379, 'subsample': 0.7917630975975714, 'colsample_bytree': 0.9325690171242614}. Best is trial 73 with value: 0.19872817452427796.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:53,130]\u001b[0m Trial 98 finished with value: 1.1540830277705996 and parameters: {'booster': 'dart', 'lambda': 0.0003667459420649371, 'alpha': 0.002975856609403404, 'subsample': 0.823155888078908, 'colsample_bytree': 0.9799446146078099, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.000629600800218406, 'gamma': 5.1095345940543394e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.0911313110090766e-06, 'skip_drop': 0.005555950891162399}. Best is trial 73 with value: 0.19872817452427796.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:53,254]\u001b[0m Trial 99 finished with value: 0.20561972515886712 and parameters: {'booster': 'gblinear', 'lambda': 1.4346354872151182e-05, 'alpha': 0.015184965001397252, 'subsample': 0.8886249655340763, 'colsample_bytree': 0.3648166590226088}. Best is trial 73 with value: 0.19872817452427796.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:53,427]\u001b[0m A new study created in memory with name: no-name-cbbb1be2-c613-4638-8651-656f3d3d1a4e\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:53,697]\u001b[0m Trial 0 finished with value: 0.7909958186026014 and parameters: {'booster': 'gblinear', 'lambda': 0.007189943287340105, 'alpha': 0.028432124072555354, 'subsample': 0.24104453042555385, 'colsample_bytree': 0.3512998927286279}. Best is trial 0 with value: 0.7909958186026014.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:59,140]\u001b[0m Trial 1 finished with value: 0.870773825129781 and parameters: {'booster': 'dart', 'lambda': 6.802901408283847e-05, 'alpha': 0.09459851556728549, 'subsample': 0.8704307521064922, 'colsample_bytree': 0.8028651683956027, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.012294690044130217, 'gamma': 0.0015536427443999517, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.33442007530429974, 'skip_drop': 3.1356965375072676e-06}. Best is trial 1 with value: 0.870773825129781.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:19:59,593]\u001b[0m Trial 2 finished with value: 0.814184567954499 and parameters: {'booster': 'gblinear', 'lambda': 0.0030750613965110597, 'alpha': 0.0013450751584537129, 'subsample': 0.7138255042031469, 'colsample_bytree': 0.2746145673711611}. Best is trial 1 with value: 0.870773825129781.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:07,347]\u001b[0m Trial 3 finished with value: 0.8578497580090444 and parameters: {'booster': 'dart', 'lambda': 4.4669220106244803e-05, 'alpha': 1.4063662322525321e-05, 'subsample': 0.2417753461771521, 'colsample_bytree': 0.45820458948201737, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.03781719253406975, 'gamma': 5.984361392849708e-08, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.8154041061364663e-08, 'skip_drop': 0.00014363983500617449}. Best is trial 1 with value: 0.870773825129781.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:07,873]\u001b[0m Trial 4 finished with value: 0.8548826486779322 and parameters: {'booster': 'gbtree', 'lambda': 0.022983521272922837, 'alpha': 0.012509686281687108, 'subsample': 0.4862285127475412, 'colsample_bytree': 0.9226443921058833, 'max_depth': 3, 'min_child_weight': 9, 'eta': 0.002489664070206989, 'gamma': 7.802949927301641e-07, 'grow_policy': 'lossguide'}. Best is trial 1 with value: 0.870773825129781.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:15,630]\u001b[0m Trial 5 finished with value: 0.8495779880116548 and parameters: {'booster': 'dart', 'lambda': 0.00038190464639251587, 'alpha': 0.006425041182892014, 'subsample': 0.361567934846841, 'colsample_bytree': 0.2976323561354134, 'max_depth': 3, 'min_child_weight': 8, 'eta': 0.016414702574199087, 'gamma': 0.8636811570915326, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 4.681105184306874e-08, 'skip_drop': 3.0580027337471058e-06}. Best is trial 1 with value: 0.870773825129781.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:16,009]\u001b[0m Trial 6 finished with value: 0.8571245675129475 and parameters: {'booster': 'gbtree', 'lambda': 1.2928196323124508e-05, 'alpha': 7.512017845773885e-05, 'subsample': 0.26936409199272754, 'colsample_bytree': 0.7294374527980827, 'max_depth': 3, 'min_child_weight': 10, 'eta': 1.0726484224668759e-06, 'gamma': 0.0005580839963316219, 'grow_policy': 'depthwise'}. Best is trial 1 with value: 0.870773825129781.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:24,041]\u001b[0m Trial 7 finished with value: 0.8410114174011503 and parameters: {'booster': 'dart', 'lambda': 1.2018063920095958e-06, 'alpha': 0.06869699918160332, 'subsample': 0.8418284832972265, 'colsample_bytree': 0.36403866585296457, 'max_depth': 9, 'min_child_weight': 9, 'eta': 1.8671901452312398e-05, 'gamma': 0.16677737880415172, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.0011292944183207208, 'skip_drop': 5.008508130116834e-07}. Best is trial 1 with value: 0.870773825129781.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:24,313]\u001b[0m Trial 8 finished with value: 0.7623474932553126 and parameters: {'booster': 'gblinear', 'lambda': 0.014828705960448458, 'alpha': 0.0426319910474556, 'subsample': 0.6674437146088424, 'colsample_bytree': 0.3380545107108297}. Best is trial 1 with value: 0.870773825129781.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:24,721]\u001b[0m Trial 9 finished with value: 0.8061356124067294 and parameters: {'booster': 'gbtree', 'lambda': 8.659438285108195e-05, 'alpha': 1.074935057373955e-07, 'subsample': 0.2438525677813945, 'colsample_bytree': 0.5995528800048132, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.48147020510444605, 'gamma': 0.3274513680420428, 'grow_policy': 'lossguide'}. Best is trial 1 with value: 0.870773825129781.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:29,488]\u001b[0m Trial 10 finished with value: 0.8597614654413852 and parameters: {'booster': 'dart', 'lambda': 1.7683069326092993e-08, 'alpha': 0.6986625911649995, 'subsample': 0.9997763854545836, 'colsample_bytree': 0.9060010322674661, 'max_depth': 7, 'min_child_weight': 4, 'eta': 4.947103221263419e-08, 'gamma': 0.0004220769707803187, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.514078154940118, 'skip_drop': 0.04110619508177516}. Best is trial 1 with value: 0.870773825129781.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:20:36,024]\u001b[0m A new study created in memory with name: no-name-936f8005-9665-4dd3-92c3-73459be8d239\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:36,222]\u001b[0m Trial 0 finished with value: 1.2631837402026842 and parameters: {'booster': 'gbtree', 'lambda': 1.627266862054432e-06, 'alpha': 0.012836509929405526, 'subsample': 0.39528350691112096, 'colsample_bytree': 0.5496435879080623, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.0002763790198419946, 'gamma': 0.00042260626791591424, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 1.2631837402026842.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:36,351]\u001b[0m Trial 1 finished with value: 0.43659883755993284 and parameters: {'booster': 'gblinear', 'lambda': 0.0024100415705331957, 'alpha': 0.0019087039571516037, 'subsample': 0.6289778211904296, 'colsample_bytree': 0.5572369782853264}. Best is trial 1 with value: 0.43659883755993284.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:20:37,866]\u001b[0m Trial 2 finished with value: 1.2682785642579226 and parameters: {'booster': 'dart', 'lambda': 0.007086233548762518, 'alpha': 0.7506098024722975, 'subsample': 0.4917958979575879, 'colsample_bytree': 0.5098748465956657, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.00024314760764213464, 'gamma': 4.572974790550638e-07, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.1219412253445366e-07, 'skip_drop': 0.0001137189107362532}. Best is trial 1 with value: 0.43659883755993284.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:39,415]\u001b[0m Trial 3 finished with value: 1.4450490287227606 and parameters: {'booster': 'dart', 'lambda': 0.004157451284604227, 'alpha': 0.18706250282081416, 'subsample': 0.48703869646574227, 'colsample_bytree': 0.802958896954429, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.8859775816073411, 'gamma': 0.007819558377148515, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.00011198616722579095, 'skip_drop': 0.7810834478534547}. Best is trial 1 with value: 0.43659883755993284.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:39,532]\u001b[0m Trial 4 finished with value: 0.46102300625312753 and parameters: {'booster': 'gblinear', 'lambda': 0.43177981322281217, 'alpha': 0.00315843729589344, 'subsample': 0.4469400831249402, 'colsample_bytree': 0.3865442725466536}. Best is trial 1 with value: 0.43659883755993284.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:39,648]\u001b[0m Trial 5 finished with value: 0.4309859422451325 and parameters: {'booster': 'gblinear', 'lambda': 5.853311526368564e-06, 'alpha': 0.004310392385860994, 'subsample': 0.8430030169126281, 'colsample_bytree': 0.9156618137784385}. Best is trial 5 with value: 0.4309859422451325.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:40,136]\u001b[0m Trial 6 finished with value: 0.4383516639262531 and parameters: {'booster': 'gbtree', 'lambda': 2.3298925551240646e-08, 'alpha': 7.866789821056297e-06, 'subsample': 0.8206729643963704, 'colsample_bytree': 0.9940461198200818, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.17223660027322593, 'gamma': 5.405150567245332e-08, 'grow_policy': 'lossguide'}. Best is trial 5 with value: 0.4309859422451325.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:41,714]\u001b[0m Trial 7 finished with value: 0.4543133796841156 and parameters: {'booster': 'dart', 'lambda': 0.0309211369185943, 'alpha': 1.952848330918298e-05, 'subsample': 0.8445492178160261, 'colsample_bytree': 0.9759920953939765, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.5343050750258357, 'gamma': 0.00017526017645530057, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.6240719429262948e-06, 'skip_drop': 0.0063187013450070025}. Best is trial 5 with value: 0.4309859422451325.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:41,832]\u001b[0m Trial 8 finished with value: 0.4367899937083297 and parameters: {'booster': 'gblinear', 'lambda': 2.60718248460537e-05, 'alpha': 0.0029490062826144398, 'subsample': 0.6559000049407384, 'colsample_bytree': 0.2381407400358696}. Best is trial 5 with value: 0.4309859422451325.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:42,010]\u001b[0m Trial 9 finished with value: 0.38175234165407085 and parameters: {'booster': 'gbtree', 'lambda': 0.0004941436645317982, 'alpha': 5.177405246272125e-08, 'subsample': 0.3704582501921186, 'colsample_bytree': 0.9515006238304642, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.05024103866664324, 'gamma': 1.853627088947326e-08, 'grow_policy': 'depthwise'}. Best is trial 9 with value: 0.38175234165407085.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:42,197]\u001b[0m Trial 10 finished with value: 1.3071105491196857 and parameters: {'booster': 'gbtree', 'lambda': 0.00018218591530876885, 'alpha': 1.2843161729393343e-08, 'subsample': 0.2155554927102769, 'colsample_bytree': 0.75475501247522, 'max_depth': 3, 'min_child_weight': 5, 'eta': 1.2428880480568493e-08, 'gamma': 0.8828684925971635, 'grow_policy': 'depthwise'}. Best is trial 9 with value: 0.38175234165407085.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:42,333]\u001b[0m Trial 11 finished with value: 0.4795215098332024 and parameters: {'booster': 'gblinear', 'lambda': 1.846078605798073e-06, 'alpha': 1.1746023168394872e-08, 'subsample': 0.9936816026290184, 'colsample_bytree': 0.8049536444734702}. Best is trial 9 with value: 0.38175234165407085.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:42,526]\u001b[0m Trial 12 finished with value: 0.6754736073730221 and parameters: {'booster': 'gbtree', 'lambda': 5.4270075982944214e-05, 'alpha': 2.0685873715926626e-06, 'subsample': 0.22798919545696644, 'colsample_bytree': 0.8904375803513958, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.007163123331286669, 'gamma': 1.0317940758969889e-08, 'grow_policy': 'depthwise'}. Best is trial 9 with value: 0.38175234165407085.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:42,793]\u001b[0m Trial 13 finished with value: 1.3070696828126558 and parameters: {'booster': 'gbtree', 'lambda': 1.4194099558831383e-06, 'alpha': 5.789680135322056e-07, 'subsample': 0.7681423005350552, 'colsample_bytree': 0.6913076980398156, 'max_depth': 5, 'min_child_weight': 10, 'eta': 2.5564746617281887e-07, 'gamma': 1.8710871157186036e-06, 'grow_policy': 'depthwise'}. Best is trial 9 with value: 0.38175234165407085.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:42,927]\u001b[0m Trial 14 finished with value: 0.46637154700219335 and parameters: {'booster': 'gblinear', 'lambda': 1.238200090505868e-07, 'alpha': 0.0002292277883616173, 'subsample': 0.3258208988976868, 'colsample_bytree': 0.8830447214743156}. Best is trial 9 with value: 0.38175234165407085.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:43,138]\u001b[0m Trial 15 finished with value: 0.7545666873396731 and parameters: {'booster': 'gbtree', 'lambda': 0.0003588724361565864, 'alpha': 3.3223236652243114e-07, 'subsample': 0.9427868079080786, 'colsample_bytree': 0.675265723376276, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.005725810512567518, 'gamma': 6.192753544039356e-06, 'grow_policy': 'depthwise'}. Best is trial 9 with value: 0.38175234165407085.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:43,274]\u001b[0m Trial 16 finished with value: 0.46958043698229196 and parameters: {'booster': 'gblinear', 'lambda': 1.1239296523444428e-05, 'alpha': 0.00017822702530172937, 'subsample': 0.7107712545150411, 'colsample_bytree': 0.9288342527867648}. Best is trial 9 with value: 0.38175234165407085.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:43,388]\u001b[0m Trial 17 finished with value: 0.5285365670266032 and parameters: {'booster': 'gblinear', 'lambda': 0.0005311711291988925, 'alpha': 0.0882366144354942, 'subsample': 0.5653479156058107, 'colsample_bytree': 0.8579020473148288}. Best is trial 9 with value: 0.38175234165407085.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:43,601]\u001b[0m Trial 18 finished with value: 1.3066730126275166 and parameters: {'booster': 'gbtree', 'lambda': 0.048149470046862514, 'alpha': 7.952841132628205e-08, 'subsample': 0.32970728974420715, 'colsample_bytree': 0.4292218713153294, 'max_depth': 5, 'min_child_weight': 6, 'eta': 2.7560213427093474e-06, 'gamma': 0.019080319678293954, 'grow_policy': 'depthwise'}. Best is trial 9 with value: 0.38175234165407085.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:44,075]\u001b[0m Trial 19 finished with value: 0.5764625342265896 and parameters: {'booster': 'dart', 'lambda': 1.570700776203255e-07, 'alpha': 3.3106099159199e-05, 'subsample': 0.877338470052962, 'colsample_bytree': 0.6549518043041545, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.01166198601719083, 'gamma': 1.7538239628753608e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.8195873433615491, 'skip_drop': 1.4866766868977222e-08}. Best is trial 9 with value: 0.38175234165407085.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:44,388]\u001b[0m Trial 20 finished with value: 1.3050434899839882 and parameters: {'booster': 'gbtree', 'lambda': 6.608683870151366e-06, 'alpha': 0.0002995267571957208, 'subsample': 0.5798989603361909, 'colsample_bytree': 0.7480089458659319, 'max_depth': 7, 'min_child_weight': 10, 'eta': 1.2098706762755618e-05, 'gamma': 2.59329911128343e-07, 'grow_policy': 'depthwise'}. Best is trial 9 with value: 0.38175234165407085.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:44,519]\u001b[0m Trial 21 finished with value: 0.43730385549134393 and parameters: {'booster': 'gblinear', 'lambda': 0.001930657593097269, 'alpha': 0.0018617702599263014, 'subsample': 0.6517815594928273, 'colsample_bytree': 0.5831244037350167}. Best is trial 9 with value: 0.38175234165407085.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:20:44,640]\u001b[0m Trial 22 finished with value: 0.440762521622342 and parameters: {'booster': 'gblinear', 'lambda': 0.00106148540063774, 'alpha': 0.019233585901683083, 'subsample': 0.7331187252538366, 'colsample_bytree': 0.4481309894655311}. Best is trial 9 with value: 0.38175234165407085.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:44,765]\u001b[0m Trial 23 finished with value: 0.4402468482185162 and parameters: {'booster': 'gblinear', 'lambda': 7.411132267646111e-05, 'alpha': 0.018326966386064188, 'subsample': 0.5488648991884826, 'colsample_bytree': 0.33065525916319505}. Best is trial 9 with value: 0.38175234165407085.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:44,897]\u001b[0m Trial 24 finished with value: 0.4387239302972137 and parameters: {'booster': 'gblinear', 'lambda': 0.017948452121114827, 'alpha': 0.001111588585612344, 'subsample': 0.3309535109703632, 'colsample_bytree': 0.5032851816991034}. Best is trial 9 with value: 0.38175234165407085.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:45,028]\u001b[0m Trial 25 finished with value: 0.45648069758143844 and parameters: {'booster': 'gblinear', 'lambda': 0.370960910135658, 'alpha': 0.0005897727760155898, 'subsample': 0.6645670811836115, 'colsample_bytree': 0.6326484953482239}. Best is trial 9 with value: 0.38175234165407085.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:45,161]\u001b[0m Trial 26 finished with value: 0.4772649261970232 and parameters: {'booster': 'gblinear', 'lambda': 0.0001409363208906032, 'alpha': 3.340510295022347e-05, 'subsample': 0.908870696954936, 'colsample_bytree': 0.9435459131275498}. Best is trial 9 with value: 0.38175234165407085.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:45,814]\u001b[0m Trial 27 finished with value: 0.3981365404526252 and parameters: {'booster': 'dart', 'lambda': 8.300614176068227e-06, 'alpha': 0.05546329142241449, 'subsample': 0.7980158243994827, 'colsample_bytree': 0.8224797712209242, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.0497478755799859, 'gamma': 0.0024381264937483518, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.7129789011467244, 'skip_drop': 1.8914327783861288e-08}. Best is trial 9 with value: 0.38175234165407085.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:46,650]\u001b[0m Trial 28 finished with value: 0.3931408538774081 and parameters: {'booster': 'dart', 'lambda': 3.80436097353666e-07, 'alpha': 0.16522177726082174, 'subsample': 0.79950003486302, 'colsample_bytree': 0.8488777766948353, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.03729867918529474, 'gamma': 0.004190128517761027, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.6622934646183068, 'skip_drop': 1.087594366817516e-08}. Best is trial 9 with value: 0.38175234165407085.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:47,295]\u001b[0m Trial 29 finished with value: 0.4051754394306923 and parameters: {'booster': 'dart', 'lambda': 3.565331889977737e-07, 'alpha': 0.9012803463008694, 'subsample': 0.7615580238157675, 'colsample_bytree': 0.8236545194214615, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.037722414676652966, 'gamma': 0.011117102872624162, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.7240267167629979, 'skip_drop': 1.3079412106519205e-08}. Best is trial 9 with value: 0.38175234165407085.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:48,708]\u001b[0m Trial 30 finished with value: 0.9985790093300625 and parameters: {'booster': 'dart', 'lambda': 1.604544259760229e-08, 'alpha': 0.09370424167668809, 'subsample': 0.3962810916852579, 'colsample_bytree': 0.7409845724826968, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.0022619299217943463, 'gamma': 0.0011175903040968854, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.006764675968539691, 'skip_drop': 5.787440906814219e-07}. Best is trial 9 with value: 0.38175234165407085.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:49,120]\u001b[0m Trial 31 finished with value: 0.40415815040160913 and parameters: {'booster': 'dart', 'lambda': 4.2590447736525004e-07, 'alpha': 0.5534884952915153, 'subsample': 0.7648323454983088, 'colsample_bytree': 0.8340247433481243, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.06710170441186693, 'gamma': 0.02526529861908094, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.9148044981765365, 'skip_drop': 1.2705106506848803e-08}. Best is trial 9 with value: 0.38175234165407085.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:50,522]\u001b[0m Trial 32 finished with value: 0.3513135198494387 and parameters: {'booster': 'dart', 'lambda': 8.458933609990329e-07, 'alpha': 0.2867456030496496, 'subsample': 0.7988297635398429, 'colsample_bytree': 0.845170767976771, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.10547110852859415, 'gamma': 0.1869498549296336, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.04824411325765929, 'skip_drop': 4.0605274723337274e-07}. Best is trial 32 with value: 0.3513135198494387.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:51,986]\u001b[0m Trial 33 finished with value: 0.3577656265879849 and parameters: {'booster': 'dart', 'lambda': 1.7693785693319493e-06, 'alpha': 0.05355362303174462, 'subsample': 0.8095668393842691, 'colsample_bytree': 0.9575038929171165, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.056071459432324944, 'gamma': 0.31922908559902863, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.007782243198278236, 'skip_drop': 1.1580118755310193e-06}. Best is trial 32 with value: 0.3513135198494387.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:53,380]\u001b[0m Trial 34 finished with value: 1.1161100906906367 and parameters: {'booster': 'dart', 'lambda': 6.895504087845298e-08, 'alpha': 0.28115375574578483, 'subsample': 0.7065699538133425, 'colsample_bytree': 0.9674051752714028, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.0013427705551102302, 'gamma': 0.33573469497138614, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.005906310867933982, 'skip_drop': 3.2469457349805777e-06}. Best is trial 32 with value: 0.3513135198494387.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:54,918]\u001b[0m Trial 35 finished with value: 0.3707030097347391 and parameters: {'booster': 'dart', 'lambda': 1.7834578388011116e-06, 'alpha': 0.034782406539838835, 'subsample': 0.8777832674576986, 'colsample_bytree': 0.9012817100441155, 'max_depth': 7, 'min_child_weight': 5, 'eta': 0.13102436570288759, 'gamma': 0.14964946343115101, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.011656935844446813, 'skip_drop': 1.188707973058208e-06}. Best is trial 32 with value: 0.3513135198494387.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:56,449]\u001b[0m Trial 36 finished with value: 0.3914329365905978 and parameters: {'booster': 'dart', 'lambda': 7.381201047173003e-07, 'alpha': 0.008078165150917168, 'subsample': 0.9784997555605911, 'colsample_bytree': 0.9033013962554551, 'max_depth': 7, 'min_child_weight': 5, 'eta': 0.24443515560989135, 'gamma': 0.05488508981416819, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.006532006187611112, 'skip_drop': 2.644885040859305e-06}. Best is trial 32 with value: 0.3513135198494387.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:58,002]\u001b[0m Trial 37 finished with value: 0.6769801414300165 and parameters: {'booster': 'dart', 'lambda': 2.4086406638022087e-06, 'alpha': 0.0343124531939088, 'subsample': 0.8994415613432944, 'colsample_bytree': 0.9881566025290455, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.9202469829936974, 'gamma': 0.19750426343637698, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.0005246730712849232, 'skip_drop': 5.026440941061055e-05}. Best is trial 32 with value: 0.3513135198494387.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:20:59,505]\u001b[0m Trial 38 finished with value: 0.380086292433614 and parameters: {'booster': 'dart', 'lambda': 1.9862533825506366e-05, 'alpha': 0.00629588668456736, 'subsample': 0.5101408745029412, 'colsample_bytree': 0.9440056611623276, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.11587209257943226, 'gamma': 0.12950587043825243, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.02746451694972828, 'skip_drop': 4.3066645458180743e-07}. Best is trial 32 with value: 0.3513135198494387.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:21:00,970]\u001b[0m Trial 39 finished with value: 0.37252862508568396 and parameters: {'booster': 'dart', 'lambda': 2.0577900417786396e-05, 'alpha': 0.006861364872507458, 'subsample': 0.46422485561009086, 'colsample_bytree': 0.7808056734241402, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.19044273988618093, 'gamma': 0.11342294185170694, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.03169104690343842, 'skip_drop': 5.109950885685712e-07}. Best is trial 32 with value: 0.3513135198494387.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:21:02,518]\u001b[0m Trial 40 finished with value: 0.42560263195337 and parameters: {'booster': 'dart', 'lambda': 3.8057676934012637e-06, 'alpha': 0.29014610366589905, 'subsample': 0.8717170041952532, 'colsample_bytree': 0.7618955010862566, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.018136431796863202, 'gamma': 0.9831409819788764, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.019971436313961324, 'skip_drop': 3.3309621454268005e-07}. Best is trial 32 with value: 0.3513135198494387.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:21:04,007]\u001b[0m Trial 41 finished with value: 0.3472489298422871 and parameters: {'booster': 'dart', 'lambda': 2.5123014471763594e-05, 'alpha': 0.007552636303420562, 'subsample': 0.5135217493122891, 'colsample_bytree': 0.8845858710761549, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.21890639308693688, 'gamma': 0.10489159641605364, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.03486862908099067, 'skip_drop': 3.921136157742104e-07}. Best is trial 41 with value: 0.3472489298422871.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:21:05,469]\u001b[0m Trial 42 finished with value: 0.3520150508079409 and parameters: {'booster': 'dart', 'lambda': 2.8545985133465318e-05, 'alpha': 0.030541704496318805, 'subsample': 0.4568592468425523, 'colsample_bytree': 0.8685395826764154, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.255044079300823, 'gamma': 0.07535503741983385, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.055841298850095755, 'skip_drop': 1.0091588652154216e-05}. Best is trial 41 with value: 0.3472489298422871.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:21:07,071]\u001b[0m Trial 43 finished with value: 0.3937115547720995 and parameters: {'booster': 'dart', 'lambda': 8.625442639396299e-07, 'alpha': 0.03813533347689714, 'subsample': 0.42038451739856997, 'colsample_bytree': 0.8725104543086696, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.28964337396579964, 'gamma': 0.046111441356587055, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.07396825601165771, 'skip_drop': 1.0299942727763039e-05}. Best is trial 41 with value: 0.3472489298422871.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:21:08,729]\u001b[0m Trial 44 finished with value: 1.0590949941479313 and parameters: {'booster': 'dart', 'lambda': 3.9706115268772516e-05, 'alpha': 0.018249884940570577, 'subsample': 0.5015445529140274, 'colsample_bytree': 0.8823543275559638, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.0016611530271578882, 'gamma': 0.3129606490577514, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.0010023666030279236, 'skip_drop': 1.0638011404912807e-05}. Best is trial 41 with value: 0.3472489298422871.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:21:10,288]\u001b[0m Trial 45 finished with value: 0.35820360594134093 and parameters: {'booster': 'dart', 'lambda': 3.8465756003612165e-06, 'alpha': 0.16157409771619868, 'subsample': 0.616185295327416, 'colsample_bytree': 0.7202681586132984, 'max_depth': 7, 'min_child_weight': 6, 'eta': 0.14976601341131138, 'gamma': 0.05443410291190186, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.07012161617246512, 'skip_drop': 1.2523860016405546e-07}. Best is trial 41 with value: 0.3472489298422871.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:21:12,055]\u001b[0m A new study created in memory with name: no-name-477beed2-43a9-4a68-875c-563a046c9504\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:21:12,997]\u001b[0m Trial 0 finished with value: 0.8904616224010601 and parameters: {'booster': 'gbtree', 'lambda': 0.00014988591305351606, 'alpha': 0.0018973737667158737, 'subsample': 0.695289209926244, 'colsample_bytree': 0.9019835001739576, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.00012417539837371623, 'gamma': 0.00034554690029355055, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.8904616224010601.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:21:13,249]\u001b[0m Trial 1 finished with value: 0.8904616224010601 and parameters: {'booster': 'gbtree', 'lambda': 0.10195981783386517, 'alpha': 0.7457730207388741, 'subsample': 0.20882324408354372, 'colsample_bytree': 0.4384395457274575, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.0014792611200672514, 'gamma': 1.0057964538510972e-08, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.8904616224010601.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:21:21,613]\u001b[0m Trial 2 finished with value: 0.8904616224010601 and parameters: {'booster': 'dart', 'lambda': 0.07950307360768194, 'alpha': 0.022734070961318402, 'subsample': 0.33720934743822695, 'colsample_bytree': 0.9183798256367177, 'max_depth': 5, 'min_child_weight': 3, 'eta': 2.6155035406499164e-07, 'gamma': 0.0008823865739205934, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 3.4115468417212624e-06, 'skip_drop': 2.2547827446116235e-08}. Best is trial 0 with value: 0.8904616224010601.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:21:22,187]\u001b[0m Trial 3 finished with value: 0.8904616224010601 and parameters: {'booster': 'gbtree', 'lambda': 2.7612972706379113e-06, 'alpha': 0.00037293674265499044, 'subsample': 0.7628858289070937, 'colsample_bytree': 0.6658304639482198, 'max_depth': 3, 'min_child_weight': 10, 'eta': 0.0005321326360681438, 'gamma': 9.768385841172678e-08, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.8904616224010601.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:21:22,775]\u001b[0m Trial 4 finished with value: 0.8892185864470031 and parameters: {'booster': 'gblinear', 'lambda': 0.0009759139155038814, 'alpha': 1.4056409069381827e-05, 'subsample': 0.9769577829120886, 'colsample_bytree': 0.8593011136524897}. Best is trial 0 with value: 0.8904616224010601.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:21:23,379]\u001b[0m Trial 5 finished with value: 0.8835222750013648 and parameters: {'booster': 'gblinear', 'lambda': 2.0276720808318253e-05, 'alpha': 9.638311171888006e-07, 'subsample': 0.22146854118038686, 'colsample_bytree': 0.6433928738505094}. Best is trial 0 with value: 0.8904616224010601.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:21:24,077]\u001b[0m Trial 6 finished with value: 0.8904616224010601 and parameters: {'booster': 'gbtree', 'lambda': 2.3292526447668677e-06, 'alpha': 0.6731808674506274, 'subsample': 0.6109812080424102, 'colsample_bytree': 0.6741750557943955, 'max_depth': 7, 'min_child_weight': 2, 'eta': 5.509691602416393e-08, 'gamma': 5.640874890853612e-08, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.8904616224010601.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:21:24,237]\u001b[0m Trial 7 finished with value: 0.8904616224010601 and parameters: {'booster': 'gblinear', 'lambda': 2.98358918870223e-08, 'alpha': 0.35846050285133213, 'subsample': 0.22087946008436551, 'colsample_bytree': 0.9632484523828799}. Best is trial 0 with value: 0.8904616224010601.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:21:24,852]\u001b[0m Trial 8 finished with value: 0.8868953104689531 and parameters: {'booster': 'gblinear', 'lambda': 0.0001479318167682616, 'alpha': 3.876251715796908e-05, 'subsample': 0.9641783444010954, 'colsample_bytree': 0.944587181433838}. Best is trial 0 with value: 0.8904616224010601.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:21:25,473]\u001b[0m Trial 9 finished with value: 0.8928951868084353 and parameters: {'booster': 'gblinear', 'lambda': 0.0034698139287751514, 'alpha': 7.461616217620186e-08, 'subsample': 0.9930808254607555, 'colsample_bytree': 0.4286918764138937}. Best is trial 9 with value: 0.8928951868084353.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:21:31,640]\u001b[0m Trial 10 finished with value: 0.8917300862506343 and parameters: {'booster': 'dart', 'lambda': 0.009153685871008323, 'alpha': 1.1688512286104494e-08, 'subsample': 0.8071086124308078, 'colsample_bytree': 0.21778385876745773, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.2854594025850673, 'gamma': 0.6778816704131844, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.9030848475554855, 'skip_drop': 0.45476186264065}. Best is trial 9 with value: 0.8928951868084353.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:21:39,362]\u001b[0m Trial 11 finished with value: 0.8916198924520156 and parameters: {'booster': 'dart', 'lambda': 0.0043763605628442705, 'alpha': 1.7163856282628495e-08, 'subsample': 0.8339797399370301, 'colsample_bytree': 0.23223762557118513, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.8749266197073674, 'gamma': 0.8224317363103385, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.5399392976713528, 'skip_drop': 0.9645266934062615}. Best is trial 9 with value: 0.8928951868084353.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:21:46,859]\u001b[0m Trial 12 finished with value: 0.9027757578139843 and parameters: {'booster': 'dart', 'lambda': 0.01353863259292044, 'alpha': 1.0310101623843814e-08, 'subsample': 0.8633575028879148, 'colsample_bytree': 0.23349413693820675, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.6390463123029743, 'gamma': 0.3117047049351583, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.11071622206169622, 'skip_drop': 0.6658208498026809}. Best is trial 12 with value: 0.9027757578139843.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:21:56,355]\u001b[0m A new study created in memory with name: no-name-10039a58-e34e-4948-89d4-dc69909c7707\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:21:56,696]\u001b[0m Trial 0 finished with value: 1.3411119703297434 and parameters: {'booster': 'gbtree', 'lambda': 0.11662309644625088, 'alpha': 5.998102986869558e-05, 'subsample': 0.8980196105747338, 'colsample_bytree': 0.8575214696351616, 'max_depth': 7, 'min_child_weight': 2, 'eta': 2.5803815686683997e-08, 'gamma': 3.6018963189390213e-06, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 1.3411119703297434.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:21:56,813]\u001b[0m Trial 1 finished with value: 0.17166003715033173 and parameters: {'booster': 'gblinear', 'lambda': 0.00019874899713224475, 'alpha': 4.8103523309775e-07, 'subsample': 0.8024858048641794, 'colsample_bytree': 0.6040406084632399}. Best is trial 1 with value: 0.17166003715033173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:21:57,071]\u001b[0m Trial 2 finished with value: 1.1953765158425138 and parameters: {'booster': 'gbtree', 'lambda': 0.0009322196008173169, 'alpha': 0.0001360574995437224, 'subsample': 0.3884999704081848, 'colsample_bytree': 0.5713724344968383, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.000733557014799867, 'gamma': 6.101647052737223e-07, 'grow_policy': 'lossguide'}. Best is trial 1 with value: 0.17166003715033173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:21:57,170]\u001b[0m Trial 3 finished with value: 0.18182209275515399 and parameters: {'booster': 'gblinear', 'lambda': 1.3332780882457525e-07, 'alpha': 0.05356806533943613, 'subsample': 0.7782929232731051, 'colsample_bytree': 0.6791613691006805}. Best is trial 1 with value: 0.17166003715033173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:21:57,338]\u001b[0m Trial 4 finished with value: 0.6058167740669036 and parameters: {'booster': 'gbtree', 'lambda': 0.0040617306331464705, 'alpha': 1.142452393013181e-06, 'subsample': 0.3161477282219832, 'colsample_bytree': 0.9626956406816534, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.005159328044761033, 'gamma': 2.648373836846882e-07, 'grow_policy': 'lossguide'}. Best is trial 1 with value: 0.17166003715033173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:21:57,489]\u001b[0m Trial 5 finished with value: 1.3399511662641728 and parameters: {'booster': 'gbtree', 'lambda': 8.020086412503438e-05, 'alpha': 0.09881391025499409, 'subsample': 0.8573729306468469, 'colsample_bytree': 0.3948850580572645, 'max_depth': 3, 'min_child_weight': 4, 'eta': 5.9777024167777785e-06, 'gamma': 7.434810222882008e-06, 'grow_policy': 'lossguide'}. Best is trial 1 with value: 0.17166003715033173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:21:57,605]\u001b[0m Trial 6 finished with value: 0.17331632730252067 and parameters: {'booster': 'gblinear', 'lambda': 2.511272502491486e-06, 'alpha': 0.00026284038621440716, 'subsample': 0.23045940828262018, 'colsample_bytree': 0.946423221262265}. Best is trial 1 with value: 0.17166003715033173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:21:58,915]\u001b[0m Trial 7 finished with value: 0.17580345754030352 and parameters: {'booster': 'dart', 'lambda': 3.7777026360482916e-06, 'alpha': 0.06782684806446533, 'subsample': 0.48830564204126126, 'colsample_bytree': 0.4367221890805175, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.33960684218917747, 'gamma': 0.024354331423844956, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.0200122863863205e-08, 'skip_drop': 0.740777304533812}. Best is trial 1 with value: 0.17166003715033173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:21:59,184]\u001b[0m Trial 8 finished with value: 1.3409071889292787 and parameters: {'booster': 'gbtree', 'lambda': 0.2607830944965289, 'alpha': 0.00777732299258842, 'subsample': 0.587261046825702, 'colsample_bytree': 0.5913788799179694, 'max_depth': 7, 'min_child_weight': 4, 'eta': 9.920389997771056e-07, 'gamma': 1.7159962939005112e-08, 'grow_policy': 'lossguide'}. Best is trial 1 with value: 0.17166003715033173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:00,554]\u001b[0m Trial 9 finished with value: 0.2525940612600101 and parameters: {'booster': 'dart', 'lambda': 0.009909694902199553, 'alpha': 0.007793028689410454, 'subsample': 0.5813248128080117, 'colsample_bytree': 0.7082327250154636, 'max_depth': 5, 'min_child_weight': 3, 'eta': 0.8195614652740278, 'gamma': 2.3068177524230063e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.029154385778908404, 'skip_drop': 5.41921196087334e-07}. Best is trial 1 with value: 0.17166003715033173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:00,687]\u001b[0m Trial 10 finished with value: 0.17259840098836735 and parameters: {'booster': 'gblinear', 'lambda': 1.8276899940510666e-08, 'alpha': 1.0585224624278585e-08, 'subsample': 0.7408700930893329, 'colsample_bytree': 0.23942588943031878}. Best is trial 1 with value: 0.17166003715033173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:00,818]\u001b[0m Trial 11 finished with value: 0.1763177593620743 and parameters: {'booster': 'gblinear', 'lambda': 1.5922116484157682e-08, 'alpha': 1.1772788223421056e-08, 'subsample': 0.7216067508200098, 'colsample_bytree': 0.20350631908374897}. Best is trial 1 with value: 0.17166003715033173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:00,950]\u001b[0m Trial 12 finished with value: 0.17193319737174914 and parameters: {'booster': 'gblinear', 'lambda': 5.606710087887044e-05, 'alpha': 1.1771010094283466e-08, 'subsample': 0.9778973493962395, 'colsample_bytree': 0.23765286891861676}. Best is trial 1 with value: 0.17166003715033173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:01,081]\u001b[0m Trial 13 finished with value: 0.17336063667316895 and parameters: {'booster': 'gblinear', 'lambda': 3.852706269433805e-05, 'alpha': 3.5390403226596017e-07, 'subsample': 0.9937619217394174, 'colsample_bytree': 0.42372855847808827}. Best is trial 1 with value: 0.17166003715033173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:01,212]\u001b[0m Trial 14 finished with value: 0.17237736677963572 and parameters: {'booster': 'gblinear', 'lambda': 0.00040708643005171237, 'alpha': 4.992302412880022e-07, 'subsample': 0.9778464764145869, 'colsample_bytree': 0.7656598996605894}. Best is trial 1 with value: 0.17166003715033173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:01,342]\u001b[0m Trial 15 finished with value: 0.17247674380044997 and parameters: {'booster': 'gblinear', 'lambda': 8.78633434146216e-06, 'alpha': 4.395612243699961e-06, 'subsample': 0.8508766124955035, 'colsample_bytree': 0.31949062910096093}. Best is trial 1 with value: 0.17166003715033173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:01,473]\u001b[0m Trial 16 finished with value: 0.17312412071886 and parameters: {'booster': 'gblinear', 'lambda': 4.370664816050303e-07, 'alpha': 7.538431548631658e-08, 'subsample': 0.648876622973245, 'colsample_bytree': 0.5110747192536519}. Best is trial 1 with value: 0.17166003715033173.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:22:03,026]\u001b[0m Trial 17 finished with value: 1.341114241799811 and parameters: {'booster': 'dart', 'lambda': 0.011077251833997789, 'alpha': 2.0124933343142345e-05, 'subsample': 0.919830649620137, 'colsample_bytree': 0.5271148114925293, 'max_depth': 9, 'min_child_weight': 10, 'eta': 1.4491486877437102e-08, 'gamma': 0.8292834846719535, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 7.21169019057762e-07, 'skip_drop': 0.00917625556238694}. Best is trial 1 with value: 0.17166003715033173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:03,158]\u001b[0m Trial 18 finished with value: 0.17674990892974604 and parameters: {'booster': 'gblinear', 'lambda': 0.0002262174123508154, 'alpha': 7.712649607194346e-08, 'subsample': 0.8023054775793025, 'colsample_bytree': 0.3157273832311326}. Best is trial 1 with value: 0.17166003715033173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:03,290]\u001b[0m Trial 19 finished with value: 0.17211070763618722 and parameters: {'booster': 'gblinear', 'lambda': 3.1413679667497595e-05, 'alpha': 5.310995508484978e-06, 'subsample': 0.6738095680149797, 'colsample_bytree': 0.6622671035845853}. Best is trial 1 with value: 0.17166003715033173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:04,176]\u001b[0m Trial 20 finished with value: 1.057039194423197 and parameters: {'booster': 'dart', 'lambda': 0.001306710184950425, 'alpha': 7.493313503580272e-08, 'subsample': 0.9314303059515955, 'colsample_bytree': 0.4924581538499634, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.01615460299576757, 'gamma': 0.00021554055839273219, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.6663943026162474, 'skip_drop': 2.574100664919438e-08}. Best is trial 1 with value: 0.17166003715033173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:04,306]\u001b[0m Trial 21 finished with value: 0.17274967750438863 and parameters: {'booster': 'gblinear', 'lambda': 1.8180324691140154e-05, 'alpha': 2.180534161782739e-06, 'subsample': 0.6700729249800235, 'colsample_bytree': 0.6644394342628156}. Best is trial 1 with value: 0.17166003715033173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:04,437]\u001b[0m Trial 22 finished with value: 0.1727238671542939 and parameters: {'booster': 'gblinear', 'lambda': 2.1113159592799342e-06, 'alpha': 1.1271611821809752e-05, 'subsample': 0.49695838356734046, 'colsample_bytree': 0.7859867265728965}. Best is trial 1 with value: 0.17166003715033173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:04,575]\u001b[0m Trial 23 finished with value: 0.17527756723313093 and parameters: {'booster': 'gblinear', 'lambda': 6.451996920872135e-05, 'alpha': 1.4033119760929813e-07, 'subsample': 0.6837432672593948, 'colsample_bytree': 0.6287008580456239}. Best is trial 1 with value: 0.17166003715033173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:04,706]\u001b[0m Trial 24 finished with value: 0.17226128192354517 and parameters: {'booster': 'gblinear', 'lambda': 5.256617598860532e-07, 'alpha': 1.8198529388853703e-08, 'subsample': 0.8001041179703089, 'colsample_bytree': 0.781940962377869}. Best is trial 1 with value: 0.17166003715033173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:04,837]\u001b[0m Trial 25 finished with value: 0.16867475699135343 and parameters: {'booster': 'gblinear', 'lambda': 0.00013612029988685013, 'alpha': 4.612170033215884e-07, 'subsample': 0.521095158141581, 'colsample_bytree': 0.8476920671386587}. Best is trial 25 with value: 0.16867475699135343.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:04,968]\u001b[0m Trial 26 finished with value: 0.16549375560879281 and parameters: {'booster': 'gblinear', 'lambda': 0.0674191129306364, 'alpha': 0.0005763041424344697, 'subsample': 0.4835174258427924, 'colsample_bytree': 0.879102090615959}. Best is trial 26 with value: 0.16549375560879281.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:05,096]\u001b[0m Trial 27 finished with value: 0.16402191386847365 and parameters: {'booster': 'gblinear', 'lambda': 0.05677622634569041, 'alpha': 0.0009539808799972524, 'subsample': 0.502468120099733, 'colsample_bytree': 0.8960798277884503}. Best is trial 27 with value: 0.16402191386847365.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:05,226]\u001b[0m Trial 28 finished with value: 0.273125092292626 and parameters: {'booster': 'gblinear', 'lambda': 0.7570337087072303, 'alpha': 0.0008189706545185773, 'subsample': 0.4900120686177622, 'colsample_bytree': 0.9000949622771969}. Best is trial 27 with value: 0.16402191386847365.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:06,741]\u001b[0m Trial 29 finished with value: 1.3352370153332227 and parameters: {'booster': 'dart', 'lambda': 0.04645789695862606, 'alpha': 0.0012264808427332214, 'subsample': 0.41941869635930396, 'colsample_bytree': 0.8686017783468247, 'max_depth': 7, 'min_child_weight': 6, 'eta': 2.6333462496284407e-05, 'gamma': 0.000571104157270962, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.00028387782997236236, 'skip_drop': 5.753696373017496e-05}. Best is trial 27 with value: 0.16402191386847365.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:07,022]\u001b[0m Trial 30 finished with value: 1.340921497355954 and parameters: {'booster': 'gbtree', 'lambda': 0.04803738243771702, 'alpha': 4.1741586369743876e-05, 'subsample': 0.5336406130591677, 'colsample_bytree': 0.9869362627449632, 'max_depth': 5, 'min_child_weight': 8, 'eta': 8.553474727547748e-07, 'gamma': 0.007432125323216977, 'grow_policy': 'depthwise'}. Best is trial 27 with value: 0.16402191386847365.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:07,126]\u001b[0m Trial 31 finished with value: 0.7679790913417762 and parameters: {'booster': 'gblinear', 'lambda': 0.04912655317312829, 'alpha': 0.7221668187901871, 'subsample': 0.4296031101922443, 'colsample_bytree': 0.9036835758206596}. Best is trial 27 with value: 0.16402191386847365.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:07,257]\u001b[0m Trial 32 finished with value: 0.16710856793041137 and parameters: {'booster': 'gblinear', 'lambda': 0.003223713200021586, 'alpha': 0.00026503143474097823, 'subsample': 0.35163871755665327, 'colsample_bytree': 0.8320370784631239}. Best is trial 27 with value: 0.16402191386847365.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:07,388]\u001b[0m Trial 33 finished with value: 0.16771918674697045 and parameters: {'booster': 'gblinear', 'lambda': 0.0025309464096813583, 'alpha': 0.0003808938423255162, 'subsample': 0.302577283828666, 'colsample_bytree': 0.8203056419398516}. Best is trial 27 with value: 0.16402191386847365.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:07,519]\u001b[0m Trial 34 finished with value: 0.16603457771175564 and parameters: {'booster': 'gblinear', 'lambda': 0.0025601383996343447, 'alpha': 0.0005215894006669159, 'subsample': 0.314778907855509, 'colsample_bytree': 0.852172404257061}. Best is trial 27 with value: 0.16402191386847365.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:07,646]\u001b[0m Trial 35 finished with value: 0.16040432744849917 and parameters: {'booster': 'gblinear', 'lambda': 0.016163364148936998, 'alpha': 0.0031998074537586915, 'subsample': 0.3399845804240231, 'colsample_bytree': 0.7315291759320152}. Best is trial 35 with value: 0.16040432744849917.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:07,924]\u001b[0m Trial 36 finished with value: 1.268880070459685 and parameters: {'booster': 'gbtree', 'lambda': 0.013277650382996596, 'alpha': 0.006224262941754961, 'subsample': 0.22536578342222152, 'colsample_bytree': 0.7449091775954987, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.00034032316773159875, 'gamma': 0.24436654334967406, 'grow_policy': 'depthwise'}. Best is trial 35 with value: 0.16040432744849917.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:08,053]\u001b[0m Trial 37 finished with value: 0.1980686075950657 and parameters: {'booster': 'gblinear', 'lambda': 0.2686839115487967, 'alpha': 0.002762396339105455, 'subsample': 0.28741492186697665, 'colsample_bytree': 0.9252858137988522}. Best is trial 35 with value: 0.16040432744849917.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:08,183]\u001b[0m Trial 38 finished with value: 0.1793919321147173 and parameters: {'booster': 'gblinear', 'lambda': 0.16241906358759078, 'alpha': 0.00010811097742935386, 'subsample': 0.3747025318631704, 'colsample_bytree': 0.7282584250916072}. Best is trial 35 with value: 0.16040432744849917.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:08,447]\u001b[0m Trial 39 finished with value: 0.15700050028478996 and parameters: {'booster': 'gbtree', 'lambda': 0.6353835919755723, 'alpha': 0.021212720753972156, 'subsample': 0.44241618201076777, 'colsample_bytree': 0.9997931065263802, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.04392354862986583, 'gamma': 2.5785399890588208e-05, 'grow_policy': 'lossguide'}. Best is trial 39 with value: 0.15700050028478996.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:22:08,711]\u001b[0m Trial 40 finished with value: 0.16286618707022732 and parameters: {'booster': 'gbtree', 'lambda': 0.39170553842892847, 'alpha': 0.02486903593460594, 'subsample': 0.42929857248872566, 'colsample_bytree': 0.999316849664537, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.03169799799042392, 'gamma': 3.0507533667361507e-05, 'grow_policy': 'lossguide'}. Best is trial 39 with value: 0.15700050028478996.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:08,973]\u001b[0m Trial 41 finished with value: 0.15721701849679331 and parameters: {'booster': 'gbtree', 'lambda': 0.5765822471801311, 'alpha': 0.041312321637453395, 'subsample': 0.4406741921260153, 'colsample_bytree': 0.9716940723171202, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.03821838379121356, 'gamma': 1.803302015705189e-05, 'grow_policy': 'lossguide'}. Best is trial 39 with value: 0.15700050028478996.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:09,236]\u001b[0m Trial 42 finished with value: 0.15623826644570235 and parameters: {'booster': 'gbtree', 'lambda': 0.8544527707199882, 'alpha': 0.025848915830936625, 'subsample': 0.43528450296462584, 'colsample_bytree': 0.9890323324522102, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.03918210721295648, 'gamma': 2.5284598587606694e-05, 'grow_policy': 'lossguide'}. Best is trial 42 with value: 0.15623826644570235.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:09,500]\u001b[0m Trial 43 finished with value: 0.15718416184822182 and parameters: {'booster': 'gbtree', 'lambda': 0.7485278012399723, 'alpha': 0.02913683215554122, 'subsample': 0.4377872095401886, 'colsample_bytree': 0.9842064200453663, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.05242954879346626, 'gamma': 2.6559971294157277e-05, 'grow_policy': 'lossguide'}. Best is trial 42 with value: 0.15623826644570235.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:09,731]\u001b[0m Trial 44 finished with value: 0.157518919324348 and parameters: {'booster': 'gbtree', 'lambda': 0.6365077225746482, 'alpha': 0.202269622657533, 'subsample': 0.2679521499671001, 'colsample_bytree': 0.9563546891745884, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.08812063159891799, 'gamma': 4.61545847902523e-05, 'grow_policy': 'lossguide'}. Best is trial 42 with value: 0.15623826644570235.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:09,960]\u001b[0m Trial 45 finished with value: 0.15692367970638782 and parameters: {'booster': 'gbtree', 'lambda': 0.9464395385546169, 'alpha': 0.30676707204534936, 'subsample': 0.2680030796034877, 'colsample_bytree': 0.9620145930713269, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.0696880356248936, 'gamma': 2.7602725313894423e-05, 'grow_policy': 'lossguide'}. Best is trial 42 with value: 0.15623826644570235.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:10,225]\u001b[0m Trial 46 finished with value: 0.7102721253113574 and parameters: {'booster': 'gbtree', 'lambda': 0.1568143968614345, 'alpha': 0.02595120694038894, 'subsample': 0.4547990703296412, 'colsample_bytree': 0.9502019258565769, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.004022699147677909, 'gamma': 8.567610150185536e-06, 'grow_policy': 'lossguide'}. Best is trial 42 with value: 0.15623826644570235.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:10,504]\u001b[0m Trial 47 finished with value: 0.17148143759866283 and parameters: {'booster': 'gbtree', 'lambda': 0.9306199600788139, 'alpha': 0.24418669473113294, 'subsample': 0.5673082624276845, 'colsample_bytree': 0.9828397691836743, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.16031671621844457, 'gamma': 0.00030830898679955145, 'grow_policy': 'lossguide'}. Best is trial 42 with value: 0.15623826644570235.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:10,717]\u001b[0m Trial 48 finished with value: 0.2315828920370657 and parameters: {'booster': 'gbtree', 'lambda': 0.43053525843277046, 'alpha': 0.9814325969210194, 'subsample': 0.20121197526976653, 'colsample_bytree': 0.9244596475167319, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.01735442153867915, 'gamma': 2.1943716066288007e-05, 'grow_policy': 'lossguide'}. Best is trial 42 with value: 0.15623826644570235.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:10,966]\u001b[0m Trial 49 finished with value: 0.14557642929316078 and parameters: {'booster': 'gbtree', 'lambda': 0.12490644425655371, 'alpha': 0.02757257726186441, 'subsample': 0.38968365549341977, 'colsample_bytree': 0.9305215309255452, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.061831483947913574, 'gamma': 1.807016712962661e-06, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:11,219]\u001b[0m Trial 50 finished with value: 0.6841106547512231 and parameters: {'booster': 'gbtree', 'lambda': 0.11902724881357901, 'alpha': 0.1186117961120464, 'subsample': 0.39386933552936243, 'colsample_bytree': 0.9388301705307341, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.004309372339546256, 'gamma': 1.443680738098217e-06, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:11,473]\u001b[0m Trial 51 finished with value: 0.15147297108540697 and parameters: {'booster': 'gbtree', 'lambda': 0.9239150575095625, 'alpha': 0.023907606907181092, 'subsample': 0.38949640875671426, 'colsample_bytree': 0.9684772038969041, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.06268429266586417, 'gamma': 4.091977474673267e-05, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:11,728]\u001b[0m Trial 52 finished with value: 0.16137629709365764 and parameters: {'booster': 'gbtree', 'lambda': 0.317731489032432, 'alpha': 0.022122525197902684, 'subsample': 0.38894470488374416, 'colsample_bytree': 0.9953478870960494, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.11195104616056573, 'gamma': 0.00013024093530892092, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:11,957]\u001b[0m Trial 53 finished with value: 0.22848512199996654 and parameters: {'booster': 'gbtree', 'lambda': 0.9058335893142032, 'alpha': 0.36940427619459965, 'subsample': 0.2552652016626975, 'colsample_bytree': 0.9243255077910918, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.3076500342748768, 'gamma': 0.0014761443596627798, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:12,241]\u001b[0m Trial 54 finished with value: 0.1544598179910568 and parameters: {'booster': 'gbtree', 'lambda': 0.2012637716859244, 'alpha': 0.012661918450836113, 'subsample': 0.34099978362309913, 'colsample_bytree': 0.956069199934696, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.040815341841157905, 'gamma': 6.0101493897269416e-05, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:12,512]\u001b[0m Trial 55 finished with value: 149.39319978506757 and parameters: {'booster': 'gbtree', 'lambda': 0.16684544720934585, 'alpha': 0.01132269842071532, 'subsample': 0.3234018012176814, 'colsample_bytree': 0.8140237059092729, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.9778509421272599, 'gamma': 2.7308503859174446e-06, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:12,806]\u001b[0m Trial 56 finished with value: 0.3247066031724082 and parameters: {'booster': 'gbtree', 'lambda': 0.028726751717758004, 'alpha': 0.09500801640065414, 'subsample': 0.36393188666602566, 'colsample_bytree': 0.9623742025729177, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.010306795991856323, 'gamma': 8.112407418653626e-05, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:13,101]\u001b[0m Trial 57 finished with value: 0.9985342871415319 and parameters: {'booster': 'gbtree', 'lambda': 0.10271459609505919, 'alpha': 0.012443055487536941, 'subsample': 0.40478201702517064, 'colsample_bytree': 0.8847843042375313, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.0018076114216625814, 'gamma': 7.2291432203524e-05, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:13,310]\u001b[0m Trial 58 finished with value: 0.15402903427180836 and parameters: {'booster': 'gbtree', 'lambda': 0.022410457116489584, 'alpha': 0.06796891009584574, 'subsample': 0.46472917410405223, 'colsample_bytree': 0.9206569281999966, 'max_depth': 3, 'min_child_weight': 10, 'eta': 0.07015354023691912, 'gamma': 1.3286915798512098e-07, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:22:13,503]\u001b[0m Trial 59 finished with value: 0.1726539698673777 and parameters: {'booster': 'gbtree', 'lambda': 0.2534090416067611, 'alpha': 0.06309286128032193, 'subsample': 0.277214598342512, 'colsample_bytree': 0.919322902086654, 'max_depth': 3, 'min_child_weight': 10, 'eta': 0.186254635059758, 'gamma': 2.10139053154289e-07, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:13,715]\u001b[0m Trial 60 finished with value: 0.22483850398666794 and parameters: {'booster': 'gbtree', 'lambda': 0.022708054916448353, 'alpha': 0.46701834052651775, 'subsample': 0.46888662119987495, 'colsample_bytree': 0.9571384414080397, 'max_depth': 3, 'min_child_weight': 10, 'eta': 0.016719669858443437, 'gamma': 9.678425091100877e-08, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:14,003]\u001b[0m Trial 61 finished with value: 0.1641965780767076 and parameters: {'booster': 'gbtree', 'lambda': 0.26489627264043125, 'alpha': 0.14221015765088973, 'subsample': 0.35755523569545133, 'colsample_bytree': 0.9473683246851625, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.08521164497939364, 'gamma': 6.441518443291279e-06, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:14,250]\u001b[0m Trial 62 finished with value: 0.15465908027658926 and parameters: {'booster': 'gbtree', 'lambda': 0.006008405637015041, 'alpha': 0.0039606215601997305, 'subsample': 0.32936634647711477, 'colsample_bytree': 0.9996797697145955, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.04733346887377578, 'gamma': 9.761598432718988e-07, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:14,445]\u001b[0m Trial 63 finished with value: 0.2268370220667633 and parameters: {'booster': 'gbtree', 'lambda': 0.009108043259743655, 'alpha': 0.0036870872554419644, 'subsample': 0.32969318496256805, 'colsample_bytree': 0.8692323896860721, 'max_depth': 3, 'min_child_weight': 8, 'eta': 0.36665422383389074, 'gamma': 3.704417525968175e-07, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:14,665]\u001b[0m Trial 64 finished with value: 0.42359751479742386 and parameters: {'booster': 'gbtree', 'lambda': 0.10591334374314278, 'alpha': 0.04899794555861814, 'subsample': 0.2267399912527585, 'colsample_bytree': 0.9011602904316391, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.00805885670333179, 'gamma': 1.3247267276327417e-06, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:14,860]\u001b[0m Trial 65 finished with value: 1.0276639349022207 and parameters: {'booster': 'gbtree', 'lambda': 0.005007427878843257, 'alpha': 0.0017569725213887077, 'subsample': 0.29809869909498876, 'colsample_bytree': 0.9334304568604884, 'max_depth': 3, 'min_child_weight': 9, 'eta': 0.001630860878440777, 'gamma': 7.735045590924908e-08, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:16,254]\u001b[0m Trial 66 finished with value: 0.16751777340222235 and parameters: {'booster': 'dart', 'lambda': 0.030377373658748548, 'alpha': 0.010199419730508936, 'subsample': 0.5580019658045395, 'colsample_bytree': 0.967163982277198, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.03629088180248047, 'gamma': 2.757266268064555e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 7.911333064205699e-05, 'skip_drop': 6.36443632312655e-05}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:16,542]\u001b[0m Trial 67 finished with value: 0.23846727899991416 and parameters: {'booster': 'gbtree', 'lambda': 0.006680888925124356, 'alpha': 0.004737005308428732, 'subsample': 0.3799772190259278, 'colsample_bytree': 0.9045148457763663, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.2857190112581951, 'gamma': 7.996635775340706e-07, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:16,810]\u001b[0m Trial 68 finished with value: 0.15250063246833878 and parameters: {'booster': 'gbtree', 'lambda': 0.07895808430155957, 'alpha': 0.07279104630658298, 'subsample': 0.6270969481988145, 'colsample_bytree': 0.8653951483624527, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.0916974443028353, 'gamma': 8.760781612260778e-06, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:17,075]\u001b[0m Trial 69 finished with value: 0.23578693620861035 and parameters: {'booster': 'gbtree', 'lambda': 0.0007461577223921207, 'alpha': 0.01649277102251815, 'subsample': 0.6212331409805019, 'colsample_bytree': 0.8047126222087665, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.5230405266147345, 'gamma': 7.0956326235414e-06, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:17,291]\u001b[0m Trial 70 finished with value: 0.2001966625251368 and parameters: {'booster': 'gbtree', 'lambda': 0.060488397676283445, 'alpha': 0.07632608898742954, 'subsample': 0.7129415566110358, 'colsample_bytree': 0.859954624023051, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.020831479300560615, 'gamma': 4.511524610530258e-08, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:17,521]\u001b[0m Trial 71 finished with value: 0.1611909562053658 and parameters: {'booster': 'gbtree', 'lambda': 0.08696585529125793, 'alpha': 0.2715830746355057, 'subsample': 0.2464951831855282, 'colsample_bytree': 0.9677621922180645, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.11040010276577918, 'gamma': 1.1126586275638232e-05, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:17,771]\u001b[0m Trial 72 finished with value: 0.15550501465431577 and parameters: {'booster': 'gbtree', 'lambda': 0.1757820011817545, 'alpha': 0.1558471002554628, 'subsample': 0.4105933202628664, 'colsample_bytree': 0.8806052358453077, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.07422609261906447, 'gamma': 2.6656385569880597e-06, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:18,019]\u001b[0m Trial 73 finished with value: 0.1665793177387193 and parameters: {'booster': 'gbtree', 'lambda': 0.032058003205123045, 'alpha': 0.044011731526649646, 'subsample': 0.41076452177403155, 'colsample_bytree': 0.8365413407253701, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.17022357858043216, 'gamma': 3.1149377490641764e-06, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:19,479]\u001b[0m Trial 74 finished with value: 0.4339649412619518 and parameters: {'booster': 'dart', 'lambda': 0.20439099261323349, 'alpha': 0.17320180896656742, 'subsample': 0.6090690804583825, 'colsample_bytree': 0.8876820906852855, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.00786842237589591, 'gamma': 5.395598408306771e-07, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.00023257911491564225, 'skip_drop': 0.7534577501270829}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:19,857]\u001b[0m Trial 75 finished with value: 0.15878549302361658 and parameters: {'booster': 'gbtree', 'lambda': 0.36348431501973266, 'alpha': 0.007683400549328965, 'subsample': 0.5216028523479175, 'colsample_bytree': 0.9183198708899567, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.03137137454212445, 'gamma': 1.448058262884232e-06, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:20,166]\u001b[0m Trial 76 finished with value: 1.3167608015019925 and parameters: {'booster': 'gbtree', 'lambda': 0.02053721828057948, 'alpha': 0.001996317682913338, 'subsample': 0.34493018484808674, 'colsample_bytree': 0.9383484637973103, 'max_depth': 7, 'min_child_weight': 5, 'eta': 0.00010847106468228345, 'gamma': 2.996764917223215e-07, 'grow_policy': 'depthwise'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:22:20,510]\u001b[0m Trial 77 finished with value: 0.15062771238645098 and parameters: {'booster': 'gbtree', 'lambda': 0.44962791439385064, 'alpha': 0.09880732105483384, 'subsample': 0.4715248896888298, 'colsample_bytree': 0.8751847400480197, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.04853897371996096, 'gamma': 1.1991583401530638e-08, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:20,805]\u001b[0m Trial 78 finished with value: 1.3411036938422396 and parameters: {'booster': 'gbtree', 'lambda': 4.60956485769189e-08, 'alpha': 0.09189026504457305, 'subsample': 0.4683499245281879, 'colsample_bytree': 0.8508788350710155, 'max_depth': 5, 'min_child_weight': 10, 'eta': 6.021082744900926e-08, 'gamma': 1.3896761550959336e-08, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:21,086]\u001b[0m Trial 79 finished with value: 0.1552538099307238 and parameters: {'booster': 'gbtree', 'lambda': 0.07083455405904146, 'alpha': 0.5012233844474365, 'subsample': 0.6320716831475571, 'colsample_bytree': 0.8812606023046179, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.05716887297099895, 'gamma': 1.1270501368518525e-07, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:21,404]\u001b[0m Trial 80 finished with value: 0.19649860851955894 and parameters: {'booster': 'gbtree', 'lambda': 0.0716624882282291, 'alpha': 0.6156396783684045, 'subsample': 0.6579348324440994, 'colsample_bytree': 0.7875238064348028, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.5288090336825283, 'gamma': 4.1292841889474536e-08, 'grow_policy': 'depthwise'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:21,680]\u001b[0m Trial 81 finished with value: 0.15596725886766974 and parameters: {'booster': 'gbtree', 'lambda': 0.14575201158700815, 'alpha': 0.0381900656160503, 'subsample': 0.690142854260664, 'colsample_bytree': 0.8762580344399571, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.0631721775854118, 'gamma': 1.4020987331212547e-07, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:21,948]\u001b[0m Trial 82 finished with value: 0.19042562772193433 and parameters: {'booster': 'gbtree', 'lambda': 0.04072735314539047, 'alpha': 0.13724590536119036, 'subsample': 0.6341424342709617, 'colsample_bytree': 0.8344087608011436, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.019961579049115004, 'gamma': 7.146665112504857e-07, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:22,203]\u001b[0m Trial 83 finished with value: 0.17600846041349813 and parameters: {'booster': 'gbtree', 'lambda': 0.44477725966088766, 'alpha': 0.05736805451789812, 'subsample': 0.5842928572216728, 'colsample_bytree': 0.764368256339449, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.19318700077681758, 'gamma': 3.063652820507718e-08, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:22,458]\u001b[0m Trial 84 finished with value: 0.1580836953112492 and parameters: {'booster': 'gbtree', 'lambda': 0.015366818576397618, 'alpha': 0.01573901660656528, 'subsample': 0.409569634247279, 'colsample_bytree': 0.9043392556112845, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.06255941347617476, 'gamma': 5.079272625378737e-06, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:23,875]\u001b[0m Trial 85 finished with value: 0.1687229776202217 and parameters: {'booster': 'dart', 'lambda': 0.0779934630997006, 'alpha': 0.5508775395210959, 'subsample': 0.7570903463960732, 'colsample_bytree': 0.5639172319540787, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.12102598283572656, 'gamma': 1.0553476312112131e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.118872119434175e-08, 'skip_drop': 0.0017904341689458292}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:24,143]\u001b[0m Trial 86 finished with value: 0.1622017582752385 and parameters: {'booster': 'gbtree', 'lambda': 0.20283441768675334, 'alpha': 0.18328804499681817, 'subsample': 0.509443446599162, 'colsample_bytree': 0.8789654510154088, 'max_depth': 5, 'min_child_weight': 5, 'eta': 0.033890331908203584, 'gamma': 7.310653239399974e-08, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:24,417]\u001b[0m Trial 87 finished with value: 0.3294070445917325 and parameters: {'booster': 'gbtree', 'lambda': 0.0016550327434987026, 'alpha': 0.0058070560471428605, 'subsample': 0.5417380264870917, 'colsample_bytree': 0.9123078407296022, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.01027060016407024, 'gamma': 1.2443648162390138e-05, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:24,661]\u001b[0m Trial 88 finished with value: 1.339494415114168 and parameters: {'booster': 'gbtree', 'lambda': 0.010048136817720914, 'alpha': 0.36533072693395635, 'subsample': 0.4691189382660521, 'colsample_bytree': 0.6960435564046427, 'max_depth': 5, 'min_child_weight': 7, 'eta': 7.567024693334192e-06, 'gamma': 1.579617875029064e-07, 'grow_policy': 'lossguide'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:24,947]\u001b[0m Trial 89 finished with value: 0.15029745182247392 and parameters: {'booster': 'gbtree', 'lambda': 0.434868689350642, 'alpha': 0.9216962453223441, 'subsample': 0.3642637465529891, 'colsample_bytree': 0.9383892894018397, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.06183060854975649, 'gamma': 1.2539104938027518e-06, 'grow_policy': 'depthwise'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:25,155]\u001b[0m Trial 90 finished with value: 0.8845641597090017 and parameters: {'booster': 'gbtree', 'lambda': 0.4801886696020226, 'alpha': 0.8020679185138581, 'subsample': 0.3143887988314198, 'colsample_bytree': 0.3153854242624312, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.003196289862021719, 'gamma': 0.00023957960707022275, 'grow_policy': 'depthwise'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:25,448]\u001b[0m Trial 91 finished with value: 0.1508814923936099 and parameters: {'booster': 'gbtree', 'lambda': 0.14059260039425545, 'alpha': 0.08335438540662177, 'subsample': 0.3690705134954509, 'colsample_bytree': 0.9403168435660106, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.07191336024316618, 'gamma': 1.8496705848393415e-06, 'grow_policy': 'depthwise'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:25,738]\u001b[0m Trial 92 finished with value: 0.16814766478338286 and parameters: {'booster': 'gbtree', 'lambda': 0.1093159932691478, 'alpha': 0.08073782632938138, 'subsample': 0.36582502482110096, 'colsample_bytree': 0.940146475077234, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.024267603002687647, 'gamma': 1.3032228880419509e-06, 'grow_policy': 'depthwise'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:26,075]\u001b[0m Trial 93 finished with value: 0.1530501825599462 and parameters: {'booster': 'gbtree', 'lambda': 0.2914970831462299, 'alpha': 0.03517331652201652, 'subsample': 0.39305070771996914, 'colsample_bytree': 0.9801463306706961, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.049541768359311275, 'gamma': 4.699485145098687e-05, 'grow_policy': 'depthwise'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:26,413]\u001b[0m Trial 94 finished with value: 0.1995381705772206 and parameters: {'booster': 'gbtree', 'lambda': 0.3101077427814715, 'alpha': 0.037921878700821414, 'subsample': 0.3876975822662713, 'colsample_bytree': 0.9811947788018109, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.22701740644481994, 'gamma': 6.0617471206358836e-05, 'grow_policy': 'depthwise'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:26,737]\u001b[0m Trial 95 finished with value: 0.17544704154890114 and parameters: {'booster': 'gbtree', 'lambda': 0.5188416485957438, 'alpha': 0.013827643205406125, 'subsample': 0.3395110453254574, 'colsample_bytree': 0.9771167837602959, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.11846056154775027, 'gamma': 3.8376162721937385e-05, 'grow_policy': 'depthwise'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:22:27,063]\u001b[0m Trial 96 finished with value: 0.27567500354862534 and parameters: {'booster': 'gbtree', 'lambda': 0.04401038192353972, 'alpha': 0.008591419210046523, 'subsample': 0.3756127468250383, 'colsample_bytree': 0.9474317041125103, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.011954822296951367, 'gamma': 0.00012677153833523362, 'grow_policy': 'depthwise'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:27,333]\u001b[0m Trial 97 finished with value: 0.15418792674590764 and parameters: {'booster': 'gbtree', 'lambda': 0.2519547078288712, 'alpha': 0.06163782699276993, 'subsample': 0.3036361538566605, 'colsample_bytree': 0.9317144285684151, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.042105215972309755, 'gamma': 0.0005347892405832196, 'grow_policy': 'depthwise'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:27,561]\u001b[0m Trial 98 finished with value: 0.3600487800429997 and parameters: {'booster': 'gbtree', 'lambda': 0.2362224001319839, 'alpha': 0.029963203417688256, 'subsample': 0.28687419486640914, 'colsample_bytree': 0.4651721492657382, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.41080322449856627, 'gamma': 0.0005843318072269916, 'grow_policy': 'depthwise'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:27,844]\u001b[0m Trial 99 finished with value: 0.16899063877662981 and parameters: {'booster': 'gbtree', 'lambda': 0.5653963063077488, 'alpha': 0.0630264525317117, 'subsample': 0.3475597809227428, 'colsample_bytree': 0.931983933806751, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.026224651893757854, 'gamma': 0.0027348273504288036, 'grow_policy': 'depthwise'}. Best is trial 49 with value: 0.14557642929316078.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:28,130]\u001b[0m A new study created in memory with name: no-name-f6722ea0-ef3c-4e83-a6a1-89ca97b386fc\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:29,492]\u001b[0m Trial 0 finished with value: 0.13840455870904683 and parameters: {'booster': 'dart', 'lambda': 0.07611332622033132, 'alpha': 0.00018621350697671708, 'subsample': 0.8335341745872327, 'colsample_bytree': 0.9500628874506771, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.44830287774829186, 'gamma': 0.013691427705537091, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.0024275525300301425, 'skip_drop': 0.20248124845157842}. Best is trial 0 with value: 0.13840455870904683.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:29,607]\u001b[0m Trial 1 finished with value: 0.20165583438145612 and parameters: {'booster': 'gblinear', 'lambda': 0.04294051989838588, 'alpha': 0.00015405117826440063, 'subsample': 0.6158400238321124, 'colsample_bytree': 0.6005164460162855}. Best is trial 0 with value: 0.13840455870904683.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:29,723]\u001b[0m Trial 2 finished with value: 0.21787995807756874 and parameters: {'booster': 'gblinear', 'lambda': 0.00010285888223353862, 'alpha': 5.651850885049895e-08, 'subsample': 0.4633632840301616, 'colsample_bytree': 0.354797267544192}. Best is trial 0 with value: 0.13840455870904683.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:31,202]\u001b[0m Trial 3 finished with value: 1.286470857258561 and parameters: {'booster': 'dart', 'lambda': 8.441478624329227e-05, 'alpha': 6.64688289344116e-08, 'subsample': 0.2919690107766777, 'colsample_bytree': 0.9255695853589465, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.00010948276975510229, 'gamma': 0.00052167361292866, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 5.369187458007e-06, 'skip_drop': 1.2889351448668949e-06}. Best is trial 0 with value: 0.13840455870904683.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:31,324]\u001b[0m Trial 4 finished with value: 0.21465765529287084 and parameters: {'booster': 'gblinear', 'lambda': 0.17574103270894278, 'alpha': 1.1386216222266975e-05, 'subsample': 0.3525338312965041, 'colsample_bytree': 0.5554684504437577}. Best is trial 0 with value: 0.13840455870904683.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:31,540]\u001b[0m Trial 5 finished with value: 1.283871875615179 and parameters: {'booster': 'gbtree', 'lambda': 4.0701600867582056e-07, 'alpha': 0.5932449578477272, 'subsample': 0.2750203626721013, 'colsample_bytree': 0.5737119026003161, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.00013059768635150946, 'gamma': 2.1699476153931748e-08, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.13840455870904683.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:31,812]\u001b[0m Trial 6 finished with value: 1.3117708395439387 and parameters: {'booster': 'gbtree', 'lambda': 2.5462758745644916e-06, 'alpha': 0.1900242735814227, 'subsample': 0.7607901690552132, 'colsample_bytree': 0.835197950114162, 'max_depth': 5, 'min_child_weight': 2, 'eta': 1.0553461345069299e-06, 'gamma': 6.798238043286034e-06, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.13840455870904683.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:31,936]\u001b[0m Trial 7 finished with value: 0.2126665950749209 and parameters: {'booster': 'gblinear', 'lambda': 0.0009126676248839734, 'alpha': 1.8104872036774818e-07, 'subsample': 0.5516683445902975, 'colsample_bytree': 0.5738287658727868}. Best is trial 0 with value: 0.13840455870904683.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:32,048]\u001b[0m Trial 8 finished with value: 0.3279904911008266 and parameters: {'booster': 'gblinear', 'lambda': 0.8168083396633599, 'alpha': 0.05683614272687979, 'subsample': 0.7256532035308358, 'colsample_bytree': 0.3246970204163921}. Best is trial 0 with value: 0.13840455870904683.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:32,171]\u001b[0m Trial 9 finished with value: 0.18896733754078365 and parameters: {'booster': 'gblinear', 'lambda': 2.7248845242489093e-08, 'alpha': 0.003238662508097569, 'subsample': 0.9990847016765618, 'colsample_bytree': 0.5137346018244968}. Best is trial 0 with value: 0.13840455870904683.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:33,285]\u001b[0m Trial 10 finished with value: 0.1428934990118596 and parameters: {'booster': 'dart', 'lambda': 0.0037409551120982636, 'alpha': 1.0359272855274445e-05, 'subsample': 0.9999769150940991, 'colsample_bytree': 0.9984769217752091, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.7936344262686367, 'gamma': 0.6556270229960288, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.7240028172450935, 'skip_drop': 0.5505322342359229}. Best is trial 0 with value: 0.13840455870904683.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:34,524]\u001b[0m Trial 11 finished with value: 0.1445436833345613 and parameters: {'booster': 'dart', 'lambda': 0.005270447693427544, 'alpha': 1.1793767007126204e-05, 'subsample': 0.9806167029445036, 'colsample_bytree': 0.9625877661757615, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.8528133115130053, 'gamma': 0.8406084193672907, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.44690168718139783, 'skip_drop': 0.5930259165364995}. Best is trial 0 with value: 0.13840455870904683.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:35,826]\u001b[0m Trial 12 finished with value: 0.1576675815553386 and parameters: {'booster': 'dart', 'lambda': 0.012467874629945662, 'alpha': 0.0004155867482394778, 'subsample': 0.8600287877662249, 'colsample_bytree': 0.7927596771062397, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.8991591163398024, 'gamma': 0.29211321942623425, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.41277452205995335, 'skip_drop': 0.7069278533913073}. Best is trial 0 with value: 0.13840455870904683.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:37,460]\u001b[0m Trial 13 finished with value: 0.33762434213050724 and parameters: {'booster': 'dart', 'lambda': 0.0006803644493875847, 'alpha': 2.8720194347097897e-06, 'subsample': 0.8864515872973273, 'colsample_bytree': 0.7547210567941476, 'max_depth': 5, 'min_child_weight': 5, 'eta': 0.00870177093922711, 'gamma': 0.0074158675802721815, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.0017313673378212653, 'skip_drop': 0.00397444452747752}. Best is trial 0 with value: 0.13840455870904683.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:38,905]\u001b[0m Trial 14 finished with value: 0.2584577435071986 and parameters: {'booster': 'dart', 'lambda': 0.1325341290729811, 'alpha': 0.004345149668337673, 'subsample': 0.8337648242787509, 'colsample_bytree': 0.893951400738661, 'max_depth': 3, 'min_child_weight': 9, 'eta': 0.011637290822327789, 'gamma': 0.019188592702440863, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.0010236769992259412, 'skip_drop': 0.003121519008790638}. Best is trial 0 with value: 0.13840455870904683.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:22:40,374]\u001b[0m Trial 15 finished with value: 0.14190479853381346 and parameters: {'booster': 'dart', 'lambda': 0.0031606759614748975, 'alpha': 1.496777327885834e-06, 'subsample': 0.6636975277321204, 'colsample_bytree': 0.6896604385406697, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.020720565738339258, 'gamma': 0.01518790572572652, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 2.989229358840557e-08, 'skip_drop': 0.011001096148581095}. Best is trial 0 with value: 0.13840455870904683.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:42,373]\u001b[0m Trial 16 finished with value: 0.30065145367164187 and parameters: {'booster': 'dart', 'lambda': 4.0198419369576985e-05, 'alpha': 6.798758554858793e-07, 'subsample': 0.6695921785488326, 'colsample_bytree': 0.7005452273499733, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.0096457841461734, 'gamma': 7.871378416896876e-05, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 2.31797111283129e-08, 'skip_drop': 0.0015067377266924013}. Best is trial 0 with value: 0.13840455870904683.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:44,040]\u001b[0m Trial 17 finished with value: 1.3120152010619817 and parameters: {'booster': 'dart', 'lambda': 0.952460476603977, 'alpha': 6.154503843260097e-05, 'subsample': 0.5157355760672473, 'colsample_bytree': 0.44507062085251126, 'max_depth': 5, 'min_child_weight': 4, 'eta': 1.1779744534355732e-08, 'gamma': 0.005555236380784628, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.8654464412342728e-08, 'skip_drop': 1.4898289321735031e-08}. Best is trial 0 with value: 0.13840455870904683.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:44,298]\u001b[0m Trial 18 finished with value: 0.1444614922354898 and parameters: {'booster': 'gbtree', 'lambda': 0.000955378555202911, 'alpha': 0.0015850542334470774, 'subsample': 0.7713100225016525, 'colsample_bytree': 0.21492702645843648, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.031912503153644044, 'gamma': 0.00020015795235782985, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.13840455870904683.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:45,786]\u001b[0m Trial 19 finished with value: 1.1313734639206574 and parameters: {'booster': 'dart', 'lambda': 0.032620146059943955, 'alpha': 1.4826885123236771e-08, 'subsample': 0.6383060408839141, 'colsample_bytree': 0.7077849980898475, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.0008638977139105352, 'gamma': 4.599677020160094e-06, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 6.239319930504136e-06, 'skip_drop': 0.018885158435916597}. Best is trial 0 with value: 0.13840455870904683.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:47,304]\u001b[0m Trial 20 finished with value: 0.11779707531518413 and parameters: {'booster': 'dart', 'lambda': 9.925521526210473e-06, 'alpha': 1.0265303386554574e-06, 'subsample': 0.42591258433336104, 'colsample_bytree': 0.65183347768156, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.06260428870747789, 'gamma': 0.0722567031336552, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.007388194712391343, 'skip_drop': 3.816107824236492e-05}. Best is trial 20 with value: 0.11779707531518413.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:48,823]\u001b[0m Trial 21 finished with value: 0.11657879976387184 and parameters: {'booster': 'dart', 'lambda': 3.7741455982686153e-06, 'alpha': 1.1325349447489775e-06, 'subsample': 0.4203603852583094, 'colsample_bytree': 0.6598564699044288, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.06305996704847003, 'gamma': 0.03883583024970528, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.006684557246838937, 'skip_drop': 1.7160404190886132e-05}. Best is trial 21 with value: 0.11657879976387184.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:50,702]\u001b[0m Trial 22 finished with value: 0.12311204222301797 and parameters: {'booster': 'dart', 'lambda': 4.7498310463347525e-06, 'alpha': 4.9004889184163806e-05, 'subsample': 0.3985320761183893, 'colsample_bytree': 0.6492689301091441, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.09565253599424868, 'gamma': 0.07096516376285673, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.007988578300737655, 'skip_drop': 2.107446043896708e-05}. Best is trial 21 with value: 0.11657879976387184.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:52,444]\u001b[0m Trial 23 finished with value: 0.11959802100898022 and parameters: {'booster': 'dart', 'lambda': 3.2390053098518525e-06, 'alpha': 2.812585713213367e-07, 'subsample': 0.42199726516069935, 'colsample_bytree': 0.6592462413112625, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.09612358416104762, 'gamma': 0.10833148170230177, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.02115416659695557, 'skip_drop': 2.1568211219026513e-05}. Best is trial 21 with value: 0.11657879976387184.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:54,039]\u001b[0m Trial 24 finished with value: 1.1021288980582855 and parameters: {'booster': 'dart', 'lambda': 2.791677370646481e-07, 'alpha': 4.212411571840947e-07, 'subsample': 0.21476984485971679, 'colsample_bytree': 0.4600491490970703, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.0010825030587724518, 'gamma': 0.10064590199619386, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.028084171354835333, 'skip_drop': 2.711272491397614e-05}. Best is trial 21 with value: 0.11657879976387184.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:54,361]\u001b[0m Trial 25 finished with value: 1.3107200754878972 and parameters: {'booster': 'gbtree', 'lambda': 7.675485910275251e-06, 'alpha': 1.0821636867247561e-08, 'subsample': 0.4212115965761171, 'colsample_bytree': 0.6404670603986066, 'max_depth': 9, 'min_child_weight': 7, 'eta': 5.712621085421122e-06, 'gamma': 0.0014500564049870536, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.11657879976387184.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:56,094]\u001b[0m Trial 26 finished with value: 0.11650989807996016 and parameters: {'booster': 'dart', 'lambda': 9.370289648220736e-07, 'alpha': 2.9722184674999403e-06, 'subsample': 0.4847837555915471, 'colsample_bytree': 0.8493315052841367, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.10111826998032102, 'gamma': 0.12006326536943715, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.000148032455535602, 'skip_drop': 1.6300567971293935e-06}. Best is trial 26 with value: 0.11650989807996016.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:57,775]\u001b[0m Trial 27 finished with value: 0.9533693917485693 and parameters: {'booster': 'dart', 'lambda': 4.109036878594547e-07, 'alpha': 3.015104777307991e-06, 'subsample': 0.512519112800003, 'colsample_bytree': 0.8524608752200982, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.0018253612661751947, 'gamma': 0.002334240198642678, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.00019785795888550403, 'skip_drop': 1.0405132987715744e-06}. Best is trial 26 with value: 0.11650989807996016.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:22:59,350]\u001b[0m Trial 28 finished with value: 0.1325444396414835 and parameters: {'booster': 'dart', 'lambda': 1.1752655238800166e-08, 'alpha': 8.63603405522462e-08, 'subsample': 0.3380903594398769, 'colsample_bytree': 0.7644924607047102, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.12685252425134563, 'gamma': 0.041211852557649135, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 3.2901280631729445e-05, 'skip_drop': 5.616590756522622e-07}. Best is trial 26 with value: 0.11650989807996016.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:01,050]\u001b[0m Trial 29 finished with value: 0.816221473280042 and parameters: {'booster': 'dart', 'lambda': 1.15109270889136e-07, 'alpha': 1.1662291409890863e-06, 'subsample': 0.5637153013582871, 'colsample_bytree': 0.8587942085517021, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.00271539900675267, 'gamma': 1.4778664898825244e-05, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.00021768424911043285, 'skip_drop': 0.00014448724960990623}. Best is trial 26 with value: 0.11650989807996016.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:23:01,349]\u001b[0m Trial 30 finished with value: 1.3108926984107203 and parameters: {'booster': 'gbtree', 'lambda': 1.72116982133975e-05, 'alpha': 5.421649969923804e-06, 'subsample': 0.47578550089498284, 'colsample_bytree': 0.7972048709493149, 'max_depth': 7, 'min_child_weight': 7, 'eta': 4.8509080875352475e-06, 'gamma': 0.25953542230799387, 'grow_policy': 'depthwise'}. Best is trial 26 with value: 0.11650989807996016.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:03,004]\u001b[0m A new study created in memory with name: no-name-9f5a6658-78a2-4fde-bb4d-b8b4ee882c2b\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:03,124]\u001b[0m Trial 0 finished with value: 0.0004957676458562004 and parameters: {'booster': 'gblinear', 'lambda': 2.643506904517419e-07, 'alpha': 0.0006134575100581775, 'subsample': 0.5116189600867178, 'colsample_bytree': 0.8491775786979625}. Best is trial 0 with value: 0.0004957676458562004.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:03,244]\u001b[0m Trial 1 finished with value: 0.0010394756611315592 and parameters: {'booster': 'gblinear', 'lambda': 3.2997395230212345e-06, 'alpha': 4.082707638373902e-06, 'subsample': 0.861454875401942, 'colsample_bytree': 0.7145552163938025}. Best is trial 0 with value: 0.0004957676458562004.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:03,364]\u001b[0m Trial 2 finished with value: 0.017247985947163973 and parameters: {'booster': 'gblinear', 'lambda': 0.06375445168635477, 'alpha': 2.191548845080238e-05, 'subsample': 0.7943082553367768, 'colsample_bytree': 0.9374473623566988}. Best is trial 0 with value: 0.0004957676458562004.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:03,483]\u001b[0m Trial 3 finished with value: 0.0007874072083341099 and parameters: {'booster': 'gblinear', 'lambda': 3.364119802482049e-08, 'alpha': 5.944096783510472e-07, 'subsample': 0.8645423606591351, 'colsample_bytree': 0.4753061246127723}. Best is trial 0 with value: 0.0004957676458562004.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:05,108]\u001b[0m Trial 4 finished with value: 0.7896004938428888 and parameters: {'booster': 'dart', 'lambda': 0.04610079745205747, 'alpha': 1.1088796179149315e-05, 'subsample': 0.8899466542406109, 'colsample_bytree': 0.49083308380251806, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.002261627376408552, 'gamma': 0.004927948104271334, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.00021385287549523658, 'skip_drop': 5.430606048545349e-08}. Best is trial 0 with value: 0.0004957676458562004.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:05,481]\u001b[0m Trial 5 finished with value: 1.182943463105195 and parameters: {'booster': 'gbtree', 'lambda': 6.983093306865564e-05, 'alpha': 5.954078290262307e-07, 'subsample': 0.4129219774247524, 'colsample_bytree': 0.8345145005787735, 'max_depth': 7, 'min_child_weight': 2, 'eta': 3.1901701745861955e-06, 'gamma': 7.271248294809134e-07, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.0004957676458562004.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:06,900]\u001b[0m Trial 6 finished with value: 1.1634787409647454 and parameters: {'booster': 'dart', 'lambda': 2.1507700734547965e-06, 'alpha': 1.052736997256277e-07, 'subsample': 0.3620381100382353, 'colsample_bytree': 0.8639129481928793, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.00025529784891076816, 'gamma': 6.075130821352508e-07, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.10261472897923865, 'skip_drop': 1.7021992886872985e-05}. Best is trial 0 with value: 0.0004957676458562004.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:08,296]\u001b[0m Trial 7 finished with value: 1.1836486908970059 and parameters: {'booster': 'dart', 'lambda': 1.8728675118733067e-06, 'alpha': 0.01935737422247602, 'subsample': 0.9821879665743201, 'colsample_bytree': 0.3413569986898255, 'max_depth': 5, 'min_child_weight': 5, 'eta': 8.013357241506985e-08, 'gamma': 6.962297045966944e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.016703088740415286, 'skip_drop': 0.041789716575836536}. Best is trial 0 with value: 0.0004957676458562004.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:09,813]\u001b[0m Trial 8 finished with value: 1.183653887409943 and parameters: {'booster': 'dart', 'lambda': 0.03869783348366952, 'alpha': 1.1735193665584241e-05, 'subsample': 0.2820471655528836, 'colsample_bytree': 0.22846998298760968, 'max_depth': 9, 'min_child_weight': 2, 'eta': 4.9005785935729847e-08, 'gamma': 2.1752187824146613e-07, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.0242931229188551e-06, 'skip_drop': 1.826105088924991e-07}. Best is trial 0 with value: 0.0004957676458562004.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:09,934]\u001b[0m Trial 9 finished with value: 0.0010290858490077284 and parameters: {'booster': 'gblinear', 'lambda': 1.1933348461499764e-06, 'alpha': 5.242322721735053e-08, 'subsample': 0.9779662444829893, 'colsample_bytree': 0.9275462007441571}. Best is trial 0 with value: 0.0004957676458562004.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:10,139]\u001b[0m Trial 10 finished with value: 0.047036364638370326 and parameters: {'booster': 'gbtree', 'lambda': 1.697367067900191e-08, 'alpha': 0.0028169446127478247, 'subsample': 0.6030285193836843, 'colsample_bytree': 0.6947302011350871, 'max_depth': 3, 'min_child_weight': 10, 'eta': 0.331337138132803, 'gamma': 0.9686130084919615, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.0004957676458562004.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:10,244]\u001b[0m Trial 11 finished with value: 0.9273838177836069 and parameters: {'booster': 'gblinear', 'lambda': 5.125052115621743e-08, 'alpha': 0.9621108303319371, 'subsample': 0.5942538851158381, 'colsample_bytree': 0.5103946583138853}. Best is trial 0 with value: 0.0004957676458562004.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:10,377]\u001b[0m Trial 12 finished with value: 0.00032438206126240076 and parameters: {'booster': 'gblinear', 'lambda': 1.0609334525181194e-08, 'alpha': 0.0004069108649727785, 'subsample': 0.6557284062997174, 'colsample_bytree': 0.5788081309702097}. Best is trial 12 with value: 0.00032438206126240076.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:10,511]\u001b[0m Trial 13 finished with value: 0.0011935947669623026 and parameters: {'booster': 'gblinear', 'lambda': 0.0010254736660792708, 'alpha': 0.0009524482943331333, 'subsample': 0.6017635953915003, 'colsample_bytree': 0.6494994756199876}. Best is trial 12 with value: 0.00032438206126240076.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:10,646]\u001b[0m Trial 14 finished with value: 0.0004492347784364132 and parameters: {'booster': 'gblinear', 'lambda': 2.449651433789425e-07, 'alpha': 0.0004073825811530521, 'subsample': 0.4924013273254461, 'colsample_bytree': 0.7927779643132744}. Best is trial 12 with value: 0.00032438206126240076.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:10,766]\u001b[0m Trial 15 finished with value: 0.0030331405079221645 and parameters: {'booster': 'gblinear', 'lambda': 5.891725130624959e-05, 'alpha': 0.031987579201799475, 'subsample': 0.7165053828876777, 'colsample_bytree': 0.7678395353044332}. Best is trial 12 with value: 0.00032438206126240076.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:10,961]\u001b[0m Trial 16 finished with value: 0.09636905678802733 and parameters: {'booster': 'gbtree', 'lambda': 1.5381650387528055e-07, 'alpha': 0.00036991565886322755, 'subsample': 0.46924607397810636, 'colsample_bytree': 0.6384451458185352, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.5838713933202213, 'gamma': 0.00035805406983150946, 'grow_policy': 'depthwise'}. Best is trial 12 with value: 0.00032438206126240076.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:11,096]\u001b[0m Trial 17 finished with value: 0.001559283455430008 and parameters: {'booster': 'gblinear', 'lambda': 1.248259974458969e-08, 'alpha': 0.0001304348824843848, 'subsample': 0.7164551921127401, 'colsample_bytree': 0.5395219786235388}. Best is trial 12 with value: 0.00032438206126240076.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:11,227]\u001b[0m Trial 18 finished with value: 0.00038226790428321655 and parameters: {'booster': 'gblinear', 'lambda': 0.001571453988522071, 'alpha': 0.009995717885334987, 'subsample': 0.2958111340021065, 'colsample_bytree': 0.3885022271935823}. Best is trial 12 with value: 0.00032438206126240076.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:11,431]\u001b[0m Trial 19 finished with value: 0.4342721764536004 and parameters: {'booster': 'gbtree', 'lambda': 0.0018153154112074395, 'alpha': 0.1757733166924744, 'subsample': 0.21760590132274882, 'colsample_bytree': 0.39611028342090476, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.006656446526956991, 'gamma': 0.6125365987938982, 'grow_policy': 'depthwise'}. Best is trial 12 with value: 0.00032438206126240076.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:23:11,560]\u001b[0m Trial 20 finished with value: 0.0008078572055442148 and parameters: {'booster': 'gblinear', 'lambda': 0.002702203989733381, 'alpha': 0.014338255071796526, 'subsample': 0.3422908957520141, 'colsample_bytree': 0.3192995829985796}. Best is trial 12 with value: 0.00032438206126240076.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:11,694]\u001b[0m Trial 21 finished with value: 0.00023810410648314508 and parameters: {'booster': 'gblinear', 'lambda': 1.4801716031657363e-05, 'alpha': 0.0024850942852974, 'subsample': 0.5245442188164385, 'colsample_bytree': 0.556651664087983}. Best is trial 21 with value: 0.00023810410648314508.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:11,826]\u001b[0m Trial 22 finished with value: 0.09985920077253559 and parameters: {'booster': 'gblinear', 'lambda': 0.9532736592213001, 'alpha': 0.004274008548757971, 'subsample': 0.6913656635309557, 'colsample_bytree': 0.5660629143197019}. Best is trial 21 with value: 0.00023810410648314508.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:11,935]\u001b[0m Trial 23 finished with value: 0.05771550232867184 and parameters: {'booster': 'gblinear', 'lambda': 1.2569350247009998e-05, 'alpha': 0.15084547569463355, 'subsample': 0.2218343036071507, 'colsample_bytree': 0.422439704929853}. Best is trial 21 with value: 0.00023810410648314508.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:12,069]\u001b[0m Trial 24 finished with value: 0.001131326401205599 and parameters: {'booster': 'gblinear', 'lambda': 0.0003777630932815948, 'alpha': 7.047292148666989e-05, 'subsample': 0.5394428821468817, 'colsample_bytree': 0.5834910978870401}. Best is trial 21 with value: 0.00023810410648314508.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:12,200]\u001b[0m Trial 25 finished with value: 0.0008484396462692798 and parameters: {'booster': 'gblinear', 'lambda': 0.00784079997241138, 'alpha': 0.004358245126150849, 'subsample': 0.43330688451410376, 'colsample_bytree': 0.21067114017143357}. Best is trial 21 with value: 0.00023810410648314508.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:12,318]\u001b[0m Trial 26 finished with value: 0.014167306214198422 and parameters: {'booster': 'gblinear', 'lambda': 0.00020435174074058697, 'alpha': 0.06910072118562191, 'subsample': 0.6794850970310452, 'colsample_bytree': 0.41943708009389064}. Best is trial 21 with value: 0.00023810410648314508.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:13,701]\u001b[0m Trial 27 finished with value: 1.1830240931696305 and parameters: {'booster': 'dart', 'lambda': 8.701022236834387e-06, 'alpha': 0.0018671195647805864, 'subsample': 0.3203850387255355, 'colsample_bytree': 0.28890315568004693, 'max_depth': 3, 'min_child_weight': 4, 'eta': 3.7645845412799944e-06, 'gamma': 3.3341601546444436e-05, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 1.6782278321424307e-08, 'skip_drop': 0.5444763333249419}. Best is trial 21 with value: 0.00023810410648314508.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:13,833]\u001b[0m Trial 28 finished with value: 0.0004894632991048682 and parameters: {'booster': 'gblinear', 'lambda': 2.6576260962125066e-05, 'alpha': 0.00011994965184370804, 'subsample': 0.5613103137922315, 'colsample_bytree': 0.6286320611698653}. Best is trial 21 with value: 0.00023810410648314508.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:14,121]\u001b[0m Trial 29 finished with value: 1.1821891751631795 and parameters: {'booster': 'gbtree', 'lambda': 0.006491906054444808, 'alpha': 0.00790141075670146, 'subsample': 0.6400963525551837, 'colsample_bytree': 0.45277744019883626, 'max_depth': 7, 'min_child_weight': 8, 'eta': 7.011408148034262e-06, 'gamma': 0.0051834647704509275, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 0.00023810410648314508.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:14,223]\u001b[0m Trial 30 finished with value: 0.6306818677913584 and parameters: {'booster': 'gblinear', 'lambda': 6.438025023644501e-07, 'alpha': 0.6196707615625175, 'subsample': 0.7773672822928845, 'colsample_bytree': 0.38021493167940246}. Best is trial 21 with value: 0.00023810410648314508.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:14,351]\u001b[0m Trial 31 finished with value: 0.00038987942443279423 and parameters: {'booster': 'gblinear', 'lambda': 2.756894050082647e-07, 'alpha': 0.00046432901085575085, 'subsample': 0.4992290681041448, 'colsample_bytree': 0.7761242620604649}. Best is trial 21 with value: 0.00023810410648314508.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:14,481]\u001b[0m Trial 32 finished with value: 0.00020170980174444837 and parameters: {'booster': 'gblinear', 'lambda': 9.881042279478047e-08, 'alpha': 0.0008458052670465823, 'subsample': 0.4079156604157772, 'colsample_bytree': 0.7116036495159864}. Best is trial 32 with value: 0.00020170980174444837.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:14,612]\u001b[0m Trial 33 finished with value: 0.0010079476793038702 and parameters: {'booster': 'gblinear', 'lambda': 5.0665391430441755e-08, 'alpha': 3.6489367583877496e-05, 'subsample': 0.40012120063338974, 'colsample_bytree': 0.7023932867439691}. Best is trial 32 with value: 0.00020170980174444837.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:14,743]\u001b[0m Trial 34 finished with value: 0.00037879329283777344 and parameters: {'booster': 'gblinear', 'lambda': 1.3682843054212402e-07, 'alpha': 0.0012276542517024695, 'subsample': 0.27774763433647, 'colsample_bytree': 0.5339655785943255}. Best is trial 32 with value: 0.00020170980174444837.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:14,873]\u001b[0m Trial 35 finished with value: 0.0002938743714514903 and parameters: {'booster': 'gblinear', 'lambda': 8.816131239268979e-08, 'alpha': 0.0011078891422966577, 'subsample': 0.2451374124514114, 'colsample_bytree': 0.5360174704904997}. Best is trial 32 with value: 0.00020170980174444837.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:15,004]\u001b[0m Trial 36 finished with value: 0.0008323934961707516 and parameters: {'booster': 'gblinear', 'lambda': 6.336928428099111e-08, 'alpha': 2.4788944108789165e-06, 'subsample': 0.3733204968802112, 'colsample_bytree': 0.6023151862037213}. Best is trial 32 with value: 0.00020170980174444837.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:15,137]\u001b[0m Trial 37 finished with value: 0.000923798115756851 and parameters: {'booster': 'gblinear', 'lambda': 5.807408095631183e-07, 'alpha': 0.00026665617386834517, 'subsample': 0.45942995369991796, 'colsample_bytree': 0.7335342157725939}. Best is trial 32 with value: 0.00020170980174444837.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:16,586]\u001b[0m Trial 38 finished with value: 0.14321544740495518 and parameters: {'booster': 'dart', 'lambda': 1.1101678080738524e-08, 'alpha': 0.0009730127177614942, 'subsample': 0.7891188194492498, 'colsample_bytree': 0.6620731743917321, 'max_depth': 5, 'min_child_weight': 3, 'eta': 0.012651095892354594, 'gamma': 2.119827843855431e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.0003070505698462321, 'skip_drop': 0.00017357434140434643}. Best is trial 32 with value: 0.00020170980174444837.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:16,716]\u001b[0m Trial 39 finished with value: 0.0032509979501670785 and parameters: {'booster': 'gblinear', 'lambda': 8.017680455305982e-06, 'alpha': 3.428154372279456e-05, 'subsample': 0.5239813009676821, 'colsample_bytree': 0.4816591460533373}. Best is trial 32 with value: 0.00020170980174444837.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:16,848]\u001b[0m Trial 40 finished with value: 0.0009063766196265138 and parameters: {'booster': 'gblinear', 'lambda': 3.607599684269631e-08, 'alpha': 3.839601991171177e-06, 'subsample': 0.4026844918795519, 'colsample_bytree': 0.5673188044666815}. Best is trial 32 with value: 0.00020170980174444837.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:16,978]\u001b[0m Trial 41 finished with value: 0.00018762681258048162 and parameters: {'booster': 'gblinear', 'lambda': 1.3728523688398572e-07, 'alpha': 0.0014939636497215995, 'subsample': 0.26034635561275693, 'colsample_bytree': 0.5240562836079231}. Best is trial 41 with value: 0.00018762681258048162.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:17,107]\u001b[0m Trial 42 finished with value: 0.00014471881947044547 and parameters: {'booster': 'gblinear', 'lambda': 3.6151966101223835e-06, 'alpha': 0.0031449061484291984, 'subsample': 0.25704410688222873, 'colsample_bytree': 0.516772741670565}. Best is trial 42 with value: 0.00014471881947044547.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:17,236]\u001b[0m Trial 43 finished with value: 0.00018151341683830452 and parameters: {'booster': 'gblinear', 'lambda': 3.592600133592023e-06, 'alpha': 0.0019102960770829432, 'subsample': 0.20219346434298902, 'colsample_bytree': 0.5111671118396287}. Best is trial 42 with value: 0.00014471881947044547.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:23:18,628]\u001b[0m Trial 44 finished with value: 1.183660405527951 and parameters: {'booster': 'dart', 'lambda': 3.64666829820774e-06, 'alpha': 0.040133644947924936, 'subsample': 0.20414446688420174, 'colsample_bytree': 0.45802062854965897, 'max_depth': 9, 'min_child_weight': 10, 'eta': 1.3492299144108121e-08, 'gamma': 0.018186022311225736, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.0009820575333816e-08, 'skip_drop': 0.0011676953150403285}. Best is trial 42 with value: 0.00014471881947044547.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:18,756]\u001b[0m Trial 45 finished with value: 0.00012701093216179802 and parameters: {'booster': 'gblinear', 'lambda': 9.355263161168864e-07, 'alpha': 0.004635731885996311, 'subsample': 0.2531469182336797, 'colsample_bytree': 0.49832157822800865}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:18,997]\u001b[0m Trial 46 finished with value: 1.1714062959894016 and parameters: {'booster': 'gbtree', 'lambda': 9.586935920530572e-07, 'alpha': 0.006179843860000258, 'subsample': 0.256721585439512, 'colsample_bytree': 0.9949302813479898, 'max_depth': 5, 'min_child_weight': 6, 'eta': 5.7254662121597457e-05, 'gamma': 3.643482129466383e-06, 'grow_policy': 'depthwise'}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:19,121]\u001b[0m Trial 47 finished with value: 0.0008531121908245886 and parameters: {'booster': 'gblinear', 'lambda': 2.8175698169075955e-06, 'alpha': 0.016976171031674637, 'subsample': 0.31812076912310805, 'colsample_bytree': 0.5131001744610391}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:19,251]\u001b[0m Trial 48 finished with value: 0.0007824777993164806 and parameters: {'booster': 'gblinear', 'lambda': 3.28326949512859e-07, 'alpha': 0.00015682059760945894, 'subsample': 0.3573694953683326, 'colsample_bytree': 0.6055693232130022}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:20,695]\u001b[0m Trial 49 finished with value: 0.04143854028309394 and parameters: {'booster': 'dart', 'lambda': 2.4472944232860075e-06, 'alpha': 0.0020639289398733654, 'subsample': 0.2521527977647499, 'colsample_bytree': 0.49527391767301815, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.07479697225805808, 'gamma': 0.00038864426203690194, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 1.7156903204507778e-06, 'skip_drop': 2.0515093673918107e-06}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:20,811]\u001b[0m Trial 50 finished with value: 0.004878564062950864 and parameters: {'booster': 'gblinear', 'lambda': 5.3665012495076505e-06, 'alpha': 0.040621186408676624, 'subsample': 0.2963760703056352, 'colsample_bytree': 0.6720366044574384}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:20,940]\u001b[0m Trial 51 finished with value: 0.00042928931028691423 and parameters: {'booster': 'gblinear', 'lambda': 1.700178252522347e-05, 'alpha': 0.002655679930518757, 'subsample': 0.20051361056687098, 'colsample_bytree': 0.4439659667479943}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:21,071]\u001b[0m Trial 52 finished with value: 0.0009209519463728691 and parameters: {'booster': 'gblinear', 'lambda': 3.62650634650425e-05, 'alpha': 1.590873778987671e-08, 'subsample': 0.24815230137784178, 'colsample_bytree': 0.8411554874548314}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:21,203]\u001b[0m Trial 53 finished with value: 0.0004885129717053838 and parameters: {'booster': 'gblinear', 'lambda': 1.3200106409263823e-06, 'alpha': 0.0006091422440430098, 'subsample': 0.31905296031137703, 'colsample_bytree': 0.5518758199073226}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:21,333]\u001b[0m Trial 54 finished with value: 0.00016373476554158386 and parameters: {'booster': 'gblinear', 'lambda': 0.00012062142738635606, 'alpha': 0.0034104604558809638, 'subsample': 0.2789162415453161, 'colsample_bytree': 0.5042763810669599}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:21,465]\u001b[0m Trial 55 finished with value: 0.0005795113424083912 and parameters: {'booster': 'gblinear', 'lambda': 2.4967451272512945e-08, 'alpha': 0.00021574357261502304, 'subsample': 0.27719598535347667, 'colsample_bytree': 0.5154883451847848}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:21,730]\u001b[0m Trial 56 finished with value: 1.183572854216272 and parameters: {'booster': 'gbtree', 'lambda': 0.00013571369052314196, 'alpha': 0.010772818981028066, 'subsample': 0.3748818946485733, 'colsample_bytree': 0.3515550899444161, 'max_depth': 7, 'min_child_weight': 4, 'eta': 4.5497141633574544e-07, 'gamma': 0.05188084916837717, 'grow_policy': 'lossguide'}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:21,856]\u001b[0m Trial 57 finished with value: 0.00016730467525748104 and parameters: {'booster': 'gblinear', 'lambda': 0.0003943619142778433, 'alpha': 0.0042177710866208385, 'subsample': 0.22890862407424128, 'colsample_bytree': 0.48092810546574827}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:21,985]\u001b[0m Trial 58 finished with value: 0.00015704744681226197 and parameters: {'booster': 'gblinear', 'lambda': 0.0006301744793665394, 'alpha': 0.0051696412179376055, 'subsample': 0.2311198731404293, 'colsample_bytree': 0.4689564089838359}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:22,103]\u001b[0m Trial 59 finished with value: 0.0022484311210064904 and parameters: {'booster': 'gblinear', 'lambda': 0.0005140096018801764, 'alpha': 0.027187442496726826, 'subsample': 0.22587482404921097, 'colsample_bytree': 0.47636236420922956}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:22,214]\u001b[0m Trial 60 finished with value: 0.030651231783169457 and parameters: {'booster': 'gblinear', 'lambda': 7.113196810857266e-05, 'alpha': 0.10401262464991677, 'subsample': 0.297234241465666, 'colsample_bytree': 0.4431255381377084}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:22,341]\u001b[0m Trial 61 finished with value: 0.00019221212135411768 and parameters: {'booster': 'gblinear', 'lambda': 0.0005458863672354744, 'alpha': 0.0051306737162996946, 'subsample': 0.23229857459123085, 'colsample_bytree': 0.4986461965321618}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:22,469]\u001b[0m Trial 62 finished with value: 0.00022721955234677375 and parameters: {'booster': 'gblinear', 'lambda': 0.0002182868889330366, 'alpha': 0.004049398733053951, 'subsample': 0.26587677166331014, 'colsample_bytree': 0.4300284830825878}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:22,592]\u001b[0m Trial 63 finished with value: 0.000909754457234171 and parameters: {'booster': 'gblinear', 'lambda': 0.004431050524173269, 'alpha': 0.013711538383608906, 'subsample': 0.34107664792673237, 'colsample_bytree': 0.3969977681683081}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:22,723]\u001b[0m Trial 64 finished with value: 0.001411748397048409 and parameters: {'booster': 'gblinear', 'lambda': 0.0008865659031691072, 'alpha': 0.0013767156028278165, 'subsample': 0.928186239404281, 'colsample_bytree': 0.5243588245068798}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:22,853]\u001b[0m Trial 65 finished with value: 0.00016037877312177634 and parameters: {'booster': 'gblinear', 'lambda': 4.0638576707099305e-05, 'alpha': 0.0033019117117110064, 'subsample': 0.20219046568829413, 'colsample_bytree': 0.46576654921990135}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:22,980]\u001b[0m Trial 66 finished with value: 0.0002428341365723226 and parameters: {'booster': 'gblinear', 'lambda': 6.159328319907105e-05, 'alpha': 0.006938965891495121, 'subsample': 0.22446512717156444, 'colsample_bytree': 0.35338917923442076}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:23:23,156]\u001b[0m Trial 67 finished with value: 1.1362982205842778 and parameters: {'booster': 'gbtree', 'lambda': 0.00011029248145134309, 'alpha': 0.002931098668818714, 'subsample': 0.30424692112683416, 'colsample_bytree': 0.46569548109812137, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.0002639478140190063, 'gamma': 2.784375612151171e-08, 'grow_policy': 'depthwise'}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:23,269]\u001b[0m Trial 68 finished with value: 0.021391341799916603 and parameters: {'booster': 'gblinear', 'lambda': 0.022039025622580043, 'alpha': 0.07189306942932105, 'subsample': 0.20822282429056846, 'colsample_bytree': 0.40884039175615894}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:23,390]\u001b[0m Trial 69 finished with value: 0.0013998862008139268 and parameters: {'booster': 'gblinear', 'lambda': 3.151065209381395e-05, 'alpha': 0.021730668250359998, 'subsample': 0.337313645732308, 'colsample_bytree': 0.48496688951227485}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:24,289]\u001b[0m Trial 70 finished with value: 1.1825809595041368 and parameters: {'booster': 'dart', 'lambda': 0.00027611427774300643, 'alpha': 0.007585290612172994, 'subsample': 0.2351694520857712, 'colsample_bytree': 0.28948957287845584, 'max_depth': 5, 'min_child_weight': 3, 'eta': 4.423003264235158e-05, 'gamma': 1.0333049035320867e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.43017934729181423, 'skip_drop': 1.0709033029947284e-08}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:24,421]\u001b[0m Trial 71 finished with value: 0.0003316282140952742 and parameters: {'booster': 'gblinear', 'lambda': 4.750863796168894e-06, 'alpha': 0.001761159318487105, 'subsample': 0.265266659617865, 'colsample_bytree': 0.5813143406021549}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:24,550]\u001b[0m Trial 72 finished with value: 0.00014796757847401255 and parameters: {'booster': 'gblinear', 'lambda': 0.0008295274602057892, 'alpha': 0.0034100063173038105, 'subsample': 0.28519531221354977, 'colsample_bytree': 0.5051665805273188}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:24,678]\u001b[0m Trial 73 finished with value: 0.0001813200228562329 and parameters: {'booster': 'gblinear', 'lambda': 0.001124928063529577, 'alpha': 0.003591277984330882, 'subsample': 0.2852890262294931, 'colsample_bytree': 0.6224228248837866}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:24,783]\u001b[0m Trial 74 finished with value: 0.16804074608577713 and parameters: {'booster': 'gblinear', 'lambda': 0.0011417132828778283, 'alpha': 0.2659303355159919, 'subsample': 0.29379117818785966, 'colsample_bytree': 0.6068532549759444}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:24,915]\u001b[0m Trial 75 finished with value: 0.00036715421744070863 and parameters: {'booster': 'gblinear', 'lambda': 0.0035341871195444254, 'alpha': 0.003264643375248194, 'subsample': 0.2828058469777801, 'colsample_bytree': 0.6198576729543834}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:25,047]\u001b[0m Trial 76 finished with value: 0.0027520875151723838 and parameters: {'booster': 'gblinear', 'lambda': 0.014260428732746716, 'alpha': 0.0004868448746326824, 'subsample': 0.23607313971365892, 'colsample_bytree': 0.5489413969324717}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:25,175]\u001b[0m Trial 77 finished with value: 0.0004990915799833797 and parameters: {'booster': 'gblinear', 'lambda': 0.0019736422411921937, 'alpha': 0.01135067041246161, 'subsample': 0.3274328356178277, 'colsample_bytree': 0.3796891387472836}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:25,303]\u001b[0m Trial 78 finished with value: 0.0001555115513518205 and parameters: {'booster': 'gblinear', 'lambda': 0.0007367271712628812, 'alpha': 0.004549585910564581, 'subsample': 0.36165111958932716, 'colsample_bytree': 0.4613457364028087}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:25,435]\u001b[0m Trial 79 finished with value: 0.00031374654848781935 and parameters: {'booster': 'gblinear', 'lambda': 0.0005564918737629346, 'alpha': 0.0006176156158297579, 'subsample': 0.383324338712113, 'colsample_bytree': 0.4390086468410161}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:25,695]\u001b[0m Trial 80 finished with value: 1.0386200493058195 and parameters: {'booster': 'gbtree', 'lambda': 0.00016060878221298621, 'alpha': 0.053629204435809534, 'subsample': 0.42648132124147603, 'colsample_bytree': 0.4660930982152098, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.0007560923016805644, 'gamma': 0.09868445459429862, 'grow_policy': 'lossguide'}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:25,823]\u001b[0m Trial 81 finished with value: 0.00015157056027394962 and parameters: {'booster': 'gblinear', 'lambda': 0.0008738522194337812, 'alpha': 0.004276068641694868, 'subsample': 0.2758807548898912, 'colsample_bytree': 0.4990410093923145}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:25,950]\u001b[0m Trial 82 finished with value: 0.00022051645746587922 and parameters: {'booster': 'gblinear', 'lambda': 0.0003780543918772291, 'alpha': 0.00671156771510077, 'subsample': 0.35745590933391413, 'colsample_bytree': 0.49482683960396634}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:26,073]\u001b[0m Trial 83 finished with value: 0.0007485536509995198 and parameters: {'booster': 'gblinear', 'lambda': 0.000308611243724557, 'alpha': 0.015657838451109483, 'subsample': 0.26669856976809875, 'colsample_bytree': 0.46638883838559836}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:26,192]\u001b[0m Trial 84 finished with value: 0.0021659391438487064 and parameters: {'booster': 'gblinear', 'lambda': 0.0020107964411143673, 'alpha': 0.025540237890053538, 'subsample': 0.31329063627354936, 'colsample_bytree': 0.4179306523257572}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:26,316]\u001b[0m Trial 85 finished with value: 0.00018635484464392442 and parameters: {'booster': 'gblinear', 'lambda': 0.000783692638068475, 'alpha': 0.005431967049962657, 'subsample': 0.24638017963621575, 'colsample_bytree': 0.5695978098482605}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:26,445]\u001b[0m Trial 86 finished with value: 0.06254555308358463 and parameters: {'booster': 'gblinear', 'lambda': 0.3996098552211, 'alpha': 0.0007719739619432536, 'subsample': 0.2204060250741813, 'colsample_bytree': 0.4942272824597941}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:27,746]\u001b[0m Trial 87 finished with value: 0.052363394570206924 and parameters: {'booster': 'dart', 'lambda': 4.678215067607165e-05, 'alpha': 0.0003141526254962418, 'subsample': 0.2740368375286922, 'colsample_bytree': 0.5443936277508746, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.045821784113178506, 'gamma': 5.352823939073266e-06, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.0041631865970846865, 'skip_drop': 0.007104411244175243}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:27,870]\u001b[0m Trial 88 finished with value: 0.00026595738253703513 and parameters: {'booster': 'gblinear', 'lambda': 0.00010106247766776643, 'alpha': 0.009358833757057275, 'subsample': 0.8306781679468156, 'colsample_bytree': 0.36916311010943864}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:27,998]\u001b[0m Trial 89 finished with value: 0.0005454301616825915 and parameters: {'booster': 'gblinear', 'lambda': 2.1293780558788873e-05, 'alpha': 7.353584863775854e-05, 'subsample': 0.2488289136232613, 'colsample_bytree': 0.5290051128125953}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:23:28,125]\u001b[0m Trial 90 finished with value: 0.00035190554895165324 and parameters: {'booster': 'gblinear', 'lambda': 0.003223899736049778, 'alpha': 0.0025714350206291047, 'subsample': 0.3459866622358333, 'colsample_bytree': 0.451374498077991}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:28,250]\u001b[0m Trial 91 finished with value: 0.00021488005718564877 and parameters: {'booster': 'gblinear', 'lambda': 0.0014051237609727003, 'alpha': 0.0041384854296656745, 'subsample': 0.2845628347681331, 'colsample_bytree': 0.5830695396647749}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:28,406]\u001b[0m Trial 92 finished with value: 0.0008911451712907637 and parameters: {'booster': 'gblinear', 'lambda': 0.005554516284888507, 'alpha': 0.0010916040008085639, 'subsample': 0.3028135914915858, 'colsample_bytree': 0.5070460807877183}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:28,558]\u001b[0m Trial 93 finished with value: 0.00013107757171334957 and parameters: {'booster': 'gblinear', 'lambda': 0.0007431361436812739, 'alpha': 0.0035934560000291374, 'subsample': 0.217324637436807, 'colsample_bytree': 0.47597555493742455}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:28,702]\u001b[0m Trial 94 finished with value: 0.0005251234219438418 and parameters: {'booster': 'gblinear', 'lambda': 0.000662326947345819, 'alpha': 6.273972833435672e-07, 'subsample': 0.21481904460050733, 'colsample_bytree': 0.4778646696061713}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:28,833]\u001b[0m Trial 95 finished with value: 0.000251827832337636 and parameters: {'booster': 'gblinear', 'lambda': 0.00021089771806233795, 'alpha': 0.0021378451220525818, 'subsample': 0.20095363515432796, 'colsample_bytree': 0.4069641003937904}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:28,957]\u001b[0m Trial 96 finished with value: 0.00032207589265358203 and parameters: {'booster': 'gblinear', 'lambda': 1.6403288416253893e-06, 'alpha': 0.010404051912577827, 'subsample': 0.2381531142871951, 'colsample_bytree': 0.46006052414454846}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:29,091]\u001b[0m Trial 97 finished with value: 0.00048749215256790613 and parameters: {'booster': 'gblinear', 'lambda': 0.00034306243183919227, 'alpha': 0.0014610014720703498, 'subsample': 0.2614890015942162, 'colsample_bytree': 0.43662124580524186}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:29,222]\u001b[0m Trial 98 finished with value: 0.00015257286541498811 and parameters: {'booster': 'gblinear', 'lambda': 6.572147333217542e-07, 'alpha': 0.005474666703382845, 'subsample': 0.2225386878358008, 'colsample_bytree': 0.4804519873361082}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:29,342]\u001b[0m Trial 99 finished with value: 0.0007862296985335629 and parameters: {'booster': 'gblinear', 'lambda': 2.2135539521161974e-07, 'alpha': 0.016297369824479758, 'subsample': 0.21814565990719145, 'colsample_bytree': 0.5113445324156747}. Best is trial 45 with value: 0.00012701093216179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:29,487]\u001b[0m A new study created in memory with name: no-name-a7624412-8e72-4c25-97e4-219d450f08b2\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:29,660]\u001b[0m Trial 0 finished with value: 1.1945250871911999 and parameters: {'booster': 'gbtree', 'lambda': 0.020699254651541835, 'alpha': 1.0283397862523887e-08, 'subsample': 0.986769287510574, 'colsample_bytree': 0.2071361788461016, 'max_depth': 5, 'min_child_weight': 10, 'eta': 4.937883965662591e-05, 'gamma': 0.21273041467191525, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 1.1945250871911999.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:29,774]\u001b[0m Trial 1 finished with value: 0.4666432281261151 and parameters: {'booster': 'gblinear', 'lambda': 0.001202491540883872, 'alpha': 4.849613763060163e-07, 'subsample': 0.49848403982886175, 'colsample_bytree': 0.7671986261203785}. Best is trial 1 with value: 0.4666432281261151.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:29,886]\u001b[0m Trial 2 finished with value: 0.4651121283823466 and parameters: {'booster': 'gblinear', 'lambda': 3.47966567003782e-07, 'alpha': 0.00035872019386317875, 'subsample': 0.6586606069132861, 'colsample_bytree': 0.28483976592512134}. Best is trial 2 with value: 0.4651121283823466.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:31,547]\u001b[0m Trial 3 finished with value: 0.3905203797934079 and parameters: {'booster': 'dart', 'lambda': 2.5838061053644652e-05, 'alpha': 1.0918012610350709e-08, 'subsample': 0.8699332001422382, 'colsample_bytree': 0.9157804413848705, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.5308087533895816, 'gamma': 8.674944523083743e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.018642921607376836, 'skip_drop': 1.6043111277404865e-05}. Best is trial 3 with value: 0.3905203797934079.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:32,980]\u001b[0m Trial 4 finished with value: 0.3837855213549186 and parameters: {'booster': 'dart', 'lambda': 0.0003442727233730276, 'alpha': 7.124618313771334e-06, 'subsample': 0.618968875257637, 'colsample_bytree': 0.20449070149776205, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.06885300512071593, 'gamma': 8.190818142927581e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.0008966473877992183, 'skip_drop': 0.0006604334382722431}. Best is trial 4 with value: 0.3837855213549186.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:33,097]\u001b[0m Trial 5 finished with value: 0.4677923628765707 and parameters: {'booster': 'gblinear', 'lambda': 0.22333346172483973, 'alpha': 0.0060971623645330415, 'subsample': 0.4816328380574928, 'colsample_bytree': 0.9091111608190674}. Best is trial 4 with value: 0.3837855213549186.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:33,280]\u001b[0m Trial 6 finished with value: 1.1285812505474897 and parameters: {'booster': 'gbtree', 'lambda': 1.6031393301956374e-05, 'alpha': 0.036949787748365964, 'subsample': 0.7718206958605744, 'colsample_bytree': 0.7381546127838086, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.0005004111820348043, 'gamma': 0.021608343112064134, 'grow_policy': 'depthwise'}. Best is trial 4 with value: 0.3837855213549186.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:33,399]\u001b[0m Trial 7 finished with value: 0.4689993311290689 and parameters: {'booster': 'gblinear', 'lambda': 0.0001290850732118986, 'alpha': 1.8327790858586714e-05, 'subsample': 0.5359677359088535, 'colsample_bytree': 0.4638318793728008}. Best is trial 4 with value: 0.3837855213549186.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:33,693]\u001b[0m Trial 8 finished with value: 1.2007213050436787 and parameters: {'booster': 'gbtree', 'lambda': 1.3664554063733666e-06, 'alpha': 9.488439384964051e-07, 'subsample': 0.7908037636026515, 'colsample_bytree': 0.6458706786615835, 'max_depth': 7, 'min_child_weight': 8, 'eta': 3.933937770559355e-08, 'gamma': 1.1560192191782163e-08, 'grow_policy': 'depthwise'}. Best is trial 4 with value: 0.3837855213549186.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:33,882]\u001b[0m Trial 9 finished with value: 1.1989380845040039 and parameters: {'booster': 'gbtree', 'lambda': 1.3950334770003017e-06, 'alpha': 0.6064334342333904, 'subsample': 0.7984602408765005, 'colsample_bytree': 0.25481269862687034, 'max_depth': 5, 'min_child_weight': 8, 'eta': 1.3792523501114434e-05, 'gamma': 2.0862093558027183e-07, 'grow_policy': 'lossguide'}. Best is trial 4 with value: 0.3837855213549186.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:35,400]\u001b[0m Trial 10 finished with value: 108011550.24553505 and parameters: {'booster': 'dart', 'lambda': 3.9823197321838075e-08, 'alpha': 4.4605556833767434e-05, 'subsample': 0.24991740115769218, 'colsample_bytree': 0.47901308154298117, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.933125692046878, 'gamma': 4.65708098464508e-05, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 9.483873680855874e-07, 'skip_drop': 0.5423739798098084}. Best is trial 4 with value: 0.3837855213549186.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:37,007]\u001b[0m Trial 11 finished with value: 0.3253264252222058 and parameters: {'booster': 'dart', 'lambda': 0.0006348265936953643, 'alpha': 5.3660215387179115e-08, 'subsample': 0.9650069531989063, 'colsample_bytree': 0.9671783624957611, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.8026601151004122, 'gamma': 2.765851162932132e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.06492847923820863, 'skip_drop': 1.2229202076890075e-05}. Best is trial 11 with value: 0.3253264252222058.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:23:38,391]\u001b[0m Trial 12 finished with value: 0.40988831564699185 and parameters: {'booster': 'dart', 'lambda': 0.0018082928276409477, 'alpha': 7.251887275456613e-07, 'subsample': 0.3236198965017206, 'colsample_bytree': 0.42519609648781287, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.026374981432834437, 'gamma': 5.9653260127021626e-06, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.05126006145210851, 'skip_drop': 8.115986641447677e-05}. Best is trial 11 with value: 0.3253264252222058.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:39,998]\u001b[0m Trial 13 finished with value: 0.43297907938064395 and parameters: {'booster': 'dart', 'lambda': 0.0013161417984633383, 'alpha': 4.185803169794659e-06, 'subsample': 0.9744990436032119, 'colsample_bytree': 0.587954594858983, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.012186790715958412, 'gamma': 2.833188507059136e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.0005136924411680122, 'skip_drop': 1.6896155917820395e-08}. Best is trial 11 with value: 0.3253264252222058.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:40,489]\u001b[0m Trial 14 finished with value: 0.3889274694818803 and parameters: {'booster': 'dart', 'lambda': 0.8987328433979135, 'alpha': 5.419890312181099e-08, 'subsample': 0.6677185002620145, 'colsample_bytree': 0.9575363665881871, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.016219152732608662, 'gamma': 0.0003567169282003438, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.9305795458933386, 'skip_drop': 0.009083637610765962}. Best is trial 11 with value: 0.3253264252222058.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:42,023]\u001b[0m Trial 15 finished with value: 0.4754708933226034 and parameters: {'booster': 'dart', 'lambda': 0.007625178770798167, 'alpha': 0.001016499593042642, 'subsample': 0.39678068950978373, 'colsample_bytree': 0.3647471710688637, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.15378670515681211, 'gamma': 1.4828623593550548e-06, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.00010424185948414653, 'skip_drop': 1.951019507460092e-06}. Best is trial 11 with value: 0.3253264252222058.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:43,615]\u001b[0m Trial 16 finished with value: 1.0010865912586777 and parameters: {'booster': 'dart', 'lambda': 0.00010868191556654597, 'alpha': 1.2370742687015607e-07, 'subsample': 0.615535800939548, 'colsample_bytree': 0.7945680366132285, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.0013741977759340678, 'gamma': 0.0004665438556775343, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.003416657370858074, 'skip_drop': 0.003417050402489744}. Best is trial 11 with value: 0.3253264252222058.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:45,162]\u001b[0m Trial 17 finished with value: 1.2004920334081404 and parameters: {'booster': 'dart', 'lambda': 0.03619830615359277, 'alpha': 4.568140819442578e-06, 'subsample': 0.9097135748917533, 'colsample_bytree': 0.6474864717538058, 'max_depth': 5, 'min_child_weight': 5, 'eta': 1.4836988141500462e-06, 'gamma': 2.919348705178862e-05, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 8.710497927812696e-07, 'skip_drop': 5.629159004950791e-07}. Best is trial 11 with value: 0.3253264252222058.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:46,173]\u001b[0m Trial 18 finished with value: 0.356372091322919 and parameters: {'booster': 'dart', 'lambda': 0.00026214980297975163, 'alpha': 7.542303010128239e-06, 'subsample': 0.750481712341025, 'colsample_bytree': 0.5531483875984635, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.07335740931968311, 'gamma': 2.4703065867287065e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.7722988410147225, 'skip_drop': 0.0015926636214560967}. Best is trial 11 with value: 0.3253264252222058.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:47,312]\u001b[0m Trial 19 finished with value: 1.1434061554786674 and parameters: {'booster': 'dart', 'lambda': 6.801496395258442e-06, 'alpha': 0.0001541032717984045, 'subsample': 0.7413592205356434, 'colsample_bytree': 0.5566928979232122, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.001785391125536779, 'gamma': 1.468106604867386e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.48141522568018336, 'skip_drop': 0.09592388398032556}. Best is trial 11 with value: 0.3253264252222058.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:48,802]\u001b[0m Trial 20 finished with value: 0.5228301544420438 and parameters: {'booster': 'dart', 'lambda': 1.8153672930035585e-08, 'alpha': 9.227074360319903e-08, 'subsample': 0.8821350248019451, 'colsample_bytree': 0.84938556536163, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.5859474596363855, 'gamma': 1.2083344604329194e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 2.25554327345677e-08, 'skip_drop': 0.00016597588521293123}. Best is trial 11 with value: 0.3253264252222058.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:50,423]\u001b[0m Trial 21 finished with value: 0.35351066975440737 and parameters: {'booster': 'dart', 'lambda': 0.0003604856447544622, 'alpha': 7.159129662991548e-06, 'subsample': 0.682209785041907, 'colsample_bytree': 0.35067192534182523, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.04606937309990493, 'gamma': 4.904549090694885e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.07671846954713481, 'skip_drop': 0.001145484987015738}. Best is trial 11 with value: 0.3253264252222058.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:52,018]\u001b[0m Trial 22 finished with value: 0.7952643646110913 and parameters: {'booster': 'dart', 'lambda': 0.0006179937571333496, 'alpha': 1.497872680760063e-06, 'subsample': 0.7187020246156791, 'colsample_bytree': 0.35827508480711673, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.0036002551208389254, 'gamma': 1.0744376919826299e-05, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.05810425788537542, 'skip_drop': 0.0026397753973683566}. Best is trial 11 with value: 0.3253264252222058.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:53,525]\u001b[0m Trial 23 finished with value: 0.33560866452554877 and parameters: {'booster': 'dart', 'lambda': 0.005513160627177263, 'alpha': 4.670894140764315e-05, 'subsample': 0.8509257763275182, 'colsample_bytree': 0.5392053980083492, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.07198078622459625, 'gamma': 2.0529905403772735e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.13906039947194307, 'skip_drop': 9.725130158977149e-06}. Best is trial 11 with value: 0.3253264252222058.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:55,153]\u001b[0m Trial 24 finished with value: 1.1644844342532847 and parameters: {'booster': 'dart', 'lambda': 0.00808044481731771, 'alpha': 0.0025749722664086465, 'subsample': 0.8407328262283225, 'colsample_bytree': 0.6867834131980375, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.00021910570047752468, 'gamma': 8.01840340453232e-07, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.016926443301834133, 'skip_drop': 6.617652788563896e-06}. Best is trial 11 with value: 0.3253264252222058.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:56,612]\u001b[0m Trial 25 finished with value: 0.353164675254496 and parameters: {'booster': 'dart', 'lambda': 0.12559733629098935, 'alpha': 4.9844482031809595e-05, 'subsample': 0.9261912477990408, 'colsample_bytree': 0.49807476380679994, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.1750010217540625, 'gamma': 3.968973603393397e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.09695099130730761, 'skip_drop': 1.734993774859361e-07}. Best is trial 11 with value: 0.3253264252222058.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:58,176]\u001b[0m Trial 26 finished with value: 0.36732950982137963 and parameters: {'booster': 'dart', 'lambda': 0.1052092130309785, 'alpha': 0.02351400413469645, 'subsample': 0.9446984362611566, 'colsample_bytree': 0.48840309229324064, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.2221577510061517, 'gamma': 4.40206626306284e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.006301558047437205, 'skip_drop': 1.15649430159547e-07}. Best is trial 11 with value: 0.3253264252222058.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:23:58,313]\u001b[0m Trial 27 finished with value: 0.46596522155845493 and parameters: {'booster': 'gblinear', 'lambda': 0.006602985352511641, 'alpha': 3.8176378341325474e-05, 'subsample': 0.9194892047001123, 'colsample_bytree': 0.5322677156597453}. Best is trial 11 with value: 0.3253264252222058.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:59,742]\u001b[0m Trial 28 finished with value: 0.3719352802281943 and parameters: {'booster': 'dart', 'lambda': 0.8806373600730372, 'alpha': 0.0002518652672248462, 'subsample': 0.999892720208967, 'colsample_bytree': 0.6417892221596416, 'max_depth': 7, 'min_child_weight': 5, 'eta': 0.7826865255895815, 'gamma': 4.0770737367804794e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.13432628206193756, 'skip_drop': 2.009366789121378e-07}. Best is trial 11 with value: 0.3253264252222058.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:23:59,980]\u001b[0m Trial 29 finished with value: 0.6201417219313075 and parameters: {'booster': 'gbtree', 'lambda': 0.03496993451135115, 'alpha': 0.5645166827598903, 'subsample': 0.8386887940702468, 'colsample_bytree': 0.425673843535663, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.006759620172012616, 'gamma': 0.0002903273350451131, 'grow_policy': 'lossguide'}. Best is trial 11 with value: 0.3253264252222058.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:24:00,352]\u001b[0m Trial 30 finished with value: 0.3519524489414299 and parameters: {'booster': 'gbtree', 'lambda': 0.155401375033798, 'alpha': 2.6680859355466208e-08, 'subsample': 0.9521783035543117, 'colsample_bytree': 0.9840381949971778, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.15739268288880331, 'gamma': 0.0018131805187020277, 'grow_policy': 'lossguide'}. Best is trial 11 with value: 0.3253264252222058.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:24:00,724]\u001b[0m Trial 31 finished with value: 0.35421366815788846 and parameters: {'booster': 'gbtree', 'lambda': 0.16456599667063074, 'alpha': 1.3988409693237856e-08, 'subsample': 0.951806771986228, 'colsample_bytree': 0.9877528462586739, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.24162556126294368, 'gamma': 0.0021167673372211545, 'grow_policy': 'lossguide'}. Best is trial 11 with value: 0.3253264252222058.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:24:01,076]\u001b[0m Trial 32 finished with value: 0.33904856752149004 and parameters: {'booster': 'gbtree', 'lambda': 0.002892446209984749, 'alpha': 3.0789772331017303e-07, 'subsample': 0.9956359173349404, 'colsample_bytree': 0.8659572598222633, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.05343084752113468, 'gamma': 0.005938988720494685, 'grow_policy': 'lossguide'}. Best is trial 11 with value: 0.3253264252222058.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:24:01,507]\u001b[0m Trial 33 finished with value: 0.33314022827137835 and parameters: {'booster': 'gbtree', 'lambda': 0.0028441294418314737, 'alpha': 2.576837992176887e-07, 'subsample': 0.985187871231499, 'colsample_bytree': 0.8505242124076853, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.02756169980598116, 'gamma': 0.009547321653636533, 'grow_policy': 'lossguide'}. Best is trial 11 with value: 0.3253264252222058.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:24:01,942]\u001b[0m Trial 34 finished with value: 0.35372615117965867 and parameters: {'booster': 'gbtree', 'lambda': 0.0017894641779038572, 'alpha': 2.0004235131536232e-07, 'subsample': 0.9863840374144454, 'colsample_bytree': 0.8411258429911783, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.019285603003993998, 'gamma': 0.03560901093338709, 'grow_policy': 'lossguide'}. Best is trial 11 with value: 0.3253264252222058.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:24:02,348]\u001b[0m Trial 35 finished with value: 1.197103726743552 and parameters: {'booster': 'gbtree', 'lambda': 0.003759041970503654, 'alpha': 2.658274479855821e-07, 'subsample': 0.8675847078396207, 'colsample_bytree': 0.8832786913557974, 'max_depth': 9, 'min_child_weight': 9, 'eta': 2.119235129538203e-05, 'gamma': 0.46202037096760024, 'grow_policy': 'lossguide'}. Best is trial 11 with value: 0.3253264252222058.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:24:02,764]\u001b[0m Trial 36 finished with value: 0.7528114733295191 and parameters: {'booster': 'gbtree', 'lambda': 3.6341243782129496e-05, 'alpha': 3.725452207742913e-08, 'subsample': 0.8907090514307532, 'colsample_bytree': 0.7805196063531525, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.0037379202893689937, 'gamma': 0.030631759153414134, 'grow_policy': 'lossguide'}. Best is trial 11 with value: 0.3253264252222058.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:24:04,615]\u001b[0m A new study created in memory with name: no-name-6ec928a0-2cc6-454f-8e32-cb87dfd60948\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:24:05,067]\u001b[0m Trial 0 finished with value: 0.5863230664398553 and parameters: {'booster': 'gblinear', 'lambda': 0.007492162530240482, 'alpha': 3.901907518014844e-07, 'subsample': 0.7509238457743148, 'colsample_bytree': 0.9426533725585742}. Best is trial 0 with value: 0.5863230664398553.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:24:05,515]\u001b[0m Trial 1 finished with value: 0.6011956950992818 and parameters: {'booster': 'gblinear', 'lambda': 1.3355649659059776e-08, 'alpha': 7.249749994351299e-05, 'subsample': 0.9531743271658388, 'colsample_bytree': 0.5282959736958476}. Best is trial 1 with value: 0.6011956950992818.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:24:12,641]\u001b[0m Trial 2 finished with value: 0.5832228922210633 and parameters: {'booster': 'dart', 'lambda': 1.2945029571285145e-06, 'alpha': 0.019304480988634406, 'subsample': 0.9484035718948569, 'colsample_bytree': 0.7168128926158042, 'max_depth': 7, 'min_child_weight': 6, 'eta': 4.3062042115701875e-06, 'gamma': 7.460330452631351e-07, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.2176096336044907e-05, 'skip_drop': 0.686580139651092}. Best is trial 1 with value: 0.6011956950992818.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:24:12,895]\u001b[0m Trial 3 finished with value: 0.41459333940060117 and parameters: {'booster': 'gblinear', 'lambda': 0.9477005995633173, 'alpha': 0.0402112120862437, 'subsample': 0.332993009257028, 'colsample_bytree': 0.8931663927867004}. Best is trial 1 with value: 0.6011956950992818.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:24:13,543]\u001b[0m Trial 4 finished with value: 0.5848158674466016 and parameters: {'booster': 'gbtree', 'lambda': 7.246648247399029e-08, 'alpha': 4.039373185245571e-06, 'subsample': 0.3354284200126083, 'colsample_bytree': 0.703281632990336, 'max_depth': 9, 'min_child_weight': 3, 'eta': 3.875590223078658e-08, 'gamma': 1.5365823565452795e-08, 'grow_policy': 'lossguide'}. Best is trial 1 with value: 0.6011956950992818.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:24:14,419]\u001b[0m Trial 5 finished with value: 0.5816547114359731 and parameters: {'booster': 'gbtree', 'lambda': 0.043519276984325214, 'alpha': 0.00022321296817524386, 'subsample': 0.6603784960877839, 'colsample_bytree': 0.9519139135219226, 'max_depth': 7, 'min_child_weight': 9, 'eta': 2.135904058806314e-05, 'gamma': 0.0017989065890840655, 'grow_policy': 'lossguide'}. Best is trial 1 with value: 0.6011956950992818.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:24:21,246]\u001b[0m Trial 6 finished with value: 0.5795361561830153 and parameters: {'booster': 'dart', 'lambda': 2.5072700988732828e-06, 'alpha': 0.0008179919051709936, 'subsample': 0.423826441455486, 'colsample_bytree': 0.8921796075101793, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.00826268082213102, 'gamma': 3.221064221503122e-06, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.00013422966631514727, 'skip_drop': 6.292036963739734e-07}. Best is trial 1 with value: 0.6011956950992818.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:24:27,589]\u001b[0m Trial 7 finished with value: 0.5863050564066159 and parameters: {'booster': 'dart', 'lambda': 7.712951716108572e-06, 'alpha': 2.861271586460566e-05, 'subsample': 0.5423538498102136, 'colsample_bytree': 0.4837757119899025, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.004732935030934957, 'gamma': 1.1107679203501845e-06, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.07298200725558336, 'skip_drop': 5.3109247118345444e-08}. Best is trial 1 with value: 0.6011956950992818.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:24:34,315]\u001b[0m Trial 8 finished with value: 0.5799153605660455 and parameters: {'booster': 'dart', 'lambda': 0.001688383916873945, 'alpha': 0.0016487281077218925, 'subsample': 0.3618108818572512, 'colsample_bytree': 0.2035816651410242, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.0002637256760511285, 'gamma': 3.2742461248355904e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 2.343611861418204e-05, 'skip_drop': 0.00012061610766918781}. Best is trial 1 with value: 0.6011956950992818.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:24:34,796]\u001b[0m Trial 9 finished with value: 0.5955956341972604 and parameters: {'booster': 'gblinear', 'lambda': 0.002750484636762945, 'alpha': 5.323620705312516e-08, 'subsample': 0.6353087643004881, 'colsample_bytree': 0.6507632026408907}. Best is trial 1 with value: 0.6011956950992818.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:24:34,933]\u001b[0m Trial 10 finished with value: 0.301869850258922 and parameters: {'booster': 'gblinear', 'lambda': 1.4746994020546077e-08, 'alpha': 0.4102583209584412, 'subsample': 0.9977279894474972, 'colsample_bytree': 0.4350585564670604}. Best is trial 1 with value: 0.6011956950992818.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:24:35,405]\u001b[0m Trial 11 finished with value: 0.6065743343589978 and parameters: {'booster': 'gblinear', 'lambda': 0.00022906687878160404, 'alpha': 3.08729458201303e-08, 'subsample': 0.7786078423981149, 'colsample_bytree': 0.556394847872712}. Best is trial 11 with value: 0.6065743343589978.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:24:35,870]\u001b[0m Trial 12 finished with value: 0.5966902460574539 and parameters: {'booster': 'gblinear', 'lambda': 0.00013346514667968162, 'alpha': 3.433897994088153e-08, 'subsample': 0.8411335953960025, 'colsample_bytree': 0.4489368976789119}. Best is trial 11 with value: 0.6065743343589978.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:24:36,341]\u001b[0m Trial 13 finished with value: 0.5976433003830265 and parameters: {'booster': 'gblinear', 'lambda': 7.97287736241755e-05, 'alpha': 2.2617959568790587e-06, 'subsample': 0.8556821996856667, 'colsample_bytree': 0.5361550292905337}. Best is trial 11 with value: 0.6065743343589978.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:24:36,767]\u001b[0m Trial 14 finished with value: 0.5926578551320675 and parameters: {'booster': 'gblinear', 'lambda': 9.835787132853989e-05, 'alpha': 1.2676385116972349e-08, 'subsample': 0.85576984317258, 'colsample_bytree': 0.3031124742940345}. Best is trial 11 with value: 0.6065743343589978.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:24:37,192]\u001b[0m Trial 15 finished with value: 0.5979133829519231 and parameters: {'booster': 'gblinear', 'lambda': 2.1542505663293423e-07, 'alpha': 1.5510563098739043e-05, 'subsample': 0.7468033718518322, 'colsample_bytree': 0.5926914207661964}. Best is trial 11 with value: 0.6065743343589978.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:24:37,660]\u001b[0m Trial 16 finished with value: 0.6006579176160776 and parameters: {'booster': 'gbtree', 'lambda': 0.00028599228632963345, 'alpha': 3.925731701364428e-07, 'subsample': 0.925125431648336, 'colsample_bytree': 0.791670750808436, 'max_depth': 3, 'min_child_weight': 10, 'eta': 0.9467386804170359, 'gamma': 0.5339031959557686, 'grow_policy': 'lossguide'}. Best is trial 11 with value: 0.6065743343589978.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:24:38,494]\u001b[0m A new study created in memory with name: no-name-a253009b-b118-475e-a9e3-3aaba0847437\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:24:45,786]\u001b[0m Trial 0 finished with value: 0.9631675944749493 and parameters: {'booster': 'dart', 'lambda': 1.8488829009416232e-05, 'alpha': 0.0036020053138764146, 'subsample': 0.834288085564687, 'colsample_bytree': 0.7380660496266536, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.0001829443728426005, 'gamma': 6.560847086062049e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.06759872903806537, 'skip_drop': 6.021504494566414e-06}. Best is trial 0 with value: 0.9631675944749493.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:24:46,175]\u001b[0m Trial 1 finished with value: 0.9631675944749493 and parameters: {'booster': 'gbtree', 'lambda': 0.0018501013820611581, 'alpha': 0.011942939143459676, 'subsample': 0.9805048880153022, 'colsample_bytree': 0.4658668890754051, 'max_depth': 3, 'min_child_weight': 3, 'eta': 6.324785625317311e-06, 'gamma': 0.006308245839899566, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.9631675944749493.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:24:46,301]\u001b[0m Trial 2 finished with value: 0.9631675944749493 and parameters: {'booster': 'gblinear', 'lambda': 3.140287297022385e-05, 'alpha': 0.9876195052933513, 'subsample': 0.6505476072876841, 'colsample_bytree': 0.9094703659506904}. Best is trial 0 with value: 0.9631675944749493.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:24:46,873]\u001b[0m Trial 3 finished with value: 0.9631675944749493 and parameters: {'booster': 'gblinear', 'lambda': 0.08825087733970938, 'alpha': 2.170317151517876e-06, 'subsample': 0.611631854846817, 'colsample_bytree': 0.29703591090880654}. Best is trial 0 with value: 0.9631675944749493.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:24:47,178]\u001b[0m Trial 4 finished with value: 0.9631675944749493 and parameters: {'booster': 'gbtree', 'lambda': 0.001251589300168129, 'alpha': 0.11036393061419708, 'subsample': 0.8455710217968724, 'colsample_bytree': 0.36980585553954504, 'max_depth': 9, 'min_child_weight': 9, 'eta': 2.965035184393086e-06, 'gamma': 1.019547427051906e-07, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.9631675944749493.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:24:47,644]\u001b[0m Trial 5 finished with value: 0.9680977526083518 and parameters: {'booster': 'gblinear', 'lambda': 0.00040071618864704283, 'alpha': 0.0007790719829329841, 'subsample': 0.7358292310447703, 'colsample_bytree': 0.31201718199168776}. Best is trial 5 with value: 0.9680977526083518.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:24:53,228]\u001b[0m Trial 6 finished with value: 0.9645053272450532 and parameters: {'booster': 'dart', 'lambda': 5.967350535762833e-07, 'alpha': 0.013469767517693809, 'subsample': 0.6795223378708669, 'colsample_bytree': 0.3849996817595308, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.20542152456394752, 'gamma': 3.50106747897233e-07, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.2724971019333272, 'skip_drop': 0.004538151548365796}. Best is trial 5 with value: 0.9680977526083518.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:25:00,807]\u001b[0m Trial 7 finished with value: 0.9603790527502342 and parameters: {'booster': 'dart', 'lambda': 0.0030734981740016118, 'alpha': 9.14772382000844e-08, 'subsample': 0.8881008443101992, 'colsample_bytree': 0.3473033670587934, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.6753222935722454, 'gamma': 0.7040339537283421, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 2.6980936095615037e-06, 'skip_drop': 1.1990474956991054e-08}. Best is trial 5 with value: 0.9680977526083518.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:25:01,036]\u001b[0m Trial 8 finished with value: 0.9631675944749493 and parameters: {'booster': 'gblinear', 'lambda': 1.1840675243789644e-08, 'alpha': 0.015365550265397055, 'subsample': 0.7116840071294781, 'colsample_bytree': 0.34721458053615817}. Best is trial 5 with value: 0.9680977526083518.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:25:01,591]\u001b[0m Trial 9 finished with value: 0.9631675944749493 and parameters: {'booster': 'gbtree', 'lambda': 3.173037348055446e-05, 'alpha': 7.56917620890477e-05, 'subsample': 0.7716317698071269, 'colsample_bytree': 0.77409956868475, 'max_depth': 5, 'min_child_weight': 2, 'eta': 1.075162823490675e-05, 'gamma': 0.3431633048184424, 'grow_policy': 'depthwise'}. Best is trial 5 with value: 0.9680977526083518.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:25:02,186]\u001b[0m Trial 10 finished with value: 0.9631675944749493 and parameters: {'booster': 'gblinear', 'lambda': 0.4432632619695843, 'alpha': 0.00013073603515556997, 'subsample': 0.33603690712598805, 'colsample_bytree': 0.5824700556805118}. Best is trial 5 with value: 0.9680977526083518.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:25:07,288]\u001b[0m Trial 11 finished with value: 0.9631675944749493 and parameters: {'booster': 'dart', 'lambda': 2.5770067965959203e-07, 'alpha': 8.39176287072304e-05, 'subsample': 0.4636453221013036, 'colsample_bytree': 0.20140066214340022, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.6043027562008115, 'gamma': 5.579002012974634e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.7400269179765075, 'skip_drop': 0.5071431830057553}. Best is trial 5 with value: 0.9680977526083518.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:25:15,194]\u001b[0m Trial 12 finished with value: 0.9631675944749493 and parameters: {'booster': 'dart', 'lambda': 1.2169969274344874e-06, 'alpha': 0.0009323939927645548, 'subsample': 0.5087784590761932, 'colsample_bytree': 0.5164197490547253, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.010391107217690895, 'gamma': 1.623891186633077e-05, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.001668461864046364, 'skip_drop': 0.03595169956312673}. Best is trial 5 with value: 0.9680977526083518.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:25:16,184]\u001b[0m A new study created in memory with name: no-name-fd093e4b-11d9-4e18-8dca-d5ff0211cb6a\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:25:26,810]\u001b[0m Trial 0 finished with value: 0.8996379340003153 and parameters: {'booster': 'dart', 'lambda': 0.0004482119572865945, 'alpha': 2.1066069672743996e-06, 'subsample': 0.43404277951261305, 'colsample_bytree': 0.501009628739314, 'max_depth': 7, 'min_child_weight': 2, 'eta': 1.6972944624169846e-05, 'gamma': 0.0001331263633078028, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.0009101557540455124, 'skip_drop': 0.2181276228524851}. Best is trial 0 with value: 0.8996379340003153.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:25:27,683]\u001b[0m Trial 1 finished with value: 0.8228562867927095 and parameters: {'booster': 'gblinear', 'lambda': 0.02507871610994079, 'alpha': 5.147623638767877e-07, 'subsample': 0.9715386015618976, 'colsample_bytree': 0.7298896582179619}. Best is trial 0 with value: 0.8996379340003153.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:25:38,496]\u001b[0m Trial 2 finished with value: 0.8970711501136689 and parameters: {'booster': 'dart', 'lambda': 0.00020364159967269788, 'alpha': 0.528201554434995, 'subsample': 0.45697259880373614, 'colsample_bytree': 0.7823040175137042, 'max_depth': 5, 'min_child_weight': 5, 'eta': 0.0024872531440546554, 'gamma': 4.060594727296489e-06, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.0007282445762075413, 'skip_drop': 0.023073432610927574}. Best is trial 0 with value: 0.8996379340003153.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:25:39,374]\u001b[0m Trial 3 finished with value: 0.8571713315439946 and parameters: {'booster': 'gblinear', 'lambda': 3.3367771935324785e-05, 'alpha': 2.2486394513243658e-06, 'subsample': 0.6637495361944492, 'colsample_bytree': 0.22426412716509195}. Best is trial 0 with value: 0.8996379340003153.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:25:39,821]\u001b[0m Trial 4 finished with value: 0.8112816365453104 and parameters: {'booster': 'gblinear', 'lambda': 5.685678414168227e-08, 'alpha': 0.006525476622402652, 'subsample': 0.29672327723905456, 'colsample_bytree': 0.8621285013792783}. Best is trial 0 with value: 0.8996379340003153.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:25:40,605]\u001b[0m Trial 5 finished with value: 0.9589757176513724 and parameters: {'booster': 'gbtree', 'lambda': 0.0008755471058610876, 'alpha': 0.00013960024912806017, 'subsample': 0.9703324476318174, 'colsample_bytree': 0.6306053095499642, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.058489362617041414, 'gamma': 4.039643647231707e-05, 'grow_policy': 'lossguide'}. Best is trial 5 with value: 0.9589757176513724.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:25:50,701]\u001b[0m Trial 6 finished with value: 0.8319190051953673 and parameters: {'booster': 'dart', 'lambda': 0.002155189231434342, 'alpha': 2.231099595617644e-08, 'subsample': 0.5608536651904397, 'colsample_bytree': 0.28676130061713234, 'max_depth': 5, 'min_child_weight': 5, 'eta': 6.817405395933004e-07, 'gamma': 0.000990137928267195, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.0027242267435786003, 'skip_drop': 0.0024646496028176805}. Best is trial 5 with value: 0.9589757176513724.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:25:52,209]\u001b[0m A new study created in memory with name: no-name-3d855be5-2138-4fae-857c-f21d3c27339d\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:25:52,378]\u001b[0m Trial 0 finished with value: 1.2774115342975996 and parameters: {'booster': 'gbtree', 'lambda': 3.101803092544718e-08, 'alpha': 0.00025250891309350345, 'subsample': 0.45454978000836493, 'colsample_bytree': 0.5740887668311868, 'max_depth': 7, 'min_child_weight': 9, 'eta': 6.986043791932168e-07, 'gamma': 0.006010627406421145, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 1.2774115342975996.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:25:53,715]\u001b[0m Trial 1 finished with value: 1.277526849850137 and parameters: {'booster': 'dart', 'lambda': 7.992792189704178e-07, 'alpha': 0.011941260039839634, 'subsample': 0.44621187232944026, 'colsample_bytree': 0.23200061079682632, 'max_depth': 9, 'min_child_weight': 5, 'eta': 2.1494848919655553e-08, 'gamma': 4.457778655387411e-05, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 3.0110860170834e-07, 'skip_drop': 5.519151327981197e-07}. Best is trial 0 with value: 1.2774115342975996.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:25:54,018]\u001b[0m Trial 2 finished with value: 0.24361130483809793 and parameters: {'booster': 'gbtree', 'lambda': 0.0017826917431127372, 'alpha': 0.021128225201427094, 'subsample': 0.8679801711491275, 'colsample_bytree': 0.7345579047685484, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.05322215279099896, 'gamma': 1.5268147149748703e-06, 'grow_policy': 'depthwise'}. Best is trial 2 with value: 0.24361130483809793.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:25:54,194]\u001b[0m Trial 3 finished with value: 0.516668874262656 and parameters: {'booster': 'gbtree', 'lambda': 0.001228300353925525, 'alpha': 8.031856633630467e-07, 'subsample': 0.5524350297629392, 'colsample_bytree': 0.8039308692602172, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.007659345091753501, 'gamma': 0.4938101660192057, 'grow_policy': 'depthwise'}. Best is trial 2 with value: 0.24361130483809793.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:25:54,311]\u001b[0m Trial 4 finished with value: 0.4603426348842435 and parameters: {'booster': 'gblinear', 'lambda': 0.016231185881567564, 'alpha': 7.176394040201413e-08, 'subsample': 0.28414334321234436, 'colsample_bytree': 0.9269284114104628}. Best is trial 2 with value: 0.24361130483809793.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:25:54,427]\u001b[0m Trial 5 finished with value: 0.5234484630137067 and parameters: {'booster': 'gblinear', 'lambda': 0.05408482796945204, 'alpha': 2.6114580975526132e-05, 'subsample': 0.6590955191486811, 'colsample_bytree': 0.2636429322234657}. Best is trial 2 with value: 0.24361130483809793.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:25:55,807]\u001b[0m Trial 6 finished with value: 0.9377424224875549 and parameters: {'booster': 'dart', 'lambda': 0.00042275987609743997, 'alpha': 8.623953973558435e-06, 'subsample': 0.8985104900834042, 'colsample_bytree': 0.20775349191231057, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.003064036973758939, 'gamma': 0.4375111844463236, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 6.466066187355021e-06, 'skip_drop': 2.4498262513416907e-08}. Best is trial 2 with value: 0.24361130483809793.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:25:56,036]\u001b[0m Trial 7 finished with value: 1.2765385853040156 and parameters: {'booster': 'gbtree', 'lambda': 0.915363016881496, 'alpha': 0.0005702125486097843, 'subsample': 0.8447120655879967, 'colsample_bytree': 0.8918551628979927, 'max_depth': 7, 'min_child_weight': 6, 'eta': 5.206236412781139e-06, 'gamma': 0.00021734842575493887, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 0.24361130483809793.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:25:56,152]\u001b[0m Trial 8 finished with value: 0.4588615072351106 and parameters: {'booster': 'gblinear', 'lambda': 0.016561113775253974, 'alpha': 3.6873517645411774e-07, 'subsample': 0.46389736319138647, 'colsample_bytree': 0.5695298355833823}. Best is trial 2 with value: 0.24361130483809793.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:25:56,268]\u001b[0m Trial 9 finished with value: 0.4151059367834367 and parameters: {'booster': 'gblinear', 'lambda': 1.2257840626002555e-05, 'alpha': 1.2917168350120736e-06, 'subsample': 0.6192154688884957, 'colsample_bytree': 0.7352739590071318}. Best is trial 2 with value: 0.24361130483809793.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:25:56,487]\u001b[0m Trial 10 finished with value: 0.32481793302131157 and parameters: {'booster': 'gbtree', 'lambda': 7.387796967127718e-05, 'alpha': 0.5214333953076693, 'subsample': 0.9871724493991829, 'colsample_bytree': 0.4191544013921306, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.3511293315998149, 'gamma': 1.694085279048608e-08, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 0.24361130483809793.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:25:56,709]\u001b[0m Trial 11 finished with value: 0.3398586169987254 and parameters: {'booster': 'gbtree', 'lambda': 2.0357670088422465e-05, 'alpha': 0.40708073755615687, 'subsample': 0.9631088111772464, 'colsample_bytree': 0.4323350822809348, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.4774499785646958, 'gamma': 1.66901455893912e-08, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 0.24361130483809793.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:25:56,967]\u001b[0m Trial 12 finished with value: 0.47076514749892806 and parameters: {'booster': 'gbtree', 'lambda': 0.00016070847140325128, 'alpha': 0.4715870559790619, 'subsample': 0.781611966425941, 'colsample_bytree': 0.39822258215363904, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.5180441619024133, 'gamma': 2.108029534353544e-08, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 0.24361130483809793.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:25:57,204]\u001b[0m Trial 13 finished with value: 0.629465541095872 and parameters: {'booster': 'gbtree', 'lambda': 1.1887159403354438e-06, 'alpha': 0.02245621912396234, 'subsample': 0.98758939488575, 'colsample_bytree': 0.6761353421678555, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.005488235248483823, 'gamma': 1.1102771485530798e-06, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 0.24361130483809793.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:25:57,477]\u001b[0m Trial 14 finished with value: 0.27791725846200427 and parameters: {'booster': 'gbtree', 'lambda': 0.0022908057260642195, 'alpha': 0.014738549499351149, 'subsample': 0.7520247833444551, 'colsample_bytree': 0.43416316032137614, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.03723320345917897, 'gamma': 7.709048524958595e-07, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 0.24361130483809793.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:25:57,694]\u001b[0m Trial 15 finished with value: 1.2328064899424447 and parameters: {'booster': 'gbtree', 'lambda': 0.0025594761845673854, 'alpha': 0.008016057984617053, 'subsample': 0.741087778948211, 'colsample_bytree': 0.5046664574523267, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.00026103611892406246, 'gamma': 1.9439279045400264e-06, 'grow_policy': 'depthwise'}. Best is trial 2 with value: 0.24361130483809793.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:25:59,177]\u001b[0m Trial 16 finished with value: 0.2557325782095677 and parameters: {'booster': 'dart', 'lambda': 0.2808901447706687, 'alpha': 0.0013332074046476165, 'subsample': 0.7324331056015563, 'colsample_bytree': 0.6829092313598775, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.05676415635285291, 'gamma': 1.5060152026997809e-06, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.030934558913935914, 'skip_drop': 0.16906970097007118}. Best is trial 2 with value: 0.24361130483809793.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:00,600]\u001b[0m Trial 17 finished with value: 1.2442602626181511 and parameters: {'booster': 'dart', 'lambda': 0.7270342937242922, 'alpha': 0.0011533428073788657, 'subsample': 0.8394926832892642, 'colsample_bytree': 0.8155813845760554, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.00018316515399839693, 'gamma': 1.4114137011201911e-05, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.05447185796626401, 'skip_drop': 0.9717322485503554}. Best is trial 2 with value: 0.24361130483809793.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:01,832]\u001b[0m Trial 18 finished with value: 0.2424092517905551 and parameters: {'booster': 'dart', 'lambda': 0.08731577211376602, 'alpha': 0.00237399493560533, 'subsample': 0.7013908643997382, 'colsample_bytree': 0.6918779529545033, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.0514532030119347, 'gamma': 0.0006388342437292294, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.3161155653174102, 'skip_drop': 0.20100648405675503}. Best is trial 18 with value: 0.2424092517905551.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:02,249]\u001b[0m Trial 19 finished with value: 1.268050339067123 and parameters: {'booster': 'dart', 'lambda': 0.06195599020767158, 'alpha': 0.06116604833628595, 'subsample': 0.5644337556397814, 'colsample_bytree': 0.8054260325810283, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.0007708083462490857, 'gamma': 0.0004301459610290084, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.8673872406447494, 'skip_drop': 0.0006892545585579067}. Best is trial 18 with value: 0.2424092517905551.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:03,653]\u001b[0m Trial 20 finished with value: 1.2726430632673056 and parameters: {'booster': 'dart', 'lambda': 0.016620054400162624, 'alpha': 6.76639926887205e-05, 'subsample': 0.268764144853079, 'colsample_bytree': 0.9876211787714013, 'max_depth': 5, 'min_child_weight': 7, 'eta': 2.746621761632355e-05, 'gamma': 0.0037887770678069655, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.00029033157107011064, 'skip_drop': 0.0014306195673038915}. Best is trial 18 with value: 0.2424092517905551.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:05,220]\u001b[0m Trial 21 finished with value: 0.24084546328883033 and parameters: {'booster': 'dart', 'lambda': 0.11686788709554706, 'alpha': 0.002020597892368243, 'subsample': 0.6813649891487494, 'colsample_bytree': 0.6658055830481163, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.04810498533731254, 'gamma': 1.1008665764404225e-05, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.005950649077710291, 'skip_drop': 0.6722306207542993}. Best is trial 21 with value: 0.24084546328883033.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:06,735]\u001b[0m Trial 22 finished with value: 0.2637121871061424 and parameters: {'booster': 'dart', 'lambda': 0.10996808535040152, 'alpha': 0.0018310492404663425, 'subsample': 0.6620486488527432, 'colsample_bytree': 0.6519936985241737, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.019665738484255357, 'gamma': 1.0573812626437595e-05, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.0018881358529021835, 'skip_drop': 0.04918817002733111}. Best is trial 21 with value: 0.24084546328883033.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:07,464]\u001b[0m Trial 23 finished with value: 0.24801491735475256 and parameters: {'booster': 'dart', 'lambda': 0.006318161691954934, 'alpha': 0.060342155515279, 'subsample': 0.8888882474614839, 'colsample_bytree': 0.7559930897593361, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.1067650728884025, 'gamma': 0.0014462303015230285, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.6405777142847247, 'skip_drop': 0.014988730089979826}. Best is trial 21 with value: 0.24084546328883033.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:08,919]\u001b[0m Trial 24 finished with value: 1.148191781902799 and parameters: {'booster': 'dart', 'lambda': 0.12997593943066643, 'alpha': 0.0035060055860275854, 'subsample': 0.7090901907670846, 'colsample_bytree': 0.6081613298146761, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.0007640178203888218, 'gamma': 0.024229434952759706, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.008614472741775741, 'skip_drop': 0.9969814409422356}. Best is trial 21 with value: 0.24084546328883033.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:26:10,439]\u001b[0m Trial 25 finished with value: 0.22290398994314994 and parameters: {'booster': 'dart', 'lambda': 0.0008294591698252834, 'alpha': 0.00012541851654772218, 'subsample': 0.8125674783940203, 'colsample_bytree': 0.7416470019055375, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.1369292747184106, 'gamma': 1.270606311812687e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 2.7276121786079252e-05, 'skip_drop': 1.342719596000539e-05}. Best is trial 25 with value: 0.22290398994314994.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:11,918]\u001b[0m Trial 26 finished with value: 0.24953328958456455 and parameters: {'booster': 'dart', 'lambda': 0.0005116939526861726, 'alpha': 0.00012667565587240706, 'subsample': 0.7832209262920478, 'colsample_bytree': 0.5185984099140009, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.16762504411078105, 'gamma': 1.9152700968563296e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.214504103194219e-05, 'skip_drop': 8.575948506660227e-06}. Best is trial 25 with value: 0.22290398994314994.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:13,390]\u001b[0m Trial 27 finished with value: 0.9633876266824183 and parameters: {'booster': 'dart', 'lambda': 0.010299872739631732, 'alpha': 5.9668098300952205e-06, 'subsample': 0.6742348988611977, 'colsample_bytree': 0.8797506607693789, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.0020455244210905864, 'gamma': 4.816651803046621e-05, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.00013880656432413346, 'skip_drop': 2.277718821616055e-05}. Best is trial 25 with value: 0.22290398994314994.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:14,830]\u001b[0m Trial 28 finished with value: 0.42301588263869255 and parameters: {'booster': 'dart', 'lambda': 0.28935656142440686, 'alpha': 0.000360139802479321, 'subsample': 0.5198142147766065, 'colsample_bytree': 0.6329785449565336, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.012274071028369986, 'gamma': 1.760708122001121e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.001121239898389382, 'skip_drop': 0.0037212726905045622}. Best is trial 25 with value: 0.22290398994314994.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:16,314]\u001b[0m Trial 29 finished with value: 3.2465337183463974 and parameters: {'booster': 'dart', 'lambda': 1.066621746837217e-07, 'alpha': 6.299775797303734e-05, 'subsample': 0.3654177906129288, 'colsample_bytree': 0.5572354446713736, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.8018254919760892, 'gamma': 0.06266085055957366, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.9050315278690937e-05, 'skip_drop': 2.0498876455743544e-06}. Best is trial 25 with value: 0.22290398994314994.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:17,795]\u001b[0m Trial 30 finished with value: 1.2735475904937237 and parameters: {'booster': 'dart', 'lambda': 0.04188526591039717, 'alpha': 1.2144011629987985e-08, 'subsample': 0.618127240601261, 'colsample_bytree': 0.7173012646654483, 'max_depth': 9, 'min_child_weight': 3, 'eta': 2.1801622681394006e-05, 'gamma': 0.0005468523465022464, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.2172236898230622e-08, 'skip_drop': 0.00014774721746000394}. Best is trial 25 with value: 0.22290398994314994.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:19,309]\u001b[0m Trial 31 finished with value: 0.2130522819853261 and parameters: {'booster': 'dart', 'lambda': 0.004105079356457953, 'alpha': 0.003128256413417044, 'subsample': 0.8179337012967355, 'colsample_bytree': 0.7630379314969334, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.05799797912889371, 'gamma': 5.501707237026026e-06, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.0729554218978666, 'skip_drop': 0.09412717179548384}. Best is trial 31 with value: 0.2130522819853261.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:20,785]\u001b[0m Trial 32 finished with value: 0.25715666084214195 and parameters: {'booster': 'dart', 'lambda': 0.004730048649954483, 'alpha': 0.00024317976740011383, 'subsample': 0.790300433753326, 'colsample_bytree': 0.7834086257886291, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.023307093921887522, 'gamma': 8.954553521883073e-06, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.11513598960657596, 'skip_drop': 0.12172035081511359}. Best is trial 31 with value: 0.2130522819853261.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:22,359]\u001b[0m Trial 33 finished with value: 0.21724479082621856 and parameters: {'booster': 'dart', 'lambda': 0.0003401106577318117, 'alpha': 0.004329674000274963, 'subsample': 0.8217601775128774, 'colsample_bytree': 0.6964358278280524, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.16299532673791828, 'gamma': 1.2064907687230192e-07, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.005979486551708492, 'skip_drop': 0.03009354756608005}. Best is trial 31 with value: 0.2130522819853261.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:23,894]\u001b[0m Trial 34 finished with value: 0.20023553007592482 and parameters: {'booster': 'dart', 'lambda': 3.320150604489276e-05, 'alpha': 0.07905754338348292, 'subsample': 0.9311208300678201, 'colsample_bytree': 0.8382561162628714, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.1996048433393405, 'gamma': 7.294133715708776e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.00790636281254928, 'skip_drop': 0.012877495426542176}. Best is trial 34 with value: 0.20023553007592482.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:25,434]\u001b[0m Trial 35 finished with value: 0.1908244979572941 and parameters: {'booster': 'dart', 'lambda': 2.382127170492183e-05, 'alpha': 0.05641534472870829, 'subsample': 0.9414121919779814, 'colsample_bytree': 0.8586028715280496, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.17429653772660894, 'gamma': 8.102392523726958e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.011517499801765517, 'skip_drop': 0.01430810982985629}. Best is trial 35 with value: 0.1908244979572941.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:27,106]\u001b[0m A new study created in memory with name: no-name-60f633d8-1435-40e8-942e-590087182654\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:27,391]\u001b[0m Trial 0 finished with value: 0.7095419893195241 and parameters: {'booster': 'gbtree', 'lambda': 0.00120280382830056, 'alpha': 0.02196341423899678, 'subsample': 0.27539788320248215, 'colsample_bytree': 0.4820562164086541, 'max_depth': 3, 'min_child_weight': 10, 'eta': 2.447807867631496e-05, 'gamma': 0.054325212344652596, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.7095419893195241.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:33,260]\u001b[0m Trial 1 finished with value: 0.7641381020269015 and parameters: {'booster': 'dart', 'lambda': 7.888212156724178e-07, 'alpha': 0.001975458718097434, 'subsample': 0.8013143843265196, 'colsample_bytree': 0.7389398471421518, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.0012006122830275575, 'gamma': 7.370471848781547e-08, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 2.6496867799110706e-06, 'skip_drop': 0.024891406877674407}. Best is trial 1 with value: 0.7641381020269015.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:38,736]\u001b[0m Trial 2 finished with value: 0.7671693039588308 and parameters: {'booster': 'dart', 'lambda': 7.573884800880307e-05, 'alpha': 0.00837909358554996, 'subsample': 0.44707894424951244, 'colsample_bytree': 0.7353531976453915, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.00018697147919366562, 'gamma': 0.24779608818542923, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.02741504705000683, 'skip_drop': 0.0021204381856461778}. Best is trial 2 with value: 0.7671693039588308.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:39,169]\u001b[0m Trial 3 finished with value: 0.7463602262163349 and parameters: {'booster': 'gbtree', 'lambda': 0.0007148824905601131, 'alpha': 5.782801675039103e-05, 'subsample': 0.6016119931911712, 'colsample_bytree': 0.7135620978509274, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.7776864691474433, 'gamma': 1.2963039413931352e-05, 'grow_policy': 'depthwise'}. Best is trial 2 with value: 0.7671693039588308.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:26:39,847]\u001b[0m Trial 4 finished with value: 0.7802708442374909 and parameters: {'booster': 'gbtree', 'lambda': 0.00025867301947183745, 'alpha': 0.004809383615368454, 'subsample': 0.4692235638096669, 'colsample_bytree': 0.9942134082727898, 'max_depth': 7, 'min_child_weight': 6, 'eta': 0.06868762610169649, 'gamma': 0.027084058594374683, 'grow_policy': 'depthwise'}. Best is trial 4 with value: 0.7802708442374909.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:45,263]\u001b[0m Trial 5 finished with value: 0.7506089124409969 and parameters: {'booster': 'dart', 'lambda': 0.0015404112813109689, 'alpha': 2.0834846844066837e-07, 'subsample': 0.4206168284127825, 'colsample_bytree': 0.41099274865901525, 'max_depth': 9, 'min_child_weight': 7, 'eta': 2.2739856670323384e-05, 'gamma': 1.1080154256540399e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.025742854651236866, 'skip_drop': 0.17391266651406917}. Best is trial 4 with value: 0.7802708442374909.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:45,690]\u001b[0m Trial 6 finished with value: 0.736473237155574 and parameters: {'booster': 'gbtree', 'lambda': 4.1812855418265864e-08, 'alpha': 0.01316908351943406, 'subsample': 0.40644411677412917, 'colsample_bytree': 0.8970195526392377, 'max_depth': 3, 'min_child_weight': 6, 'eta': 4.1096513357120493e-07, 'gamma': 0.5680674743923726, 'grow_policy': 'depthwise'}. Best is trial 4 with value: 0.7802708442374909.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:46,037]\u001b[0m Trial 7 finished with value: 0.7274077843734686 and parameters: {'booster': 'gblinear', 'lambda': 0.00014182768838124922, 'alpha': 6.000196539918544e-06, 'subsample': 0.7878455250461216, 'colsample_bytree': 0.45312766214796696}. Best is trial 4 with value: 0.7802708442374909.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:46,978]\u001b[0m Trial 8 finished with value: 0.7669797122077416 and parameters: {'booster': 'gbtree', 'lambda': 1.4808061209727902e-07, 'alpha': 7.042362328363406e-05, 'subsample': 0.5537711785470966, 'colsample_bytree': 0.9904779311218321, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.0011983598381097459, 'gamma': 0.0030958536896702775, 'grow_policy': 'lossguide'}. Best is trial 4 with value: 0.7802708442374909.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:47,506]\u001b[0m Trial 9 finished with value: 0.747927429064722 and parameters: {'booster': 'gbtree', 'lambda': 0.0001552536605757747, 'alpha': 0.09908811586662077, 'subsample': 0.32631071933619227, 'colsample_bytree': 0.813431628607497, 'max_depth': 9, 'min_child_weight': 6, 'eta': 2.7230074596663193e-08, 'gamma': 0.24332509966135235, 'grow_policy': 'depthwise'}. Best is trial 4 with value: 0.7802708442374909.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:47,634]\u001b[0m Trial 10 finished with value: 0.3137366115514142 and parameters: {'booster': 'gblinear', 'lambda': 0.3221419791587011, 'alpha': 0.918934335903572, 'subsample': 0.6518387100524408, 'colsample_bytree': 0.2179985111981575}. Best is trial 4 with value: 0.7802708442374909.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:50,546]\u001b[0m Trial 11 finished with value: 0.7737798225050773 and parameters: {'booster': 'dart', 'lambda': 3.5390228385348056e-06, 'alpha': 0.002902751433379063, 'subsample': 0.982938319697039, 'colsample_bytree': 0.9895911862708211, 'max_depth': 5, 'min_child_weight': 3, 'eta': 0.5192207194372694, 'gamma': 0.0009332510856903695, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.6116170373592362, 'skip_drop': 2.0457493602148578e-07}. Best is trial 4 with value: 0.7802708442374909.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:52,069]\u001b[0m Trial 12 finished with value: 0.7802527029828719 and parameters: {'booster': 'dart', 'lambda': 3.398245845440003e-06, 'alpha': 0.0006665599830879324, 'subsample': 0.9701042685463902, 'colsample_bytree': 0.988888420885598, 'max_depth': 5, 'min_child_weight': 2, 'eta': 0.6889008770646119, 'gamma': 0.0005963544976194252, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.9028869927461886, 'skip_drop': 2.0674248024922095e-08}. Best is trial 4 with value: 0.7802708442374909.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:57,978]\u001b[0m Trial 13 finished with value: 0.7708829960551462 and parameters: {'booster': 'dart', 'lambda': 0.03391571098398867, 'alpha': 0.00031440529248458784, 'subsample': 0.9478031010020765, 'colsample_bytree': 0.8607298773604298, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.03060390007022154, 'gamma': 1.9720023286363436e-05, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 1.2229817206011498e-07, 'skip_drop': 1.1571584271857682e-08}. Best is trial 4 with value: 0.7802708442374909.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:58,342]\u001b[0m Trial 14 finished with value: 0.7273867124567114 and parameters: {'booster': 'gblinear', 'lambda': 5.725654900558226e-06, 'alpha': 2.23118919002029e-06, 'subsample': 0.7387546764184101, 'colsample_bytree': 0.5949257899943305}. Best is trial 4 with value: 0.7802708442374909.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:26:58,857]\u001b[0m Trial 15 finished with value: 0.7771196146360951 and parameters: {'booster': 'gbtree', 'lambda': 1.2588040252306166e-05, 'alpha': 0.00046781841435286094, 'subsample': 0.21828309130930534, 'colsample_bytree': 0.9117372435756972, 'max_depth': 5, 'min_child_weight': 2, 'eta': 0.032543187030932196, 'gamma': 0.0030986434002166275, 'grow_policy': 'depthwise'}. Best is trial 4 with value: 0.7802708442374909.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:04,833]\u001b[0m Trial 16 finished with value: 0.7778263484721409 and parameters: {'booster': 'dart', 'lambda': 1.0746992734120553e-08, 'alpha': 1.187001159820789e-08, 'subsample': 0.8640103059519526, 'colsample_bytree': 0.6224887384019389, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.03559858644160986, 'gamma': 0.00012154651066066014, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.00022470580881972253, 'skip_drop': 8.056029169433959e-06}. Best is trial 4 with value: 0.7802708442374909.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:27:05,996]\u001b[0m A new study created in memory with name: no-name-eac66317-0b6b-414f-8b6b-868e00edf7b9\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:11,346]\u001b[0m Trial 0 finished with value: 0.9240330019394939 and parameters: {'booster': 'dart', 'lambda': 5.254535391223237e-07, 'alpha': 2.7111385183982988e-05, 'subsample': 0.6730328945851922, 'colsample_bytree': 0.6868416736576497, 'max_depth': 3, 'min_child_weight': 2, 'eta': 2.0669731524045864e-06, 'gamma': 1.4711111409013696e-05, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 3.884704904293892e-05, 'skip_drop': 1.3472606092429306e-05}. Best is trial 0 with value: 0.9240330019394939.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:16,470]\u001b[0m Trial 1 finished with value: 0.9108750634627119 and parameters: {'booster': 'dart', 'lambda': 0.011043418899216208, 'alpha': 8.592566998168163e-05, 'subsample': 0.7298037216538555, 'colsample_bytree': 0.6285575328897124, 'max_depth': 3, 'min_child_weight': 5, 'eta': 8.619491923113025e-08, 'gamma': 0.07128523280942102, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.1523635709814527, 'skip_drop': 0.6464495255488637}. Best is trial 0 with value: 0.9240330019394939.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:16,806]\u001b[0m Trial 2 finished with value: 0.9041926436102167 and parameters: {'booster': 'gblinear', 'lambda': 5.057942947882745e-06, 'alpha': 9.420363320189832e-06, 'subsample': 0.5473719818365834, 'colsample_bytree': 0.9464538564965226}. Best is trial 0 with value: 0.9240330019394939.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:22,766]\u001b[0m Trial 3 finished with value: 0.8877259492310398 and parameters: {'booster': 'dart', 'lambda': 2.5840215209873933e-07, 'alpha': 6.731498452400516e-07, 'subsample': 0.6966330869949072, 'colsample_bytree': 0.5847443861559969, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.0008710035796094247, 'gamma': 1.0713879073953309e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.005499743791483146, 'skip_drop': 3.5190967776054803e-06}. Best is trial 0 with value: 0.9240330019394939.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:27:23,105]\u001b[0m Trial 4 finished with value: 0.9202753306401468 and parameters: {'booster': 'gblinear', 'lambda': 0.00030185463520947036, 'alpha': 3.340174476558286e-08, 'subsample': 0.5901303263459856, 'colsample_bytree': 0.622361745530843}. Best is trial 0 with value: 0.9240330019394939.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:23,565]\u001b[0m Trial 5 finished with value: 0.9261415667541167 and parameters: {'booster': 'gbtree', 'lambda': 2.70984345341534e-08, 'alpha': 3.179883046834785e-06, 'subsample': 0.8058786304051984, 'colsample_bytree': 0.8409417892192284, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.888334174097755, 'gamma': 0.8498031455601693, 'grow_policy': 'lossguide'}. Best is trial 5 with value: 0.9261415667541167.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:23,908]\u001b[0m Trial 6 finished with value: 0.8864613823517933 and parameters: {'booster': 'gblinear', 'lambda': 0.09248234458954449, 'alpha': 8.360900148203078e-06, 'subsample': 0.7233531654035881, 'colsample_bytree': 0.8859134145265568}. Best is trial 5 with value: 0.9261415667541167.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:24,249]\u001b[0m Trial 7 finished with value: 0.9101027947957919 and parameters: {'booster': 'gblinear', 'lambda': 1.168488043555987e-05, 'alpha': 1.1458422568320492e-05, 'subsample': 0.6107273463695118, 'colsample_bytree': 0.3686683247084841}. Best is trial 5 with value: 0.9261415667541167.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:24,534]\u001b[0m Trial 8 finished with value: 0.9294799298614522 and parameters: {'booster': 'gblinear', 'lambda': 1.1223532291737455e-08, 'alpha': 0.0025827557279362303, 'subsample': 0.7885575580500757, 'colsample_bytree': 0.5255147827259674}. Best is trial 8 with value: 0.9294799298614522.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:30,377]\u001b[0m Trial 9 finished with value: 0.8864613823517933 and parameters: {'booster': 'dart', 'lambda': 0.00041186728415954394, 'alpha': 3.762748933159147e-08, 'subsample': 0.5011704729610594, 'colsample_bytree': 0.6270533171806717, 'max_depth': 9, 'min_child_weight': 9, 'eta': 2.4352077100278567e-07, 'gamma': 0.00837736757516168, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 7.653492511761093e-08, 'skip_drop': 0.0005368499080827951}. Best is trial 8 with value: 0.9294799298614522.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:30,878]\u001b[0m Trial 10 finished with value: 0.8864613823517933 and parameters: {'booster': 'gbtree', 'lambda': 1.879050615324049e-08, 'alpha': 0.06239118586275427, 'subsample': 0.9563651168971767, 'colsample_bytree': 0.20175332798869267, 'max_depth': 5, 'min_child_weight': 2, 'eta': 0.002383012249128653, 'gamma': 2.171860722176648e-06, 'grow_policy': 'depthwise'}. Best is trial 8 with value: 0.9294799298614522.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:31,302]\u001b[0m Trial 11 finished with value: 0.9344073347174924 and parameters: {'booster': 'gbtree', 'lambda': 1.7117897929702236e-08, 'alpha': 0.006250131743573037, 'subsample': 0.9109925972959002, 'colsample_bytree': 0.42078525740766276, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.5011594966090642, 'gamma': 0.6468750713757926, 'grow_policy': 'lossguide'}. Best is trial 11 with value: 0.9344073347174924.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:31,593]\u001b[0m Trial 12 finished with value: 0.8903098792287955 and parameters: {'booster': 'gbtree', 'lambda': 1.8854422448344134e-08, 'alpha': 0.005737352988172209, 'subsample': 0.26695711350881884, 'colsample_bytree': 0.4327557778728814, 'max_depth': 7, 'min_child_weight': 6, 'eta': 0.8899028363365251, 'gamma': 0.0012877201771688428, 'grow_policy': 'lossguide'}. Best is trial 11 with value: 0.9344073347174924.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:32,184]\u001b[0m Trial 13 finished with value: 0.9085404553069875 and parameters: {'booster': 'gbtree', 'lambda': 4.3005184347855337e-07, 'alpha': 0.002065484845356512, 'subsample': 0.969043367565764, 'colsample_bytree': 0.4301052325635342, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.013328933143838007, 'gamma': 0.0002772188704013861, 'grow_policy': 'depthwise'}. Best is trial 11 with value: 0.9344073347174924.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:32,325]\u001b[0m Trial 14 finished with value: 0.8864613823517933 and parameters: {'booster': 'gblinear', 'lambda': 1.4567351806946769e-05, 'alpha': 0.39652165305433923, 'subsample': 0.8556060939650114, 'colsample_bytree': 0.2892822750743251}. Best is trial 11 with value: 0.9344073347174924.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:33,086]\u001b[0m Trial 15 finished with value: 0.9107552268368274 and parameters: {'booster': 'gbtree', 'lambda': 1.7696029838465557e-07, 'alpha': 0.0015428001387518709, 'subsample': 0.8617052605922544, 'colsample_bytree': 0.5078403115051235, 'max_depth': 7, 'min_child_weight': 5, 'eta': 4.1827473057738324e-05, 'gamma': 0.6083390356987312, 'grow_policy': 'lossguide'}. Best is trial 11 with value: 0.9344073347174924.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:33,273]\u001b[0m Trial 16 finished with value: 0.8864613823517933 and parameters: {'booster': 'gblinear', 'lambda': 0.005680475346462763, 'alpha': 0.02677790969747636, 'subsample': 0.3568966688997053, 'colsample_bytree': 0.7790513273186865}. Best is trial 11 with value: 0.9344073347174924.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:33,895]\u001b[0m Trial 17 finished with value: 0.9046708054974469 and parameters: {'booster': 'gbtree', 'lambda': 0.7017770971864914, 'alpha': 0.0004351039007460061, 'subsample': 0.8936982128135331, 'colsample_bytree': 0.5083912872389426, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.022537866252196476, 'gamma': 3.464196943077825e-07, 'grow_policy': 'depthwise'}. Best is trial 11 with value: 0.9344073347174924.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:34,037]\u001b[0m Trial 18 finished with value: 0.8864613823517933 and parameters: {'booster': 'gblinear', 'lambda': 2.4338775944255175e-06, 'alpha': 0.6826478234944565, 'subsample': 0.999843521876238, 'colsample_bytree': 0.32112833738987984}. Best is trial 11 with value: 0.9344073347174924.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:34,743]\u001b[0m Trial 19 finished with value: 0.9142715540312828 and parameters: {'booster': 'gbtree', 'lambda': 1.1017803915127358e-08, 'alpha': 0.040222920635909196, 'subsample': 0.7848689984933861, 'colsample_bytree': 0.7384282358014925, 'max_depth': 5, 'min_child_weight': 7, 'eta': 3.8607828615496745e-05, 'gamma': 0.004708205160117291, 'grow_policy': 'lossguide'}. Best is trial 11 with value: 0.9344073347174924.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:35,420]\u001b[0m Trial 20 finished with value: 0.9266053389678074 and parameters: {'booster': 'gbtree', 'lambda': 5.968416751979318e-08, 'alpha': 0.0003068602445465511, 'subsample': 0.789934910482373, 'colsample_bytree': 0.5216146942040845, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.08022955476743061, 'gamma': 4.684099636701334e-05, 'grow_policy': 'lossguide'}. Best is trial 11 with value: 0.9344073347174924.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:36,005]\u001b[0m Trial 21 finished with value: 0.9356583732512428 and parameters: {'booster': 'gbtree', 'lambda': 8.732568959719025e-08, 'alpha': 0.0010273830896742162, 'subsample': 0.8990411987449447, 'colsample_bytree': 0.5087761568704098, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.13154222871739846, 'gamma': 6.893144922289793e-05, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 0.9356583732512428.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:36,531]\u001b[0m Trial 22 finished with value: 0.9326195541341573 and parameters: {'booster': 'gbtree', 'lambda': 8.575620892624795e-08, 'alpha': 0.0073429066822531825, 'subsample': 0.8880973391306775, 'colsample_bytree': 0.4295162706278066, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.10911674460013907, 'gamma': 0.00020821451539951947, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 0.9356583732512428.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:37,027]\u001b[0m Trial 23 finished with value: 0.9266058856767613 and parameters: {'booster': 'gbtree', 'lambda': 1.489671935570118e-06, 'alpha': 0.01227611457616777, 'subsample': 0.915548013826289, 'colsample_bytree': 0.41062760146149313, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.14400381664863351, 'gamma': 0.00038254329164256356, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 0.9356583732512428.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:37,561]\u001b[0m Trial 24 finished with value: 0.8864613823517933 and parameters: {'booster': 'gbtree', 'lambda': 8.58741730308691e-08, 'alpha': 0.11953740733285487, 'subsample': 0.9236088265722795, 'colsample_bytree': 0.27503678061703274, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.0014898196958904866, 'gamma': 5.778339218855835e-06, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 0.9356583732512428.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:27:37,999]\u001b[0m Trial 25 finished with value: 0.9253380034578617 and parameters: {'booster': 'gbtree', 'lambda': 1.134681549231479e-06, 'alpha': 0.00034236639563257963, 'subsample': 0.8346472870702784, 'colsample_bytree': 0.3869519965082743, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.1479701398677736, 'gamma': 4.3127209876102274e-07, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 0.9356583732512428.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:38,527]\u001b[0m Trial 26 finished with value: 0.8939256360078279 and parameters: {'booster': 'gbtree', 'lambda': 2.858313637928663e-05, 'alpha': 0.006948318055350079, 'subsample': 0.46491802546352834, 'colsample_bytree': 0.477974819550083, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.007969067719076123, 'gamma': 0.054513374646777364, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 0.9356583732512428.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:38,995]\u001b[0m Trial 27 finished with value: 0.9193688751135897 and parameters: {'booster': 'gbtree', 'lambda': 6.607140440134473e-08, 'alpha': 0.17808201872500298, 'subsample': 0.9078853618696385, 'colsample_bytree': 0.33050475538521745, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.1433066580228771, 'gamma': 9.673960649854963e-05, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 0.9356583732512428.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:39,507]\u001b[0m Trial 28 finished with value: 0.8864613823517933 and parameters: {'booster': 'gbtree', 'lambda': 8.995931210253961e-08, 'alpha': 0.0008382348332214603, 'subsample': 0.9733903512132585, 'colsample_bytree': 0.21347243249341497, 'max_depth': 7, 'min_child_weight': 5, 'eta': 0.00040335994322416137, 'gamma': 0.02569646684310345, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 0.9356583732512428.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:27:40,467]\u001b[0m A new study created in memory with name: no-name-2fe08d98-f9e1-4634-8a3c-bbfc2eada038\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:40,687]\u001b[0m Trial 0 finished with value: 0.9252844207104712 and parameters: {'booster': 'gblinear', 'lambda': 0.07466301750183595, 'alpha': 1.2537894786710855e-06, 'subsample': 0.7224036224064769, 'colsample_bytree': 0.8228760095579268}. Best is trial 0 with value: 0.9252844207104712.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:43,968]\u001b[0m Trial 1 finished with value: 0.9211067561799061 and parameters: {'booster': 'dart', 'lambda': 0.27662789797720805, 'alpha': 3.3744989498583806e-06, 'subsample': 0.767841796122084, 'colsample_bytree': 0.7820056183561539, 'max_depth': 7, 'min_child_weight': 6, 'eta': 1.3123329713291034e-07, 'gamma': 0.8112681736556047, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.25836825686976067, 'skip_drop': 0.048316373934604535}. Best is trial 0 with value: 0.9252844207104712.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:44,289]\u001b[0m Trial 2 finished with value: 0.9284214963119073 and parameters: {'booster': 'gbtree', 'lambda': 9.16271617491678e-05, 'alpha': 1.9242750048139002e-08, 'subsample': 0.42037449402071997, 'colsample_bytree': 0.8592916032575588, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.00024229963798555319, 'gamma': 1.0721148928202435e-06, 'grow_policy': 'depthwise'}. Best is trial 2 with value: 0.9284214963119073.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:48,319]\u001b[0m Trial 3 finished with value: 0.9197318566015739 and parameters: {'booster': 'dart', 'lambda': 0.0002636647449786961, 'alpha': 0.988478935841071, 'subsample': 0.724064312856961, 'colsample_bytree': 0.6998004397718769, 'max_depth': 9, 'min_child_weight': 6, 'eta': 1.4151621686301945e-07, 'gamma': 0.0001185824677768625, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 1.8016775775233732e-08, 'skip_drop': 2.2305711229176284e-06}. Best is trial 2 with value: 0.9284214963119073.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:48,697]\u001b[0m Trial 4 finished with value: 0.9224777663676348 and parameters: {'booster': 'gbtree', 'lambda': 1.1066660928105175e-05, 'alpha': 5.352868621995933e-07, 'subsample': 0.615156595552648, 'colsample_bytree': 0.3659991231549589, 'max_depth': 9, 'min_child_weight': 4, 'eta': 1.2782773107701574e-05, 'gamma': 0.22611552385464, 'grow_policy': 'depthwise'}. Best is trial 2 with value: 0.9284214963119073.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:48,930]\u001b[0m Trial 5 finished with value: 0.9354313217326916 and parameters: {'booster': 'gblinear', 'lambda': 1.3767471780967011e-08, 'alpha': 2.273841512907271e-07, 'subsample': 0.7495394691597024, 'colsample_bytree': 0.34575592502480423}. Best is trial 5 with value: 0.9354313217326916.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:49,275]\u001b[0m Trial 6 finished with value: 0.9244614520160431 and parameters: {'booster': 'gbtree', 'lambda': 0.0008377950081427875, 'alpha': 0.0020507125084584187, 'subsample': 0.3656859455585999, 'colsample_bytree': 0.7901335352674963, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.00014031491131779404, 'gamma': 0.0007434323586928827, 'grow_policy': 'depthwise'}. Best is trial 5 with value: 0.9354313217326916.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:49,480]\u001b[0m Trial 7 finished with value: 0.9239954852639352 and parameters: {'booster': 'gbtree', 'lambda': 9.975359355419658e-08, 'alpha': 4.5570784237218834e-07, 'subsample': 0.26860371137217226, 'colsample_bytree': 0.5971911352839461, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.8553857921104497, 'gamma': 0.0004698123198481936, 'grow_policy': 'lossguide'}. Best is trial 5 with value: 0.9354313217326916.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:53,513]\u001b[0m Trial 8 finished with value: 0.9322122474612956 and parameters: {'booster': 'dart', 'lambda': 0.11227037639654275, 'alpha': 0.19970452720125828, 'subsample': 0.9369436048194355, 'colsample_bytree': 0.7706251543115552, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.28368073446609304, 'gamma': 0.0024501321851433024, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.00013054803737314285, 'skip_drop': 9.531204179512649e-07}. Best is trial 5 with value: 0.9354313217326916.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:57,464]\u001b[0m Trial 9 finished with value: 0.9225127201565557 and parameters: {'booster': 'dart', 'lambda': 4.7451870003236735e-06, 'alpha': 0.047857333283371044, 'subsample': 0.4436409319258496, 'colsample_bytree': 0.5537182256744388, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.5318104337197496, 'gamma': 1.2647826967164122e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.0011434497263861007, 'skip_drop': 0.8226144518590102}. Best is trial 5 with value: 0.9354313217326916.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:57,712]\u001b[0m Trial 10 finished with value: 0.9358446768740536 and parameters: {'booster': 'gblinear', 'lambda': 2.5154879415235185e-08, 'alpha': 0.00010239152068380945, 'subsample': 0.9050730224641435, 'colsample_bytree': 0.21207416494221518}. Best is trial 10 with value: 0.9358446768740536.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:57,962]\u001b[0m Trial 11 finished with value: 0.9358446768740536 and parameters: {'booster': 'gblinear', 'lambda': 1.143604062988026e-08, 'alpha': 0.00012816450860120724, 'subsample': 0.965125007131473, 'colsample_bytree': 0.20526869030846245}. Best is trial 10 with value: 0.9358446768740536.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:58,209]\u001b[0m Trial 12 finished with value: 0.9356407476758319 and parameters: {'booster': 'gblinear', 'lambda': 2.2706482235405545e-07, 'alpha': 0.00019530044319475932, 'subsample': 0.9947535503318772, 'colsample_bytree': 0.205776891018406}. Best is trial 10 with value: 0.9358446768740536.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:58,458]\u001b[0m Trial 13 finished with value: 0.9358446768740536 and parameters: {'booster': 'gblinear', 'lambda': 1.660331921285087e-08, 'alpha': 3.535132730621517e-05, 'subsample': 0.880801233536785, 'colsample_bytree': 0.20359108818121224}. Best is trial 10 with value: 0.9358446768740536.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:27:58,680]\u001b[0m Trial 14 finished with value: 0.9305708277296885 and parameters: {'booster': 'gblinear', 'lambda': 5.476405446368428e-07, 'alpha': 0.0008843025909064926, 'subsample': 0.8664935624467738, 'colsample_bytree': 0.4004412753324511}. Best is trial 10 with value: 0.9358446768740536.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:58,911]\u001b[0m Trial 15 finished with value: 0.9358446768740536 and parameters: {'booster': 'gblinear', 'lambda': 2.8112001267447784e-06, 'alpha': 2.6172287553006217e-05, 'subsample': 0.615098480252265, 'colsample_bytree': 0.9893359181628809}. Best is trial 10 with value: 0.9358446768740536.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:59,086]\u001b[0m Trial 16 finished with value: 0.9309647333139025 and parameters: {'booster': 'gblinear', 'lambda': 0.002740481724957709, 'alpha': 0.005791745557624179, 'subsample': 0.8516577760501034, 'colsample_bytree': 0.47748395520469844}. Best is trial 10 with value: 0.9358446768740536.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:59,319]\u001b[0m Trial 17 finished with value: 0.943013698630137 and parameters: {'booster': 'gblinear', 'lambda': 1.1078771453989979e-08, 'alpha': 1.6626171954582656e-05, 'subsample': 0.9839029894641304, 'colsample_bytree': 0.2865239688243023}. Best is trial 17 with value: 0.943013698630137.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:59,553]\u001b[0m Trial 18 finished with value: 0.943013698630137 and parameters: {'booster': 'gblinear', 'lambda': 2.437126592038002e-06, 'alpha': 8.571017235157374e-06, 'subsample': 0.5618041389103449, 'colsample_bytree': 0.9849868635164875}. Best is trial 17 with value: 0.943013698630137.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:27:59,790]\u001b[0m Trial 19 finished with value: 0.9340181987589952 and parameters: {'booster': 'gblinear', 'lambda': 3.478197967596496e-05, 'alpha': 8.751235661416511e-06, 'subsample': 0.512367170389496, 'colsample_bytree': 0.9966862080867632}. Best is trial 17 with value: 0.943013698630137.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:28:00,028]\u001b[0m Trial 20 finished with value: 0.9419554744959656 and parameters: {'booster': 'gblinear', 'lambda': 1.2082854965019435e-06, 'alpha': 4.557480953812872e-08, 'subsample': 0.5321430030208322, 'colsample_bytree': 0.6642485129294698}. Best is trial 17 with value: 0.943013698630137.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:28:00,263]\u001b[0m Trial 21 finished with value: 0.9384353472167235 and parameters: {'booster': 'gblinear', 'lambda': 7.836139354301218e-07, 'alpha': 1.0638383400469687e-08, 'subsample': 0.5386222317657207, 'colsample_bytree': 0.6798882818753806}. Best is trial 17 with value: 0.943013698630137.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:28:00,498]\u001b[0m Trial 22 finished with value: 0.9320051014676634 and parameters: {'booster': 'gblinear', 'lambda': 1.1162845499404198e-07, 'alpha': 9.014486696765741e-08, 'subsample': 0.5627659065664343, 'colsample_bytree': 0.507876439842916}. Best is trial 17 with value: 0.943013698630137.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:28:00,731]\u001b[0m Trial 23 finished with value: 0.9449691731261025 and parameters: {'booster': 'gblinear', 'lambda': 2.4902130120243485e-06, 'alpha': 6.612082819205782e-08, 'subsample': 0.6737213572642227, 'colsample_bytree': 0.9209322863341017}. Best is trial 23 with value: 0.9449691731261025.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:28:00,965]\u001b[0m Trial 24 finished with value: 0.9340181987589952 and parameters: {'booster': 'gblinear', 'lambda': 1.690624537853557e-05, 'alpha': 4.803621092288265e-06, 'subsample': 0.639332589963876, 'colsample_bytree': 0.9104462060002555}. Best is trial 23 with value: 0.9449691731261025.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:28:01,201]\u001b[0m Trial 25 finished with value: 0.9295264187866927 and parameters: {'booster': 'gblinear', 'lambda': 0.004623570254138539, 'alpha': 1.7000305937743706e-06, 'subsample': 0.6752825398579954, 'colsample_bytree': 0.8798491559384032}. Best is trial 23 with value: 0.9449691731261025.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:28:01,438]\u001b[0m Trial 26 finished with value: 0.9376125244618394 and parameters: {'booster': 'gblinear', 'lambda': 3.4747400260102848e-06, 'alpha': 2.4956161353431e-05, 'subsample': 0.808498741115042, 'colsample_bytree': 0.9511997454784664}. Best is trial 23 with value: 0.9449691731261025.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:28:01,924]\u001b[0m Trial 27 finished with value: 0.923965978643915 and parameters: {'booster': 'gbtree', 'lambda': 9.733051588269445e-08, 'alpha': 8.784170919182124e-08, 'subsample': 0.45830525571155595, 'colsample_bytree': 0.9240052928992484, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.004021444527026404, 'gamma': 1.1225498865518398e-06, 'grow_policy': 'lossguide'}. Best is trial 23 with value: 0.9449691731261025.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:28:02,155]\u001b[0m Trial 28 finished with value: 0.9360771443795847 and parameters: {'booster': 'gblinear', 'lambda': 7.705037124267254e-05, 'alpha': 1.3610192497868923e-05, 'subsample': 0.6751688639510232, 'colsample_bytree': 0.29110425194670425}. Best is trial 23 with value: 0.9449691731261025.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:28:06,046]\u001b[0m Trial 29 finished with value: 0.9185799729886166 and parameters: {'booster': 'dart', 'lambda': 0.031027408914165163, 'alpha': 0.0005485325504296736, 'subsample': 0.2152818224339222, 'colsample_bytree': 0.46091218925967964, 'max_depth': 3, 'min_child_weight': 8, 'eta': 2.36722589479674e-06, 'gamma': 1.3191327040486629e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.272049697526641e-08, 'skip_drop': 0.0007672342004235104}. Best is trial 23 with value: 0.9449691731261025.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:28:06,282]\u001b[0m Trial 30 finished with value: 0.9373283816496946 and parameters: {'booster': 'gblinear', 'lambda': 4.7001596842217335e-07, 'alpha': 1.19427786001371e-06, 'subsample': 0.30375613665310536, 'colsample_bytree': 0.8809930074068334}. Best is trial 23 with value: 0.9449691731261025.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:28:06,516]\u001b[0m Trial 31 finished with value: 0.9419554744959656 and parameters: {'booster': 'gblinear', 'lambda': 1.5345376396455796e-06, 'alpha': 3.76396379900996e-08, 'subsample': 0.5146868964880758, 'colsample_bytree': 0.7086715774534392}. Best is trial 23 with value: 0.9449691731261025.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:28:06,749]\u001b[0m Trial 32 finished with value: 0.9410845798181027 and parameters: {'booster': 'gblinear', 'lambda': 1.333857794092683e-05, 'alpha': 2.0440758666334252e-07, 'subsample': 0.4839193302382611, 'colsample_bytree': 0.7356930980857803}. Best is trial 23 with value: 0.9449691731261025.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:28:06,985]\u001b[0m Trial 33 finished with value: 0.9185799729886166 and parameters: {'booster': 'gblinear', 'lambda': 0.9699594986386119, 'alpha': 2.002593727055588e-06, 'subsample': 0.8025694358712265, 'colsample_bytree': 0.8294328432834507}. Best is trial 23 with value: 0.9449691731261025.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:28:07,222]\u001b[0m Trial 34 finished with value: 0.9368418398468789 and parameters: {'booster': 'gblinear', 'lambda': 0.00027955155279860985, 'alpha': 3.922563904227504e-08, 'subsample': 0.5760702225865276, 'colsample_bytree': 0.6129543122567568}. Best is trial 23 with value: 0.9449691731261025.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:28:10,219]\u001b[0m Trial 35 finished with value: 0.929870241218475 and parameters: {'booster': 'dart', 'lambda': 5.860960282145697e-08, 'alpha': 1.134467439194387e-08, 'subsample': 0.6951139345876067, 'colsample_bytree': 0.8438231103965343, 'max_depth': 5, 'min_child_weight': 2, 'eta': 0.005815809218620171, 'gamma': 0.021105078168109744, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.5529854013585485, 'skip_drop': 8.460019725947301e-08}. Best is trial 23 with value: 0.9449691731261025.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:28:10,582]\u001b[0m Trial 36 finished with value: 0.9185799729886166 and parameters: {'booster': 'gbtree', 'lambda': 1.9690213883339455e-06, 'alpha': 8.70883318294336e-07, 'subsample': 0.3904889713541819, 'colsample_bytree': 0.7247057085442137, 'max_depth': 9, 'min_child_weight': 8, 'eta': 2.6891191756452875e-08, 'gamma': 4.359075687273465e-06, 'grow_policy': 'lossguide'}. Best is trial 23 with value: 0.9449691731261025.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:28:10,818]\u001b[0m Trial 37 finished with value: 0.9373283816496946 and parameters: {'booster': 'gblinear', 'lambda': 2.931847876649345e-07, 'alpha': 2.53235761814107e-07, 'subsample': 0.3891844061457586, 'colsample_bytree': 0.9387465195785066}. Best is trial 23 with value: 0.9449691731261025.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:28:11,052]\u001b[0m Trial 38 finished with value: 0.9410845798181027 and parameters: {'booster': 'gblinear', 'lambda': 8.209469685218265e-06, 'alpha': 3.27226311098125e-06, 'subsample': 0.7638761162061904, 'colsample_bytree': 0.7791703850803555}. Best is trial 23 with value: 0.9449691731261025.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:28:11,511]\u001b[0m Trial 39 finished with value: 0.9267519379961489 and parameters: {'booster': 'gbtree', 'lambda': 3.876013451151616e-05, 'alpha': 8.128968542967304e-08, 'subsample': 0.6429774148880392, 'colsample_bytree': 0.6602865845893606, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.012412417691591396, 'gamma': 1.097720727591987e-05, 'grow_policy': 'lossguide'}. Best is trial 23 with value: 0.9449691731261025.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:28:15,520]\u001b[0m Trial 40 finished with value: 0.9235406639516229 and parameters: {'booster': 'dart', 'lambda': 4.3227618850402496e-08, 'alpha': 0.012597679020797779, 'subsample': 0.3403798271228062, 'colsample_bytree': 0.6418774837119758, 'max_depth': 7, 'min_child_weight': 3, 'eta': 3.23904932390553e-06, 'gamma': 0.020776518546220514, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.1413206132010524e-05, 'skip_drop': 0.00031596948069932234}. Best is trial 23 with value: 0.9449691731261025.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:28:16,006]\u001b[0m A new study created in memory with name: no-name-ee3ce87e-2713-4da1-b91a-8c6ca4ece214\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:28:22,365]\u001b[0m Trial 0 finished with value: 0.6327302489876798 and parameters: {'booster': 'dart', 'lambda': 1.4645796847601588e-05, 'alpha': 0.00935070141182206, 'subsample': 0.7382325122881566, 'colsample_bytree': 0.271843344086138, 'max_depth': 3, 'min_child_weight': 9, 'eta': 1.8626745428754836e-05, 'gamma': 2.3795973445332987e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 9.429346609809006e-06, 'skip_drop': 0.24958797833283924}. Best is trial 0 with value: 0.6327302489876798.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:28:23,228]\u001b[0m Trial 1 finished with value: 0.7025683244483433 and parameters: {'booster': 'gbtree', 'lambda': 0.22667620045803075, 'alpha': 1.5764505702989506e-08, 'subsample': 0.7347499632334336, 'colsample_bytree': 0.7555978567141375, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.06691529967505593, 'gamma': 1.8882163889101008e-06, 'grow_policy': 'lossguide'}. Best is trial 1 with value: 0.7025683244483433.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:28:29,794]\u001b[0m Trial 2 finished with value: 0.6327302489876798 and parameters: {'booster': 'dart', 'lambda': 0.004197121995013038, 'alpha': 0.01808447161859269, 'subsample': 0.560843153505124, 'colsample_bytree': 0.26450315495586046, 'max_depth': 3, 'min_child_weight': 7, 'eta': 4.600383141044595e-06, 'gamma': 0.00019804706521403038, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 1.5110244504317616e-08, 'skip_drop': 1.7888674011868606e-07}. Best is trial 1 with value: 0.7025683244483433.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:28:30,213]\u001b[0m Trial 3 finished with value: 0.6814812851360202 and parameters: {'booster': 'gblinear', 'lambda': 1.2156903930108944e-06, 'alpha': 0.00038784507064286753, 'subsample': 0.3519635992486597, 'colsample_bytree': 0.8709251882904485}. Best is trial 1 with value: 0.7025683244483433.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:28:30,939]\u001b[0m Trial 4 finished with value: 0.6327302489876798 and parameters: {'booster': 'gbtree', 'lambda': 0.0012812920157993567, 'alpha': 5.263518084989755e-08, 'subsample': 0.88845540223323, 'colsample_bytree': 0.44366591520306314, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.003801874514646492, 'gamma': 1.1087923412205335e-08, 'grow_policy': 'lossguide'}. Best is trial 1 with value: 0.7025683244483433.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:28:31,682]\u001b[0m Trial 5 finished with value: 0.6509288210866484 and parameters: {'booster': 'gbtree', 'lambda': 9.683568721853304e-08, 'alpha': 0.16281752709334685, 'subsample': 0.7386283374242497, 'colsample_bytree': 0.3842093069958047, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.013336029408275541, 'gamma': 0.00030114440651409424, 'grow_policy': 'depthwise'}. Best is trial 1 with value: 0.7025683244483433.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:28:38,135]\u001b[0m Trial 6 finished with value: 0.6327302489876798 and parameters: {'booster': 'dart', 'lambda': 0.00209470024546037, 'alpha': 0.25433045150581557, 'subsample': 0.21510463439008323, 'colsample_bytree': 0.5710493174478912, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.000668552572637681, 'gamma': 0.00042380052038730194, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.07863006009271759, 'skip_drop': 5.896261613475767e-05}. Best is trial 1 with value: 0.7025683244483433.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:28:45,289]\u001b[0m Trial 7 finished with value: 0.7149133324291332 and parameters: {'booster': 'dart', 'lambda': 5.593605787581407e-07, 'alpha': 1.4554994444798575e-05, 'subsample': 0.9452865814155011, 'colsample_bytree': 0.9891539799486886, 'max_depth': 5, 'min_child_weight': 7, 'eta': 8.156817696741882e-06, 'gamma': 0.025803306368521205, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.1047198478878963e-05, 'skip_drop': 3.682664315509898e-08}. Best is trial 7 with value: 0.7149133324291332.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:28:46,258]\u001b[0m Trial 8 finished with value: 0.7077141957397036 and parameters: {'booster': 'gbtree', 'lambda': 0.000452047197135799, 'alpha': 0.6339844329118509, 'subsample': 0.9532836160094444, 'colsample_bytree': 0.9915880114479811, 'max_depth': 7, 'min_child_weight': 8, 'eta': 2.820844208921993e-05, 'gamma': 1.2369487465975434e-06, 'grow_policy': 'depthwise'}. Best is trial 7 with value: 0.7149133324291332.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:28:53,065]\u001b[0m Trial 9 finished with value: 0.6310372438269601 and parameters: {'booster': 'dart', 'lambda': 5.6483141882195684e-05, 'alpha': 0.24017914051397463, 'subsample': 0.3938925991300817, 'colsample_bytree': 0.34530766057666906, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.018726499572764094, 'gamma': 2.610101809763418e-05, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 3.7955498040122364e-06, 'skip_drop': 0.00023189940114624682}. Best is trial 7 with value: 0.7149133324291332.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:29:01,539]\u001b[0m A new study created in memory with name: no-name-27bf7e02-2cf5-4c21-a650-6e651d20353b\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:02,109]\u001b[0m Trial 0 finished with value: 0.7109507663095076 and parameters: {'booster': 'gbtree', 'lambda': 3.934783868592282e-06, 'alpha': 0.0007070597757549542, 'subsample': 0.7158267367187061, 'colsample_bytree': 0.3047594547612759, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.002253281289794024, 'gamma': 0.008594082637487637, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.7109507663095076.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:07,481]\u001b[0m Trial 1 finished with value: 0.7297506146821215 and parameters: {'booster': 'dart', 'lambda': 6.404541900697153e-07, 'alpha': 4.458430071234699e-05, 'subsample': 0.5311652438795507, 'colsample_bytree': 0.7728504873752848, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.0765048666383597, 'gamma': 0.0002429225543466733, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 1.7591050337052214e-07, 'skip_drop': 1.6638366098604245e-06}. Best is trial 1 with value: 0.7297506146821215.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:29:07,795]\u001b[0m Trial 2 finished with value: 0.7345924293971988 and parameters: {'booster': 'gbtree', 'lambda': 0.35526941255690925, 'alpha': 0.011190719824752388, 'subsample': 0.943768924803897, 'colsample_bytree': 0.34348380373418674, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.04452101334162999, 'gamma': 2.6689879055522067e-08, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 0.7345924293971988.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:13,085]\u001b[0m Trial 3 finished with value: 0.7266905383880217 and parameters: {'booster': 'dart', 'lambda': 0.05417997442090594, 'alpha': 0.0008751152704835861, 'subsample': 0.4548078938700175, 'colsample_bytree': 0.5934389187291385, 'max_depth': 5, 'min_child_weight': 6, 'eta': 5.018010086180353e-05, 'gamma': 4.4507828497167294e-05, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 3.8082833082998e-07, 'skip_drop': 0.00010726540561914812}. Best is trial 2 with value: 0.7345924293971988.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:15,898]\u001b[0m Trial 4 finished with value: 0.7411438780468207 and parameters: {'booster': 'dart', 'lambda': 1.0101260680148104e-05, 'alpha': 0.00024884153086977796, 'subsample': 0.5647002444167841, 'colsample_bytree': 0.4888412332456817, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.11829566998283521, 'gamma': 0.38608346865820403, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.5064651804732311, 'skip_drop': 1.9573617733197098e-05}. Best is trial 4 with value: 0.7411438780468207.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:16,189]\u001b[0m Trial 5 finished with value: 0.6921613120757633 and parameters: {'booster': 'gblinear', 'lambda': 0.006453055662893217, 'alpha': 0.0009034562573659425, 'subsample': 0.615812360240482, 'colsample_bytree': 0.9458990073361306}. Best is trial 4 with value: 0.7411438780468207.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:16,486]\u001b[0m Trial 6 finished with value: 0.7484451812301874 and parameters: {'booster': 'gbtree', 'lambda': 0.17457115482344485, 'alpha': 8.461177451987664e-08, 'subsample': 0.6631232019776263, 'colsample_bytree': 0.4886145559350376, 'max_depth': 3, 'min_child_weight': 9, 'eta': 0.15270398780716, 'gamma': 0.00020391108004030637, 'grow_policy': 'lossguide'}. Best is trial 6 with value: 0.7484451812301874.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:17,286]\u001b[0m Trial 7 finished with value: 0.7337925117875178 and parameters: {'booster': 'gbtree', 'lambda': 0.010912814663193665, 'alpha': 0.0036507161729148877, 'subsample': 0.5929766112347792, 'colsample_bytree': 0.7363750755199308, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.00041655087791637714, 'gamma': 0.14973305985423163, 'grow_policy': 'depthwise'}. Best is trial 6 with value: 0.7484451812301874.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:17,587]\u001b[0m Trial 8 finished with value: 0.6816510070874303 and parameters: {'booster': 'gblinear', 'lambda': 0.015766209985362108, 'alpha': 0.0001992403876303931, 'subsample': 0.8523426891173174, 'colsample_bytree': 0.8240105322460269}. Best is trial 6 with value: 0.7484451812301874.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:17,893]\u001b[0m Trial 9 finished with value: 0.6627052156146972 and parameters: {'booster': 'gblinear', 'lambda': 6.038684784593389e-06, 'alpha': 1.1640742542470784e-06, 'subsample': 0.6833771429248704, 'colsample_bytree': 0.40406328965037597}. Best is trial 6 with value: 0.7484451812301874.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:18,167]\u001b[0m Trial 10 finished with value: 0.6098050696035776 and parameters: {'booster': 'gbtree', 'lambda': 1.5905819476570867e-08, 'alpha': 1.1059308365399279e-08, 'subsample': 0.2209357293532443, 'colsample_bytree': 0.21911002606298174, 'max_depth': 7, 'min_child_weight': 10, 'eta': 4.8630094889553256e-08, 'gamma': 4.0882734800553695e-06, 'grow_policy': 'lossguide'}. Best is trial 6 with value: 0.7484451812301874.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:21,784]\u001b[0m Trial 11 finished with value: 0.6904726454821669 and parameters: {'booster': 'dart', 'lambda': 0.00031290852354492067, 'alpha': 0.7133532440789584, 'subsample': 0.3860142073916528, 'colsample_bytree': 0.5283675345647164, 'max_depth': 3, 'min_child_weight': 10, 'eta': 0.8983648402102806, 'gamma': 0.961539812893498, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.7604190746781634, 'skip_drop': 0.5043322259545069}. Best is trial 6 with value: 0.7484451812301874.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:25,986]\u001b[0m Trial 12 finished with value: 0.7158117455581174 and parameters: {'booster': 'dart', 'lambda': 0.00016948840761723562, 'alpha': 3.624396942883354e-06, 'subsample': 0.8100386547964255, 'colsample_bytree': 0.47234381762326405, 'max_depth': 5, 'min_child_weight': 8, 'eta': 6.524120419202434e-06, 'gamma': 0.0036489625678287896, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.24463222617448438, 'skip_drop': 1.747186453614433e-08}. Best is trial 6 with value: 0.7484451812301874.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:31,566]\u001b[0m Trial 13 finished with value: 0.6928383494628236 and parameters: {'booster': 'dart', 'lambda': 0.0004524983639325944, 'alpha': 1.4918559549589467e-08, 'subsample': 0.3572627340476908, 'colsample_bytree': 0.6387877285568219, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.6619743102379974, 'gamma': 3.095408882716295e-07, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.0007146175491842301, 'skip_drop': 0.0006115637372682396}. Best is trial 6 with value: 0.7484451812301874.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:31,954]\u001b[0m Trial 14 finished with value: 0.6987632225052203 and parameters: {'booster': 'gbtree', 'lambda': 1.680378387842519e-07, 'alpha': 4.030492379610757e-07, 'subsample': 0.7229547055047059, 'colsample_bytree': 0.4570546740841309, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.005488794978621004, 'gamma': 0.012938114189528012, 'grow_policy': 'lossguide'}. Best is trial 6 with value: 0.7484451812301874.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:32,597]\u001b[0m Trial 15 finished with value: 0.7324343098829748 and parameters: {'booster': 'gbtree', 'lambda': 1.8302791415281693e-05, 'alpha': 3.251222815653833e-05, 'subsample': 0.5099400839718997, 'colsample_bytree': 0.6462043850092234, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.01788679818893727, 'gamma': 0.00019076323802752547, 'grow_policy': 'lossguide'}. Best is trial 6 with value: 0.7484451812301874.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:37,992]\u001b[0m Trial 16 finished with value: 0.6684098130110944 and parameters: {'booster': 'dart', 'lambda': 0.6138318451452202, 'alpha': 1.8076538821433252e-07, 'subsample': 0.8291477399385325, 'colsample_bytree': 0.5262235549138721, 'max_depth': 3, 'min_child_weight': 4, 'eta': 7.068880578059246e-07, 'gamma': 6.629734230457235e-06, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.0009769889727923792, 'skip_drop': 0.015695676421348725}. Best is trial 6 with value: 0.7484451812301874.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:29:38,674]\u001b[0m A new study created in memory with name: no-name-ee1fa181-3817-44a5-8923-e12d36068adb\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:38,769]\u001b[0m Trial 0 finished with value: 1.2665953219299302 and parameters: {'booster': 'gblinear', 'lambda': 9.019050664766002e-06, 'alpha': 0.05756618737064395, 'subsample': 0.6493077079593528, 'colsample_bytree': 0.5269700759225688}. Best is trial 0 with value: 1.2665953219299302.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:39,861]\u001b[0m Trial 1 finished with value: 1.5574253031696221 and parameters: {'booster': 'dart', 'lambda': 0.0010393711526917222, 'alpha': 4.587357622833125e-08, 'subsample': 0.8963010270493132, 'colsample_bytree': 0.3103195198112634, 'max_depth': 7, 'min_child_weight': 7, 'eta': 2.5996100003185088e-05, 'gamma': 4.7426379772850056e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.3073208172447103, 'skip_drop': 0.026674951497046535}. Best is trial 0 with value: 1.2665953219299302.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:29:39,981]\u001b[0m Trial 2 finished with value: 0.8401133634467142 and parameters: {'booster': 'gblinear', 'lambda': 3.501361790285006e-08, 'alpha': 7.304389908775018e-08, 'subsample': 0.8355755072428399, 'colsample_bytree': 0.25789187969477245}. Best is trial 2 with value: 0.8401133634467142.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:41,413]\u001b[0m Trial 3 finished with value: 1.5575288840856738 and parameters: {'booster': 'dart', 'lambda': 0.3405959563099087, 'alpha': 0.00015533822052985152, 'subsample': 0.72246196247552, 'colsample_bytree': 0.7168359737959746, 'max_depth': 5, 'min_child_weight': 3, 'eta': 2.4362236960692547e-06, 'gamma': 0.0001759966122823616, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 4.694791685970656e-05, 'skip_drop': 0.0006441882975075558}. Best is trial 2 with value: 0.8401133634467142.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:41,647]\u001b[0m Trial 4 finished with value: 1.5578218911832016 and parameters: {'booster': 'gbtree', 'lambda': 0.14539409477803414, 'alpha': 0.00026213466763548403, 'subsample': 0.7039597629716314, 'colsample_bytree': 0.8655273347049055, 'max_depth': 5, 'min_child_weight': 4, 'eta': 2.1055090195179593e-08, 'gamma': 8.197401467985798e-06, 'grow_policy': 'depthwise'}. Best is trial 2 with value: 0.8401133634467142.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:43,046]\u001b[0m Trial 5 finished with value: 1.5468279891003622 and parameters: {'booster': 'dart', 'lambda': 0.001486344742391577, 'alpha': 2.258681895333115e-05, 'subsample': 0.34937434574908394, 'colsample_bytree': 0.7593448686966553, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.00012344757373380187, 'gamma': 0.06280341532222537, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.0019285412469482938, 'skip_drop': 2.600888263834524e-07}. Best is trial 2 with value: 0.8401133634467142.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:44,652]\u001b[0m Trial 6 finished with value: 0.5338085027277205 and parameters: {'booster': 'dart', 'lambda': 2.7870943314406034e-07, 'alpha': 0.3950004329756792, 'subsample': 0.8492091733286096, 'colsample_bytree': 0.970365352510745, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.2382726920003435, 'gamma': 0.29398800438588546, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 9.071682955995378e-08, 'skip_drop': 0.13009350786681378}. Best is trial 6 with value: 0.5338085027277205.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:44,770]\u001b[0m Trial 7 finished with value: 0.8424838301741981 and parameters: {'booster': 'gblinear', 'lambda': 8.991985396895439e-05, 'alpha': 0.0006071588252671484, 'subsample': 0.6335929015698312, 'colsample_bytree': 0.953805592718098}. Best is trial 6 with value: 0.5338085027277205.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:46,200]\u001b[0m Trial 8 finished with value: 1.5577815567134292 and parameters: {'booster': 'dart', 'lambda': 0.5012074251269865, 'alpha': 2.0441000175721733e-06, 'subsample': 0.8990408018535783, 'colsample_bytree': 0.6142385352843249, 'max_depth': 7, 'min_child_weight': 7, 'eta': 3.839401448885565e-07, 'gamma': 1.6482860565600015e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.003495252831486694, 'skip_drop': 0.00010027292143680986}. Best is trial 6 with value: 0.5338085027277205.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:46,322]\u001b[0m Trial 9 finished with value: 0.8567669481183816 and parameters: {'booster': 'gblinear', 'lambda': 2.108469100942995e-05, 'alpha': 1.7007150477024048e-07, 'subsample': 0.6014567203831096, 'colsample_bytree': 0.2396770536873347}. Best is trial 6 with value: 0.5338085027277205.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:46,590]\u001b[0m Trial 10 finished with value: 1.058922505812852 and parameters: {'booster': 'gbtree', 'lambda': 1.4674040230140763e-08, 'alpha': 0.9519273073111504, 'subsample': 0.42934472309397387, 'colsample_bytree': 0.4603968440372742, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.2892389849316558, 'gamma': 0.474785971118824, 'grow_policy': 'lossguide'}. Best is trial 6 with value: 0.5338085027277205.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:46,721]\u001b[0m Trial 11 finished with value: 0.8984928274036887 and parameters: {'booster': 'gblinear', 'lambda': 1.2320795374339879e-08, 'alpha': 0.010180546383152703, 'subsample': 0.9900058599347437, 'colsample_bytree': 0.39116313263658375}. Best is trial 6 with value: 0.5338085027277205.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:48,403]\u001b[0m Trial 12 finished with value: 0.9794348290619923 and parameters: {'booster': 'dart', 'lambda': 4.626897453756787e-07, 'alpha': 2.721564777369568e-06, 'subsample': 0.8212847830304448, 'colsample_bytree': 0.9988561823645066, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.7039868468150694, 'gamma': 0.0035040110122276946, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.3361760114865404e-08, 'skip_drop': 0.9875547341157238}. Best is trial 6 with value: 0.5338085027277205.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:48,540]\u001b[0m Trial 13 finished with value: 0.8550224557908078 and parameters: {'booster': 'gblinear', 'lambda': 3.5180292841313777e-07, 'alpha': 1.3359626838261537e-08, 'subsample': 0.7995899773973445, 'colsample_bytree': 0.2080244387342877}. Best is trial 6 with value: 0.5338085027277205.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:48,744]\u001b[0m Trial 14 finished with value: 1.2770649526677944 and parameters: {'booster': 'gbtree', 'lambda': 5.745378066750493e-07, 'alpha': 0.007896305912193178, 'subsample': 0.978427936190797, 'colsample_bytree': 0.6467488696175661, 'max_depth': 3, 'min_child_weight': 9, 'eta': 0.003897390029129468, 'gamma': 0.004471248813228318, 'grow_policy': 'lossguide'}. Best is trial 6 with value: 0.5338085027277205.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:48,878]\u001b[0m Trial 15 finished with value: 0.8623135894777689 and parameters: {'booster': 'gblinear', 'lambda': 9.484886703812381e-08, 'alpha': 1.1640941654741922e-06, 'subsample': 0.507803460083934, 'colsample_bytree': 0.8340603566760323}. Best is trial 6 with value: 0.5338085027277205.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:50,270]\u001b[0m Trial 16 finished with value: 1.283440775336575 and parameters: {'booster': 'dart', 'lambda': 4.065572280884662e-06, 'alpha': 0.6418990361178474, 'subsample': 0.24390410316094446, 'colsample_bytree': 0.49950646780783214, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.007866321129351924, 'gamma': 1.2221819799210569e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.5894868471359256e-08, 'skip_drop': 2.9219054340242116e-08}. Best is trial 6 with value: 0.5338085027277205.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:51,673]\u001b[0m Trial 17 finished with value: 1.0671631682768274 and parameters: {'booster': 'dart', 'lambda': 6.656817573398306e-08, 'alpha': 1.9557385541413613e-05, 'subsample': 0.7973777378303446, 'colsample_bytree': 0.3762888795391197, 'max_depth': 3, 'min_child_weight': 8, 'eta': 0.012984973236198535, 'gamma': 0.8063832017298707, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.2856538831572474e-06, 'skip_drop': 0.4628961480554401}. Best is trial 6 with value: 0.5338085027277205.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:51,807]\u001b[0m Trial 18 finished with value: 0.8279549639746518 and parameters: {'booster': 'gblinear', 'lambda': 2.390637006328411e-06, 'alpha': 0.0022328577666299583, 'subsample': 0.5115353593708883, 'colsample_bytree': 0.9036350214071135}. Best is trial 6 with value: 0.5338085027277205.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:52,074]\u001b[0m Trial 19 finished with value: 1.5232948613538722 and parameters: {'booster': 'gbtree', 'lambda': 1.9156722018217185e-06, 'alpha': 0.08150175110762733, 'subsample': 0.527468460235732, 'colsample_bytree': 0.8798820755605337, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.0003499754709321014, 'gamma': 0.007587149310074673, 'grow_policy': 'lossguide'}. Best is trial 6 with value: 0.5338085027277205.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:53,566]\u001b[0m Trial 20 finished with value: 0.7321803686669427 and parameters: {'booster': 'dart', 'lambda': 0.001322915550855764, 'alpha': 0.0023354119596628886, 'subsample': 0.48925399178452245, 'colsample_bytree': 0.9315199923204371, 'max_depth': 5, 'min_child_weight': 2, 'eta': 0.06793215845045862, 'gamma': 0.00023887528409229615, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.518030995815633e-06, 'skip_drop': 0.0036310710242921733}. Best is trial 6 with value: 0.5338085027277205.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:29:55,060]\u001b[0m Trial 21 finished with value: 0.6824562619142337 and parameters: {'booster': 'dart', 'lambda': 0.0030145268528751533, 'alpha': 0.004193458370423608, 'subsample': 0.4974027666523209, 'colsample_bytree': 0.9347823738969652, 'max_depth': 5, 'min_child_weight': 2, 'eta': 0.10882722210971323, 'gamma': 0.00019219951636309962, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.7941134087212761e-06, 'skip_drop': 0.005875783110235078}. Best is trial 6 with value: 0.5338085027277205.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:56,528]\u001b[0m Trial 22 finished with value: 0.7461549556410717 and parameters: {'booster': 'dart', 'lambda': 0.010142337001613247, 'alpha': 0.0867440529666995, 'subsample': 0.39648252710068205, 'colsample_bytree': 0.7769508103378099, 'max_depth': 5, 'min_child_weight': 2, 'eta': 0.09830852331047508, 'gamma': 0.00029754025240509444, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.4924822034606345e-06, 'skip_drop': 0.005389332127672516}. Best is trial 6 with value: 0.5338085027277205.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:58,080]\u001b[0m Trial 23 finished with value: 0.9187126650065492 and parameters: {'booster': 'dart', 'lambda': 0.01658284369740364, 'alpha': 0.0022649857396829934, 'subsample': 0.30379126979051035, 'colsample_bytree': 0.995823575264633, 'max_depth': 5, 'min_child_weight': 3, 'eta': 0.05286288727587886, 'gamma': 6.009461566730347e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 6.407945844339233e-07, 'skip_drop': 0.01101215746248261}. Best is trial 6 with value: 0.5338085027277205.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:29:59,508]\u001b[0m Trial 24 finished with value: 1.668271631019207 and parameters: {'booster': 'dart', 'lambda': 0.0005291906538198717, 'alpha': 0.014700876969454605, 'subsample': 0.45698938514850085, 'colsample_bytree': 0.9217614603431548, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.7060737506075486, 'gamma': 0.0007575554291261165, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 3.2042347420443173e-07, 'skip_drop': 0.05488987293474738}. Best is trial 6 with value: 0.5338085027277205.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:01,123]\u001b[0m Trial 25 finished with value: 1.4000451072283646 and parameters: {'booster': 'dart', 'lambda': 0.006207903246186221, 'alpha': 0.001201820548165399, 'subsample': 0.5455375854701732, 'colsample_bytree': 0.8092155562100258, 'max_depth': 5, 'min_child_weight': 2, 'eta': 0.0013851237204800756, 'gamma': 1.0535252872044878e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.979446515246078e-05, 'skip_drop': 0.0011661828023957457}. Best is trial 6 with value: 0.5338085027277205.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:02,574]\u001b[0m Trial 26 finished with value: 0.8998890300153864 and parameters: {'booster': 'dart', 'lambda': 0.0001570560824734139, 'alpha': 0.24324925707785988, 'subsample': 0.2074886961211761, 'colsample_bytree': 0.733719799005873, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.03858634512277855, 'gamma': 3.978217190116054e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 7.466090804884394e-08, 'skip_drop': 8.714267457472141e-06}. Best is trial 6 with value: 0.5338085027277205.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:04,057]\u001b[0m Trial 27 finished with value: 0.7158469245048072 and parameters: {'booster': 'dart', 'lambda': 0.06026818590291517, 'alpha': 3.144573123552549e-05, 'subsample': 0.7056286006892548, 'colsample_bytree': 0.687414029116459, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.11449661902547696, 'gamma': 0.06987961514430145, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.1042480954327976e-05, 'skip_drop': 0.0672980938485391}. Best is trial 6 with value: 0.5338085027277205.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:05,569]\u001b[0m Trial 28 finished with value: 1.4251424045482044 and parameters: {'booster': 'dart', 'lambda': 0.0590086457888268, 'alpha': 3.230122689987234e-05, 'subsample': 0.7304744803371984, 'colsample_bytree': 0.6855983877051531, 'max_depth': 7, 'min_child_weight': 5, 'eta': 0.0013630536026466467, 'gamma': 0.0649453893332961, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.2775683481220389e-05, 'skip_drop': 0.10025522377562715}. Best is trial 6 with value: 0.5338085027277205.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:07,002]\u001b[0m Trial 29 finished with value: 0.6735675591565564 and parameters: {'booster': 'dart', 'lambda': 0.02884138568078351, 'alpha': 0.03398418465138385, 'subsample': 0.642420041386614, 'colsample_bytree': 0.5775771745226466, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.19649441068059822, 'gamma': 0.08714606372432555, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.000624247720309637, 'skip_drop': 0.10652099252574614}. Best is trial 6 with value: 0.5338085027277205.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:08,414]\u001b[0m Trial 30 finished with value: 0.964570695708086 and parameters: {'booster': 'dart', 'lambda': 3.155490086383796e-05, 'alpha': 0.029705638388663115, 'subsample': 0.574114562706252, 'colsample_bytree': 0.5071948756595184, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.01819189280628832, 'gamma': 0.196298664846642, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.0006349214663428657, 'skip_drop': 0.2263183899327894}. Best is trial 6 with value: 0.5338085027277205.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:09,833]\u001b[0m Trial 31 finished with value: 0.7484173054471932 and parameters: {'booster': 'dart', 'lambda': 0.04797251615256216, 'alpha': 0.22023240625814375, 'subsample': 0.6844447567026704, 'colsample_bytree': 0.5801152290047037, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.21708761934257323, 'gamma': 0.018815703307343806, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.0002431313380039724, 'skip_drop': 0.040706364794176164}. Best is trial 6 with value: 0.5338085027277205.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:11,259]\u001b[0m Trial 32 finished with value: 0.9742003972554415 and parameters: {'booster': 'dart', 'lambda': 0.02523648022815053, 'alpha': 0.04233169823897353, 'subsample': 0.6584894915636663, 'colsample_bytree': 0.5550559180739599, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.9896171545151656, 'gamma': 0.06640336736637512, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.031282903084079196, 'skip_drop': 0.11825986384872772}. Best is trial 6 with value: 0.5338085027277205.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:12,679]\u001b[0m Trial 33 finished with value: 0.6368196322145177 and parameters: {'booster': 'dart', 'lambda': 0.12355796474488503, 'alpha': 0.006040778418136036, 'subsample': 0.8788712053616269, 'colsample_bytree': 0.6388132381130688, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.2011522036287048, 'gamma': 0.16129195724499087, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.2499132146495852e-05, 'skip_drop': 0.012693354634745637}. Best is trial 6 with value: 0.5338085027277205.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:14,442]\u001b[0m A new study created in memory with name: no-name-80010eaa-e19f-4e66-b4da-e263d31c0ac2\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:14,669]\u001b[0m Trial 0 finished with value: 1.3711666890376486 and parameters: {'booster': 'gbtree', 'lambda': 0.42610861938502237, 'alpha': 2.5400077070431925e-08, 'subsample': 0.43795194105147417, 'colsample_bytree': 0.5724949358309419, 'max_depth': 7, 'min_child_weight': 10, 'eta': 5.07571544070462e-08, 'gamma': 0.27950193868561873, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 1.3711666890376486.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:16,140]\u001b[0m Trial 1 finished with value: 1.3678597082700628 and parameters: {'booster': 'dart', 'lambda': 2.3851975663788832e-06, 'alpha': 0.0002695792397634039, 'subsample': 0.24912161560214097, 'colsample_bytree': 0.33138909184657905, 'max_depth': 9, 'min_child_weight': 2, 'eta': 1.717103334834703e-05, 'gamma': 0.3751766874381901, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.9415074451563865e-08, 'skip_drop': 0.1111756345389914}. Best is trial 1 with value: 1.3678597082700628.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:30:17,635]\u001b[0m Trial 2 finished with value: 1.3710645532866745 and parameters: {'booster': 'dart', 'lambda': 9.861705364889923e-06, 'alpha': 5.454867435890253e-05, 'subsample': 0.3954574741977836, 'colsample_bytree': 0.9983549223762997, 'max_depth': 7, 'min_child_weight': 10, 'eta': 4.5658621885431376e-07, 'gamma': 0.08374705671943042, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.0011831515726275991, 'skip_drop': 0.18462353239559018}. Best is trial 1 with value: 1.3678597082700628.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:17,930]\u001b[0m Trial 3 finished with value: 0.12972071223349987 and parameters: {'booster': 'gbtree', 'lambda': 1.5906560374315747e-05, 'alpha': 0.5159100040211732, 'subsample': 0.8112555734412756, 'colsample_bytree': 0.8803194607508065, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.015280840851760331, 'gamma': 1.1533655672022361e-08, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 0.12972071223349987.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:19,313]\u001b[0m Trial 4 finished with value: 0.06830474211878214 and parameters: {'booster': 'dart', 'lambda': 6.467720815800474e-05, 'alpha': 2.272938412046009e-08, 'subsample': 0.23928479046298837, 'colsample_bytree': 0.6984828410514835, 'max_depth': 5, 'min_child_weight': 5, 'eta': 0.1844181412801749, 'gamma': 3.717370461935151e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.015718191806137226, 'skip_drop': 1.4367628766511604e-05}. Best is trial 4 with value: 0.06830474211878214.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:19,492]\u001b[0m Trial 5 finished with value: 1.3354323212597992 and parameters: {'booster': 'gbtree', 'lambda': 1.93462791383426e-06, 'alpha': 4.480288352550136e-05, 'subsample': 0.24407229773938743, 'colsample_bytree': 0.5451380789547426, 'max_depth': 5, 'min_child_weight': 3, 'eta': 0.00015905688127535678, 'gamma': 0.05060597099266716, 'grow_policy': 'depthwise'}. Best is trial 4 with value: 0.06830474211878214.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:19,581]\u001b[0m Trial 6 finished with value: 1.189386953800559 and parameters: {'booster': 'gblinear', 'lambda': 0.0003815127342183434, 'alpha': 0.835273018980706, 'subsample': 0.8553806182559063, 'colsample_bytree': 0.43017668935357156}. Best is trial 4 with value: 0.06830474211878214.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:19,724]\u001b[0m Trial 7 finished with value: 0.09261853232922804 and parameters: {'booster': 'gbtree', 'lambda': 5.087354083726012e-08, 'alpha': 3.6982114133080034e-06, 'subsample': 0.37584079286556804, 'colsample_bytree': 0.2448155276374589, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.05683026531866727, 'gamma': 4.573429967142069e-06, 'grow_policy': 'lossguide'}. Best is trial 4 with value: 0.06830474211878214.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:19,829]\u001b[0m Trial 8 finished with value: 0.5358155720929221 and parameters: {'booster': 'gblinear', 'lambda': 0.11242693740828556, 'alpha': 0.036052105974435894, 'subsample': 0.48770837588562244, 'colsample_bytree': 0.3991379858216087}. Best is trial 4 with value: 0.06830474211878214.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:19,946]\u001b[0m Trial 9 finished with value: 0.0977805552201126 and parameters: {'booster': 'gblinear', 'lambda': 2.3395377655566533e-08, 'alpha': 0.0011625249135953628, 'subsample': 0.25750963525605103, 'colsample_bytree': 0.35810321833653114}. Best is trial 4 with value: 0.06830474211878214.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:20,689]\u001b[0m Trial 10 finished with value: 0.13399019731770007 and parameters: {'booster': 'dart', 'lambda': 0.0026808675841207877, 'alpha': 1.1247947242572257e-08, 'subsample': 0.657024297551591, 'colsample_bytree': 0.7368472352071355, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.5866653272720835, 'gamma': 2.6399675552462507e-05, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.5967232338400091, 'skip_drop': 1.8740188175631447e-07}. Best is trial 4 with value: 0.06830474211878214.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:20,896]\u001b[0m Trial 11 finished with value: 0.0598296513474799 and parameters: {'booster': 'gbtree', 'lambda': 1.0385728530222072e-08, 'alpha': 4.891028159903878e-07, 'subsample': 0.6187570841294945, 'colsample_bytree': 0.7014337594801704, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.3716971571306168, 'gamma': 4.458755873123661e-06, 'grow_policy': 'lossguide'}. Best is trial 11 with value: 0.0598296513474799.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:22,371]\u001b[0m Trial 12 finished with value: 0.5171626953701008 and parameters: {'booster': 'dart', 'lambda': 0.016583701108806262, 'alpha': 4.327284484119212e-07, 'subsample': 0.660052706029782, 'colsample_bytree': 0.7289556065349624, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.006051716576346152, 'gamma': 3.7370511698930155e-07, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.01064156729823099, 'skip_drop': 5.551209229684839e-06}. Best is trial 11 with value: 0.0598296513474799.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:22,582]\u001b[0m Trial 13 finished with value: 0.0662228587157693 and parameters: {'booster': 'gbtree', 'lambda': 1.7456574559469556e-07, 'alpha': 4.5473111678575024e-07, 'subsample': 0.9899447893783426, 'colsample_bytree': 0.7262152726166585, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.36132528928595176, 'gamma': 0.0010649751229915938, 'grow_policy': 'lossguide'}. Best is trial 11 with value: 0.0598296513474799.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:22,806]\u001b[0m Trial 14 finished with value: 1.0981483697427044 and parameters: {'booster': 'gbtree', 'lambda': 2.3654517393707474e-07, 'alpha': 1.179112158692748e-06, 'subsample': 0.9582483190905448, 'colsample_bytree': 0.8679631933329406, 'max_depth': 3, 'min_child_weight': 8, 'eta': 0.001357244344819703, 'gamma': 0.0010770854868015697, 'grow_policy': 'depthwise'}. Best is trial 11 with value: 0.0598296513474799.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:23,015]\u001b[0m Trial 15 finished with value: 0.06692767104081235 and parameters: {'booster': 'gbtree', 'lambda': 3.0581072276086236e-07, 'alpha': 3.3265842832879477e-07, 'subsample': 0.976760735683594, 'colsample_bytree': 0.643443709456448, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.8506163771338064, 'gamma': 0.0014248730176217679, 'grow_policy': 'lossguide'}. Best is trial 11 with value: 0.0598296513474799.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:23,232]\u001b[0m Trial 16 finished with value: 1.2845162162003108 and parameters: {'booster': 'gbtree', 'lambda': 1.0088797617004503e-08, 'alpha': 1.151144813132053e-05, 'subsample': 0.7707523396572651, 'colsample_bytree': 0.8071086942622689, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.00039821651458087575, 'gamma': 0.0007907717995462417, 'grow_policy': 'lossguide'}. Best is trial 11 with value: 0.0598296513474799.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:23,638]\u001b[0m Trial 17 finished with value: 1.3679957148461999 and parameters: {'booster': 'gbtree', 'lambda': 1.9673123726191334e-07, 'alpha': 2.7061907052350277e-07, 'subsample': 0.5501163978853829, 'colsample_bytree': 0.5272007510011382, 'max_depth': 5, 'min_child_weight': 4, 'eta': 1.3834191783288386e-05, 'gamma': 0.0001118849846545448, 'grow_policy': 'lossguide'}. Best is trial 11 with value: 0.0598296513474799.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:24,017]\u001b[0m Trial 18 finished with value: 0.06622422420103587 and parameters: {'booster': 'gbtree', 'lambda': 8.913657231211222e-07, 'alpha': 0.0028744840312992285, 'subsample': 0.7369905294824949, 'colsample_bytree': 0.6490549469779374, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.02777686127266943, 'gamma': 8.183144372892378e-08, 'grow_policy': 'depthwise'}. Best is trial 11 with value: 0.0598296513474799.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:24,251]\u001b[0m Trial 19 finished with value: 0.903154796644837 and parameters: {'booster': 'gbtree', 'lambda': 8.370585408793575e-08, 'alpha': 7.767246321333923e-08, 'subsample': 0.9094096561973349, 'colsample_bytree': 0.9731676855007897, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.002491223955539298, 'gamma': 0.004741335148072896, 'grow_policy': 'lossguide'}. Best is trial 11 with value: 0.0598296513474799.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:24,390]\u001b[0m Trial 20 finished with value: 0.10889932639855035 and parameters: {'booster': 'gblinear', 'lambda': 1.0157516396017136e-08, 'alpha': 5.629197066288635e-06, 'subsample': 0.6916955547054522, 'colsample_bytree': 0.7932314853854248}. Best is trial 11 with value: 0.0598296513474799.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:30:24,763]\u001b[0m Trial 21 finished with value: 0.05818177364661526 and parameters: {'booster': 'gbtree', 'lambda': 1.155184296961537e-06, 'alpha': 0.0020246967645093507, 'subsample': 0.742281607745926, 'colsample_bytree': 0.6165183024258802, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.06232409330542869, 'gamma': 5.197026229509377e-08, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.05818177364661526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:25,112]\u001b[0m Trial 22 finished with value: 0.06017516740636693 and parameters: {'booster': 'gbtree', 'lambda': 6.656122612679448e-06, 'alpha': 0.01003053786777472, 'subsample': 0.595037851862734, 'colsample_bytree': 0.4927422550905759, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.08641097226703387, 'gamma': 4.307295256697451e-07, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.05818177364661526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:25,451]\u001b[0m Trial 23 finished with value: 0.061354538321798074 and parameters: {'booster': 'gbtree', 'lambda': 1.0590003027204857e-05, 'alpha': 0.007552309742390139, 'subsample': 0.5452184712584565, 'colsample_bytree': 0.4833935892591859, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.058179145333771616, 'gamma': 2.926120872325636e-07, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.05818177364661526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:25,821]\u001b[0m Trial 24 finished with value: 0.06286784535045337 and parameters: {'booster': 'gbtree', 'lambda': 0.00018079205477983633, 'alpha': 0.06913584543599531, 'subsample': 0.5710119944146616, 'colsample_bytree': 0.630554540404821, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.0966488548905651, 'gamma': 1.0481577557074495e-08, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.05818177364661526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:26,107]\u001b[0m Trial 25 finished with value: 0.32418955826741364 and parameters: {'booster': 'gbtree', 'lambda': 0.000849214884707775, 'alpha': 0.0005408813780436648, 'subsample': 0.6387195323226321, 'colsample_bytree': 0.45986276344773325, 'max_depth': 7, 'min_child_weight': 6, 'eta': 0.00942825330154536, 'gamma': 2.2234593693495454e-06, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.05818177364661526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:26,447]\u001b[0m Trial 26 finished with value: 1.1946613019393804 and parameters: {'booster': 'gbtree', 'lambda': 3.29468256544314e-05, 'alpha': 0.02468904272189595, 'subsample': 0.7372292086003285, 'colsample_bytree': 0.5072488584761184, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.0007939741979916908, 'gamma': 7.712873345920867e-08, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.05818177364661526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:26,737]\u001b[0m Trial 27 finished with value: 1.3626154409619784 and parameters: {'booster': 'gbtree', 'lambda': 2.0113642266145833e-06, 'alpha': 0.010000560928860647, 'subsample': 0.6074993483237149, 'colsample_bytree': 0.585938857253481, 'max_depth': 7, 'min_child_weight': 4, 'eta': 3.558645844465636e-05, 'gamma': 8.968861837955952e-07, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.05818177364661526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:27,014]\u001b[0m Trial 28 finished with value: 0.07273395639978793 and parameters: {'booster': 'gbtree', 'lambda': 6.475632381322038e-07, 'alpha': 0.1957738496951463, 'subsample': 0.5183304964639432, 'colsample_bytree': 0.3050917344423227, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.14962575634109082, 'gamma': 4.2863672285929244e-05, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.05818177364661526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:27,149]\u001b[0m Trial 29 finished with value: 0.1060054439386412 and parameters: {'booster': 'gblinear', 'lambda': 7.240057542891035e-06, 'alpha': 0.00012840885327460757, 'subsample': 0.4389336370621394, 'colsample_bytree': 0.5811549138609731}. Best is trial 21 with value: 0.05818177364661526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:27,501]\u001b[0m Trial 30 finished with value: 1.3703977779802328 and parameters: {'booster': 'gbtree', 'lambda': 7.835123986766517e-05, 'alpha': 0.001087176903558026, 'subsample': 0.834529964433228, 'colsample_bytree': 0.6641390175510488, 'max_depth': 9, 'min_child_weight': 6, 'eta': 3.129740153143748e-06, 'gamma': 7.957650441223451e-08, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.05818177364661526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:27,816]\u001b[0m Trial 31 finished with value: 0.06402089722530407 and parameters: {'booster': 'gbtree', 'lambda': 5.00293307464752e-06, 'alpha': 0.006644608216238688, 'subsample': 0.49239231147871687, 'colsample_bytree': 0.4721992486025971, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.045094931741778775, 'gamma': 4.146620177520888e-07, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.05818177364661526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:28,137]\u001b[0m Trial 32 finished with value: 0.357658020297894 and parameters: {'booster': 'gbtree', 'lambda': 2.441793968955402e-05, 'alpha': 0.004277226580354266, 'subsample': 0.5742677916814118, 'colsample_bytree': 0.48329460075976804, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.008467930137114218, 'gamma': 8.968568249755727e-06, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.05818177364661526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:28,458]\u001b[0m Trial 33 finished with value: 0.12928317625695612 and parameters: {'booster': 'gbtree', 'lambda': 0.9386698008604379, 'alpha': 0.000312356565816585, 'subsample': 0.7131694043665191, 'colsample_bytree': 0.5575644186025104, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.7578053880598878, 'gamma': 1.800147878550395e-07, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.05818177364661526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:28,741]\u001b[0m Trial 34 finished with value: 0.06763235037786457 and parameters: {'booster': 'gbtree', 'lambda': 4.3476999150484745e-06, 'alpha': 0.15498448466457754, 'subsample': 0.6121491688206243, 'colsample_bytree': 0.41109326678950764, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.13670171826022814, 'gamma': 1.4290421361845113e-06, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.05818177364661526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:30,314]\u001b[0m Trial 35 finished with value: 0.06888673795347541 and parameters: {'booster': 'dart', 'lambda': 2.2562628063530486e-05, 'alpha': 0.0018650388017827895, 'subsample': 0.4230914826494006, 'colsample_bytree': 0.6062185471529286, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.03012915815309268, 'gamma': 5.8178171939140526e-08, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 6.862505314050201e-07, 'skip_drop': 0.0014677554739475982}. Best is trial 21 with value: 0.05818177364661526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:30,619]\u001b[0m Trial 36 finished with value: 0.8277027101056855 and parameters: {'booster': 'gbtree', 'lambda': 1.5778420844443263e-06, 'alpha': 0.013541565611210421, 'subsample': 0.7839887326484488, 'colsample_bytree': 0.6881318748478091, 'max_depth': 7, 'min_child_weight': 5, 'eta': 0.0028194861120943255, 'gamma': 5.657333417787194e-07, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.05818177364661526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:30,919]\u001b[0m Trial 37 finished with value: 0.06850251713649869 and parameters: {'booster': 'gbtree', 'lambda': 5.871986422782829e-08, 'alpha': 0.00019059795024078643, 'subsample': 0.32420216419264475, 'colsample_bytree': 0.3669317212740518, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.05859304023823607, 'gamma': 1.4831171110801063e-05, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.05818177364661526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:32,416]\u001b[0m Trial 38 finished with value: 1.371163729850783 and parameters: {'booster': 'dart', 'lambda': 5.962340059173577e-07, 'alpha': 6.093676937926449e-05, 'subsample': 0.5122494626868512, 'colsample_bytree': 0.5301069503337726, 'max_depth': 7, 'min_child_weight': 10, 'eta': 6.327298151790078e-08, 'gamma': 2.6180295774059072e-08, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 7.282201778244029e-06, 'skip_drop': 5.8358860784894334e-08}. Best is trial 21 with value: 0.05818177364661526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:32,667]\u001b[0m Trial 39 finished with value: 0.11620913148803139 and parameters: {'booster': 'gbtree', 'lambda': 0.0012520591931029436, 'alpha': 2.361002128315049e-05, 'subsample': 0.4563259428024079, 'colsample_bytree': 0.2486630884745229, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.22775113649295664, 'gamma': 2.0259177335970616e-07, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.05818177364661526.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:30:32,802]\u001b[0m Trial 40 finished with value: 0.10157223383666218 and parameters: {'booster': 'gblinear', 'lambda': 0.00021753116837644888, 'alpha': 0.0004874007373202596, 'subsample': 0.5462765442803583, 'colsample_bytree': 0.4293784332967663}. Best is trial 21 with value: 0.05818177364661526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:33,156]\u001b[0m Trial 41 finished with value: 0.059586473922412724 and parameters: {'booster': 'gbtree', 'lambda': 0.00022697394540376672, 'alpha': 0.05530839156047012, 'subsample': 0.5750604209403519, 'colsample_bytree': 0.6173811650529907, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.06820783923566784, 'gamma': 1.0784907295564114e-08, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.05818177364661526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:33,527]\u001b[0m Trial 42 finished with value: 0.081269067995937 and parameters: {'booster': 'gbtree', 'lambda': 6.699998299686079e-05, 'alpha': 0.034219503862438265, 'subsample': 0.6811484478302708, 'colsample_bytree': 0.7795235047198577, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.02077692687688097, 'gamma': 2.5545749908298875e-08, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.05818177364661526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:33,883]\u001b[0m Trial 43 finished with value: 0.06698715032188857 and parameters: {'booster': 'gbtree', 'lambda': 1.2596163852027845e-05, 'alpha': 0.10386598422464718, 'subsample': 0.6196669653970849, 'colsample_bytree': 0.6168789726312222, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.2530068215013719, 'gamma': 2.9450039641740644e-08, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.05818177364661526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:34,113]\u001b[0m Trial 44 finished with value: 0.06245188173281821 and parameters: {'booster': 'gbtree', 'lambda': 0.004270648870622039, 'alpha': 0.011304098315641057, 'subsample': 0.3684263012489953, 'colsample_bytree': 0.5688878000609315, 'max_depth': 5, 'min_child_weight': 2, 'eta': 0.10549336916957476, 'gamma': 1.755716528151493e-07, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 0.05818177364661526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:35,651]\u001b[0m Trial 45 finished with value: 0.6474860603034891 and parameters: {'booster': 'dart', 'lambda': 0.00045125460660437323, 'alpha': 0.3372691734612208, 'subsample': 0.5927784664681073, 'colsample_bytree': 0.6933771544047852, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.004364621924392055, 'gamma': 2.809012464395534e-06, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 1.0854919353666723e-08, 'skip_drop': 0.0021582153335053364}. Best is trial 21 with value: 0.05818177364661526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:35,912]\u001b[0m Trial 46 finished with value: 0.1738505687087948 and parameters: {'booster': 'gbtree', 'lambda': 0.009274236313994827, 'alpha': 0.9430428303254734, 'subsample': 0.6601695542169893, 'colsample_bytree': 0.4908837478022464, 'max_depth': 7, 'min_child_weight': 5, 'eta': 0.015227509983279333, 'gamma': 1.0368662546620419e-08, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 0.05818177364661526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:36,277]\u001b[0m Trial 47 finished with value: 0.060493600862453395 and parameters: {'booster': 'gbtree', 'lambda': 0.1062881331098005, 'alpha': 0.07053365735772726, 'subsample': 0.5360236142733009, 'colsample_bytree': 0.7548336582409724, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.3967110639417393, 'gamma': 7.091842709375559e-07, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.05818177364661526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:36,646]\u001b[0m Trial 48 finished with value: 0.0660698262333056 and parameters: {'booster': 'gbtree', 'lambda': 0.13186509797151427, 'alpha': 0.04793639251511105, 'subsample': 0.4713898784525605, 'colsample_bytree': 0.8404280001998682, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.43804831896017277, 'gamma': 5.810261125692615e-06, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 0.05818177364661526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:36,771]\u001b[0m Trial 49 finished with value: 0.3072507406854653 and parameters: {'booster': 'gblinear', 'lambda': 0.04184673580133744, 'alpha': 0.018377429651454284, 'subsample': 0.8879647515466855, 'colsample_bytree': 0.7640157711044583}. Best is trial 21 with value: 0.05818177364661526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:37,056]\u001b[0m Trial 50 finished with value: 0.06982267254238143 and parameters: {'booster': 'gbtree', 'lambda': 0.054757541497130933, 'alpha': 0.2832561144328456, 'subsample': 0.7565435718140722, 'colsample_bytree': 0.9385884288104369, 'max_depth': 5, 'min_child_weight': 5, 'eta': 0.9709983949933294, 'gamma': 1.6966067304892181e-06, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.05818177364661526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:37,415]\u001b[0m Trial 51 finished with value: 0.05881814522671453 and parameters: {'booster': 'gbtree', 'lambda': 3.0333886686812864e-06, 'alpha': 0.07853323917237322, 'subsample': 0.5288132966477753, 'colsample_bytree': 0.7303638403714873, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.07403404417741952, 'gamma': 5.348795614107776e-07, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.05818177364661526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:37,785]\u001b[0m Trial 52 finished with value: 0.05690292455585754 and parameters: {'booster': 'gbtree', 'lambda': 9.836274213762358e-07, 'alpha': 0.07302074462303192, 'subsample': 0.5723314352174548, 'colsample_bytree': 0.7488799128909757, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.1675113745454609, 'gamma': 8.982711333522281e-07, 'grow_policy': 'depthwise'}. Best is trial 52 with value: 0.05690292455585754.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:38,128]\u001b[0m Trial 53 finished with value: 0.05830998240362577 and parameters: {'booster': 'gbtree', 'lambda': 3.5231595349237605e-06, 'alpha': 0.5538853029645919, 'subsample': 0.6393666290720236, 'colsample_bytree': 0.7167575260822021, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.12301562895020335, 'gamma': 2.5295212338614855e-08, 'grow_policy': 'depthwise'}. Best is trial 52 with value: 0.05690292455585754.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:38,467]\u001b[0m Trial 54 finished with value: 0.055609365506183485 and parameters: {'booster': 'gbtree', 'lambda': 3.1978989534227847e-08, 'alpha': 0.518701121399868, 'subsample': 0.702266849304579, 'colsample_bytree': 0.7186718609431457, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.21709955870742959, 'gamma': 3.390236733648066e-08, 'grow_policy': 'depthwise'}. Best is trial 54 with value: 0.055609365506183485.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:38,825]\u001b[0m Trial 55 finished with value: 0.14674448624518946 and parameters: {'booster': 'gbtree', 'lambda': 2.3926972272846876e-08, 'alpha': 0.4955055512988231, 'subsample': 0.798903722132082, 'colsample_bytree': 0.8268207936155881, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.013998109906656354, 'gamma': 3.297733797499252e-08, 'grow_policy': 'depthwise'}. Best is trial 54 with value: 0.055609365506183485.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:40,431]\u001b[0m Trial 56 finished with value: 0.07189944555844818 and parameters: {'booster': 'dart', 'lambda': 3.662962154060862e-07, 'alpha': 0.1443255173519828, 'subsample': 0.6980137239332972, 'colsample_bytree': 0.7332296170856577, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.0362366259816375, 'gamma': 0.9015225433442177, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 2.3776688950631578e-05, 'skip_drop': 0.0009515174560077562}. Best is trial 54 with value: 0.055609365506183485.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:40,770]\u001b[0m Trial 57 finished with value: 0.05432879813196563 and parameters: {'booster': 'gbtree', 'lambda': 1.1291570867942927e-07, 'alpha': 0.5105310640485401, 'subsample': 0.6536543813408988, 'colsample_bytree': 0.672517573454817, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.15101089087836886, 'gamma': 2.1068899566025763e-08, 'grow_policy': 'depthwise'}. Best is trial 57 with value: 0.05432879813196563.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:41,116]\u001b[0m Trial 58 finished with value: 0.05091251644189493 and parameters: {'booster': 'gbtree', 'lambda': 2.7958691329834914e-08, 'alpha': 0.5576434224560819, 'subsample': 0.7285455347056488, 'colsample_bytree': 0.7118967293097412, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.22477949004956763, 'gamma': 1.1107555557445937e-07, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.05091251644189493.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:30:41,449]\u001b[0m Trial 59 finished with value: 0.05135579265252346 and parameters: {'booster': 'gbtree', 'lambda': 9.284077141407044e-08, 'alpha': 0.6008039418741633, 'subsample': 0.7337185380957446, 'colsample_bytree': 0.668192152875751, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.2265505946318991, 'gamma': 1.3054584935389536e-07, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.05091251644189493.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:41,558]\u001b[0m Trial 60 finished with value: 1.0092133047073915 and parameters: {'booster': 'gblinear', 'lambda': 1.191209716138312e-07, 'alpha': 0.2154017850984506, 'subsample': 0.8193484503401615, 'colsample_bytree': 0.6764232887816065}. Best is trial 58 with value: 0.05091251644189493.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:41,896]\u001b[0m Trial 61 finished with value: 0.052907694910314974 and parameters: {'booster': 'gbtree', 'lambda': 2.1698442029548085e-08, 'alpha': 0.5791952517222144, 'subsample': 0.7128863384565141, 'colsample_bytree': 0.7001817955343486, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.2154802464393124, 'gamma': 1.277079266023288e-07, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.05091251644189493.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:42,190]\u001b[0m Trial 62 finished with value: 0.0619549125906103 and parameters: {'booster': 'gbtree', 'lambda': 2.6339554764944962e-08, 'alpha': 0.5861825988053274, 'subsample': 0.7359927772644453, 'colsample_bytree': 0.6571606437397433, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.5512281559282709, 'gamma': 1.117693127195252e-07, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.05091251644189493.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:42,517]\u001b[0m Trial 63 finished with value: 0.05552392600772683 and parameters: {'booster': 'gbtree', 'lambda': 3.688830850105956e-08, 'alpha': 0.937242203542099, 'subsample': 0.7246303072463791, 'colsample_bytree': 0.7638848364427305, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.24560408881898554, 'gamma': 4.502127983002496e-08, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.05091251644189493.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:42,866]\u001b[0m Trial 64 finished with value: 0.056659883404003054 and parameters: {'booster': 'gbtree', 'lambda': 3.636343503470084e-08, 'alpha': 0.8678418800332351, 'subsample': 0.7077080715378764, 'colsample_bytree': 0.8860566953626332, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.2611610258922004, 'gamma': 1.336331244199135e-07, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.05091251644189493.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:43,210]\u001b[0m Trial 65 finished with value: 0.06020224625042915 and parameters: {'booster': 'gbtree', 'lambda': 4.1332036382676556e-08, 'alpha': 0.9685256791850478, 'subsample': 0.719770165470652, 'colsample_bytree': 0.8962649126245005, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.29216945822569784, 'gamma': 1.344198315210387e-07, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.05091251644189493.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:43,579]\u001b[0m Trial 66 finished with value: 0.061495893152494756 and parameters: {'booster': 'gbtree', 'lambda': 1.7984064837368753e-08, 'alpha': 0.33343265191693977, 'subsample': 0.6692794328385593, 'colsample_bytree': 0.9130204651699563, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.3332813266788902, 'gamma': 4.160034849335517e-08, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.05091251644189493.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:43,886]\u001b[0m Trial 67 finished with value: 0.08236641260498252 and parameters: {'booster': 'gbtree', 'lambda': 1.0523995801603665e-07, 'alpha': 0.33803916904282283, 'subsample': 0.7669048458052447, 'colsample_bytree': 0.8631220441956673, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.9754286552180939, 'gamma': 2.1961576028913915e-08, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.05091251644189493.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:44,296]\u001b[0m Trial 68 finished with value: 0.056859337550231426 and parameters: {'booster': 'gbtree', 'lambda': 4.0951633019030085e-08, 'alpha': 0.5922930873623511, 'subsample': 0.8573468549875629, 'colsample_bytree': 0.8087615561493888, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.21088808100261594, 'gamma': 0.04827153606408146, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.05091251644189493.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:44,615]\u001b[0m Trial 69 finished with value: 1.3078296846645456 and parameters: {'booster': 'gbtree', 'lambda': 1.5161950034203997e-07, 'alpha': 0.14648168763494843, 'subsample': 0.7148319631862834, 'colsample_bytree': 0.7833477331703387, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.00025506982416225674, 'gamma': 6.992311674534368e-08, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.05091251644189493.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:44,934]\u001b[0m Trial 70 finished with value: 0.058798181985155566 and parameters: {'booster': 'gbtree', 'lambda': 1.511289216289279e-08, 'alpha': 0.9825573649821633, 'subsample': 0.6918308656942902, 'colsample_bytree': 0.9828392316610853, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.45968105916494056, 'gamma': 2.8485726927506057e-07, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.05091251644189493.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:45,326]\u001b[0m Trial 71 finished with value: 0.05670237730550815 and parameters: {'booster': 'gbtree', 'lambda': 4.889225238072108e-08, 'alpha': 0.5482486843182672, 'subsample': 0.8580547085196505, 'colsample_bytree': 0.8126096454619105, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.2930967645420245, 'gamma': 0.00971337695698648, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.05091251644189493.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:45,699]\u001b[0m Trial 72 finished with value: 0.05360715254133144 and parameters: {'booster': 'gbtree', 'lambda': 8.511569113875871e-08, 'alpha': 0.5100033028859007, 'subsample': 0.7948900981829622, 'colsample_bytree': 0.7043700111341876, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.18828754888665392, 'gamma': 0.009294156530148505, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.05091251644189493.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:46,095]\u001b[0m Trial 73 finished with value: 0.05715171022041352 and parameters: {'booster': 'gbtree', 'lambda': 6.86970182647468e-08, 'alpha': 0.22548875158843937, 'subsample': 0.7972710945954193, 'colsample_bytree': 0.7053766628471093, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.14204971426256768, 'gamma': 0.00016681375169401425, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.05091251644189493.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:46,472]\u001b[0m Trial 74 finished with value: 0.0608619075714915 and parameters: {'booster': 'gbtree', 'lambda': 3.0371364820902514e-07, 'alpha': 0.11732212054417195, 'subsample': 0.6433714262671708, 'colsample_bytree': 0.6469394192577267, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.030940033221888704, 'gamma': 0.00037726545797654384, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.05091251644189493.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:46,812]\u001b[0m Trial 75 finished with value: 0.07167442801825047 and parameters: {'booster': 'gbtree', 'lambda': 3.311239634987732e-08, 'alpha': 0.3987725438094873, 'subsample': 0.7750694606308237, 'colsample_bytree': 0.6749607562454089, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.5568166343384382, 'gamma': 1.5949251125572128e-08, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.05091251644189493.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:47,191]\u001b[0m Trial 76 finished with value: 1.370997968259311 and parameters: {'booster': 'gbtree', 'lambda': 8.587012876091532e-08, 'alpha': 0.21602696348888276, 'subsample': 0.8253717511512902, 'colsample_bytree': 0.7153646657437798, 'max_depth': 9, 'min_child_weight': 3, 'eta': 7.134764374083402e-07, 'gamma': 0.1440108968709335, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.05091251644189493.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:48,291]\u001b[0m Trial 77 finished with value: 0.06714115619346707 and parameters: {'booster': 'dart', 'lambda': 1.3748259345047014e-08, 'alpha': 0.6522450602959055, 'subsample': 0.7498915244677634, 'colsample_bytree': 0.6350774605880802, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.10648583843225345, 'gamma': 1.1389183450702802e-07, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.4442984188765047, 'skip_drop': 1.1133081300002907e-08}. Best is trial 58 with value: 0.05091251644189493.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:30:48,765]\u001b[0m A new study created in memory with name: no-name-06035b85-b573-45fc-af00-ec9dab29f8c6\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:30:55,748]\u001b[0m Trial 0 finished with value: 0.8938206889138088 and parameters: {'booster': 'dart', 'lambda': 0.00019519716682629319, 'alpha': 1.88628809948022e-07, 'subsample': 0.6784366751525123, 'colsample_bytree': 0.6577944272130951, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.19732378722272384, 'gamma': 1.804244454983883e-05, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 4.7044993294484653e-05, 'skip_drop': 0.16176402443332713}. Best is trial 0 with value: 0.8938206889138088.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:02,883]\u001b[0m Trial 1 finished with value: 0.8769590595434335 and parameters: {'booster': 'dart', 'lambda': 0.36336041657701557, 'alpha': 0.23411216543698926, 'subsample': 0.8390943398358808, 'colsample_bytree': 0.609567713138895, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.000723251877200352, 'gamma': 2.565748602364875e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.8656250066513555e-06, 'skip_drop': 0.19831364156928938}. Best is trial 0 with value: 0.8938206889138088.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:08,573]\u001b[0m Trial 2 finished with value: 0.8533981966098766 and parameters: {'booster': 'dart', 'lambda': 3.0057483918791566e-07, 'alpha': 0.004543780166596284, 'subsample': 0.4268218235065815, 'colsample_bytree': 0.6030311114922098, 'max_depth': 5, 'min_child_weight': 5, 'eta': 0.04859754759841426, 'gamma': 2.2591718966865617e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.24568462202385524, 'skip_drop': 9.557792138229896e-05}. Best is trial 0 with value: 0.8938206889138088.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:15,383]\u001b[0m Trial 3 finished with value: 0.8843696567437194 and parameters: {'booster': 'dart', 'lambda': 0.0008381258721082402, 'alpha': 7.028829037348469e-08, 'subsample': 0.35414729299117803, 'colsample_bytree': 0.6308829452308241, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.02045160985580269, 'gamma': 0.1283850147332271, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 7.65920784945797e-06, 'skip_drop': 0.028526564900849923}. Best is trial 0 with value: 0.8938206889138088.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:16,174]\u001b[0m Trial 4 finished with value: 0.8511492185258328 and parameters: {'booster': 'gbtree', 'lambda': 8.144692450570726e-07, 'alpha': 1.6042462078396738e-07, 'subsample': 0.8054409123203903, 'colsample_bytree': 0.9920480111735122, 'max_depth': 7, 'min_child_weight': 9, 'eta': 1.0919810631189874e-05, 'gamma': 0.0008939320386059219, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.8938206889138088.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:23,048]\u001b[0m Trial 5 finished with value: 0.8219419460256551 and parameters: {'booster': 'dart', 'lambda': 9.120694425089874e-06, 'alpha': 4.005049594965908e-06, 'subsample': 0.872992107933029, 'colsample_bytree': 0.23512338016612544, 'max_depth': 5, 'min_child_weight': 2, 'eta': 0.003341736498081791, 'gamma': 0.33026128678615885, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.00019902977023734047, 'skip_drop': 0.0002810052890470148}. Best is trial 0 with value: 0.8938206889138088.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:31:30,719]\u001b[0m A new study created in memory with name: no-name-59df38c6-b901-459e-82eb-94163ba845f2\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:30,892]\u001b[0m Trial 0 finished with value: 0.40645389849515856 and parameters: {'booster': 'gbtree', 'lambda': 3.499395013354603e-05, 'alpha': 0.003291754253290732, 'subsample': 0.4687367476572729, 'colsample_bytree': 0.712875460975009, 'max_depth': 7, 'min_child_weight': 6, 'eta': 1.0846568385402943e-08, 'gamma': 8.186823623949567e-05, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.40645389849515856.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:31,054]\u001b[0m Trial 1 finished with value: 0.4064502393810244 and parameters: {'booster': 'gbtree', 'lambda': 0.037145357151594796, 'alpha': 0.0016506590627346895, 'subsample': 0.3161564247661008, 'colsample_bytree': 0.9369254436063925, 'max_depth': 9, 'min_child_weight': 8, 'eta': 3.5464344899638964e-08, 'gamma': 8.622772673843895e-06, 'grow_policy': 'lossguide'}. Best is trial 1 with value: 0.4064502393810244.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:31,295]\u001b[0m Trial 2 finished with value: 0.3973657812692245 and parameters: {'booster': 'gbtree', 'lambda': 3.437625137359862e-08, 'alpha': 0.1950675666133111, 'subsample': 0.9609797791202006, 'colsample_bytree': 0.6859366009102741, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.00012609785291623523, 'gamma': 0.0016533656755097327, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 0.3973657812692245.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:32,713]\u001b[0m Trial 3 finished with value: 0.40620051989569284 and parameters: {'booster': 'dart', 'lambda': 1.591896402178157e-07, 'alpha': 0.0004370579952762005, 'subsample': 0.7570745206184053, 'colsample_bytree': 0.44352353664482475, 'max_depth': 9, 'min_child_weight': 7, 'eta': 3.474597058634437e-06, 'gamma': 8.760864497600134e-06, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.001148323104891193, 'skip_drop': 0.00036277856503391534}. Best is trial 2 with value: 0.3973657812692245.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:32,833]\u001b[0m Trial 4 finished with value: 0.4303688963332084 and parameters: {'booster': 'gblinear', 'lambda': 1.0978935347343532e-05, 'alpha': 0.00044143802765846693, 'subsample': 0.29531247402337435, 'colsample_bytree': 0.40759100054612507}. Best is trial 2 with value: 0.3973657812692245.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:33,013]\u001b[0m Trial 5 finished with value: 0.403176604996541 and parameters: {'booster': 'gbtree', 'lambda': 0.005059228557842376, 'alpha': 7.305977797663803e-08, 'subsample': 0.8100864988814283, 'colsample_bytree': 0.8816157149825468, 'max_depth': 9, 'min_child_weight': 10, 'eta': 4.0765116444687714e-05, 'gamma': 0.0047887244881480474, 'grow_policy': 'depthwise'}. Best is trial 2 with value: 0.3973657812692245.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:33,222]\u001b[0m Trial 6 finished with value: 0.22467296680477314 and parameters: {'booster': 'gbtree', 'lambda': 0.2871340592296977, 'alpha': 0.005658087766663721, 'subsample': 0.8871171798102899, 'colsample_bytree': 0.7849831471423003, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.0031850212080189342, 'gamma': 1.0166100191937816e-06, 'grow_policy': 'lossguide'}. Best is trial 6 with value: 0.22467296680477314.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:34,560]\u001b[0m Trial 7 finished with value: 0.30633000789287246 and parameters: {'booster': 'dart', 'lambda': 0.0051289973068581515, 'alpha': 0.2849887325959677, 'subsample': 0.9140240439510172, 'colsample_bytree': 0.4185058081755589, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.0027842087314110496, 'gamma': 2.1623804904269053e-05, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.04935432427020031, 'skip_drop': 2.0938453321928618e-05}. Best is trial 6 with value: 0.22467296680477314.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:34,799]\u001b[0m Trial 8 finished with value: 0.03382694577815163 and parameters: {'booster': 'gbtree', 'lambda': 0.24413848940463323, 'alpha': 1.3229678493667462e-07, 'subsample': 0.9244155876706583, 'colsample_bytree': 0.5537279727709161, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.02820492752191438, 'gamma': 0.00014804379668185733, 'grow_policy': 'depthwise'}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:34,919]\u001b[0m Trial 9 finished with value: 0.47596367020888247 and parameters: {'booster': 'gblinear', 'lambda': 9.845932666489021e-08, 'alpha': 8.416283570199761e-08, 'subsample': 0.2985940697083974, 'colsample_bytree': 0.9870497922478412}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:31:35,054]\u001b[0m Trial 10 finished with value: 0.09927676445754417 and parameters: {'booster': 'gblinear', 'lambda': 0.9849280307975007, 'alpha': 2.4601456349915072e-06, 'subsample': 0.6365570976363693, 'colsample_bytree': 0.2030751689033795}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:35,189]\u001b[0m Trial 11 finished with value: 0.09788143047464443 and parameters: {'booster': 'gblinear', 'lambda': 0.778034522071443, 'alpha': 4.228032110904236e-06, 'subsample': 0.6157981124977088, 'colsample_bytree': 0.2148244167685659}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:35,324]\u001b[0m Trial 12 finished with value: 0.2708023610650585 and parameters: {'booster': 'gblinear', 'lambda': 0.00080550142755082, 'alpha': 6.5074105166176405e-06, 'subsample': 0.6237115251377168, 'colsample_bytree': 0.2019444646314606}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:35,460]\u001b[0m Trial 13 finished with value: 0.10821500492708726 and parameters: {'booster': 'gblinear', 'lambda': 0.07572075895128275, 'alpha': 2.1985384078679876e-06, 'subsample': 0.5153049839955005, 'colsample_bytree': 0.5595101636614673}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:36,850]\u001b[0m Trial 14 finished with value: 0.7249114805660988 and parameters: {'booster': 'dart', 'lambda': 0.9770188989753914, 'alpha': 1.9415916266076762e-08, 'subsample': 0.7325193228584874, 'colsample_bytree': 0.2972665737125392, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.8105130544877769, 'gamma': 0.6405517428658376, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 2.854027489961005e-08, 'skip_drop': 0.29802075938361633}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:37,049]\u001b[0m Trial 15 finished with value: 0.21522142530121108 and parameters: {'booster': 'gbtree', 'lambda': 2.9542250373641133e-06, 'alpha': 2.9492130008926085e-05, 'subsample': 0.5315345078678222, 'colsample_bytree': 0.620557647674971, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.25378128527375343, 'gamma': 1.690784380457573e-08, 'grow_policy': 'depthwise'}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:37,186]\u001b[0m Trial 16 finished with value: 0.36133816409367214 and parameters: {'booster': 'gblinear', 'lambda': 0.0003036570980758194, 'alpha': 4.694685489051493e-07, 'subsample': 0.4340985624424189, 'colsample_bytree': 0.5423687012539203}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:37,394]\u001b[0m Trial 17 finished with value: 0.04564103105085074 and parameters: {'booster': 'gbtree', 'lambda': 0.01940336607155907, 'alpha': 4.39309373864626e-05, 'subsample': 0.6641861395232673, 'colsample_bytree': 0.30009739432172045, 'max_depth': 5, 'min_child_weight': 2, 'eta': 0.02911866964498517, 'gamma': 0.01509116453920909, 'grow_policy': 'lossguide'}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:37,607]\u001b[0m Trial 18 finished with value: 0.05161200840034394 and parameters: {'booster': 'gbtree', 'lambda': 0.014379297418066525, 'alpha': 0.0001025934496702255, 'subsample': 0.9958950793658174, 'colsample_bytree': 0.3229664067046899, 'max_depth': 5, 'min_child_weight': 2, 'eta': 0.01727844673081372, 'gamma': 0.03202917603516227, 'grow_policy': 'lossguide'}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:37,833]\u001b[0m Trial 19 finished with value: 0.03871924660681336 and parameters: {'booster': 'gbtree', 'lambda': 0.0013319174048128251, 'alpha': 2.0803398209268516e-07, 'subsample': 0.8253610371618894, 'colsample_bytree': 0.48938301091337677, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.036172921903643664, 'gamma': 0.001849941474345302, 'grow_policy': 'lossguide'}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:38,037]\u001b[0m Trial 20 finished with value: 0.38641259421023777 and parameters: {'booster': 'gbtree', 'lambda': 0.0008664184655018394, 'alpha': 1.2551604034934825e-08, 'subsample': 0.8256675732007477, 'colsample_bytree': 0.5052318832728386, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.0002828590864386704, 'gamma': 0.0005782046942370035, 'grow_policy': 'lossguide'}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:38,244]\u001b[0m Trial 21 finished with value: 0.07700876108530336 and parameters: {'booster': 'gbtree', 'lambda': 0.00297838594483555, 'alpha': 3.252660934330439e-07, 'subsample': 0.7085243288219718, 'colsample_bytree': 0.3227605299132693, 'max_depth': 5, 'min_child_weight': 3, 'eta': 0.09651307749641604, 'gamma': 0.0562096321860102, 'grow_policy': 'lossguide'}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:38,516]\u001b[0m Trial 22 finished with value: 0.043833869940134954 and parameters: {'booster': 'gbtree', 'lambda': 0.0001245645566509848, 'alpha': 5.087901971137428e-07, 'subsample': 0.8489453000478335, 'colsample_bytree': 0.4802860690635294, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.01976212994563593, 'gamma': 0.0005105877718221481, 'grow_policy': 'lossguide'}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:38,777]\u001b[0m Trial 23 finished with value: 0.22720632198634763 and parameters: {'booster': 'gbtree', 'lambda': 0.00010488790277944671, 'alpha': 3.0489727715077314e-07, 'subsample': 0.8487607092050167, 'colsample_bytree': 0.476576967557234, 'max_depth': 7, 'min_child_weight': 5, 'eta': 0.0034015809559656885, 'gamma': 0.0002556641197280505, 'grow_policy': 'lossguide'}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:39,071]\u001b[0m Trial 24 finished with value: 0.0339914856465447 and parameters: {'booster': 'gbtree', 'lambda': 3.2810323841612693e-06, 'alpha': 4.4318257481947056e-08, 'subsample': 0.926430312211679, 'colsample_bytree': 0.6023828917784151, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.024912611273346725, 'gamma': 0.0001237232112303928, 'grow_policy': 'lossguide'}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:39,347]\u001b[0m Trial 25 finished with value: 0.364573471935035 and parameters: {'booster': 'gbtree', 'lambda': 1.0915981252125592e-06, 'alpha': 6.26204079961126e-08, 'subsample': 0.9468475324852393, 'colsample_bytree': 0.6119161428266083, 'max_depth': 7, 'min_child_weight': 5, 'eta': 0.000615491611556012, 'gamma': 1.6322203353147852e-06, 'grow_policy': 'depthwise'}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:40,990]\u001b[0m Trial 26 finished with value: 0.07395098914327233 and parameters: {'booster': 'dart', 'lambda': 1.0522450673650553e-06, 'alpha': 1.0036478012251038e-08, 'subsample': 0.9997911085419905, 'colsample_bytree': 0.6943233198222062, 'max_depth': 5, 'min_child_weight': 3, 'eta': 0.08252766963003774, 'gamma': 6.815523239121165e-05, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 2.906070931857582e-08, 'skip_drop': 2.4862780705892315e-08}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:41,340]\u001b[0m Trial 27 finished with value: 0.12280655539178428 and parameters: {'booster': 'gbtree', 'lambda': 1.4982318783954261e-05, 'alpha': 6.47548294974767e-08, 'subsample': 0.7741692943829429, 'colsample_bytree': 0.8039635175307285, 'max_depth': 7, 'min_child_weight': 5, 'eta': 0.6635454004126945, 'gamma': 0.0024748683573946753, 'grow_policy': 'lossguide'}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:41,530]\u001b[0m Trial 28 finished with value: 0.40583357978671647 and parameters: {'booster': 'gbtree', 'lambda': 0.11022264413591513, 'alpha': 9.874133429568611e-07, 'subsample': 0.8978067237220285, 'colsample_bytree': 0.627437670713504, 'max_depth': 3, 'min_child_weight': 3, 'eta': 8.584954791487926e-06, 'gamma': 7.099503188882738e-07, 'grow_policy': 'depthwise'}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:41,835]\u001b[0m Trial 29 finished with value: 0.0956977874887091 and parameters: {'booster': 'gbtree', 'lambda': 4.0245003973033645e-05, 'alpha': 1.756944407593692e-05, 'subsample': 0.7919108570857744, 'colsample_bytree': 0.7612583674639526, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.008057571967969607, 'gamma': 0.3548756419003392, 'grow_policy': 'lossguide'}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:31:42,068]\u001b[0m Trial 30 finished with value: 0.3521199425027616 and parameters: {'booster': 'gbtree', 'lambda': 3.616387132639641e-06, 'alpha': 1.324142489936153e-07, 'subsample': 0.9339860724998224, 'colsample_bytree': 0.5634714186942356, 'max_depth': 5, 'min_child_weight': 3, 'eta': 0.0008380594183541511, 'gamma': 0.00012694220004995442, 'grow_policy': 'depthwise'}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:42,330]\u001b[0m Trial 31 finished with value: 0.04313184117012238 and parameters: {'booster': 'gbtree', 'lambda': 0.00016866471883556205, 'alpha': 4.711771728180125e-07, 'subsample': 0.8619485918371571, 'colsample_bytree': 0.3800471949959472, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.03581111348138138, 'gamma': 0.0004565010714053332, 'grow_policy': 'lossguide'}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:42,598]\u001b[0m Trial 32 finished with value: 0.08486165658883896 and parameters: {'booster': 'gbtree', 'lambda': 0.0004962887541219859, 'alpha': 2.993549525551159e-08, 'subsample': 0.8690187886949745, 'colsample_bytree': 0.37692876435341727, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.09319251681372723, 'gamma': 0.0007576992088734404, 'grow_policy': 'lossguide'}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:42,824]\u001b[0m Trial 33 finished with value: 0.07700953625689178 and parameters: {'booster': 'gbtree', 'lambda': 4.327266219482457e-05, 'alpha': 1.0699921339193082e-06, 'subsample': 0.22654300144317369, 'colsample_bytree': 0.5016796126877984, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.0515408944260431, 'gamma': 0.006846498177258777, 'grow_policy': 'lossguide'}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:43,080]\u001b[0m Trial 34 finished with value: 0.1437167957242531 and parameters: {'booster': 'gbtree', 'lambda': 1.2014657520172174e-08, 'alpha': 0.02289679570891241, 'subsample': 0.7091101249122843, 'colsample_bytree': 0.6695889825691316, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.33401976204833156, 'gamma': 1.5995194387120483e-05, 'grow_policy': 'lossguide'}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:43,333]\u001b[0m Trial 35 finished with value: 0.1246140205946453 and parameters: {'booster': 'gbtree', 'lambda': 0.0016442944899729786, 'alpha': 1.9722916200302394e-07, 'subsample': 0.9657935374419715, 'colsample_bytree': 0.3684041745891831, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.007335067373464807, 'gamma': 6.812937722042152e-05, 'grow_policy': 'lossguide'}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:44,516]\u001b[0m Trial 36 finished with value: 0.06361041105911094 and parameters: {'booster': 'dart', 'lambda': 9.850052152225598e-06, 'alpha': 3.0116586112841694e-08, 'subsample': 0.9269042698776824, 'colsample_bytree': 0.45010409336978263, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.15330881970769042, 'gamma': 0.001344855804164124, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.9636389896807761, 'skip_drop': 0.5949826653810583}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:44,779]\u001b[0m Trial 37 finished with value: 0.31960740892188216 and parameters: {'booster': 'gbtree', 'lambda': 3.570719058205339e-07, 'alpha': 9.86144889270351e-06, 'subsample': 0.815016423936643, 'colsample_bytree': 0.5327142892432628, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.0013265610840332705, 'gamma': 0.00017426722607990017, 'grow_policy': 'depthwise'}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:45,029]\u001b[0m Trial 38 finished with value: 0.07178421890051993 and parameters: {'booster': 'gbtree', 'lambda': 0.0002130691710737484, 'alpha': 1.0406158645467026e-06, 'subsample': 0.8852897561380006, 'colsample_bytree': 0.651855792084368, 'max_depth': 5, 'min_child_weight': 5, 'eta': 0.010731805319360951, 'gamma': 4.742953653590115e-05, 'grow_policy': 'lossguide'}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:45,244]\u001b[0m Trial 39 finished with value: 0.40645044969881877 and parameters: {'booster': 'gbtree', 'lambda': 0.01945812813076165, 'alpha': 0.00044566522216321993, 'subsample': 0.7735915073379593, 'colsample_bytree': 0.42020482185049096, 'max_depth': 7, 'min_child_weight': 4, 'eta': 5.428940069913935e-08, 'gamma': 2.492729379017516e-06, 'grow_policy': 'depthwise'}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:46,710]\u001b[0m Trial 40 finished with value: 0.40339184322688104 and parameters: {'booster': 'dart', 'lambda': 0.2242114872190269, 'alpha': 1.427304264499736e-07, 'subsample': 0.9526953053483723, 'colsample_bytree': 0.5823813119561303, 'max_depth': 9, 'min_child_weight': 3, 'eta': 4.206785450271682e-05, 'gamma': 1.2211208916982802e-07, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.0941651025560092e-05, 'skip_drop': 6.755385034407841e-08}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:46,985]\u001b[0m Trial 41 finished with value: 0.06516595102301694 and parameters: {'booster': 'gbtree', 'lambda': 0.00011190046201887221, 'alpha': 4.0432457745050034e-07, 'subsample': 0.8532675501648215, 'colsample_bytree': 0.47698684300486843, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.032091440875232885, 'gamma': 0.00041216675548892885, 'grow_policy': 'lossguide'}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:47,243]\u001b[0m Trial 42 finished with value: 0.04518502610893135 and parameters: {'booster': 'gbtree', 'lambda': 1.515114793096444e-05, 'alpha': 3.161231452436524e-08, 'subsample': 0.8360495704224017, 'colsample_bytree': 0.3651400814639002, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.021462541010332997, 'gamma': 0.0017604267730507949, 'grow_policy': 'lossguide'}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:47,468]\u001b[0m Trial 43 finished with value: 0.15833780127725422 and parameters: {'booster': 'gbtree', 'lambda': 0.005677449580492338, 'alpha': 0.8060251846911151, 'subsample': 0.9050629839039253, 'colsample_bytree': 0.5148646151828891, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.0057248040165382786, 'gamma': 0.0002831737306059563, 'grow_policy': 'lossguide'}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:47,747]\u001b[0m Trial 44 finished with value: 0.26433720714646075 and parameters: {'booster': 'gbtree', 'lambda': 6.786837048086374e-05, 'alpha': 2.3111087333706574e-06, 'subsample': 0.7343901146590737, 'colsample_bytree': 0.45951937367456236, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.27016279487390726, 'gamma': 0.005613361668040368, 'grow_policy': 'lossguide'}. Best is trial 8 with value: 0.03382694577815163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:48,106]\u001b[0m Trial 45 finished with value: 0.021748589330333898 and parameters: {'booster': 'gbtree', 'lambda': 0.00026163224412662157, 'alpha': 6.383714933501765e-07, 'subsample': 0.8603506565307538, 'colsample_bytree': 0.7497470775443669, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.04355356262473961, 'gamma': 3.589587306776174e-05, 'grow_policy': 'lossguide'}. Best is trial 45 with value: 0.021748589330333898.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:48,303]\u001b[0m Trial 46 finished with value: 0.30809601246832846 and parameters: {'booster': 'gbtree', 'lambda': 0.000865286219109533, 'alpha': 5.8420753073653844e-08, 'subsample': 0.41754854667058816, 'colsample_bytree': 0.7348806125897951, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.001534969496799178, 'gamma': 7.900668612197531e-06, 'grow_policy': 'depthwise'}. Best is trial 45 with value: 0.021748589330333898.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:48,669]\u001b[0m Trial 47 finished with value: 0.027884676928303067 and parameters: {'booster': 'gbtree', 'lambda': 5.848979203637967e-06, 'alpha': 1.434320913064589e-07, 'subsample': 0.9754670858163978, 'colsample_bytree': 0.8540791198769591, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.05497521272025582, 'gamma': 2.97982997252121e-05, 'grow_policy': 'lossguide'}. Best is trial 45 with value: 0.021748589330333898.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:31:48,804]\u001b[0m Trial 48 finished with value: 0.47492201790956123 and parameters: {'booster': 'gblinear', 'lambda': 5.80115149195948e-06, 'alpha': 1.1592902343371431e-07, 'subsample': 0.9761171114328796, 'colsample_bytree': 0.8428877003598694}. Best is trial 45 with value: 0.021748589330333898.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:50,252]\u001b[0m Trial 49 finished with value: 0.4064341645833053 and parameters: {'booster': 'dart', 'lambda': 1.544473600131357e-06, 'alpha': 4.027506126182333e-06, 'subsample': 0.9179570703454657, 'colsample_bytree': 0.9115921337620136, 'max_depth': 9, 'min_child_weight': 7, 'eta': 2.3453711681321198e-07, 'gamma': 5.2918962178988504e-06, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.2794235893895881e-05, 'skip_drop': 0.00038549957787557956}. Best is trial 45 with value: 0.021748589330333898.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:50,643]\u001b[0m Trial 50 finished with value: 0.4991011148670075 and parameters: {'booster': 'gbtree', 'lambda': 0.04599049372310816, 'alpha': 1.1228418240274313e-06, 'subsample': 0.5576267750245958, 'colsample_bytree': 0.9737824567219853, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.8284386874372591, 'gamma': 2.7238836416625985e-05, 'grow_policy': 'lossguide'}. Best is trial 45 with value: 0.021748589330333898.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:51,005]\u001b[0m Trial 51 finished with value: 0.04080333057817188 and parameters: {'booster': 'gbtree', 'lambda': 2.4381004079842376e-05, 'alpha': 1.6472359090532214e-07, 'subsample': 0.8791699660606455, 'colsample_bytree': 0.9198621285206778, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.053132650391107955, 'gamma': 3.113973001003636e-05, 'grow_policy': 'lossguide'}. Best is trial 45 with value: 0.021748589330333898.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:51,383]\u001b[0m Trial 52 finished with value: 0.06158669988464138 and parameters: {'booster': 'gbtree', 'lambda': 6.6441508427900006e-06, 'alpha': 1.943011426491586e-07, 'subsample': 0.8930445006675265, 'colsample_bytree': 0.8651029475845705, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.18310023239809484, 'gamma': 1.9485561349928937e-05, 'grow_policy': 'lossguide'}. Best is trial 45 with value: 0.021748589330333898.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:51,736]\u001b[0m Trial 53 finished with value: 0.03337810684896674 and parameters: {'booster': 'gbtree', 'lambda': 2.89622195251485e-07, 'alpha': 3.929467096870703e-08, 'subsample': 0.9788590463638622, 'colsample_bytree': 0.9396064801627197, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.05115049862977674, 'gamma': 3.214430807154956e-05, 'grow_policy': 'lossguide'}. Best is trial 45 with value: 0.021748589330333898.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:51,978]\u001b[0m Trial 54 finished with value: 0.04309705466406484 and parameters: {'booster': 'gbtree', 'lambda': 4.325642250240729e-07, 'alpha': 2.0211694554481397e-08, 'subsample': 0.9700929005544713, 'colsample_bytree': 0.9650755216163799, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.014140732756907283, 'gamma': 0.00011166718616606611, 'grow_policy': 'lossguide'}. Best is trial 45 with value: 0.021748589330333898.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:52,112]\u001b[0m Trial 55 finished with value: 0.4813544868373208 and parameters: {'booster': 'gblinear', 'lambda': 5.455069717030254e-07, 'alpha': 3.2505157793668316e-08, 'subsample': 0.9385768409983403, 'colsample_bytree': 0.8818745240655274}. Best is trial 45 with value: 0.021748589330333898.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:52,472]\u001b[0m Trial 56 finished with value: 0.17916530004586423 and parameters: {'booster': 'gbtree', 'lambda': 7.75978543049104e-08, 'alpha': 5.826707114131402e-08, 'subsample': 0.9986807630558868, 'colsample_bytree': 0.8006832515143459, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.00424463070984101, 'gamma': 3.4126770961984826e-06, 'grow_policy': 'lossguide'}. Best is trial 45 with value: 0.021748589330333898.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:52,861]\u001b[0m Trial 57 finished with value: 0.09201012035762476 and parameters: {'booster': 'gbtree', 'lambda': 1.0956288308150327e-07, 'alpha': 1.0195482229469384e-08, 'subsample': 0.8032684192619852, 'colsample_bytree': 0.9401519547454813, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.4552591581500508, 'gamma': 1.3747798178993522e-05, 'grow_policy': 'lossguide'}. Best is trial 45 with value: 0.021748589330333898.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:53,272]\u001b[0m Trial 58 finished with value: 0.0384678619320705 and parameters: {'booster': 'gbtree', 'lambda': 2.755920948278928e-06, 'alpha': 7.15202940805402e-07, 'subsample': 0.9151601083019406, 'colsample_bytree': 0.9968971684562037, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.10531086620532948, 'gamma': 3.9794416892023275e-07, 'grow_policy': 'depthwise'}. Best is trial 45 with value: 0.021748589330333898.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:53,689]\u001b[0m Trial 59 finished with value: 0.06939706709264502 and parameters: {'booster': 'gbtree', 'lambda': 2.264009562687829e-06, 'alpha': 6.198688792882361e-07, 'subsample': 0.9708911412204433, 'colsample_bytree': 0.9985567932686144, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.17469341297051785, 'gamma': 1.4655248925412294e-07, 'grow_policy': 'depthwise'}. Best is trial 45 with value: 0.021748589330333898.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:53,823]\u001b[0m Trial 60 finished with value: 0.48804203969519944 and parameters: {'booster': 'gblinear', 'lambda': 5.005846010907589e-08, 'alpha': 8.097735903535356e-08, 'subsample': 0.9323612388056824, 'colsample_bytree': 0.8308410995774443}. Best is trial 45 with value: 0.021748589330333898.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:54,184]\u001b[0m Trial 61 finished with value: 0.03250003779783978 and parameters: {'booster': 'gbtree', 'lambda': 1.8147133866171834e-07, 'alpha': 2.0111671149279662e-07, 'subsample': 0.9089109821287344, 'colsample_bytree': 0.7136182156806513, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.061846327374627696, 'gamma': 7.148593254168074e-05, 'grow_policy': 'depthwise'}. Best is trial 45 with value: 0.021748589330333898.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:54,543]\u001b[0m Trial 62 finished with value: 0.03407308182700895 and parameters: {'booster': 'gbtree', 'lambda': 2.9609247611391877e-07, 'alpha': 2.0429493954607276e-06, 'subsample': 0.9140150908529827, 'colsample_bytree': 0.7155066037746967, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.06719651850243255, 'gamma': 1.4821076591561943e-08, 'grow_policy': 'depthwise'}. Best is trial 45 with value: 0.021748589330333898.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:54,910]\u001b[0m Trial 63 finished with value: 0.03273433340466413 and parameters: {'booster': 'gbtree', 'lambda': 2.5433402748440075e-07, 'alpha': 1.777973020470119e-06, 'subsample': 0.9579796991777723, 'colsample_bytree': 0.7334883907164884, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.05932018523348791, 'gamma': 1.3714246735480947e-08, 'grow_policy': 'depthwise'}. Best is trial 45 with value: 0.021748589330333898.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:55,279]\u001b[0m Trial 64 finished with value: 0.03627251769993185 and parameters: {'booster': 'gbtree', 'lambda': 2.2577540354878013e-08, 'alpha': 3.024534504591383e-07, 'subsample': 0.978785276034202, 'colsample_bytree': 0.7673586415581313, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.01625278594800147, 'gamma': 4.927927165807216e-05, 'grow_policy': 'depthwise'}. Best is trial 45 with value: 0.021748589330333898.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:55,637]\u001b[0m Trial 65 finished with value: 0.02793510717181089 and parameters: {'booster': 'gbtree', 'lambda': 1.7984371036585602e-07, 'alpha': 9.369498601368929e-08, 'subsample': 0.9536869025784899, 'colsample_bytree': 0.7311906045076437, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.03379573375942298, 'gamma': 4.135914281312637e-08, 'grow_policy': 'depthwise'}. Best is trial 45 with value: 0.021748589330333898.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:55,874]\u001b[0m Trial 66 finished with value: 0.3890824048103363 and parameters: {'booster': 'gbtree', 'lambda': 1.4419073613444291e-07, 'alpha': 9.386436063118047e-08, 'subsample': 0.9448333884891879, 'colsample_bytree': 0.742565876930037, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.00022418718515537396, 'gamma': 5.4933620787045206e-08, 'grow_policy': 'depthwise'}. Best is trial 45 with value: 0.021748589330333898.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:31:56,235]\u001b[0m Trial 67 finished with value: 0.024074343182466745 and parameters: {'booster': 'gbtree', 'lambda': 2.3070482811303645e-07, 'alpha': 1.8797163960218587e-08, 'subsample': 0.994437825964458, 'colsample_bytree': 0.7027154504767416, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.04783699634381603, 'gamma': 3.132062966423538e-08, 'grow_policy': 'depthwise'}. Best is trial 45 with value: 0.021748589330333898.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:57,826]\u001b[0m Trial 68 finished with value: 0.032319771844580326 and parameters: {'booster': 'dart', 'lambda': 2.4680312588975567e-07, 'alpha': 1.6151102255983627e-08, 'subsample': 0.9968551484223633, 'colsample_bytree': 0.702595833695654, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.04777541109342912, 'gamma': 2.9009623059490435e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.0006042850284687236, 'skip_drop': 3.924254100013936e-06}. Best is trial 45 with value: 0.021748589330333898.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:31:59,332]\u001b[0m Trial 69 finished with value: 0.2786070710392209 and parameters: {'booster': 'dart', 'lambda': 6.866641749957856e-07, 'alpha': 1.607757946480178e-08, 'subsample': 0.9933200584562569, 'colsample_bytree': 0.7010949192306452, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.002073966947119979, 'gamma': 3.036921588076311e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.0007469321408563987, 'skip_drop': 3.5140594645606874e-06}. Best is trial 45 with value: 0.021748589330333898.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:00,929]\u001b[0m Trial 70 finished with value: 0.0507627812965881 and parameters: {'booster': 'dart', 'lambda': 5.2361393669567254e-08, 'alpha': 1.6858452990324286e-08, 'subsample': 0.9544280442316381, 'colsample_bytree': 0.6663044784741093, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.12376441612864983, 'gamma': 2.9222146244382378e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 2.2930348849475718e-06, 'skip_drop': 8.910256942642298e-07}. Best is trial 45 with value: 0.021748589330333898.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:02,511]\u001b[0m Trial 71 finished with value: 0.02994682039227671 and parameters: {'booster': 'dart', 'lambda': 1.9946560887907726e-07, 'alpha': 4.1448172109203984e-08, 'subsample': 0.9977247736061832, 'colsample_bytree': 0.7296100134039356, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.05078596193810999, 'gamma': 1.0175798263959789e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.003942173018117708, 'skip_drop': 0.011652887040258795}. Best is trial 45 with value: 0.021748589330333898.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:04,128]\u001b[0m Trial 72 finished with value: 0.0902689061197015 and parameters: {'booster': 'dart', 'lambda': 2.0255754867183486e-07, 'alpha': 2.9477252289399783e-07, 'subsample': 0.9633390394451852, 'colsample_bytree': 0.7260733074677004, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.43066685565570606, 'gamma': 1.1616064676869996e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.005379194856604151, 'skip_drop': 0.011337815935552508}. Best is trial 45 with value: 0.021748589330333898.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:04,542]\u001b[0m A new study created in memory with name: no-name-39943e30-ed00-4247-96dd-e5fd473839cd\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:04,767]\u001b[0m Trial 0 finished with value: 1.3700833480163537 and parameters: {'booster': 'gbtree', 'lambda': 2.3133993589001555e-05, 'alpha': 0.050338039253845425, 'subsample': 0.9039894702164726, 'colsample_bytree': 0.22187966271128534, 'max_depth': 7, 'min_child_weight': 5, 'eta': 9.097444485951628e-08, 'gamma': 9.112759069898656e-05, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 1.3700833480163537.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:05,032]\u001b[0m Trial 1 finished with value: 1.3688645670182555 and parameters: {'booster': 'gbtree', 'lambda': 6.134568578315644e-06, 'alpha': 2.8940020645371633e-05, 'subsample': 0.6002480054311241, 'colsample_bytree': 0.5260931248410381, 'max_depth': 7, 'min_child_weight': 5, 'eta': 1.912080462864756e-05, 'gamma': 0.0010557629199834198, 'grow_policy': 'lossguide'}. Best is trial 1 with value: 1.3688645670182555.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:06,485]\u001b[0m Trial 2 finished with value: 1.3584587726800599 and parameters: {'booster': 'dart', 'lambda': 3.198724078179427e-08, 'alpha': 0.0013828335010471538, 'subsample': 0.30550926799355693, 'colsample_bytree': 0.4248655425079555, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.00020653254278584914, 'gamma': 2.981987554392497e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.01493992473443486, 'skip_drop': 0.09134598282327705}. Best is trial 2 with value: 1.3584587726800599.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:06,759]\u001b[0m Trial 3 finished with value: 1.369997264694781 and parameters: {'booster': 'gbtree', 'lambda': 1.7705032359184232e-07, 'alpha': 2.772595088437344e-07, 'subsample': 0.8666882396362614, 'colsample_bytree': 0.9275625173230784, 'max_depth': 5, 'min_child_weight': 8, 'eta': 1.337025417334079e-06, 'gamma': 0.000144836566855837, 'grow_policy': 'depthwise'}. Best is trial 2 with value: 1.3584587726800599.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:07,099]\u001b[0m Trial 4 finished with value: 1.3700776712318679 and parameters: {'booster': 'gbtree', 'lambda': 2.195909179247285e-06, 'alpha': 0.00011791653297770631, 'subsample': 0.6228484063270912, 'colsample_bytree': 0.7389121392257758, 'max_depth': 9, 'min_child_weight': 10, 'eta': 1.6947276882429462e-07, 'gamma': 0.5255376611663191, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 1.3584587726800599.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:07,196]\u001b[0m Trial 5 finished with value: 1.0633875478004235 and parameters: {'booster': 'gblinear', 'lambda': 7.109639677452643e-05, 'alpha': 0.07529158047552441, 'subsample': 0.5621744590491784, 'colsample_bytree': 0.598579957936091}. Best is trial 5 with value: 1.0633875478004235.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:08,558]\u001b[0m Trial 6 finished with value: 1.370028619499688 and parameters: {'booster': 'dart', 'lambda': 0.0064836166104248446, 'alpha': 0.007017298374583532, 'subsample': 0.5434052519292738, 'colsample_bytree': 0.8570348363365885, 'max_depth': 7, 'min_child_weight': 8, 'eta': 8.861527500702861e-07, 'gamma': 2.915675568526412e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.14800548953011472, 'skip_drop': 1.209229699250887e-06}. Best is trial 5 with value: 1.0633875478004235.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:08,647]\u001b[0m Trial 7 finished with value: 1.081307598873231 and parameters: {'booster': 'gblinear', 'lambda': 0.0010175047508183311, 'alpha': 0.4367865017031775, 'subsample': 0.8077176917784035, 'colsample_bytree': 0.7742129511481912}. Best is trial 5 with value: 1.0633875478004235.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:10,230]\u001b[0m Trial 8 finished with value: 1.3499440666371865 and parameters: {'booster': 'dart', 'lambda': 2.2070173183751225e-05, 'alpha': 0.0010786676979901739, 'subsample': 0.8882888776999796, 'colsample_bytree': 0.38219788440143054, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.00034130226254483763, 'gamma': 0.0032341667452195533, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 8.023827815364467e-06, 'skip_drop': 0.001584937250806743}. Best is trial 5 with value: 1.0633875478004235.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:11,620]\u001b[0m Trial 9 finished with value: 1.364017272683164 and parameters: {'booster': 'dart', 'lambda': 0.8195923268915752, 'alpha': 0.10209431558005841, 'subsample': 0.7472845747465988, 'colsample_bytree': 0.40101440872245475, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.00010912652694781134, 'gamma': 3.661265749618457e-05, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.011067104526221052, 'skip_drop': 2.2136901586382758e-08}. Best is trial 5 with value: 1.0633875478004235.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:11,756]\u001b[0m Trial 10 finished with value: 1.1116609580681902 and parameters: {'booster': 'gblinear', 'lambda': 0.020001495230610213, 'alpha': 1.0677879210466742e-08, 'subsample': 0.34953534592101554, 'colsample_bytree': 0.6164551951062726}. Best is trial 5 with value: 1.0633875478004235.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:32:11,857]\u001b[0m Trial 11 finished with value: 1.081307598873231 and parameters: {'booster': 'gblinear', 'lambda': 0.0007731943391734644, 'alpha': 0.7039051834985639, 'subsample': 0.46231006948853803, 'colsample_bytree': 0.7199140813206608}. Best is trial 5 with value: 1.0633875478004235.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:11,960]\u001b[0m Trial 12 finished with value: 1.081307598873231 and parameters: {'booster': 'gblinear', 'lambda': 0.0005645364215205464, 'alpha': 0.8263637415566624, 'subsample': 0.7385701506209132, 'colsample_bytree': 0.7593571074974182}. Best is trial 5 with value: 1.0633875478004235.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:12,079]\u001b[0m Trial 13 finished with value: 1.0536437473799327 and parameters: {'booster': 'gblinear', 'lambda': 0.0002774356215085026, 'alpha': 0.038627503499741436, 'subsample': 0.7399638705506866, 'colsample_bytree': 0.6286554653807955}. Best is trial 13 with value: 1.0536437473799327.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:12,209]\u001b[0m Trial 14 finished with value: 1.0555721048787914 and parameters: {'booster': 'gblinear', 'lambda': 5.601983426066341e-07, 'alpha': 0.010336526010744636, 'subsample': 0.4476180762307748, 'colsample_bytree': 0.6025651376886709}. Best is trial 13 with value: 1.0536437473799327.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:12,344]\u001b[0m Trial 15 finished with value: 1.160101073675127 and parameters: {'booster': 'gblinear', 'lambda': 1.832675122440248e-06, 'alpha': 1.4408380383235843e-05, 'subsample': 0.21765359763051767, 'colsample_bytree': 0.5466357666671458}. Best is trial 13 with value: 1.0536437473799327.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:12,474]\u001b[0m Trial 16 finished with value: 1.0595973043819502 and parameters: {'booster': 'gblinear', 'lambda': 2.8669185258192373e-07, 'alpha': 0.008470751162664141, 'subsample': 0.9989990306325904, 'colsample_bytree': 0.6376496898123926}. Best is trial 13 with value: 1.0536437473799327.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:12,609]\u001b[0m Trial 17 finished with value: 1.0802928561023695 and parameters: {'booster': 'gblinear', 'lambda': 0.09095030976967579, 'alpha': 0.0002744195805886986, 'subsample': 0.4378741333998569, 'colsample_bytree': 0.9953301621011998}. Best is trial 13 with value: 1.0536437473799327.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:12,737]\u001b[0m Trial 18 finished with value: 1.0608480746455147 and parameters: {'booster': 'gblinear', 'lambda': 3.296068387989399e-08, 'alpha': 0.007805251569754861, 'subsample': 0.691216279243021, 'colsample_bytree': 0.29506602890483896}. Best is trial 13 with value: 1.0536437473799327.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:12,871]\u001b[0m Trial 19 finished with value: 1.1585700124604583 and parameters: {'booster': 'gblinear', 'lambda': 4.7609591366785433e-07, 'alpha': 2.2693686815303456e-06, 'subsample': 0.4682503789294916, 'colsample_bytree': 0.46113197908684744}. Best is trial 13 with value: 1.0536437473799327.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:13,005]\u001b[0m Trial 20 finished with value: 1.1256104772727105 and parameters: {'booster': 'gblinear', 'lambda': 0.00014746483341620542, 'alpha': 0.001134841716070111, 'subsample': 0.6676898978474418, 'colsample_bytree': 0.6647721166292414}. Best is trial 13 with value: 1.0536437473799327.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:13,130]\u001b[0m Trial 21 finished with value: 1.05466770957806 and parameters: {'booster': 'gblinear', 'lambda': 2.6678591711481064e-07, 'alpha': 0.011288543266071926, 'subsample': 0.9797408454749588, 'colsample_bytree': 0.6669474428270153}. Best is trial 13 with value: 1.0536437473799327.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:13,249]\u001b[0m Trial 22 finished with value: 1.0501351182568894 and parameters: {'booster': 'gblinear', 'lambda': 8.61488489459397e-08, 'alpha': 0.026552217314612485, 'subsample': 0.9862567742831493, 'colsample_bytree': 0.5185254396780204}. Best is trial 22 with value: 1.0501351182568894.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:13,366]\u001b[0m Trial 23 finished with value: 1.054408789429518 and parameters: {'booster': 'gblinear', 'lambda': 1.6743521196090252e-08, 'alpha': 0.04291709999278797, 'subsample': 0.9793465904388493, 'colsample_bytree': 0.5240865011054032}. Best is trial 22 with value: 1.0501351182568894.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:13,475]\u001b[0m Trial 24 finished with value: 1.0644867278095975 and parameters: {'booster': 'gblinear', 'lambda': 2.0091239873693257e-08, 'alpha': 0.07972859696976375, 'subsample': 0.9462903025109444, 'colsample_bytree': 0.49131771543580216}. Best is trial 22 with value: 1.0501351182568894.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:13,580]\u001b[0m Trial 25 finished with value: 1.081307598873231 and parameters: {'booster': 'gblinear', 'lambda': 8.257264935669003e-08, 'alpha': 0.15567917792486122, 'subsample': 0.8264844502745755, 'colsample_bytree': 0.3353756462988039}. Best is trial 22 with value: 1.0501351182568894.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:13,706]\u001b[0m Trial 26 finished with value: 1.0485518001695633 and parameters: {'booster': 'gblinear', 'lambda': 1.3289716099299169e-08, 'alpha': 0.01958697332714102, 'subsample': 0.7852331305491258, 'colsample_bytree': 0.5443187093142224}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:13,907]\u001b[0m Trial 27 finished with value: 1.1999670256376536 and parameters: {'booster': 'gbtree', 'lambda': 0.0036374075199746524, 'alpha': 0.002292400226360521, 'subsample': 0.7861023926182474, 'colsample_bytree': 0.5729386302527435, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.2502622666934702, 'gamma': 1.6250813622522249e-06, 'grow_policy': 'depthwise'}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:14,042]\u001b[0m Trial 28 finished with value: 1.1451822979968458 and parameters: {'booster': 'gblinear', 'lambda': 3.876151259175287e-06, 'alpha': 0.0002830084903004853, 'subsample': 0.6931409028366483, 'colsample_bytree': 0.8061151442913369}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:15,571]\u001b[0m Trial 29 finished with value: 1.3396891455256197 and parameters: {'booster': 'dart', 'lambda': 3.828997117581738e-05, 'alpha': 0.026744016386910745, 'subsample': 0.8399657436925028, 'colsample_bytree': 0.27829789229020874, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.45124951650725775, 'gamma': 0.9390408746132292, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 5.857296029143931e-08, 'skip_drop': 0.6892302426159925}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:15,778]\u001b[0m Trial 30 finished with value: 1.0755709254008738 and parameters: {'booster': 'gbtree', 'lambda': 1.1082149022485676e-05, 'alpha': 0.18152791055402984, 'subsample': 0.9078795788271825, 'colsample_bytree': 0.20267591076559632, 'max_depth': 5, 'min_child_weight': 3, 'eta': 0.013536302914766787, 'gamma': 0.012830308360937097, 'grow_policy': 'depthwise'}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:15,900]\u001b[0m Trial 31 finished with value: 1.0505667098188411 and parameters: {'booster': 'gblinear', 'lambda': 1.587045421307004e-08, 'alpha': 0.027464909649684444, 'subsample': 0.9333268242009408, 'colsample_bytree': 0.5167679544128275}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:16,021]\u001b[0m Trial 32 finished with value: 1.0496181186920168 and parameters: {'booster': 'gblinear', 'lambda': 7.073938554337655e-08, 'alpha': 0.02529265123536537, 'subsample': 0.9190554675932218, 'colsample_bytree': 0.4847047112407479}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:16,155]\u001b[0m Trial 33 finished with value: 1.1001557878120192 and parameters: {'booster': 'gblinear', 'lambda': 1.0180153279656658e-08, 'alpha': 0.002568721627028399, 'subsample': 0.9138809644735167, 'colsample_bytree': 0.4695800152120829}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:16,279]\u001b[0m Trial 34 finished with value: 1.0488273640976238 and parameters: {'booster': 'gblinear', 'lambda': 6.439807226719026e-08, 'alpha': 0.021147574393071036, 'subsample': 0.9216385112688654, 'colsample_bytree': 0.5159051431574688}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:16,469]\u001b[0m Trial 35 finished with value: 1.3700884553531727 and parameters: {'booster': 'gbtree', 'lambda': 7.904826917564136e-08, 'alpha': 0.2760223530277436, 'subsample': 0.8641952461793225, 'colsample_bytree': 0.44160813939643523, 'max_depth': 3, 'min_child_weight': 3, 'eta': 1.5893161238629497e-08, 'gamma': 1.9130666081731907e-06, 'grow_policy': 'lossguide'}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:32:16,606]\u001b[0m Trial 36 finished with value: 1.154152862338998 and parameters: {'booster': 'gblinear', 'lambda': 9.582001426335416e-08, 'alpha': 4.1103236692814175e-05, 'subsample': 0.9629456791178218, 'colsample_bytree': 0.37471836198339514}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:18,088]\u001b[0m Trial 37 finished with value: 1.0642739183539973 and parameters: {'booster': 'dart', 'lambda': 4.100148595418594e-08, 'alpha': 0.00046046913563141254, 'subsample': 0.864055693495924, 'colsample_bytree': 0.5559404016954154, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.011189736278141916, 'gamma': 0.02938679455789172, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 1.4692972824884287e-08, 'skip_drop': 3.460135387641686e-05}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:18,440]\u001b[0m Trial 38 finished with value: 1.1532904728733389 and parameters: {'booster': 'gbtree', 'lambda': 1.316520555558927e-06, 'alpha': 0.004358614998900751, 'subsample': 0.7783088663014186, 'colsample_bytree': 0.49534235732248577, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.005486620196881415, 'gamma': 4.164999824339294e-06, 'grow_policy': 'lossguide'}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:18,565]\u001b[0m Trial 39 finished with value: 1.0487138428702176 and parameters: {'booster': 'gblinear', 'lambda': 1.1394567938264018e-07, 'alpha': 0.020397566534008656, 'subsample': 0.924440830283969, 'colsample_bytree': 0.42066349290405125}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:18,701]\u001b[0m Trial 40 finished with value: 1.1640947326124622 and parameters: {'booster': 'gblinear', 'lambda': 8.068285087981093e-07, 'alpha': 3.1937489222000605e-06, 'subsample': 0.9012689254555757, 'colsample_bytree': 0.4175872618915509}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:18,824]\u001b[0m Trial 41 finished with value: 1.0487935710450897 and parameters: {'booster': 'gblinear', 'lambda': 1.4187351348054177e-07, 'alpha': 0.020823303488653164, 'subsample': 0.938727802891904, 'colsample_bytree': 0.34572626641123594}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:18,950]\u001b[0m Trial 42 finished with value: 1.0495331656019045 and parameters: {'booster': 'gblinear', 'lambda': 1.8056555685298394e-07, 'alpha': 0.016155567570293135, 'subsample': 0.9355079379878194, 'colsample_bytree': 0.3520682972174688}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:19,073]\u001b[0m Trial 43 finished with value: 1.0507600605209437 and parameters: {'booster': 'gblinear', 'lambda': 2.2706161620809586e-07, 'alpha': 0.015101540813336934, 'subsample': 0.8625058198075782, 'colsample_bytree': 0.2636222217146301}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:20,531]\u001b[0m Trial 44 finished with value: 1.3696601676566538 and parameters: {'booster': 'dart', 'lambda': 5.885485191093746e-06, 'alpha': 0.002895124697029877, 'subsample': 0.7955724945562044, 'colsample_bytree': 0.3509580040843213, 'max_depth': 5, 'min_child_weight': 4, 'eta': 7.082709739211051e-06, 'gamma': 3.6385196390148064e-07, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 4.3797925011740884e-05, 'skip_drop': 0.003791167581479806}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:20,666]\u001b[0m Trial 45 finished with value: 1.1419178639435412 and parameters: {'booster': 'gblinear', 'lambda': 1.6070233220131685e-07, 'alpha': 0.0005701058481348888, 'subsample': 0.9533294209537189, 'colsample_bytree': 0.31466196313798567}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:20,778]\u001b[0m Trial 46 finished with value: 1.071141154206585 and parameters: {'booster': 'gblinear', 'lambda': 3.702344347869769e-08, 'alpha': 0.10380669164467995, 'subsample': 0.8846786526976212, 'colsample_bytree': 0.24033067272026776}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:20,881]\u001b[0m Trial 47 finished with value: 1.081307598873231 and parameters: {'booster': 'gblinear', 'lambda': 1.0021956195140108e-08, 'alpha': 0.4066335459560869, 'subsample': 0.8388712407042745, 'colsample_bytree': 0.3849601069139543}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:21,016]\u001b[0m Trial 48 finished with value: 1.159503602832355 and parameters: {'booster': 'gblinear', 'lambda': 1.028544065272083e-06, 'alpha': 9.385457284920691e-08, 'subsample': 0.9348885251450494, 'colsample_bytree': 0.4164820843497896}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:22,413]\u001b[0m Trial 49 finished with value: 1.298676417610674 and parameters: {'booster': 'dart', 'lambda': 3.005175767623516e-06, 'alpha': 0.07157895371220112, 'subsample': 0.6238954048747059, 'colsample_bytree': 0.3315243825684922, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.0013541318811752497, 'gamma': 0.051805058261345856, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 1.5886820970232285e-06, 'skip_drop': 2.895858252122994e-08}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:22,544]\u001b[0m Trial 50 finished with value: 1.0679072146564765 and parameters: {'booster': 'gblinear', 'lambda': 4.4052859315327963e-07, 'alpha': 0.0062474646915557765, 'subsample': 0.7646433550956842, 'colsample_bytree': 0.4397220854909539}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:22,672]\u001b[0m Trial 51 finished with value: 1.048624704431938 and parameters: {'booster': 'gblinear', 'lambda': 3.5769541145955e-08, 'alpha': 0.0196645283016949, 'subsample': 0.9116289292919048, 'colsample_bytree': 0.5793397652032232}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:22,801]\u001b[0m Trial 52 finished with value: 1.051248730294001 and parameters: {'booster': 'gblinear', 'lambda': 1.497997998639106e-07, 'alpha': 0.014802807927134743, 'subsample': 0.8801946282726503, 'colsample_bytree': 0.36048190191321483}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:22,934]\u001b[0m Trial 53 finished with value: 1.083646970462769 and parameters: {'booster': 'gblinear', 'lambda': 3.3854766010285745e-08, 'alpha': 0.004101058728722681, 'subsample': 0.8233083080791133, 'colsample_bytree': 0.5590460875015022}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:23,048]\u001b[0m Trial 54 finished with value: 1.058894474516408 and parameters: {'booster': 'gblinear', 'lambda': 4.618742090224645e-08, 'alpha': 0.05876945758275614, 'subsample': 0.9517253698364843, 'colsample_bytree': 0.5931138746886188}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:23,152]\u001b[0m Trial 55 finished with value: 1.081307598873231 and parameters: {'booster': 'gblinear', 'lambda': 1.7666056699601062e-07, 'alpha': 0.8461335911789779, 'subsample': 0.9031506523459885, 'colsample_bytree': 0.6867437820082998}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:23,287]\u001b[0m Trial 56 finished with value: 1.1227345305222556 and parameters: {'booster': 'gblinear', 'lambda': 1.8456204074769215e-08, 'alpha': 0.001142435074637171, 'subsample': 0.9843952438396252, 'colsample_bytree': 0.444799218535042}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:23,415]\u001b[0m Trial 57 finished with value: 1.0502721726360749 and parameters: {'booster': 'gblinear', 'lambda': 3.828418091877075e-07, 'alpha': 0.015635149271846876, 'subsample': 0.9994217851284649, 'colsample_bytree': 0.40033071883538307}. Best is trial 26 with value: 1.0485518001695633.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:23,746]\u001b[0m Trial 58 finished with value: 1.0382501193196245 and parameters: {'booster': 'gbtree', 'lambda': 0.6539210191817181, 'alpha': 0.1993428767374164, 'subsample': 0.5420081498766218, 'colsample_bytree': 0.5985560305479264, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.07211212908291076, 'gamma': 1.1492566369480011e-08, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 1.0382501193196245.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:32:24,081]\u001b[0m Trial 59 finished with value: 1.0709616674420948 and parameters: {'booster': 'gbtree', 'lambda': 0.2151301590952014, 'alpha': 0.19012196626013275, 'subsample': 0.5117700102006391, 'colsample_bytree': 0.6413467261435282, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.06282778795276141, 'gamma': 2.4576029125194275e-07, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 1.0382501193196245.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:24,391]\u001b[0m Trial 60 finished with value: 26.989255063624128 and parameters: {'booster': 'gbtree', 'lambda': 0.02584337120732942, 'alpha': 0.31982627792549406, 'subsample': 0.40766655364015236, 'colsample_bytree': 0.5848916980890906, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.9252278254391562, 'gamma': 9.63441773230938e-06, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 1.0382501193196245.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:24,754]\u001b[0m Trial 61 finished with value: 1.1072623314600534 and parameters: {'booster': 'gbtree', 'lambda': 1.217343158359241e-07, 'alpha': 0.043368764851436724, 'subsample': 0.5734641946649596, 'colsample_bytree': 0.7129935459280705, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.07043505666890675, 'gamma': 1.1890817548961719e-07, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 1.0382501193196245.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:25,038]\u001b[0m Trial 62 finished with value: 1.2677578294188712 and parameters: {'booster': 'gbtree', 'lambda': 0.0022513238740275734, 'alpha': 0.09204084997044738, 'subsample': 0.5110043691192618, 'colsample_bytree': 0.5462361892399504, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.0019161938181753368, 'gamma': 0.0005692691559785923, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 1.0382501193196245.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:25,168]\u001b[0m Trial 63 finished with value: 1.0649191140197465 and parameters: {'booster': 'gblinear', 'lambda': 7.589495878730553e-07, 'alpha': 0.007056922143443986, 'subsample': 0.591706812137254, 'colsample_bytree': 0.6173260652422219}. Best is trial 58 with value: 1.0382501193196245.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:25,489]\u001b[0m Trial 64 finished with value: 1.3688338433727305 and parameters: {'booster': 'gbtree', 'lambda': 5.351365472405876e-08, 'alpha': 0.0019491221899385642, 'subsample': 0.6364417446730294, 'colsample_bytree': 0.5058090632368497, 'max_depth': 9, 'min_child_weight': 10, 'eta': 1.9899927112985226e-05, 'gamma': 1.1651480398670609e-08, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 1.0382501193196245.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:25,617]\u001b[0m Trial 65 finished with value: 1.048196576658573 and parameters: {'booster': 'gblinear', 'lambda': 2.4241596274737254e-08, 'alpha': 0.01895068391662334, 'subsample': 0.543360634537196, 'colsample_bytree': 0.3068682222711539}. Best is trial 58 with value: 1.0382501193196245.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:25,737]\u001b[0m Trial 66 finished with value: 1.0541979756542408 and parameters: {'booster': 'gblinear', 'lambda': 2.0305167596435145e-08, 'alpha': 0.04060244000049431, 'subsample': 0.5504958771179982, 'colsample_bytree': 0.2992489989519884}. Best is trial 58 with value: 1.0382501193196245.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:25,843]\u001b[0m Trial 67 finished with value: 1.081307598873231 and parameters: {'booster': 'gblinear', 'lambda': 0.018105908045568764, 'alpha': 0.13569770327861072, 'subsample': 0.5220430835300788, 'colsample_bytree': 0.6625142893384517}. Best is trial 58 with value: 1.0382501193196245.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:27,320]\u001b[0m Trial 68 finished with value: 1.1408051173075582 and parameters: {'booster': 'dart', 'lambda': 0.00031279726359878627, 'alpha': 0.5298358827907788, 'subsample': 0.7246810485175535, 'colsample_bytree': 0.5319980833969816, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.12914339429384547, 'gamma': 2.4078025434669503e-05, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.0006507688565923866, 'skip_drop': 7.458209505715824e-06}. Best is trial 58 with value: 1.0382501193196245.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:27,454]\u001b[0m Trial 69 finished with value: 1.074319401588879 and parameters: {'booster': 'gblinear', 'lambda': 2.3655754225919927e-08, 'alpha': 0.005218634888135669, 'subsample': 0.3588440276096101, 'colsample_bytree': 0.4658751045121063}. Best is trial 58 with value: 1.0382501193196245.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:27,752]\u001b[0m Trial 70 finished with value: 1.0153480509642128 and parameters: {'booster': 'gbtree', 'lambda': 6.703135060239061e-05, 'alpha': 0.0007555965267478939, 'subsample': 0.6762752021069998, 'colsample_bytree': 0.6019860659379787, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.024295657126037644, 'gamma': 4.595064195036723e-07, 'grow_policy': 'depthwise'}. Best is trial 70 with value: 1.0153480509642128.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:28,047]\u001b[0m Trial 71 finished with value: 1.0311596250949993 and parameters: {'booster': 'gbtree', 'lambda': 0.6606554589356705, 'alpha': 0.0006510631261162169, 'subsample': 0.7011633934620554, 'colsample_bytree': 0.5726188294331523, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.037685258930249155, 'gamma': 5.338511099860945e-07, 'grow_policy': 'depthwise'}. Best is trial 70 with value: 1.0153480509642128.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:28,354]\u001b[0m Trial 72 finished with value: 1.0305183943637595 and parameters: {'booster': 'gbtree', 'lambda': 0.6931696337203811, 'alpha': 0.00016323176348828955, 'subsample': 0.6651259904742333, 'colsample_bytree': 0.6337210377539761, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.029672206468610646, 'gamma': 6.145843202708529e-07, 'grow_policy': 'depthwise'}. Best is trial 70 with value: 1.0153480509642128.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:28,654]\u001b[0m Trial 73 finished with value: 1.0211812697515956 and parameters: {'booster': 'gbtree', 'lambda': 0.6016860919458211, 'alpha': 0.00013329480185539336, 'subsample': 0.5963126251226851, 'colsample_bytree': 0.6389508543107523, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.030507587281129223, 'gamma': 5.530687407275601e-07, 'grow_policy': 'depthwise'}. Best is trial 70 with value: 1.0153480509642128.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:28,982]\u001b[0m Trial 74 finished with value: 1.0276847912370757 and parameters: {'booster': 'gbtree', 'lambda': 0.9643608225420277, 'alpha': 7.164241078491351e-05, 'subsample': 0.6536124165306151, 'colsample_bytree': 0.7867689322178233, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.02374608694944957, 'gamma': 7.441196186395924e-07, 'grow_policy': 'depthwise'}. Best is trial 70 with value: 1.0153480509642128.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:29,320]\u001b[0m Trial 75 finished with value: 1.0101255307503259 and parameters: {'booster': 'gbtree', 'lambda': 0.8837766247535767, 'alpha': 4.7385221536435946e-05, 'subsample': 0.6690317649845536, 'colsample_bytree': 0.8387314989246226, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.024614382183156595, 'gamma': 6.89816397833249e-07, 'grow_policy': 'depthwise'}. Best is trial 75 with value: 1.0101255307503259.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:29,663]\u001b[0m Trial 76 finished with value: 1.0153315378220207 and parameters: {'booster': 'gbtree', 'lambda': 0.9688908899307535, 'alpha': 7.792381065853099e-05, 'subsample': 0.6609295919783876, 'colsample_bytree': 0.8840183650431721, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.037372636547162295, 'gamma': 5.869599740467174e-07, 'grow_policy': 'depthwise'}. Best is trial 75 with value: 1.0101255307503259.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:30,007]\u001b[0m Trial 77 finished with value: 1.004118322567163 and parameters: {'booster': 'gbtree', 'lambda': 0.81585816076892, 'alpha': 7.8035493652582e-05, 'subsample': 0.6577215284648248, 'colsample_bytree': 0.8903105146174473, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.03204781556455534, 'gamma': 8.042247724327244e-07, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 1.004118322567163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:30,356]\u001b[0m Trial 78 finished with value: 1.0096780766423306 and parameters: {'booster': 'gbtree', 'lambda': 0.5005075574703737, 'alpha': 0.0001175675187625879, 'subsample': 0.6668249493985301, 'colsample_bytree': 0.9085586139731041, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.02483792269200932, 'gamma': 5.248923651968749e-07, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 1.004118322567163.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:32:30,697]\u001b[0m Trial 79 finished with value: 1.0258025385199916 and parameters: {'booster': 'gbtree', 'lambda': 0.2791049542091987, 'alpha': 9.091644212368277e-05, 'subsample': 0.6556255450672297, 'colsample_bytree': 0.8866647102411411, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.01556566669239281, 'gamma': 1.103049485430864e-06, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 1.004118322567163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:31,046]\u001b[0m Trial 80 finished with value: 1.1318984263322571 and parameters: {'booster': 'gbtree', 'lambda': 0.2846236956406217, 'alpha': 4.9146571929000206e-05, 'subsample': 0.6541451507919833, 'colsample_bytree': 0.8955053434019642, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.005487709088462741, 'gamma': 1.3931894049540002e-06, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 1.004118322567163.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:31,381]\u001b[0m Trial 81 finished with value: 1.0030040838090017 and parameters: {'booster': 'gbtree', 'lambda': 0.32789011298060194, 'alpha': 0.00012189491488779863, 'subsample': 0.6629380553026345, 'colsample_bytree': 0.8228107455224382, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.02436240482511851, 'gamma': 5.735880979206074e-07, 'grow_policy': 'depthwise'}. Best is trial 81 with value: 1.0030040838090017.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:31,712]\u001b[0m Trial 82 finished with value: 1.0279353695275737 and parameters: {'booster': 'gbtree', 'lambda': 0.34415710448168696, 'alpha': 1.028318132824403e-05, 'subsample': 0.5986886415591935, 'colsample_bytree': 0.8312325645306378, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.016945885685710895, 'gamma': 1.372923935197529e-07, 'grow_policy': 'depthwise'}. Best is trial 81 with value: 1.0030040838090017.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:32,064]\u001b[0m Trial 83 finished with value: 1.0139958998555676 and parameters: {'booster': 'gbtree', 'lambda': 0.09887821925772909, 'alpha': 8.450757305278748e-05, 'subsample': 0.7189722830099897, 'colsample_bytree': 0.9353584662334682, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.024237866487377968, 'gamma': 1.0253006067008971e-06, 'grow_policy': 'depthwise'}. Best is trial 81 with value: 1.0030040838090017.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:32,425]\u001b[0m Trial 84 finished with value: 1.1996641949867624 and parameters: {'booster': 'gbtree', 'lambda': 0.0777993393200138, 'alpha': 1.8783874613928156e-05, 'subsample': 0.714432747403466, 'colsample_bytree': 0.9674349800385458, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.00325503021496539, 'gamma': 3.881946972696192e-06, 'grow_policy': 'depthwise'}. Best is trial 81 with value: 1.0030040838090017.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:32,768]\u001b[0m Trial 85 finished with value: 1.109901209302953 and parameters: {'booster': 'gbtree', 'lambda': 0.13575089633158893, 'alpha': 0.00014554612286554893, 'subsample': 0.6777264588634133, 'colsample_bytree': 0.8820968564894114, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.12841450194519954, 'gamma': 1.1426031810317075e-07, 'grow_policy': 'depthwise'}. Best is trial 81 with value: 1.0030040838090017.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:33,119]\u001b[0m Trial 86 finished with value: 1.0707700394258546 and parameters: {'booster': 'gbtree', 'lambda': 0.4344215302294178, 'alpha': 0.0002578192530392923, 'subsample': 0.6341870854995052, 'colsample_bytree': 0.9223496451471879, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.009154673340474085, 'gamma': 3.9240087316762156e-07, 'grow_policy': 'depthwise'}. Best is trial 81 with value: 1.0030040838090017.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:33,461]\u001b[0m Trial 87 finished with value: 1.0374227950236126 and parameters: {'booster': 'gbtree', 'lambda': 0.04765897307854378, 'alpha': 9.71496455341973e-05, 'subsample': 0.7568471905702688, 'colsample_bytree': 0.8427173709111859, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.029657872929434136, 'gamma': 1.320150028870403e-06, 'grow_policy': 'depthwise'}. Best is trial 81 with value: 1.0030040838090017.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:33,811]\u001b[0m Trial 88 finished with value: 1.1505980117265524 and parameters: {'booster': 'gbtree', 'lambda': 0.15751717220095104, 'alpha': 2.578590882827043e-05, 'subsample': 0.6140702126276425, 'colsample_bytree': 0.9442572183796689, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.15995782706329698, 'gamma': 5.829973544057935e-08, 'grow_policy': 'depthwise'}. Best is trial 81 with value: 1.0030040838090017.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:34,157]\u001b[0m Trial 89 finished with value: 1.0130585179854803 and parameters: {'booster': 'gbtree', 'lambda': 0.5096381240347155, 'alpha': 6.052700559735143e-06, 'subsample': 0.6885174576936722, 'colsample_bytree': 0.8749286923750372, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.03830029038440196, 'gamma': 3.070413213927155e-06, 'grow_policy': 'depthwise'}. Best is trial 81 with value: 1.0030040838090017.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:34,515]\u001b[0m Trial 90 finished with value: 1.0475712608453132 and parameters: {'booster': 'gbtree', 'lambda': 0.10351002305831962, 'alpha': 8.500583102036418e-06, 'subsample': 0.730028891774569, 'colsample_bytree': 0.9158809795985877, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.045987854726886226, 'gamma': 3.3807057699158317e-06, 'grow_policy': 'depthwise'}. Best is trial 81 with value: 1.0030040838090017.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:34,859]\u001b[0m Trial 91 finished with value: 1.0334063353870306 and parameters: {'booster': 'gbtree', 'lambda': 0.4614972759676501, 'alpha': 6.928773809176782e-05, 'subsample': 0.6848677167434547, 'colsample_bytree': 0.8673847367161727, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.01585723073810109, 'gamma': 8.048940498911001e-07, 'grow_policy': 'depthwise'}. Best is trial 81 with value: 1.0030040838090017.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:35,212]\u001b[0m Trial 92 finished with value: 1.019018458433094 and parameters: {'booster': 'gbtree', 'lambda': 0.2023373812602689, 'alpha': 0.00020128643960167782, 'subsample': 0.6461360926337103, 'colsample_bytree': 0.9480862816408178, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.039396683646174234, 'gamma': 2.5468458212492714e-07, 'grow_policy': 'depthwise'}. Best is trial 81 with value: 1.0030040838090017.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:35,573]\u001b[0m Trial 93 finished with value: 1.0118797387237286 and parameters: {'booster': 'gbtree', 'lambda': 0.00010575136857555727, 'alpha': 0.00023300909413056156, 'subsample': 0.7050496059510207, 'colsample_bytree': 0.9772189079661868, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.05763328651663966, 'gamma': 2.5676449284961467e-07, 'grow_policy': 'depthwise'}. Best is trial 81 with value: 1.0030040838090017.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:35,938]\u001b[0m Trial 94 finished with value: 1.173355767320834 and parameters: {'booster': 'gbtree', 'lambda': 6.137748360315575e-05, 'alpha': 0.0003574283388489532, 'subsample': 0.6946833847496958, 'colsample_bytree': 0.975496473393412, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.27012032179130285, 'gamma': 2.0682902995160467e-07, 'grow_policy': 'depthwise'}. Best is trial 81 with value: 1.0030040838090017.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:36,293]\u001b[0m Trial 95 finished with value: 1.0471733490992987 and parameters: {'booster': 'gbtree', 'lambda': 2.0105619312195668e-05, 'alpha': 4.128556036971741e-06, 'subsample': 0.7135430913451305, 'colsample_bytree': 0.9439649219481099, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.07936960034642182, 'gamma': 2.5998886611536404e-07, 'grow_policy': 'depthwise'}. Best is trial 81 with value: 1.0030040838090017.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:36,662]\u001b[0m Trial 96 finished with value: 1.0953369269035265 and parameters: {'booster': 'gbtree', 'lambda': 0.20303560252682049, 'alpha': 3.9744305266556395e-05, 'subsample': 0.7420302760336571, 'colsample_bytree': 0.9969163196663052, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.007403224358034488, 'gamma': 6.18297904606727e-08, 'grow_policy': 'depthwise'}. Best is trial 81 with value: 1.0030040838090017.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:36,993]\u001b[0m Trial 97 finished with value: 1.3086006930215182 and parameters: {'booster': 'gbtree', 'lambda': 0.06014183327293622, 'alpha': 0.00017989780269303153, 'subsample': 0.6391942373559476, 'colsample_bytree': 0.8055741850624106, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.0009753814049732155, 'gamma': 2.5575875317582987e-06, 'grow_policy': 'depthwise'}. Best is trial 81 with value: 1.0030040838090017.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:32:37,344]\u001b[0m Trial 98 finished with value: 1.2747471538863586 and parameters: {'booster': 'gbtree', 'lambda': 0.9163928617097222, 'alpha': 1.3585536053799772e-06, 'subsample': 0.6740783610813396, 'colsample_bytree': 0.9076117299341656, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.34453399005705115, 'gamma': 6.680696073366156e-06, 'grow_policy': 'depthwise'}. Best is trial 81 with value: 1.0030040838090017.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:37,701]\u001b[0m Trial 99 finished with value: 1.046861547163321 and parameters: {'booster': 'gbtree', 'lambda': 0.00013090617871444436, 'alpha': 0.0007941845893481993, 'subsample': 0.6150719853724324, 'colsample_bytree': 0.9453686080462894, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.04512488934073492, 'gamma': 6.107698349751518e-08, 'grow_policy': 'depthwise'}. Best is trial 81 with value: 1.0030040838090017.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:38,096]\u001b[0m A new study created in memory with name: no-name-65107a64-ac16-4fa8-8e57-c22c5ee8a9c3\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:38,702]\u001b[0m Trial 0 finished with value: 1.052280720950567 and parameters: {'booster': 'dart', 'lambda': 1.755247800148711e-08, 'alpha': 3.4444842496468555e-07, 'subsample': 0.6566254098906288, 'colsample_bytree': 0.4804623870325269, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.0066803992041029525, 'gamma': 0.2716632258453958, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.6984864723180899, 'skip_drop': 3.567247375773278e-06}. Best is trial 0 with value: 1.052280720950567.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:39,117]\u001b[0m Trial 1 finished with value: 1.3599306044675747 and parameters: {'booster': 'gbtree', 'lambda': 5.349527295640615e-06, 'alpha': 4.03218123926049e-06, 'subsample': 0.9480140374778989, 'colsample_bytree': 0.6915212942759092, 'max_depth': 9, 'min_child_weight': 4, 'eta': 1.7261207055739612e-05, 'gamma': 3.507277639739271e-08, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 1.052280720950567.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:39,366]\u001b[0m Trial 2 finished with value: 0.9116462315834534 and parameters: {'booster': 'gbtree', 'lambda': 9.918740554367785e-06, 'alpha': 2.6282286231315634e-05, 'subsample': 0.5065965240023624, 'colsample_bytree': 0.9122090528472164, 'max_depth': 5, 'min_child_weight': 5, 'eta': 0.019353229154642784, 'gamma': 0.13908444916436158, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 0.9116462315834534.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:39,485]\u001b[0m Trial 3 finished with value: 0.9374658464889712 and parameters: {'booster': 'gblinear', 'lambda': 0.015577668530548058, 'alpha': 5.492236605659478e-07, 'subsample': 0.2859601010527006, 'colsample_bytree': 0.9412856839272201}. Best is trial 2 with value: 0.9116462315834534.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:39,679]\u001b[0m Trial 4 finished with value: 1.3614334488918247 and parameters: {'booster': 'gbtree', 'lambda': 0.027242357112725712, 'alpha': 0.004925618589273713, 'subsample': 0.944068382172534, 'colsample_bytree': 0.8400895539388202, 'max_depth': 3, 'min_child_weight': 6, 'eta': 5.652810727741806e-07, 'gamma': 3.011740095163121e-07, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 0.9116462315834534.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:39,798]\u001b[0m Trial 5 finished with value: 0.9570595901436076 and parameters: {'booster': 'gblinear', 'lambda': 6.908606970770913e-08, 'alpha': 0.0006426067929399032, 'subsample': 0.6363174365223024, 'colsample_bytree': 0.7907272269649672}. Best is trial 2 with value: 0.9116462315834534.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:41,183]\u001b[0m Trial 6 finished with value: 1.357872799867078 and parameters: {'booster': 'dart', 'lambda': 1.0108371997700754e-08, 'alpha': 7.688330394522872e-08, 'subsample': 0.8704571796683687, 'colsample_bytree': 0.5725952158719767, 'max_depth': 3, 'min_child_weight': 7, 'eta': 4.639242708300154e-05, 'gamma': 0.005507981549125144, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 1.0529683654450308e-08, 'skip_drop': 0.0009243166020744079}. Best is trial 2 with value: 0.9116462315834534.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:42,819]\u001b[0m Trial 7 finished with value: 1.3609939596080174 and parameters: {'booster': 'dart', 'lambda': 0.006490426140312547, 'alpha': 0.0005366849247672158, 'subsample': 0.7032141281367628, 'colsample_bytree': 0.8368366337913626, 'max_depth': 9, 'min_child_weight': 6, 'eta': 5.453736754287757e-06, 'gamma': 1.8544189627574939e-06, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.0007923236289706033, 'skip_drop': 0.00021402731435755248}. Best is trial 2 with value: 0.9116462315834534.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:44,231]\u001b[0m Trial 8 finished with value: 1.3613349362740435 and parameters: {'booster': 'dart', 'lambda': 0.6913882625534171, 'alpha': 0.029632685588841377, 'subsample': 0.379732960583151, 'colsample_bytree': 0.43603952814176705, 'max_depth': 5, 'min_child_weight': 8, 'eta': 1.8304321272817435e-06, 'gamma': 8.297927992941321e-07, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.00019325187644977186, 'skip_drop': 0.23904289504240717}. Best is trial 2 with value: 0.9116462315834534.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:45,584]\u001b[0m Trial 9 finished with value: 1.361432758393651 and parameters: {'booster': 'dart', 'lambda': 2.3659576769804214e-05, 'alpha': 1.6915308816270542e-06, 'subsample': 0.46521229671233083, 'colsample_bytree': 0.7172460939864014, 'max_depth': 3, 'min_child_weight': 8, 'eta': 5.965639493181572e-07, 'gamma': 0.000703402543470686, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.00016353924023992372, 'skip_drop': 5.432711682181124e-08}. Best is trial 2 with value: 0.9116462315834534.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:45,805]\u001b[0m Trial 10 finished with value: 5542.633906611206 and parameters: {'booster': 'gbtree', 'lambda': 1.1032765109398549e-06, 'alpha': 0.43970460030888026, 'subsample': 0.21285294014536432, 'colsample_bytree': 0.2765300813327504, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.7409169045387878, 'gamma': 0.9293161831686786, 'grow_policy': 'depthwise'}. Best is trial 2 with value: 0.9116462315834534.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:45,936]\u001b[0m Trial 11 finished with value: 0.9775250492774158 and parameters: {'booster': 'gblinear', 'lambda': 0.001211957005394064, 'alpha': 1.8733666863553156e-05, 'subsample': 0.20662847006670038, 'colsample_bytree': 0.9998770872680677}. Best is trial 2 with value: 0.9116462315834534.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:46,067]\u001b[0m Trial 12 finished with value: 0.9860546289583506 and parameters: {'booster': 'gblinear', 'lambda': 0.00031797084645664023, 'alpha': 1.9272773492878e-08, 'subsample': 0.44510244008757316, 'colsample_bytree': 0.9799603137132493}. Best is trial 2 with value: 0.9116462315834534.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:46,197]\u001b[0m Trial 13 finished with value: 0.9036888172822528 and parameters: {'booster': 'gblinear', 'lambda': 0.15860542789274507, 'alpha': 1.3940217068912787e-05, 'subsample': 0.3380949814117805, 'colsample_bytree': 0.9197340517738856}. Best is trial 13 with value: 0.9036888172822528.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:46,540]\u001b[0m Trial 14 finished with value: 1.1363372964240166 and parameters: {'booster': 'gbtree', 'lambda': 8.912064044060045e-07, 'alpha': 3.5627351761716173e-05, 'subsample': 0.5293022936548101, 'colsample_bytree': 0.874552750521568, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.0036264440818162312, 'gamma': 0.013981778202876308, 'grow_policy': 'lossguide'}. Best is trial 13 with value: 0.9036888172822528.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:46,787]\u001b[0m Trial 15 finished with value: 1.3614787226688678 and parameters: {'booster': 'gbtree', 'lambda': 0.8783383441574701, 'alpha': 8.701579611676266e-05, 'subsample': 0.34461058477630097, 'colsample_bytree': 0.6993891015276665, 'max_depth': 5, 'min_child_weight': 4, 'eta': 1.1511399966340623e-08, 'gamma': 3.437407730045177e-05, 'grow_policy': 'depthwise'}. Best is trial 13 with value: 0.9036888172822528.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:46,920]\u001b[0m Trial 16 finished with value: 0.989838023888537 and parameters: {'booster': 'gblinear', 'lambda': 3.871914227082795e-05, 'alpha': 6.8831121550308756e-06, 'subsample': 0.7492212312439557, 'colsample_bytree': 0.5702659924389755}. Best is trial 13 with value: 0.9036888172822528.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:32:47,052]\u001b[0m Trial 17 finished with value: 0.9088163956825879 and parameters: {'booster': 'gblinear', 'lambda': 0.07240782609158665, 'alpha': 0.0006765644179763197, 'subsample': 0.5217385238599689, 'colsample_bytree': 0.9209578969778767}. Best is trial 13 with value: 0.9036888172822528.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:47,182]\u001b[0m Trial 18 finished with value: 0.9059825952084906 and parameters: {'booster': 'gblinear', 'lambda': 0.10137316961951352, 'alpha': 0.002370178336598244, 'subsample': 0.5720354092510103, 'colsample_bytree': 0.7727322722229835}. Best is trial 13 with value: 0.9036888172822528.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:47,302]\u001b[0m Trial 19 finished with value: 0.9127843963220714 and parameters: {'booster': 'gblinear', 'lambda': 0.0016687521541473799, 'alpha': 0.017008700885377162, 'subsample': 0.8077949491128351, 'colsample_bytree': 0.7738528135598848}. Best is trial 13 with value: 0.9036888172822528.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:47,405]\u001b[0m Trial 20 finished with value: 1.1078865887522678 and parameters: {'booster': 'gblinear', 'lambda': 0.20150024377895812, 'alpha': 0.2601238331786325, 'subsample': 0.6015326073742693, 'colsample_bytree': 0.6362286773650612}. Best is trial 13 with value: 0.9036888172822528.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:47,535]\u001b[0m Trial 21 finished with value: 0.9098296963583673 and parameters: {'booster': 'gblinear', 'lambda': 0.06657720313454765, 'alpha': 0.00046973384356712355, 'subsample': 0.5703197732020912, 'colsample_bytree': 0.8821556535193829}. Best is trial 13 with value: 0.9036888172822528.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:47,666]\u001b[0m Trial 22 finished with value: 0.9059418968451224 and parameters: {'booster': 'gblinear', 'lambda': 0.12765250841883838, 'alpha': 0.0032024409895503227, 'subsample': 0.39960960257262446, 'colsample_bytree': 0.7763461124532243}. Best is trial 13 with value: 0.9036888172822528.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:47,792]\u001b[0m Trial 23 finished with value: 0.9096624863165743 and parameters: {'booster': 'gblinear', 'lambda': 0.003996807873167948, 'alpha': 0.007476058000355194, 'subsample': 0.3916408129193327, 'colsample_bytree': 0.7724764173943363}. Best is trial 13 with value: 0.9036888172822528.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:47,921]\u001b[0m Trial 24 finished with value: 0.9057443991121298 and parameters: {'booster': 'gblinear', 'lambda': 0.21692667568086355, 'alpha': 0.003522085398758916, 'subsample': 0.2664775845182916, 'colsample_bytree': 0.8087961422629039}. Best is trial 13 with value: 0.9036888172822528.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:48,030]\u001b[0m Trial 25 finished with value: 0.9534302600053997 and parameters: {'booster': 'gblinear', 'lambda': 0.0003843416105140719, 'alpha': 0.06955093260475916, 'subsample': 0.2931388463999079, 'colsample_bytree': 0.20630102433241415}. Best is trial 13 with value: 0.9036888172822528.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:48,160]\u001b[0m Trial 26 finished with value: 0.9036022271511331 and parameters: {'booster': 'gblinear', 'lambda': 0.32008206069865586, 'alpha': 0.00011717795216731604, 'subsample': 0.2798208316398746, 'colsample_bytree': 0.6559666118012021}. Best is trial 26 with value: 0.9036022271511331.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:48,290]\u001b[0m Trial 27 finished with value: 0.9054052099658213 and parameters: {'booster': 'gblinear', 'lambda': 0.4332007500169237, 'alpha': 0.00010553549003716387, 'subsample': 0.28273878624676496, 'colsample_bytree': 0.6394377535898325}. Best is trial 26 with value: 0.9036022271511331.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:48,423]\u001b[0m Trial 28 finished with value: 0.9171654604605872 and parameters: {'booster': 'gblinear', 'lambda': 0.9648017260276671, 'alpha': 0.00016442606793248, 'subsample': 0.3278498798998125, 'colsample_bytree': 0.40740982929532266}. Best is trial 26 with value: 0.9036022271511331.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:48,556]\u001b[0m Trial 29 finished with value: 0.9344515282427761 and parameters: {'booster': 'gblinear', 'lambda': 0.01637527642313193, 'alpha': 5.761565801786562e-07, 'subsample': 0.26517799419899013, 'colsample_bytree': 0.5100794412412651}. Best is trial 26 with value: 0.9036022271511331.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:48,687]\u001b[0m Trial 30 finished with value: 0.9036111603733267 and parameters: {'booster': 'gblinear', 'lambda': 0.3228951887555874, 'alpha': 0.00015954192751777731, 'subsample': 0.4417609478892143, 'colsample_bytree': 0.6291352544439278}. Best is trial 26 with value: 0.9036022271511331.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:48,818]\u001b[0m Trial 31 finished with value: 0.903641987143919 and parameters: {'booster': 'gblinear', 'lambda': 0.32433262927392936, 'alpha': 0.00010124488072956093, 'subsample': 0.3376594644034874, 'colsample_bytree': 0.6323788949103623}. Best is trial 26 with value: 0.9036022271511331.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:48,949]\u001b[0m Trial 32 finished with value: 0.9222715941242704 and parameters: {'booster': 'gblinear', 'lambda': 0.03331102843619308, 'alpha': 7.132539353266229e-06, 'subsample': 0.4374780739626113, 'colsample_bytree': 0.5123233706456045}. Best is trial 26 with value: 0.9036022271511331.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:49,080]\u001b[0m Trial 33 finished with value: 0.9031102864693691 and parameters: {'booster': 'gblinear', 'lambda': 0.2986559072622773, 'alpha': 1.9776735554781366e-06, 'subsample': 0.3453086266639582, 'colsample_bytree': 0.6573641491925627}. Best is trial 33 with value: 0.9031102864693691.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:49,212]\u001b[0m Trial 34 finished with value: 0.9490769469265132 and parameters: {'booster': 'gblinear', 'lambda': 0.006628219397344968, 'alpha': 3.335750029979006e-06, 'subsample': 0.4767808207102559, 'colsample_bytree': 0.6212581864658829}. Best is trial 33 with value: 0.9031102864693691.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:49,342]\u001b[0m Trial 35 finished with value: 0.9033350886131633 and parameters: {'booster': 'gblinear', 'lambda': 0.2919954185536767, 'alpha': 0.00017781765937386192, 'subsample': 0.3999964147925489, 'colsample_bytree': 0.675152046605881}. Best is trial 33 with value: 0.9031102864693691.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:50,818]\u001b[0m Trial 36 finished with value: 1.3614764476536974 and parameters: {'booster': 'dart', 'lambda': 0.03860449366995529, 'alpha': 1.278720694052367e-06, 'subsample': 0.4283707940536354, 'colsample_bytree': 0.682880294655759, 'max_depth': 7, 'min_child_weight': 10, 'eta': 2.4865285536671128e-08, 'gamma': 1.776297455552816e-05, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.0550125620111372e-08, 'skip_drop': 0.6122495200357992}. Best is trial 33 with value: 0.9031102864693691.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:51,111]\u001b[0m Trial 37 finished with value: 1.3388199161153507 and parameters: {'booster': 'gbtree', 'lambda': 0.011881973071188691, 'alpha': 4.037570162031649e-05, 'subsample': 0.23742606609718941, 'colsample_bytree': 0.5617484031930772, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.00028866049676517857, 'gamma': 0.0004953883735071892, 'grow_policy': 'depthwise'}. Best is trial 33 with value: 0.9031102864693691.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:51,242]\u001b[0m Trial 38 finished with value: 0.9038664860728055 and parameters: {'booster': 'gblinear', 'lambda': 0.33587783621997835, 'alpha': 0.00026928410317783905, 'subsample': 0.38434868450294035, 'colsample_bytree': 0.708309975537647}. Best is trial 33 with value: 0.9031102864693691.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:51,374]\u001b[0m Trial 39 finished with value: 0.9183718332719562 and parameters: {'booster': 'gblinear', 'lambda': 0.0447739751059186, 'alpha': 1.7641247423076693e-07, 'subsample': 0.4967996969514716, 'colsample_bytree': 0.6703676254757954}. Best is trial 33 with value: 0.9031102864693691.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:52,582]\u001b[0m Trial 40 finished with value: 0.9506769554353076 and parameters: {'booster': 'dart', 'lambda': 0.0018578544289387369, 'alpha': 0.0010326067215051444, 'subsample': 0.41100556919174136, 'colsample_bytree': 0.5442025619061319, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.47080834968970936, 'gamma': 2.5430851039052265e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.2046182692355903, 'skip_drop': 1.4216558789919564e-08}. Best is trial 33 with value: 0.9031102864693691.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:32:52,713]\u001b[0m Trial 41 finished with value: 0.9029901164007267 and parameters: {'booster': 'gblinear', 'lambda': 0.2743957177651317, 'alpha': 7.471033145906157e-05, 'subsample': 0.33247099983022627, 'colsample_bytree': 0.5986733041738934}. Best is trial 41 with value: 0.9029901164007267.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:52,843]\u001b[0m Trial 42 finished with value: 0.9068957551731422 and parameters: {'booster': 'gblinear', 'lambda': 0.44152957689697553, 'alpha': 0.0014620598398702317, 'subsample': 0.3164945976098333, 'colsample_bytree': 0.7325817271391131}. Best is trial 41 with value: 0.9029901164007267.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:52,976]\u001b[0m Trial 43 finished with value: 0.9940769624419928 and parameters: {'booster': 'gblinear', 'lambda': 4.222712058498906e-08, 'alpha': 4.673222125540773e-05, 'subsample': 0.35503078676263644, 'colsample_bytree': 0.5922723326090717}. Best is trial 41 with value: 0.9029901164007267.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:53,107]\u001b[0m Trial 44 finished with value: 0.9178511564007709 and parameters: {'booster': 'gblinear', 'lambda': 0.995171902023468, 'alpha': 0.00021305057059063808, 'subsample': 0.30775255627668363, 'colsample_bytree': 0.4502092791065908}. Best is trial 41 with value: 0.9029901164007267.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:53,237]\u001b[0m Trial 45 finished with value: 0.933044749764767 and parameters: {'booster': 'gblinear', 'lambda': 0.019175255992891056, 'alpha': 1.3618975560959725e-05, 'subsample': 0.23711426320177836, 'colsample_bytree': 0.7344117583203286}. Best is trial 41 with value: 0.9029901164007267.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:54,609]\u001b[0m Trial 46 finished with value: 1.3463483503577516 and parameters: {'booster': 'dart', 'lambda': 0.11752172514918617, 'alpha': 2.0117024879820208e-08, 'subsample': 0.35570015168815383, 'colsample_bytree': 0.6675141790610916, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.00020021105989135503, 'gamma': 6.53623367335134e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.6326034846540085e-06, 'skip_drop': 0.004126094783953106}. Best is trial 41 with value: 0.9029901164007267.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:54,916]\u001b[0m Trial 47 finished with value: 0.8907929317554906 and parameters: {'booster': 'gbtree', 'lambda': 3.6768538565548902e-06, 'alpha': 1.4632228024871188e-06, 'subsample': 0.45506945644737634, 'colsample_bytree': 0.5946813572052916, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.05417912009872432, 'gamma': 0.0003118439326917183, 'grow_policy': 'depthwise'}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:55,230]\u001b[0m Trial 48 finished with value: 0.9458342658432237 and parameters: {'booster': 'gbtree', 'lambda': 2.263210005072832e-06, 'alpha': 2.285506775268077e-06, 'subsample': 0.6751884551198328, 'colsample_bytree': 0.5237721008689354, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.08830314566429712, 'gamma': 0.0002595376732793997, 'grow_policy': 'depthwise'}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:55,524]\u001b[0m Trial 49 finished with value: 1.283574398663112 and parameters: {'booster': 'gbtree', 'lambda': 2.9739741805973886e-07, 'alpha': 6.166166898121468e-08, 'subsample': 0.48231374019807477, 'colsample_bytree': 0.3879176604629755, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.001049043419126394, 'gamma': 0.013528956888451007, 'grow_policy': 'depthwise'}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:55,785]\u001b[0m Trial 50 finished with value: 0.9590590320650295 and parameters: {'booster': 'gbtree', 'lambda': 2.7618826408871913e-05, 'alpha': 7.217705217006295e-07, 'subsample': 0.36919437184772735, 'colsample_bytree': 0.6039670159135735, 'max_depth': 7, 'min_child_weight': 5, 'eta': 0.05832733919353851, 'gamma': 0.0026417162195982286, 'grow_policy': 'depthwise'}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:56,098]\u001b[0m Trial 51 finished with value: 1.281469617129179 and parameters: {'booster': 'gbtree', 'lambda': 4.443377970917629e-06, 'alpha': 2.7260140004454656e-07, 'subsample': 0.4451577569915221, 'colsample_bytree': 0.6494976692639836, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.0010841851842448478, 'gamma': 8.316511571712017e-05, 'grow_policy': 'depthwise'}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:56,377]\u001b[0m Trial 52 finished with value: 1.0568470822331748 and parameters: {'booster': 'gbtree', 'lambda': 0.00030501306576062316, 'alpha': 9.55231686076267e-06, 'subsample': 0.540919617069346, 'colsample_bytree': 0.5985736358042343, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.1778099856965487, 'gamma': 0.062016029801755045, 'grow_policy': 'depthwise'}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:56,509]\u001b[0m Trial 53 finished with value: 0.9064682478237452 and parameters: {'booster': 'gblinear', 'lambda': 0.4827547434548553, 'alpha': 6.283338585227964e-05, 'subsample': 0.2477717075777111, 'colsample_bytree': 0.4892212184819916}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:56,828]\u001b[0m Trial 54 finished with value: 0.9669725150065982 and parameters: {'booster': 'gbtree', 'lambda': 4.967593176115622e-07, 'alpha': 0.0003135996559177061, 'subsample': 0.419768918895146, 'colsample_bytree': 0.5756229088231154, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.010852138899005012, 'gamma': 3.112964455112802e-07, 'grow_policy': 'depthwise'}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:56,961]\u001b[0m Trial 55 finished with value: 0.9903622409855516 and parameters: {'booster': 'gblinear', 'lambda': 7.495173334652692e-05, 'alpha': 2.053714344112795e-05, 'subsample': 0.20638742292734724, 'colsample_bytree': 0.5445039386876946}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:57,093]\u001b[0m Trial 56 finished with value: 1.000886706318041 and parameters: {'booster': 'gblinear', 'lambda': 9.228352968057608e-06, 'alpha': 5.2331810014700086e-06, 'subsample': 0.29891345115337475, 'colsample_bytree': 0.7302691703398051}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:58,609]\u001b[0m Trial 57 finished with value: 1.2835366761882625 and parameters: {'booster': 'dart', 'lambda': 0.06299731647025715, 'alpha': 1.0933941093995794e-06, 'subsample': 0.4650136056757183, 'colsample_bytree': 0.6865034295881256, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.0011642720121228074, 'gamma': 5.251020101097317e-06, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.01249537397926485, 'skip_drop': 1.5342414656260442e-06}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:58,773]\u001b[0m Trial 58 finished with value: 0.9039854554275066 and parameters: {'booster': 'gblinear', 'lambda': 0.17172168251114173, 'alpha': 0.0005299656330412097, 'subsample': 0.8879169915912721, 'colsample_bytree': 0.6555962056530139}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:58,900]\u001b[0m Trial 59 finished with value: 0.909934741159847 and parameters: {'booster': 'gblinear', 'lambda': 0.2511477587940025, 'alpha': 0.008003779081639543, 'subsample': 0.3731930170285082, 'colsample_bytree': 0.611883463063059}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:59,216]\u001b[0m Trial 60 finished with value: 0.9146373278862175 and parameters: {'booster': 'gbtree', 'lambda': 0.06763179917932388, 'alpha': 1.0339451457519476e-07, 'subsample': 0.5625622641749378, 'colsample_bytree': 0.7511867626573079, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.05738336533141441, 'gamma': 0.00013223658805748835, 'grow_policy': 'depthwise'}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:59,347]\u001b[0m Trial 61 finished with value: 0.9062234819126715 and parameters: {'booster': 'gblinear', 'lambda': 0.4668895080411112, 'alpha': 0.00012331321436721495, 'subsample': 0.33298150986095426, 'colsample_bytree': 0.635658574535514}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:59,478]\u001b[0m Trial 62 finished with value: 0.9028186218706379 and parameters: {'booster': 'gblinear', 'lambda': 0.22044977301276972, 'alpha': 2.6802015563109505e-05, 'subsample': 0.39077402364776337, 'colsample_bytree': 0.7011896562479788}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:32:59,609]\u001b[0m Trial 63 finished with value: 0.905299714754645 and parameters: {'booster': 'gblinear', 'lambda': 0.12545393395241072, 'alpha': 3.4333078321230725e-05, 'subsample': 0.4023472871250937, 'colsample_bytree': 0.6937515353998885}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:59,739]\u001b[0m Trial 64 finished with value: 0.9100997043030787 and parameters: {'booster': 'gblinear', 'lambda': 0.6481582682652693, 'alpha': 2.8633885707011453e-06, 'subsample': 0.6208062144677975, 'colsample_bytree': 0.8259577450668932}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:32:59,872]\u001b[0m Trial 65 finished with value: 0.9918146834846515 and parameters: {'booster': 'gblinear', 'lambda': 1.69108108866456e-07, 'alpha': 1.1654947253766425e-05, 'subsample': 0.4546880536185236, 'colsample_bytree': 0.5755576711415472}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:00,004]\u001b[0m Trial 66 finished with value: 0.9027864247976587 and parameters: {'booster': 'gblinear', 'lambda': 0.25434827891074585, 'alpha': 2.4912037514269043e-05, 'subsample': 0.5003804316995688, 'colsample_bytree': 0.7011608136061575}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:00,137]\u001b[0m Trial 67 finished with value: 0.942167623342068 and parameters: {'booster': 'gblinear', 'lambda': 0.009571964060007756, 'alpha': 6.53028965222025e-05, 'subsample': 0.5369248879845486, 'colsample_bytree': 0.7137617452349175}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:00,268]\u001b[0m Trial 68 finished with value: 0.9265319076897598 and parameters: {'booster': 'gblinear', 'lambda': 0.025708756151340335, 'alpha': 1.826288132649732e-05, 'subsample': 0.5108626523503722, 'colsample_bytree': 0.8590968119841993}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:00,403]\u001b[0m Trial 69 finished with value: 0.9067311196851042 and parameters: {'booster': 'gblinear', 'lambda': 0.10120556433821888, 'alpha': 4.7386475122532e-06, 'subsample': 0.28692629793444946, 'colsample_bytree': 0.7522068393347052}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:00,536]\u001b[0m Trial 70 finished with value: 0.9027796192727192 and parameters: {'booster': 'gblinear', 'lambda': 0.2258737841552011, 'alpha': 2.750977527823589e-05, 'subsample': 0.3743393794452644, 'colsample_bytree': 0.7967933332558813}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:00,669]\u001b[0m Trial 71 finished with value: 0.9028570556961266 and parameters: {'booster': 'gblinear', 'lambda': 0.21158483615020532, 'alpha': 2.414167409836715e-05, 'subsample': 0.37784237468817566, 'colsample_bytree': 0.7979284508356338}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:00,802]\u001b[0m Trial 72 finished with value: 0.9037409517384942 and parameters: {'booster': 'gblinear', 'lambda': 0.15533441274773166, 'alpha': 2.1704317083021143e-05, 'subsample': 0.3910458484721162, 'colsample_bytree': 0.8053850916229277}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:00,934]\u001b[0m Trial 73 finished with value: 0.9027278422105934 and parameters: {'booster': 'gblinear', 'lambda': 0.22928808982751572, 'alpha': 8.340125694022781e-06, 'subsample': 0.41680432388248856, 'colsample_bytree': 0.798899839750123}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:01,065]\u001b[0m Trial 74 finished with value: 0.9141030981067276 and parameters: {'booster': 'gblinear', 'lambda': 0.055545122467166995, 'alpha': 9.764025305567141e-06, 'subsample': 0.3722872119833852, 'colsample_bytree': 0.8425715812127554}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:01,198]\u001b[0m Trial 75 finished with value: 0.9123057694381929 and parameters: {'booster': 'gblinear', 'lambda': 0.7466011673842614, 'alpha': 6.000680679603326e-06, 'subsample': 0.42163681159268607, 'colsample_bytree': 0.8892523484144249}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:01,331]\u001b[0m Trial 76 finished with value: 0.9028229651805713 and parameters: {'booster': 'gblinear', 'lambda': 0.2106522019838627, 'alpha': 1.4738321233160908e-06, 'subsample': 0.3520545104673672, 'colsample_bytree': 0.804595677266594}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:02,904]\u001b[0m Trial 77 finished with value: 1.3561354323958634 and parameters: {'booster': 'dart', 'lambda': 0.09139052600127814, 'alpha': 3.005931216869923e-05, 'subsample': 0.48686871248284275, 'colsample_bytree': 0.7850080632321904, 'max_depth': 9, 'min_child_weight': 6, 'eta': 6.245079227737864e-05, 'gamma': 0.0013746138042770636, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.4368099056558781e-06, 'skip_drop': 0.01930406448976329}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:03,035]\u001b[0m Trial 78 finished with value: 0.9250133030766252 and parameters: {'booster': 'gblinear', 'lambda': 0.02825822861826548, 'alpha': 3.371482368620912e-06, 'subsample': 0.46088377182260587, 'colsample_bytree': 0.8141475295707822}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:03,167]\u001b[0m Trial 79 finished with value: 0.96484943812147 and parameters: {'booster': 'gblinear', 'lambda': 0.0031773652710194323, 'alpha': 8.984158399268059e-07, 'subsample': 0.32300443605437146, 'colsample_bytree': 0.959528549542543}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:03,425]\u001b[0m Trial 80 finished with value: 1.3614710282466134 and parameters: {'booster': 'gbtree', 'lambda': 0.18874716455302062, 'alpha': 3.444124800704859e-07, 'subsample': 0.42668489789263975, 'colsample_bytree': 0.8520232318242515, 'max_depth': 5, 'min_child_weight': 7, 'eta': 9.679152435194578e-08, 'gamma': 0.025738570495160436, 'grow_policy': 'depthwise'}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:03,556]\u001b[0m Trial 81 finished with value: 0.9093011756833684 and parameters: {'booster': 'gblinear', 'lambda': 0.6143068242261839, 'alpha': 1.848826692841539e-06, 'subsample': 0.35081623312870913, 'colsample_bytree': 0.7590676739116548}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:03,688]\u001b[0m Trial 82 finished with value: 0.9823402089030749 and parameters: {'booster': 'gblinear', 'lambda': 0.0006227496488087646, 'alpha': 1.6775640382317919e-06, 'subsample': 0.35785578611454016, 'colsample_bytree': 0.7972066034531688}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:03,821]\u001b[0m Trial 83 finished with value: 0.9030285939969812 and parameters: {'booster': 'gblinear', 'lambda': 0.20118325712561147, 'alpha': 6.0300882749025436e-05, 'subsample': 0.39070735987770167, 'colsample_bytree': 0.9071273322823614}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:03,951]\u001b[0m Trial 84 finished with value: 0.9031372261227657 and parameters: {'booster': 'gblinear', 'lambda': 0.19122780084605592, 'alpha': 5.292690753974901e-05, 'subsample': 0.40345253222473787, 'colsample_bytree': 0.9196575000462017}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:04,082]\u001b[0m Trial 85 finished with value: 0.9084456561031875 and parameters: {'booster': 'gblinear', 'lambda': 0.08592276023554163, 'alpha': 2.323164840160583e-05, 'subsample': 0.38102620822985966, 'colsample_bytree': 0.9664203370179965}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:04,215]\u001b[0m Trial 86 finished with value: 0.9159939657205044 and parameters: {'booster': 'gblinear', 'lambda': 0.04805842994767342, 'alpha': 7.921363536316236e-06, 'subsample': 0.9843382751200466, 'colsample_bytree': 0.8240946041769188}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:04,348]\u001b[0m Trial 87 finished with value: 0.9028736491724387 and parameters: {'booster': 'gblinear', 'lambda': 0.24680713449952826, 'alpha': 9.060840494194923e-05, 'subsample': 0.3124266807109099, 'colsample_bytree': 0.8970448722066535}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:33:04,489]\u001b[0m Trial 88 finished with value: 0.9059205162452042 and parameters: {'booster': 'gblinear', 'lambda': 0.45353120511782835, 'alpha': 8.482582695270235e-05, 'subsample': 0.31557838897257623, 'colsample_bytree': 0.883787129193082}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:04,621]\u001b[0m Trial 89 finished with value: 0.9048757163624175 and parameters: {'booster': 'gblinear', 'lambda': 0.13132107881450955, 'alpha': 1.4711487715057883e-05, 'subsample': 0.26867199451972745, 'colsample_bytree': 0.7696031843114324}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:04,892]\u001b[0m Trial 90 finished with value: 0.9142129128884596 and parameters: {'booster': 'gbtree', 'lambda': 0.9541283555539742, 'alpha': 3.4748016126230356e-05, 'subsample': 0.33124328479203863, 'colsample_bytree': 0.8583943254752772, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.02102777594662445, 'gamma': 9.735329216448864e-08, 'grow_policy': 'lossguide'}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:05,023]\u001b[0m Trial 91 finished with value: 0.9028357000102126 and parameters: {'booster': 'gblinear', 'lambda': 0.22437386283570634, 'alpha': 7.055366320425639e-05, 'subsample': 0.43983895983948085, 'colsample_bytree': 0.9326060201583493}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:05,157]\u001b[0m Trial 92 finished with value: 0.9034610226715818 and parameters: {'booster': 'gblinear', 'lambda': 0.25872604363966006, 'alpha': 0.000413197809001938, 'subsample': 0.4456809027178379, 'colsample_bytree': 0.9490248992964121}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:05,288]\u001b[0m Trial 93 finished with value: 0.9032660039156387 and parameters: {'booster': 'gblinear', 'lambda': 0.2970792171268642, 'alpha': 9.684162828336014e-05, 'subsample': 0.508113692488675, 'colsample_bytree': 0.7903334952907248}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:05,422]\u001b[0m Trial 94 finished with value: 0.9095344027350524 and parameters: {'booster': 'gblinear', 'lambda': 0.6214222595659518, 'alpha': 2.686691158919537e-05, 'subsample': 0.4736461132754182, 'colsample_bytree': 0.9914332372701501}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:05,554]\u001b[0m Trial 95 finished with value: 0.9269116419692571 and parameters: {'booster': 'gblinear', 'lambda': 0.021086498402236583, 'alpha': 0.00023151607400300308, 'subsample': 0.3088258287614025, 'colsample_bytree': 0.9056955074707497}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:07,112]\u001b[0m Trial 96 finished with value: 1.0561577777476712 and parameters: {'booster': 'dart', 'lambda': 1.3481501217223713e-08, 'alpha': 0.00015921549713606505, 'subsample': 0.41508921688120426, 'colsample_bytree': 0.8738045851822746, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.006193954187846098, 'gamma': 0.4382934439645317, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 5.845763740029885e-06, 'skip_drop': 1.0375759171908851e-05}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:07,246]\u001b[0m Trial 97 finished with value: 0.921415281253934 and parameters: {'booster': 'gblinear', 'lambda': 0.034732092781228116, 'alpha': 1.4397887349198319e-05, 'subsample': 0.3703767206572271, 'colsample_bytree': 0.9390889904790788}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:07,379]\u001b[0m Trial 98 finished with value: 0.9848646782952014 and parameters: {'booster': 'gblinear', 'lambda': 0.00017246365944568597, 'alpha': 3.9092636236356674e-05, 'subsample': 0.4360857025445636, 'colsample_bytree': 0.8305606305381097}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:07,581]\u001b[0m Trial 99 finished with value: 1.3605168340571627 and parameters: {'booster': 'gbtree', 'lambda': 0.3981251864212942, 'alpha': 7.679025140649542e-05, 'subsample': 0.34522066310953936, 'colsample_bytree': 0.720534822864891, 'max_depth': 3, 'min_child_weight': 8, 'eta': 1.273450324227542e-05, 'gamma': 2.562596943959996e-05, 'grow_policy': 'depthwise'}. Best is trial 47 with value: 0.8907929317554906.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:07,943]\u001b[0m A new study created in memory with name: no-name-e31a96fe-72c6-4216-a6a6-0adfda5c763b\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:09,549]\u001b[0m Trial 0 finished with value: 1.381348527338662 and parameters: {'booster': 'dart', 'lambda': 0.02359177257382612, 'alpha': 2.0411364784338686e-05, 'subsample': 0.9749139061361685, 'colsample_bytree': 0.9738808645126709, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.00010918766667893853, 'gamma': 5.800464606477829e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 3.7417863497599802e-06, 'skip_drop': 2.9559183991278347e-07}. Best is trial 0 with value: 1.381348527338662.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:09,720]\u001b[0m Trial 1 finished with value: 1.3969345044386414 and parameters: {'booster': 'gbtree', 'lambda': 0.0071640881667365975, 'alpha': 0.0015576069634357975, 'subsample': 0.9095805246726316, 'colsample_bytree': 0.6026483443553772, 'max_depth': 3, 'min_child_weight': 10, 'eta': 3.0422712122311293e-06, 'gamma': 0.009250437303351847, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 1.381348527338662.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:09,977]\u001b[0m Trial 2 finished with value: 0.6201847047220329 and parameters: {'booster': 'gbtree', 'lambda': 5.627982649325e-08, 'alpha': 0.885646805315439, 'subsample': 0.7464443934096214, 'colsample_bytree': 0.9361067432051675, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.05330415556219257, 'gamma': 0.9739135689484525, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 0.6201847047220329.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:10,159]\u001b[0m Trial 3 finished with value: 1.3469097357429984 and parameters: {'booster': 'gbtree', 'lambda': 0.0001270956537345933, 'alpha': 0.5639077430102263, 'subsample': 0.7451053833839738, 'colsample_bytree': 0.814730635341973, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.00042481192318488697, 'gamma': 1.0293895979306908e-07, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 0.6201847047220329.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:10,276]\u001b[0m Trial 4 finished with value: 0.6917627172367179 and parameters: {'booster': 'gblinear', 'lambda': 0.0015093035068194922, 'alpha': 2.5784557999871576e-08, 'subsample': 0.6766260272127408, 'colsample_bytree': 0.5854026430377759}. Best is trial 2 with value: 0.6201847047220329.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:10,452]\u001b[0m Trial 5 finished with value: 0.7543689240093929 and parameters: {'booster': 'gbtree', 'lambda': 9.156353031875876e-07, 'alpha': 4.306763491749694e-08, 'subsample': 0.8791435773728271, 'colsample_bytree': 0.2435443151899772, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.43494376497489473, 'gamma': 0.1353721758692335, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 0.6201847047220329.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:10,567]\u001b[0m Trial 6 finished with value: 0.6829336236674262 and parameters: {'booster': 'gblinear', 'lambda': 0.00010394929604247348, 'alpha': 0.0015916666668263132, 'subsample': 0.9854913878180913, 'colsample_bytree': 0.3305435644849688}. Best is trial 2 with value: 0.6201847047220329.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:10,683]\u001b[0m Trial 7 finished with value: 0.6919472531523047 and parameters: {'booster': 'gblinear', 'lambda': 0.006879971314471253, 'alpha': 4.649961214305297e-08, 'subsample': 0.9768602882330375, 'colsample_bytree': 0.7960069997042438}. Best is trial 2 with value: 0.6201847047220329.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:10,848]\u001b[0m Trial 8 finished with value: 1.0776483345567138 and parameters: {'booster': 'gbtree', 'lambda': 0.012852245949145814, 'alpha': 2.9987155295061986e-05, 'subsample': 0.35589793071683806, 'colsample_bytree': 0.2831471070564048, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.004724700194444516, 'gamma': 1.26720470186838e-08, 'grow_policy': 'depthwise'}. Best is trial 2 with value: 0.6201847047220329.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:12,267]\u001b[0m Trial 9 finished with value: 1.3960461433982514 and parameters: {'booster': 'dart', 'lambda': 0.0013562676795922481, 'alpha': 0.0005864289697995556, 'subsample': 0.521495695575677, 'colsample_bytree': 0.7924816742474408, 'max_depth': 5, 'min_child_weight': 5, 'eta': 9.27106188345634e-06, 'gamma': 0.00027429672446917794, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.00015959492679613383, 'skip_drop': 1.3490934154080862e-08}. Best is trial 2 with value: 0.6201847047220329.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:33:12,557]\u001b[0m Trial 10 finished with value: 107361.8371999802 and parameters: {'booster': 'gbtree', 'lambda': 2.7310602073480857e-08, 'alpha': 0.5027505029889384, 'subsample': 0.21722977225617285, 'colsample_bytree': 0.9858188202570102, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.8965515059019402, 'gamma': 0.20278926181810833, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 0.6201847047220329.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:12,670]\u001b[0m Trial 11 finished with value: 0.866910515785556 and parameters: {'booster': 'gblinear', 'lambda': 2.2928249500899447e-06, 'alpha': 0.04735907882955926, 'subsample': 0.808401910006709, 'colsample_bytree': 0.4109850267773625}. Best is trial 2 with value: 0.6201847047220329.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:12,796]\u001b[0m Trial 12 finished with value: 0.9001778692572272 and parameters: {'booster': 'gblinear', 'lambda': 0.8628534496852148, 'alpha': 0.009521953260397004, 'subsample': 0.5710876558071307, 'colsample_bytree': 0.4717145915588335}. Best is trial 2 with value: 0.6201847047220329.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:12,928]\u001b[0m Trial 13 finished with value: 0.6942446099784677 and parameters: {'booster': 'gblinear', 'lambda': 5.640192360536417e-06, 'alpha': 2.300729255228385e-06, 'subsample': 0.6872504575053331, 'colsample_bytree': 0.6550418675012539}. Best is trial 2 with value: 0.6201847047220329.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:14,091]\u001b[0m Trial 14 finished with value: 1.3972746367528526 and parameters: {'booster': 'dart', 'lambda': 1.1024988859849207e-08, 'alpha': 0.03382591764478714, 'subsample': 0.8287696293247692, 'colsample_bytree': 0.38514225237515365, 'max_depth': 7, 'min_child_weight': 2, 'eta': 6.552433246025434e-08, 'gamma': 2.4754601832303594e-05, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.8478040288864381, 'skip_drop': 0.38247694796914}. Best is trial 2 with value: 0.6201847047220329.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:14,388]\u001b[0m Trial 15 finished with value: 0.7058417928690766 and parameters: {'booster': 'gbtree', 'lambda': 1.56926072265791e-07, 'alpha': 1.5903474283205216e-06, 'subsample': 0.4998725677944078, 'colsample_bytree': 0.6882605294468263, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.0150773289071536, 'gamma': 0.002097957242323352, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 0.6201847047220329.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:14,518]\u001b[0m Trial 16 finished with value: 0.6880452465362945 and parameters: {'booster': 'gblinear', 'lambda': 8.456458547181486e-06, 'alpha': 0.0005569091096481343, 'subsample': 0.6552629022014873, 'colsample_bytree': 0.4762818294740168}. Best is trial 2 with value: 0.6201847047220329.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:14,734]\u001b[0m Trial 17 finished with value: 0.6207605051384476 and parameters: {'booster': 'gbtree', 'lambda': 3.825612441322795e-05, 'alpha': 0.0902861390705466, 'subsample': 0.7651872873329101, 'colsample_bytree': 0.894551843445219, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.047479954838207813, 'gamma': 0.9202357471197212, 'grow_policy': 'depthwise'}. Best is trial 2 with value: 0.6201847047220329.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:14,951]\u001b[0m Trial 18 finished with value: 0.6569625767698296 and parameters: {'booster': 'gbtree', 'lambda': 1.5550277077241117e-07, 'alpha': 0.11985785229314407, 'subsample': 0.7567244259989564, 'colsample_bytree': 0.898740251081029, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.02432310682761871, 'gamma': 0.7762981649351898, 'grow_policy': 'depthwise'}. Best is trial 2 with value: 0.6201847047220329.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:15,156]\u001b[0m Trial 19 finished with value: 0.6208383850177067 and parameters: {'booster': 'gbtree', 'lambda': 2.2223506123930466e-05, 'alpha': 0.8456933301195102, 'subsample': 0.43371590244706915, 'colsample_bytree': 0.8619131287190027, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.052137865979151654, 'gamma': 0.01147769139669221, 'grow_policy': 'depthwise'}. Best is trial 2 with value: 0.6201847047220329.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:15,420]\u001b[0m Trial 20 finished with value: 1.230719510551498 and parameters: {'booster': 'gbtree', 'lambda': 5.939537403618771e-07, 'alpha': 0.008053391144648238, 'subsample': 0.6067565687074302, 'colsample_bytree': 0.7286205244960307, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.0014605632509883263, 'gamma': 0.05341549697241648, 'grow_policy': 'depthwise'}. Best is trial 2 with value: 0.6201847047220329.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:15,620]\u001b[0m Trial 21 finished with value: 0.6026474780008506 and parameters: {'booster': 'gbtree', 'lambda': 1.8497824360661747e-05, 'alpha': 0.9857000872122365, 'subsample': 0.3874252649335105, 'colsample_bytree': 0.8773519115797845, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.08838208822485757, 'gamma': 0.014917710625185815, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.6026474780008506.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:15,813]\u001b[0m Trial 22 finished with value: 0.614639881061035 and parameters: {'booster': 'gbtree', 'lambda': 2.6422066997806844e-05, 'alpha': 0.14424152589056896, 'subsample': 0.2805350451570424, 'colsample_bytree': 0.9105317429318317, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.07486576547822375, 'gamma': 0.45171903779783096, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.6026474780008506.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:16,008]\u001b[0m Trial 23 finished with value: 0.5983026284281632 and parameters: {'booster': 'gbtree', 'lambda': 0.0004670878678060867, 'alpha': 0.18815410867065338, 'subsample': 0.2479113356733833, 'colsample_bytree': 0.9618801559458395, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.15355758186330704, 'gamma': 0.03771776306938205, 'grow_policy': 'depthwise'}. Best is trial 23 with value: 0.5983026284281632.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:16,191]\u001b[0m Trial 24 finished with value: 0.8874507202450839 and parameters: {'booster': 'gbtree', 'lambda': 0.0004592840543309009, 'alpha': 0.13479382350014268, 'subsample': 0.21140996836517123, 'colsample_bytree': 0.8440605557671892, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.29263305114489396, 'gamma': 0.000457879482563352, 'grow_policy': 'depthwise'}. Best is trial 23 with value: 0.5983026284281632.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:16,391]\u001b[0m Trial 25 finished with value: 1.1312937456494943 and parameters: {'booster': 'gbtree', 'lambda': 0.0003589990166832949, 'alpha': 0.008245357212918789, 'subsample': 0.3140017639106358, 'colsample_bytree': 0.9893527109349058, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.002664402202255966, 'gamma': 0.021921064663549057, 'grow_policy': 'depthwise'}. Best is trial 23 with value: 0.5983026284281632.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:17,779]\u001b[0m Trial 26 finished with value: 0.6036796265456088 and parameters: {'booster': 'dart', 'lambda': 0.10732018730490818, 'alpha': 0.015688559464053193, 'subsample': 0.3012648122038024, 'colsample_bytree': 0.75815682346015, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.1277311594973645, 'gamma': 0.003005194951137437, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 2.0072952584797385e-08, 'skip_drop': 0.059045458060181286}. Best is trial 23 with value: 0.5983026284281632.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:19,250]\u001b[0m Trial 27 finished with value: 9.095764408741378 and parameters: {'booster': 'dart', 'lambda': 0.3607674863119078, 'alpha': 0.022502299116072193, 'subsample': 0.4026256307222571, 'colsample_bytree': 0.739081576976451, 'max_depth': 5, 'min_child_weight': 2, 'eta': 0.9608273923842516, 'gamma': 0.002466834374459659, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.560201790722588e-08, 'skip_drop': 0.10494989265486}. Best is trial 23 with value: 0.5983026284281632.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:20,658]\u001b[0m Trial 28 finished with value: 0.9220943947403718 and parameters: {'booster': 'dart', 'lambda': 0.1657389571483057, 'alpha': 0.21174375343199756, 'subsample': 0.2780790952357365, 'colsample_bytree': 0.7559231941043848, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.007039226991462822, 'gamma': 2.059962020131154e-05, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.1766380169309708e-08, 'skip_drop': 0.00144980423499283}. Best is trial 23 with value: 0.5983026284281632.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:33:22,243]\u001b[0m Trial 29 finished with value: 0.7792260763299825 and parameters: {'booster': 'dart', 'lambda': 0.09272736378989888, 'alpha': 6.579392404697274e-05, 'subsample': 0.421421519425229, 'colsample_bytree': 0.9586784055405078, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.17969791896626178, 'gamma': 0.0016474348785773072, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 2.1795612019555105e-05, 'skip_drop': 0.00014114884358942483}. Best is trial 23 with value: 0.5983026284281632.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:23,660]\u001b[0m Trial 30 finished with value: 1.3962272105891225 and parameters: {'booster': 'dart', 'lambda': 0.04299219674364856, 'alpha': 4.5171719485281894e-06, 'subsample': 0.3592208978215122, 'colsample_bytree': 0.8691161378927018, 'max_depth': 3, 'min_child_weight': 4, 'eta': 8.449891787193946e-06, 'gamma': 4.91817113377507e-05, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.006721451004686385, 'skip_drop': 0.0023487324813625697}. Best is trial 23 with value: 0.5983026284281632.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:25,076]\u001b[0m Trial 31 finished with value: 0.6417276534448676 and parameters: {'booster': 'dart', 'lambda': 3.483259590691692e-05, 'alpha': 0.19599957235808466, 'subsample': 0.27296887549984633, 'colsample_bytree': 0.9047574206509754, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.1537596607728015, 'gamma': 0.09207520600406588, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 4.632951069406398e-07, 'skip_drop': 2.843693732446618e-06}. Best is trial 23 with value: 0.5983026284281632.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:25,274]\u001b[0m Trial 32 finished with value: 0.611428926679653 and parameters: {'booster': 'gbtree', 'lambda': 0.0013957550319046255, 'alpha': 0.024936042796607695, 'subsample': 0.26756125959749155, 'colsample_bytree': 0.9421658236035465, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.10778871712744421, 'gamma': 0.020057268912773693, 'grow_policy': 'depthwise'}. Best is trial 23 with value: 0.5983026284281632.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:25,483]\u001b[0m Trial 33 finished with value: 1.2934895827237074 and parameters: {'booster': 'gbtree', 'lambda': 0.004119859910196077, 'alpha': 0.0024875200911137277, 'subsample': 0.336433682669268, 'colsample_bytree': 0.9979624289389085, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.0008658847243388942, 'gamma': 0.007308010865738739, 'grow_policy': 'depthwise'}. Best is trial 23 with value: 0.5983026284281632.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:25,721]\u001b[0m Trial 34 finished with value: 0.740005280930939 and parameters: {'booster': 'gbtree', 'lambda': 0.00034731792088049635, 'alpha': 0.02544242026809524, 'subsample': 0.23078077650151999, 'colsample_bytree': 0.9402714368075175, 'max_depth': 5, 'min_child_weight': 3, 'eta': 0.01345020223578731, 'gamma': 0.027812609602210377, 'grow_policy': 'depthwise'}. Best is trial 23 with value: 0.5983026284281632.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:27,167]\u001b[0m Trial 35 finished with value: 0.6080303392970212 and parameters: {'booster': 'dart', 'lambda': 0.0019394994231630377, 'alpha': 0.00041012619681108037, 'subsample': 0.46872004794391187, 'colsample_bytree': 0.8215880815930134, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.1588719575562285, 'gamma': 0.0005315867034624884, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.001229717047502468, 'skip_drop': 0.020826243026980277}. Best is trial 23 with value: 0.5983026284281632.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:28,643]\u001b[0m Trial 36 finished with value: 1.3972758844743753 and parameters: {'booster': 'dart', 'lambda': 0.02138573498682514, 'alpha': 0.0003401551480848801, 'subsample': 0.4601826452146281, 'colsample_bytree': 0.6267035066694827, 'max_depth': 3, 'min_child_weight': 4, 'eta': 1.9045903691076307e-08, 'gamma': 0.0005412095661079096, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.0030016163789695987, 'skip_drop': 0.02038110160791416}. Best is trial 23 with value: 0.5983026284281632.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:30,264]\u001b[0m Trial 37 finished with value: 1.3507987873354654 and parameters: {'booster': 'dart', 'lambda': 0.0030935602933491804, 'alpha': 0.004698430636483602, 'subsample': 0.38511576717373835, 'colsample_bytree': 0.5578029322601005, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.000388628475465637, 'gamma': 2.2145364914793902e-06, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.0024068393975680076, 'skip_drop': 0.8026982007403921}. Best is trial 23 with value: 0.5983026284281632.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:31,619]\u001b[0m Trial 38 finished with value: 1.3894220324892417 and parameters: {'booster': 'dart', 'lambda': 0.0002153774423499866, 'alpha': 0.3497954208586888, 'subsample': 0.4893175070563228, 'colsample_bytree': 0.8051095375155388, 'max_depth': 5, 'min_child_weight': 2, 'eta': 6.0635790490626e-05, 'gamma': 0.00019105546095486554, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.19815351300959885, 'skip_drop': 0.0075920115507513}. Best is trial 23 with value: 0.5983026284281632.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:33,062]\u001b[0m Trial 39 finished with value: 0.7405421400802497 and parameters: {'booster': 'dart', 'lambda': 0.0522840570375054, 'alpha': 0.8184836660563468, 'subsample': 0.32151379276454506, 'colsample_bytree': 0.8357855318527769, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.307945230363858, 'gamma': 0.0047308633881058835, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.00017866567368578313, 'skip_drop': 0.00011666478285789356}. Best is trial 23 with value: 0.5983026284281632.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:34,506]\u001b[0m Trial 40 finished with value: 0.6833550533641976 and parameters: {'booster': 'dart', 'lambda': 8.478693199158574e-05, 'alpha': 0.000132391629994057, 'subsample': 0.5471540438512043, 'colsample_bytree': 0.7670235196946353, 'max_depth': 3, 'min_child_weight': 8, 'eta': 0.022953572494814032, 'gamma': 0.0009314352721513828, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 2.6805225903955645e-07, 'skip_drop': 0.04404734601829356}. Best is trial 23 with value: 0.5983026284281632.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:34,703]\u001b[0m Trial 41 finished with value: 0.591381519044823 and parameters: {'booster': 'gbtree', 'lambda': 0.0015692510700328296, 'alpha': 0.06761775771019848, 'subsample': 0.24705507679029148, 'colsample_bytree': 0.935426542588073, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.0996527092407713, 'gamma': 0.03013340452997578, 'grow_policy': 'depthwise'}. Best is trial 41 with value: 0.591381519044823.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:34,889]\u001b[0m Trial 42 finished with value: 0.6365345963735056 and parameters: {'booster': 'gbtree', 'lambda': 0.001182067853945569, 'alpha': 0.05702209249247219, 'subsample': 0.24422387859686956, 'colsample_bytree': 0.6877011873112271, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.1019743248823045, 'gamma': 0.0070970547681739994, 'grow_policy': 'depthwise'}. Best is trial 41 with value: 0.591381519044823.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:35,089]\u001b[0m Trial 43 finished with value: 0.8476943454000071 and parameters: {'booster': 'gbtree', 'lambda': 0.008974550999852221, 'alpha': 0.3418122729319423, 'subsample': 0.3092485177191485, 'colsample_bytree': 0.827037135595683, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.42229097393619824, 'gamma': 0.031600277739083256, 'grow_policy': 'depthwise'}. Best is trial 41 with value: 0.591381519044823.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:35,301]\u001b[0m Trial 44 finished with value: 0.9157648325634268 and parameters: {'booster': 'gbtree', 'lambda': 0.0007074453859106034, 'alpha': 0.0023919887506498477, 'subsample': 0.37484694286773784, 'colsample_bytree': 0.8804095743478522, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.006536374011748662, 'gamma': 0.15229676805038378, 'grow_policy': 'depthwise'}. Best is trial 41 with value: 0.591381519044823.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:36,792]\u001b[0m Trial 45 finished with value: 1.3972242919257054 and parameters: {'booster': 'dart', 'lambda': 0.0032962715167606065, 'alpha': 1.2489773082591653e-07, 'subsample': 0.45066703050959744, 'colsample_bytree': 0.9440251876638109, 'max_depth': 5, 'min_child_weight': 5, 'eta': 4.389037727415663e-07, 'gamma': 0.002547573428290446, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.014524027104593194, 'skip_drop': 0.0009174934244228483}. Best is trial 41 with value: 0.591381519044823.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:33:36,979]\u001b[0m Trial 46 finished with value: 0.6326200911437653 and parameters: {'booster': 'gbtree', 'lambda': 0.00012226042294951136, 'alpha': 0.016932988485363315, 'subsample': 0.20483266876060613, 'colsample_bytree': 0.7928383685651856, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.04132761182120088, 'gamma': 0.00012967282007460233, 'grow_policy': 'depthwise'}. Best is trial 41 with value: 0.591381519044823.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:38,488]\u001b[0m Trial 47 finished with value: 0.9826018604514424 and parameters: {'booster': 'dart', 'lambda': 7.817879150767554e-06, 'alpha': 0.0689797369463197, 'subsample': 0.3455783717133643, 'colsample_bytree': 0.9682985017864633, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.34219652482307467, 'gamma': 0.06024959335434393, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.0561826708441214e-05, 'skip_drop': 1.0436913956031394e-05}. Best is trial 41 with value: 0.591381519044823.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:38,629]\u001b[0m Trial 48 finished with value: 0.706042025854784 and parameters: {'booster': 'gblinear', 'lambda': 0.023009341677528116, 'alpha': 0.0012618249498270002, 'subsample': 0.39584415198484124, 'colsample_bytree': 0.7097751977013751}. Best is trial 41 with value: 0.591381519044823.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:38,801]\u001b[0m Trial 49 finished with value: 6.749396165476008 and parameters: {'booster': 'gbtree', 'lambda': 6.954828926505705e-05, 'alpha': 0.3350580786306004, 'subsample': 0.247874003730477, 'colsample_bytree': 0.2103223391600656, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.8498048140047474, 'gamma': 0.0008943876613466142, 'grow_policy': 'lossguide'}. Best is trial 41 with value: 0.591381519044823.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:39,111]\u001b[0m Trial 50 finished with value: 1.372175745710725 and parameters: {'booster': 'gbtree', 'lambda': 2.291704709615193e-06, 'alpha': 0.9473510013818265, 'subsample': 0.9276686073421122, 'colsample_bytree': 0.92450926632781, 'max_depth': 5, 'min_child_weight': 3, 'eta': 0.00018278144611574067, 'gamma': 0.27332217660071123, 'grow_policy': 'depthwise'}. Best is trial 41 with value: 0.591381519044823.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:39,314]\u001b[0m Trial 51 finished with value: 0.625418836034379 and parameters: {'booster': 'gbtree', 'lambda': 0.0014545517938880535, 'alpha': 0.01597459545338843, 'subsample': 0.2884510644290671, 'colsample_bytree': 0.8609513741160406, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.12880890137797926, 'gamma': 0.018590947453072507, 'grow_policy': 'depthwise'}. Best is trial 41 with value: 0.591381519044823.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:39,516]\u001b[0m Trial 52 finished with value: 0.5782077507515458 and parameters: {'booster': 'gbtree', 'lambda': 0.000728846964742051, 'alpha': 0.04768421260759138, 'subsample': 0.2565729961820997, 'colsample_bytree': 0.9388056598146038, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.0883068193914997, 'gamma': 0.004352948894968586, 'grow_policy': 'depthwise'}. Best is trial 52 with value: 0.5782077507515458.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:39,727]\u001b[0m Trial 53 finished with value: 0.6224310767874444 and parameters: {'booster': 'gbtree', 'lambda': 0.00018299169684068563, 'alpha': 0.07390387384847566, 'subsample': 0.30974548293513615, 'colsample_bytree': 0.9168641195832583, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.035501236729848104, 'gamma': 0.0038181384288796132, 'grow_policy': 'depthwise'}. Best is trial 52 with value: 0.5782077507515458.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:39,927]\u001b[0m Trial 54 finished with value: 0.8177266466702586 and parameters: {'booster': 'gbtree', 'lambda': 0.0007014921322222191, 'alpha': 1.4298629631154635e-05, 'subsample': 0.2469190775998134, 'colsample_bytree': 0.830659402367103, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.01127502267322222, 'gamma': 0.010419115162198227, 'grow_policy': 'lossguide'}. Best is trial 52 with value: 0.5782077507515458.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:40,051]\u001b[0m Trial 55 finished with value: 0.8510690486287495 and parameters: {'booster': 'gblinear', 'lambda': 0.006731933159194687, 'alpha': 0.03795744396363442, 'subsample': 0.34608262487136265, 'colsample_bytree': 0.7762192112536219}. Best is trial 52 with value: 0.5782077507515458.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:40,280]\u001b[0m Trial 56 finished with value: 0.590630330056249 and parameters: {'booster': 'gbtree', 'lambda': 0.0027584422015554774, 'alpha': 0.004132197623670127, 'subsample': 0.4818272953376334, 'colsample_bytree': 0.9671107278689549, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.08056656363701278, 'gamma': 0.0011504086687989825, 'grow_policy': 'depthwise'}. Best is trial 52 with value: 0.5782077507515458.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:40,480]\u001b[0m Trial 57 finished with value: 0.6009813345370529 and parameters: {'booster': 'gbtree', 'lambda': 1.3511594708403298e-05, 'alpha': 0.005679308935032405, 'subsample': 0.2022751805148355, 'colsample_bytree': 0.9617568945132987, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.05994934827795535, 'gamma': 0.05690349047255726, 'grow_policy': 'depthwise'}. Best is trial 52 with value: 0.5782077507515458.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:40,679]\u001b[0m Trial 58 finished with value: 0.6711811124040895 and parameters: {'booster': 'gbtree', 'lambda': 1.766670182583097e-05, 'alpha': 0.006517894221598068, 'subsample': 0.20100659575545585, 'colsample_bytree': 0.9677121400158707, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.023793418187194732, 'gamma': 0.07141230780617222, 'grow_policy': 'depthwise'}. Best is trial 52 with value: 0.5782077507515458.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:40,915]\u001b[0m Trial 59 finished with value: 1.1320471969221764 and parameters: {'booster': 'gbtree', 'lambda': 1.6282814022145389e-06, 'alpha': 0.0009235653810420682, 'subsample': 0.6130722137849097, 'colsample_bytree': 0.989939954179907, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.002570422937480989, 'gamma': 0.34467910401984336, 'grow_policy': 'depthwise'}. Best is trial 52 with value: 0.5782077507515458.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:41,151]\u001b[0m Trial 60 finished with value: 0.652451456280465 and parameters: {'booster': 'gbtree', 'lambda': 1.1656165873126557e-05, 'alpha': 0.0034318259835457825, 'subsample': 0.25445063637844945, 'colsample_bytree': 0.8857175797948872, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.05891571613350071, 'gamma': 0.0517083584239308, 'grow_policy': 'lossguide'}. Best is trial 52 with value: 0.5782077507515458.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:41,374]\u001b[0m A new study created in memory with name: no-name-7fa1acb0-d562-473c-babe-cefde7c89441\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:41,739]\u001b[0m Trial 0 finished with value: 1.151206698897736 and parameters: {'booster': 'gbtree', 'lambda': 0.0005292312174797672, 'alpha': 0.00041676589794143734, 'subsample': 0.7377216979127654, 'colsample_bytree': 0.9390355085897035, 'max_depth': 7, 'min_child_weight': 8, 'eta': 4.082841564298678e-08, 'gamma': 3.24007436522467e-07, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 1.151206698897736.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:43,146]\u001b[0m Trial 1 finished with value: 0.44555646332197957 and parameters: {'booster': 'dart', 'lambda': 0.021153674031043963, 'alpha': 1.604131817273264e-08, 'subsample': 0.5021768714959165, 'colsample_bytree': 0.2978085395503187, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.579687592048487, 'gamma': 1.061597892050788e-05, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 2.9011262679718855e-08, 'skip_drop': 7.23154363311911e-08}. Best is trial 1 with value: 0.44555646332197957.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:44,331]\u001b[0m Trial 2 finished with value: 1.1484191067278642 and parameters: {'booster': 'dart', 'lambda': 3.3430277028505743e-06, 'alpha': 9.475387755542885e-08, 'subsample': 0.5440094588186201, 'colsample_bytree': 0.9825827184802789, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.00011527028900410245, 'gamma': 1.4653991498867792e-05, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.3856378463818985, 'skip_drop': 4.2482945568197424e-07}. Best is trial 1 with value: 0.44555646332197957.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:44,497]\u001b[0m Trial 3 finished with value: 1.150342839490709 and parameters: {'booster': 'gbtree', 'lambda': 9.680366228441737e-07, 'alpha': 7.92258628865159e-08, 'subsample': 0.28196318019907873, 'colsample_bytree': 0.3920385644947717, 'max_depth': 3, 'min_child_weight': 10, 'eta': 5.589988585107823e-06, 'gamma': 0.7740995456498944, 'grow_policy': 'depthwise'}. Best is trial 1 with value: 0.44555646332197957.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:33:44,601]\u001b[0m Trial 4 finished with value: 0.4258997821816836 and parameters: {'booster': 'gblinear', 'lambda': 0.055305682646066924, 'alpha': 0.16866747196513918, 'subsample': 0.4521227608169214, 'colsample_bytree': 0.2991085233887379}. Best is trial 4 with value: 0.4258997821816836.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:44,705]\u001b[0m Trial 5 finished with value: 0.413013702428258 and parameters: {'booster': 'gblinear', 'lambda': 5.320932076896941e-08, 'alpha': 0.15190292465320648, 'subsample': 0.9912323639587257, 'colsample_bytree': 0.7334938814667609}. Best is trial 5 with value: 0.413013702428258.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:45,006]\u001b[0m Trial 6 finished with value: 0.24810006170738885 and parameters: {'booster': 'gbtree', 'lambda': 2.457229051127406e-06, 'alpha': 3.1779027828193237e-07, 'subsample': 0.5452987146265269, 'colsample_bytree': 0.350540864568845, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.025693802704154656, 'gamma': 1.0075247359078258e-07, 'grow_policy': 'depthwise'}. Best is trial 6 with value: 0.24810006170738885.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:45,136]\u001b[0m Trial 7 finished with value: 0.2854030098148702 and parameters: {'booster': 'gblinear', 'lambda': 0.0004738017286237293, 'alpha': 5.9311357555322594e-08, 'subsample': 0.23999429655131702, 'colsample_bytree': 0.8059592419719441}. Best is trial 6 with value: 0.24810006170738885.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:46,745]\u001b[0m Trial 8 finished with value: 1.1511991592068087 and parameters: {'booster': 'dart', 'lambda': 5.933170951447653e-06, 'alpha': 2.964533555347601e-06, 'subsample': 0.39323048541198924, 'colsample_bytree': 0.6668588006071858, 'max_depth': 7, 'min_child_weight': 3, 'eta': 8.637457394305418e-08, 'gamma': 0.00025410550983751104, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.15333062435660808, 'skip_drop': 2.8074545056074605e-06}. Best is trial 6 with value: 0.24810006170738885.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:47,231]\u001b[0m Trial 9 finished with value: 1.1509221577597555 and parameters: {'booster': 'gbtree', 'lambda': 0.0005225746695657976, 'alpha': 0.0007245436567484409, 'subsample': 0.7270462311659891, 'colsample_bytree': 0.8844548040847167, 'max_depth': 7, 'min_child_weight': 2, 'eta': 1.6732291551043597e-06, 'gamma': 0.7115081273462396, 'grow_policy': 'lossguide'}. Best is trial 6 with value: 0.24810006170738885.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:47,652]\u001b[0m Trial 10 finished with value: 0.2377392431160525 and parameters: {'booster': 'gbtree', 'lambda': 1.6707096118759796e-08, 'alpha': 5.703847461855762e-06, 'subsample': 0.6865382838123775, 'colsample_bytree': 0.5206292005037823, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.0405266728049263, 'gamma': 0.002449625501981938, 'grow_policy': 'depthwise'}. Best is trial 10 with value: 0.2377392431160525.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:48,064]\u001b[0m Trial 11 finished with value: 0.24382276517006368 and parameters: {'booster': 'gbtree', 'lambda': 3.115587124091971e-08, 'alpha': 9.133343669951962e-06, 'subsample': 0.6792962039762508, 'colsample_bytree': 0.49948666233530475, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.05765590491590192, 'gamma': 0.005224937329391253, 'grow_policy': 'depthwise'}. Best is trial 10 with value: 0.2377392431160525.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:48,505]\u001b[0m Trial 12 finished with value: 0.7989676310695175 and parameters: {'booster': 'gbtree', 'lambda': 1.1498168494434255e-08, 'alpha': 1.6783487116436656e-05, 'subsample': 0.7237688095298787, 'colsample_bytree': 0.5366513531631543, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.0025619248649263156, 'gamma': 0.00362218523797469, 'grow_policy': 'depthwise'}. Best is trial 10 with value: 0.2377392431160525.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:48,921]\u001b[0m Trial 13 finished with value: 0.5723927484964313 and parameters: {'booster': 'gbtree', 'lambda': 1.1313191550970711e-07, 'alpha': 1.842064054693974e-05, 'subsample': 0.8799005326670393, 'colsample_bytree': 0.5154797894578029, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.9342589189761396, 'gamma': 0.0070109355100851315, 'grow_policy': 'depthwise'}. Best is trial 10 with value: 0.2377392431160525.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:49,304]\u001b[0m Trial 14 finished with value: 0.41612095627080775 and parameters: {'booster': 'gbtree', 'lambda': 1.0532577294515766e-08, 'alpha': 0.00430800575696132, 'subsample': 0.6503573315871989, 'colsample_bytree': 0.45826773046014474, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.00863429878600982, 'gamma': 0.016036585108376772, 'grow_policy': 'lossguide'}. Best is trial 10 with value: 0.2377392431160525.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:49,776]\u001b[0m Trial 15 finished with value: 1.0794646372077878 and parameters: {'booster': 'gbtree', 'lambda': 0.6202633328471328, 'alpha': 1.535856586619888e-06, 'subsample': 0.8543339487863855, 'colsample_bytree': 0.6008493806005843, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.00044377460090123954, 'gamma': 0.0007777430633409846, 'grow_policy': 'depthwise'}. Best is trial 10 with value: 0.2377392431160525.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:50,026]\u001b[0m Trial 16 finished with value: 0.23666957926868173 and parameters: {'booster': 'gbtree', 'lambda': 2.6850743947770576e-07, 'alpha': 6.437621566844111e-05, 'subsample': 0.6473712953199635, 'colsample_bytree': 0.4435826190283364, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.05159688291011192, 'gamma': 0.10316044280811387, 'grow_policy': 'depthwise'}. Best is trial 16 with value: 0.23666957926868173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:50,247]\u001b[0m Trial 17 finished with value: 0.2415172423216186 and parameters: {'booster': 'gbtree', 'lambda': 2.927081148710272e-07, 'alpha': 0.008705034456496615, 'subsample': 0.8270840609673904, 'colsample_bytree': 0.23144186705730035, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.10103391217885122, 'gamma': 0.07799635538128835, 'grow_policy': 'depthwise'}. Best is trial 16 with value: 0.23666957926868173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:50,390]\u001b[0m Trial 18 finished with value: 0.28505635881836605 and parameters: {'booster': 'gblinear', 'lambda': 1.9195160379690094e-05, 'alpha': 8.015621769725742e-05, 'subsample': 0.6073129436679588, 'colsample_bytree': 0.6423395028455687}. Best is trial 16 with value: 0.23666957926868173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:51,889]\u001b[0m Trial 19 finished with value: 0.9535080949102057 and parameters: {'booster': 'dart', 'lambda': 3.693295290516754e-07, 'alpha': 8.815582761750416e-05, 'subsample': 0.34423033914956674, 'colsample_bytree': 0.4182551214445645, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.0013483778960250263, 'gamma': 0.08540963386744496, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.4579825134757761e-08, 'skip_drop': 0.7087605625912081}. Best is trial 16 with value: 0.23666957926868173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:52,147]\u001b[0m Trial 20 finished with value: 1.145016618685471 and parameters: {'booster': 'gbtree', 'lambda': 0.00012528155317124398, 'alpha': 5.932113291975671e-07, 'subsample': 0.9727999781492609, 'colsample_bytree': 0.5429462920355217, 'max_depth': 5, 'min_child_weight': 7, 'eta': 3.684305164325086e-05, 'gamma': 5.309417941929163e-05, 'grow_policy': 'depthwise'}. Best is trial 16 with value: 0.23666957926868173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:52,351]\u001b[0m Trial 21 finished with value: 0.24160439250949922 and parameters: {'booster': 'gbtree', 'lambda': 2.845135625222144e-07, 'alpha': 0.0070815828692296495, 'subsample': 0.827378878431059, 'colsample_bytree': 0.2308676100610403, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.12188274310582685, 'gamma': 0.05774581708082339, 'grow_policy': 'depthwise'}. Best is trial 16 with value: 0.23666957926868173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:52,527]\u001b[0m Trial 22 finished with value: 0.25008425060537204 and parameters: {'booster': 'gbtree', 'lambda': 1.2570751808982978e-07, 'alpha': 0.013982702229712752, 'subsample': 0.7989244593315499, 'colsample_bytree': 0.20235440193896348, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.13491721813374058, 'gamma': 0.08332690709233671, 'grow_policy': 'depthwise'}. Best is trial 16 with value: 0.23666957926868173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:52,753]\u001b[0m Trial 23 finished with value: 0.28113554770391264 and parameters: {'booster': 'gbtree', 'lambda': 1.271252897248384e-05, 'alpha': 0.8447359550562059, 'subsample': 0.9186061363336049, 'colsample_bytree': 0.3413565590566811, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.018453891586479754, 'gamma': 0.0007616336072200425, 'grow_policy': 'depthwise'}. Best is trial 16 with value: 0.23666957926868173.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:33:53,076]\u001b[0m Trial 24 finished with value: 0.6079756058993273 and parameters: {'booster': 'gbtree', 'lambda': 7.727073272453352e-07, 'alpha': 0.0006301865185200342, 'subsample': 0.7726144582236294, 'colsample_bytree': 0.4402514660731755, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.004969393089159642, 'gamma': 0.1898764850820492, 'grow_policy': 'depthwise'}. Best is trial 16 with value: 0.23666957926868173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:53,370]\u001b[0m Trial 25 finished with value: 0.3425232242596666 and parameters: {'booster': 'gbtree', 'lambda': 5.0089267850944706e-08, 'alpha': 0.0017035984294848316, 'subsample': 0.6375549299830212, 'colsample_bytree': 0.27208624045776747, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.36960175422760894, 'gamma': 0.02282417408923967, 'grow_policy': 'depthwise'}. Best is trial 16 with value: 0.23666957926868173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:53,588]\u001b[0m Trial 26 finished with value: 1.066256826853004 and parameters: {'booster': 'gbtree', 'lambda': 9.560682207154048e-07, 'alpha': 0.04006904889839921, 'subsample': 0.5814478075692716, 'colsample_bytree': 0.7285085155810925, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.0005595248672226357, 'gamma': 0.002442047320049749, 'grow_policy': 'lossguide'}. Best is trial 16 with value: 0.23666957926868173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:53,725]\u001b[0m Trial 27 finished with value: 0.28615926565859917 and parameters: {'booster': 'gblinear', 'lambda': 4.077675833908054e-05, 'alpha': 0.00015601068686306772, 'subsample': 0.9154594794556444, 'colsample_bytree': 0.3668668032389845}. Best is trial 16 with value: 0.23666957926868173.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:54,002]\u001b[0m Trial 28 finished with value: 0.2312975535949436 and parameters: {'booster': 'gbtree', 'lambda': 1.829204054120297e-07, 'alpha': 4.4544720089025445e-06, 'subsample': 0.6886429390146693, 'colsample_bytree': 0.472171767499719, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.04588151475678057, 'gamma': 0.27879186808179596, 'grow_policy': 'depthwise'}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:55,644]\u001b[0m Trial 29 finished with value: 0.30346222648068116 and parameters: {'booster': 'dart', 'lambda': 0.0029995754815698703, 'alpha': 5.141363954323313e-06, 'subsample': 0.682841252078363, 'colsample_bytree': 0.47186868703297913, 'max_depth': 7, 'min_child_weight': 6, 'eta': 0.01442808019687406, 'gamma': 0.8926860440084888, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 4.629054879582422e-05, 'skip_drop': 0.012660651265328685}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:55,915]\u001b[0m Trial 30 finished with value: 1.1305650140290862 and parameters: {'booster': 'gbtree', 'lambda': 2.0900593113655763e-08, 'alpha': 4.4414638069587616e-05, 'subsample': 0.4788990773454667, 'colsample_bytree': 0.5946334050833102, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.00012401109345445207, 'gamma': 0.26707399120553116, 'grow_policy': 'depthwise'}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:56,175]\u001b[0m Trial 31 finished with value: 0.24126157608324306 and parameters: {'booster': 'gbtree', 'lambda': 1.655868444054193e-07, 'alpha': 0.00022106443273073212, 'subsample': 0.7537718178619078, 'colsample_bytree': 0.5683005574327433, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.060769907726960386, 'gamma': 0.026036957648402307, 'grow_policy': 'depthwise'}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:56,461]\u001b[0m Trial 32 finished with value: 0.23709796625450263 and parameters: {'booster': 'gbtree', 'lambda': 9.630570456221275e-08, 'alpha': 0.00017057497520124622, 'subsample': 0.7567990258010779, 'colsample_bytree': 0.5846751352398261, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.03932479916506809, 'gamma': 0.025638066814895458, 'grow_policy': 'depthwise'}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:56,748]\u001b[0m Trial 33 finished with value: 0.5939339409550659 and parameters: {'booster': 'gbtree', 'lambda': 7.129314550400932e-08, 'alpha': 1.4400181330998152e-06, 'subsample': 0.7012455452380213, 'colsample_bytree': 0.6448151434525097, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.005139208814880446, 'gamma': 0.01481149968845949, 'grow_policy': 'depthwise'}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:56,956]\u001b[0m Trial 34 finished with value: 0.26098302005104596 and parameters: {'booster': 'gbtree', 'lambda': 2.3013368072913748e-06, 'alpha': 3.1444067141830154e-05, 'subsample': 0.5524208093653911, 'colsample_bytree': 0.4910776739767847, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.16991433376349113, 'gamma': 0.0017093258704072608, 'grow_policy': 'depthwise'}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:33:58,563]\u001b[0m Trial 35 finished with value: 0.23647560622402466 and parameters: {'booster': 'dart', 'lambda': 8.103407183284042e-07, 'alpha': 7.942438331797106e-06, 'subsample': 0.6211556489217755, 'colsample_bytree': 0.42148277119387684, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.032997997451559576, 'gamma': 1.0255081202207395e-08, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.00010247287089738038, 'skip_drop': 0.0005122203625654174}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:00,099]\u001b[0m Trial 36 finished with value: 1.002540740008951 and parameters: {'booster': 'dart', 'lambda': 6.888066493866184e-07, 'alpha': 2.9700934403217363e-07, 'subsample': 0.6502799354883099, 'colsample_bytree': 0.4399201344201353, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.0009502607937786605, 'gamma': 1.845489212527348e-08, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.00013299741910804077, 'skip_drop': 0.000300759042012125}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:01,599]\u001b[0m Trial 37 finished with value: 0.3760841147771505 and parameters: {'booster': 'dart', 'lambda': 1.8976098702592006e-06, 'alpha': 1.3733379713732338e-08, 'subsample': 0.5882703047546035, 'colsample_bytree': 0.37954246352402443, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.37431519876962194, 'gamma': 1.8667565327335123e-06, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 7.334627496425415e-05, 'skip_drop': 0.00018764192676147968}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:03,044]\u001b[0m Trial 38 finished with value: 0.3398464821499617 and parameters: {'booster': 'dart', 'lambda': 8.910332441578005e-06, 'alpha': 0.0003646200480397712, 'subsample': 0.4887389173703666, 'colsample_bytree': 0.3133375715366784, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.012480242273586278, 'gamma': 1.3238823164819083e-06, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.0047731409825011945, 'skip_drop': 0.011156207574889842}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:04,457]\u001b[0m Trial 39 finished with value: 0.8287286881405286 and parameters: {'booster': 'dart', 'lambda': 7.764116582312952e-05, 'alpha': 0.001207657560343056, 'subsample': 0.43002574650108416, 'colsample_bytree': 0.40337758313677236, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.002554617409678337, 'gamma': 5.276257719532361e-05, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.3778009253467298e-06, 'skip_drop': 2.4238992063349636e-05}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:05,946]\u001b[0m Trial 40 finished with value: 1.1512114639251871 and parameters: {'booster': 'dart', 'lambda': 4.184869368134425e-06, 'alpha': 1.4398596253777156e-05, 'subsample': 0.5285789715942272, 'colsample_bytree': 0.7193341661918768, 'max_depth': 5, 'min_child_weight': 10, 'eta': 1.5023543819842454e-08, 'gamma': 7.574034102358022e-06, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.003847948564132689, 'skip_drop': 0.008738479201546655}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:34:06,082]\u001b[0m Trial 41 finished with value: 0.28719476578173164 and parameters: {'booster': 'gblinear', 'lambda': 2.70513265774573e-08, 'alpha': 6.037985711323387e-06, 'subsample': 0.6149714741274501, 'colsample_bytree': 0.555219577145044}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:06,343]\u001b[0m Trial 42 finished with value: 0.25156405084765143 and parameters: {'booster': 'gbtree', 'lambda': 6.788548923961725e-08, 'alpha': 2.500413784071677e-06, 'subsample': 0.7864227838819432, 'colsample_bytree': 0.5905853366764454, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.023158089449359317, 'gamma': 1.0311639980384773e-08, 'grow_policy': 'depthwise'}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:06,662]\u001b[0m Trial 43 finished with value: 0.23503742190927118 and parameters: {'booster': 'gbtree', 'lambda': 3.6273334227018807e-07, 'alpha': 3.9181606768216424e-05, 'subsample': 0.7084246133341146, 'colsample_bytree': 0.5115830570181937, 'max_depth': 7, 'min_child_weight': 5, 'eta': 0.03470410864924614, 'gamma': 0.1964488466559603, 'grow_policy': 'depthwise'}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:08,182]\u001b[0m Trial 44 finished with value: 0.4032609159438467 and parameters: {'booster': 'dart', 'lambda': 4.4113814529113765e-07, 'alpha': 3.6737421317592336e-05, 'subsample': 0.7240708833695985, 'colsample_bytree': 0.4760505045659878, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.5960221009924151, 'gamma': 0.2929549419104429, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 8.706479892729251e-07, 'skip_drop': 0.5932501827388422}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:08,451]\u001b[0m Trial 45 finished with value: 0.2735965265502112 and parameters: {'booster': 'gbtree', 'lambda': 1.9837737651369534e-06, 'alpha': 6.078303128539116e-07, 'subsample': 0.6570173603643473, 'colsample_bytree': 0.41049624589206285, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.2615195786104284, 'gamma': 0.27270331680327775, 'grow_policy': 'depthwise'}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:08,588]\u001b[0m Trial 46 finished with value: 0.28893696487236953 and parameters: {'booster': 'gblinear', 'lambda': 1.60107307417369e-07, 'alpha': 6.248962422045708e-05, 'subsample': 0.7444776473925419, 'colsample_bytree': 0.6914881515255865}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:08,926]\u001b[0m Trial 47 finished with value: 0.23847399506970132 and parameters: {'booster': 'gbtree', 'lambda': 1.3631369819196473e-06, 'alpha': 0.00019921920124895196, 'subsample': 0.5632589672199129, 'colsample_bytree': 0.8405977528351136, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.03737175031241825, 'gamma': 7.90060422978666e-08, 'grow_policy': 'depthwise'}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:09,317]\u001b[0m Trial 48 finished with value: 1.1511704768640516 and parameters: {'booster': 'gbtree', 'lambda': 4.395544501503016e-08, 'alpha': 6.49789303816014e-08, 'subsample': 0.6938522859870077, 'colsample_bytree': 0.9583000077849847, 'max_depth': 7, 'min_child_weight': 6, 'eta': 2.494728387693618e-07, 'gamma': 0.5745171607631375, 'grow_policy': 'depthwise'}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:09,561]\u001b[0m Trial 49 finished with value: 0.5400955172174886 and parameters: {'booster': 'gbtree', 'lambda': 0.002090356227085573, 'alpha': 2.2190693801695517e-05, 'subsample': 0.5170771705613993, 'colsample_bytree': 0.5070253407780203, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.006024811894194368, 'gamma': 0.03939792896086808, 'grow_policy': 'depthwise'}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:11,022]\u001b[0m Trial 50 finished with value: 0.24387604257702197 and parameters: {'booster': 'dart', 'lambda': 4.597384203660146e-06, 'alpha': 2.0307986786339157e-07, 'subsample': 0.622861713005537, 'colsample_bytree': 0.3171414703972825, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.04415093954911704, 'gamma': 0.1226303124042933, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.0037123394475422934, 'skip_drop': 1.20967390379577e-05}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:11,373]\u001b[0m Trial 51 finished with value: 0.2415845092202336 and parameters: {'booster': 'gbtree', 'lambda': 1.8332788882383998e-08, 'alpha': 5.80749849062181e-06, 'subsample': 0.6707748726853247, 'colsample_bytree': 0.5210173381299061, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.05750519965310685, 'gamma': 0.007503023715220416, 'grow_policy': 'depthwise'}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:11,735]\u001b[0m Trial 52 finished with value: 0.2436993140211415 and parameters: {'booster': 'gbtree', 'lambda': 2.5430490938213745e-07, 'alpha': 1.2078416047082379e-05, 'subsample': 0.7058497006686959, 'colsample_bytree': 0.445028050590233, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.025660196949281185, 'gamma': 0.009233935168182985, 'grow_policy': 'depthwise'}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:12,096]\u001b[0m Trial 53 finished with value: 0.6138962581812817 and parameters: {'booster': 'gbtree', 'lambda': 9.156925251621314e-08, 'alpha': 1.3336568530300071e-06, 'subsample': 0.7604547972427314, 'colsample_bytree': 0.5724774449937354, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.9018629141339582, 'gamma': 0.0005198303154556126, 'grow_policy': 'depthwise'}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:12,344]\u001b[0m Trial 54 finished with value: 0.23855287417801654 and parameters: {'booster': 'gbtree', 'lambda': 1.65329053455973e-08, 'alpha': 2.6050971122644017e-06, 'subsample': 0.8146278181312983, 'colsample_bytree': 0.6141203035507254, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.08981013634044843, 'gamma': 0.00024370215525802577, 'grow_policy': 'depthwise'}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:12,687]\u001b[0m Trial 55 finished with value: 0.8548061894128027 and parameters: {'booster': 'gbtree', 'lambda': 4.3620127175704084e-07, 'alpha': 0.00011732265656643703, 'subsample': 0.8674310238631024, 'colsample_bytree': 0.5301579960714004, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.002075917290774142, 'gamma': 0.045144607043513835, 'grow_policy': 'depthwise'}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:12,927]\u001b[0m Trial 56 finished with value: 0.3849505584986396 and parameters: {'booster': 'gbtree', 'lambda': 3.712155364071169e-08, 'alpha': 1.1308651208072696e-05, 'subsample': 0.7262586776562171, 'colsample_bytree': 0.4906813659257715, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.010065728679173424, 'gamma': 0.1479389786882396, 'grow_policy': 'depthwise'}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:13,060]\u001b[0m Trial 57 finished with value: 0.28054241602514984 and parameters: {'booster': 'gblinear', 'lambda': 1.8190891092924317e-07, 'alpha': 0.0003577268585395497, 'subsample': 0.6216179115292736, 'colsample_bytree': 0.6231892336581241}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:13,373]\u001b[0m Trial 58 finished with value: 0.2663253969181266 and parameters: {'booster': 'gbtree', 'lambda': 0.2881493537078815, 'alpha': 6.30580112274513e-05, 'subsample': 0.5841648408954235, 'colsample_bytree': 0.3464427458518286, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.1547098168954057, 'gamma': 0.5074588551084752, 'grow_policy': 'depthwise'}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:13,604]\u001b[0m Trial 59 finished with value: 0.2409810865481439 and parameters: {'booster': 'gbtree', 'lambda': 5.797789737138523e-07, 'alpha': 0.0020058017535407187, 'subsample': 0.6757328476013259, 'colsample_bytree': 0.4354983705930221, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.031194370023077626, 'gamma': 0.014040659444116164, 'grow_policy': 'lossguide'}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:34:13,844]\u001b[0m Trial 60 finished with value: 1.1509347488726638 and parameters: {'booster': 'gbtree', 'lambda': 1.0519729321774449e-07, 'alpha': 4.083218737818493e-06, 'subsample': 0.7768617515515015, 'colsample_bytree': 0.4631154447698057, 'max_depth': 5, 'min_child_weight': 6, 'eta': 1.6604246647113833e-06, 'gamma': 0.0015580730639886092, 'grow_policy': 'depthwise'}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:14,166]\u001b[0m Trial 61 finished with value: 0.2333478423834141 and parameters: {'booster': 'gbtree', 'lambda': 1.404987205247781e-06, 'alpha': 0.00016537623314971648, 'subsample': 0.5811005638774382, 'colsample_bytree': 0.8159078132421701, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.0390554432427643, 'gamma': 1.5015742387176846e-07, 'grow_policy': 'depthwise'}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:14,491]\u001b[0m Trial 62 finished with value: 0.24439478567714906 and parameters: {'booster': 'gbtree', 'lambda': 1.1718767749071884e-08, 'alpha': 3.40339547923355e-05, 'subsample': 0.6462272978941961, 'colsample_bytree': 0.8224250924432623, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.08657382089823032, 'gamma': 8.194608084105616e-08, 'grow_policy': 'depthwise'}. Best is trial 28 with value: 0.2312975535949436.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:14,770]\u001b[0m A new study created in memory with name: no-name-81cc5deb-3711-48b1-8af5-10d8d15f9208\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:14,984]\u001b[0m Trial 0 finished with value: 0.9103198148298255 and parameters: {'booster': 'gblinear', 'lambda': 0.0021418576919781085, 'alpha': 2.2423212335768845e-07, 'subsample': 0.7044269984422924, 'colsample_bytree': 0.849000155068236}. Best is trial 0 with value: 0.9103198148298255.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:15,202]\u001b[0m Trial 1 finished with value: 0.8885334462108285 and parameters: {'booster': 'gblinear', 'lambda': 2.24468928350272e-08, 'alpha': 4.3230438819013715e-07, 'subsample': 0.6924923495481139, 'colsample_bytree': 0.551982196793283}. Best is trial 0 with value: 0.9103198148298255.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:19,019]\u001b[0m Trial 2 finished with value: 0.8944660647571606 and parameters: {'booster': 'dart', 'lambda': 0.032064421682788065, 'alpha': 0.00012908553392193312, 'subsample': 0.22608730986472417, 'colsample_bytree': 0.31482422890769435, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.0019819402251581336, 'gamma': 0.00466077328924607, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 5.732562091138512e-06, 'skip_drop': 5.652190960151899e-07}. Best is trial 0 with value: 0.9103198148298255.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:23,277]\u001b[0m Trial 3 finished with value: 0.9160837336179802 and parameters: {'booster': 'dart', 'lambda': 4.220671403560266e-08, 'alpha': 5.710990255388045e-05, 'subsample': 0.42596663562297965, 'colsample_bytree': 0.7357115360839888, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.08636805004980773, 'gamma': 0.036801168776931396, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.00043848499693106976, 'skip_drop': 4.020162704067462e-07}. Best is trial 3 with value: 0.9160837336179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:27,476]\u001b[0m Trial 4 finished with value: 0.9083317565093335 and parameters: {'booster': 'dart', 'lambda': 3.9002213683193783e-07, 'alpha': 0.000145608254907895, 'subsample': 0.9797441700719254, 'colsample_bytree': 0.8291470290153444, 'max_depth': 5, 'min_child_weight': 7, 'eta': 8.510363949908056e-05, 'gamma': 4.7629417736694324e-05, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.6283005227683156e-07, 'skip_drop': 0.0009621368396231276}. Best is trial 3 with value: 0.9160837336179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:27,884]\u001b[0m Trial 5 finished with value: 0.9134899713467047 and parameters: {'booster': 'gbtree', 'lambda': 0.021954300353781826, 'alpha': 0.0001372714795523045, 'subsample': 0.40519694829549957, 'colsample_bytree': 0.8481569263088611, 'max_depth': 7, 'min_child_weight': 8, 'eta': 7.430977424152975e-08, 'gamma': 0.00011874957677538318, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 0.9160837336179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:28,113]\u001b[0m Trial 6 finished with value: 0.9009438999201075 and parameters: {'booster': 'gblinear', 'lambda': 0.417464857896697, 'alpha': 3.948601882946403e-07, 'subsample': 0.6505561219747962, 'colsample_bytree': 0.8015075798231148}. Best is trial 3 with value: 0.9160837336179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:28,314]\u001b[0m Trial 7 finished with value: 0.9133474159576399 and parameters: {'booster': 'gbtree', 'lambda': 6.045998852097027e-07, 'alpha': 1.9347961788769998e-05, 'subsample': 0.27925618251502143, 'colsample_bytree': 0.22843592720312067, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.10862537755629144, 'gamma': 1.264196510682898e-08, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 0.9160837336179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:28,426]\u001b[0m Trial 8 finished with value: 0.8944660647571606 and parameters: {'booster': 'gblinear', 'lambda': 0.010694946330752, 'alpha': 0.27647568155603824, 'subsample': 0.8879891148863186, 'colsample_bytree': 0.7374511319139956}. Best is trial 3 with value: 0.9160837336179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:28,799]\u001b[0m Trial 9 finished with value: 0.9114709586319814 and parameters: {'booster': 'gbtree', 'lambda': 0.7213006800659791, 'alpha': 1.3319756613916947e-06, 'subsample': 0.6196740159936858, 'colsample_bytree': 0.5278539708385811, 'max_depth': 9, 'min_child_weight': 5, 'eta': 6.241816517528665e-08, 'gamma': 2.1818206004537653e-07, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 0.9160837336179802.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:31,709]\u001b[0m Trial 10 finished with value: 0.9292567848859109 and parameters: {'booster': 'dart', 'lambda': 2.249421212386931e-05, 'alpha': 0.018239162941874967, 'subsample': 0.4369261770546394, 'colsample_bytree': 0.9974907304339239, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.3736573937443426, 'gamma': 0.6530854953981831, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.5550594731641958, 'skip_drop': 1.4847863678927451e-08}. Best is trial 10 with value: 0.9292567848859109.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:34,876]\u001b[0m Trial 11 finished with value: 0.9270850253578066 and parameters: {'booster': 'dart', 'lambda': 4.31856232844955e-05, 'alpha': 0.020441196844463834, 'subsample': 0.43476599934954263, 'colsample_bytree': 0.9748764191572289, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.7580208835991489, 'gamma': 0.8250110935684732, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.5797616390752797, 'skip_drop': 1.4430411910717789e-08}. Best is trial 10 with value: 0.9292567848859109.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:38,130]\u001b[0m Trial 12 finished with value: 0.9228646520729987 and parameters: {'booster': 'dart', 'lambda': 1.0274268567557555e-05, 'alpha': 0.04007760163377004, 'subsample': 0.4660432587060936, 'colsample_bytree': 0.9955497387370589, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.7415765637626033, 'gamma': 0.9933745668528811, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.5265934902995051, 'skip_drop': 1.2704794471361423e-08}. Best is trial 10 with value: 0.9292567848859109.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:42,287]\u001b[0m Trial 13 finished with value: 0.9110083188242836 and parameters: {'booster': 'dart', 'lambda': 8.997665443132079e-05, 'alpha': 0.017996452572689177, 'subsample': 0.5053847191051601, 'colsample_bytree': 0.9847735128545172, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.0014212097160781988, 'gamma': 0.9865021739034413, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.3858937586795703, 'skip_drop': 0.8008904035078951}. Best is trial 10 with value: 0.9292567848859109.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:46,480]\u001b[0m Trial 14 finished with value: 0.8956761503336845 and parameters: {'booster': 'dart', 'lambda': 5.511954549091924e-05, 'alpha': 0.006178048479457792, 'subsample': 0.3419193172266023, 'colsample_bytree': 0.9360053795452182, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.776362900011273, 'gamma': 0.011128474551468709, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.007066589443671671, 'skip_drop': 1.307859947372089e-08}. Best is trial 10 with value: 0.9292567848859109.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:34:50,905]\u001b[0m Trial 15 finished with value: 0.9114709586319814 and parameters: {'booster': 'dart', 'lambda': 7.899756311837588e-06, 'alpha': 0.0016668073589681102, 'subsample': 0.5611339604979996, 'colsample_bytree': 0.6605297494666214, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.00662720460153516, 'gamma': 0.09488164524675181, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.006981096057893858, 'skip_drop': 7.105351146102816e-06}. Best is trial 10 with value: 0.9292567848859109.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:34:54,210]\u001b[0m A new study created in memory with name: no-name-3fc01b51-dbd3-484f-8770-b3ba516d6fe6\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:55,532]\u001b[0m Trial 0 finished with value: 0.8418165685111337 and parameters: {'booster': 'dart', 'lambda': 3.1085386026213317e-06, 'alpha': 0.2693764203572821, 'subsample': 0.6328123221072139, 'colsample_bytree': 0.46026094263952677, 'max_depth': 9, 'min_child_weight': 2, 'eta': 1.6914276567781342e-08, 'gamma': 3.0634304459361188e-06, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.04093604388360813, 'skip_drop': 2.8922341099117125e-07}. Best is trial 0 with value: 0.8418165685111337.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:55,641]\u001b[0m Trial 1 finished with value: 0.2679053181677976 and parameters: {'booster': 'gblinear', 'lambda': 0.002676016045606008, 'alpha': 0.01891434100805968, 'subsample': 0.5906144425255733, 'colsample_bytree': 0.22262515845528805}. Best is trial 1 with value: 0.2679053181677976.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:55,797]\u001b[0m Trial 2 finished with value: 0.8403814136479452 and parameters: {'booster': 'gbtree', 'lambda': 0.03829751809755938, 'alpha': 1.7853373583578415e-08, 'subsample': 0.7779756786030698, 'colsample_bytree': 0.392287248799674, 'max_depth': 7, 'min_child_weight': 4, 'eta': 1.3327721475449207e-05, 'gamma': 0.003965471407524857, 'grow_policy': 'depthwise'}. Best is trial 1 with value: 0.2679053181677976.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:55,990]\u001b[0m Trial 3 finished with value: 0.831329428152102 and parameters: {'booster': 'gbtree', 'lambda': 7.549532908728337e-08, 'alpha': 1.6473536739808983e-06, 'subsample': 0.7315503693377454, 'colsample_bytree': 0.9845667259216171, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.00020736138960689285, 'gamma': 2.815535124137735e-07, 'grow_policy': 'depthwise'}. Best is trial 1 with value: 0.2679053181677976.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:56,103]\u001b[0m Trial 4 finished with value: 0.064181934312418 and parameters: {'booster': 'gblinear', 'lambda': 5.302012865973764e-08, 'alpha': 0.013255317195728525, 'subsample': 0.5282321002229986, 'colsample_bytree': 0.6750040957353263}. Best is trial 4 with value: 0.064181934312418.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:56,200]\u001b[0m Trial 5 finished with value: 0.5886360863498132 and parameters: {'booster': 'gblinear', 'lambda': 1.0079405524809231e-06, 'alpha': 0.08625313794003288, 'subsample': 0.2236777142691155, 'colsample_bytree': 0.8767651032306083}. Best is trial 4 with value: 0.064181934312418.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:56,288]\u001b[0m Trial 6 finished with value: 0.5630992578903176 and parameters: {'booster': 'gblinear', 'lambda': 0.00037803758174892763, 'alpha': 0.2652983395795568, 'subsample': 0.26738885285008274, 'colsample_bytree': 0.2608172270103644}. Best is trial 4 with value: 0.064181934312418.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:56,379]\u001b[0m Trial 7 finished with value: 0.5704281807651497 and parameters: {'booster': 'gblinear', 'lambda': 0.01570638372599993, 'alpha': 0.16232791910049346, 'subsample': 0.9318547374055635, 'colsample_bytree': 0.7725007513305036}. Best is trial 4 with value: 0.064181934312418.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:57,784]\u001b[0m Trial 8 finished with value: 0.7597014607820562 and parameters: {'booster': 'dart', 'lambda': 1.5599790161813696e-07, 'alpha': 9.103519682408378e-08, 'subsample': 0.9638311445333374, 'colsample_bytree': 0.4694033146718808, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.0019108024567329259, 'gamma': 0.39769038736227835, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.0015554504540110905, 'skip_drop': 1.0948498173418454e-05}. Best is trial 4 with value: 0.064181934312418.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:57,905]\u001b[0m Trial 9 finished with value: 0.08270477242114181 and parameters: {'booster': 'gblinear', 'lambda': 0.00011285311505382921, 'alpha': 0.00012956592374085754, 'subsample': 0.756207870082902, 'colsample_bytree': 0.5545738518266672}. Best is trial 4 with value: 0.064181934312418.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:58,104]\u001b[0m Trial 10 finished with value: 0.7554858016490975 and parameters: {'booster': 'gbtree', 'lambda': 1.1687510194660838e-08, 'alpha': 0.000707857093550216, 'subsample': 0.4223146521716478, 'colsample_bytree': 0.7044274625827914, 'max_depth': 3, 'min_child_weight': 10, 'eta': 0.3499575263863815, 'gamma': 1.1911865417560743e-08, 'grow_policy': 'lossguide'}. Best is trial 4 with value: 0.064181934312418.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:58,242]\u001b[0m Trial 11 finished with value: 0.08383757390083131 and parameters: {'booster': 'gblinear', 'lambda': 2.5052729061467203e-05, 'alpha': 0.0001817168770818261, 'subsample': 0.48224476196933985, 'colsample_bytree': 0.6177146580845201}. Best is trial 4 with value: 0.064181934312418.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:58,376]\u001b[0m Trial 12 finished with value: 0.04757039279535972 and parameters: {'booster': 'gblinear', 'lambda': 1.3461330899329647e-05, 'alpha': 0.0022993715994013455, 'subsample': 0.8192764682351412, 'colsample_bytree': 0.6548979327363345}. Best is trial 12 with value: 0.04757039279535972.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:58,508]\u001b[0m Trial 13 finished with value: 0.03343349120107893 and parameters: {'booster': 'gblinear', 'lambda': 5.328735367514281e-06, 'alpha': 0.0057163942838623655, 'subsample': 0.48141606942236104, 'colsample_bytree': 0.7189091943562027}. Best is trial 13 with value: 0.03343349120107893.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:34:59,986]\u001b[0m Trial 14 finished with value: 0.8418177489868685 and parameters: {'booster': 'dart', 'lambda': 0.4529512914472934, 'alpha': 0.002413437029095413, 'subsample': 0.3805326909002369, 'colsample_bytree': 0.8098891287738651, 'max_depth': 9, 'min_child_weight': 6, 'eta': 1.0335633973723483e-08, 'gamma': 0.0003566431611327233, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.4310332398668582e-08, 'skip_drop': 0.31170354256151556}. Best is trial 13 with value: 0.03343349120107893.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:35:00,123]\u001b[0m Trial 15 finished with value: 0.09477972967851503 and parameters: {'booster': 'gblinear', 'lambda': 1.1350440352458324e-05, 'alpha': 7.657735585041219e-06, 'subsample': 0.857446010701884, 'colsample_bytree': 0.8993160133091543}. Best is trial 13 with value: 0.03343349120107893.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:35:00,258]\u001b[0m Trial 16 finished with value: 0.0883290864092881 and parameters: {'booster': 'gblinear', 'lambda': 2.1325332758769082e-06, 'alpha': 2.0733423192992185e-05, 'subsample': 0.6506803975134741, 'colsample_bytree': 0.5770911412141915}. Best is trial 13 with value: 0.03343349120107893.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:35:00,389]\u001b[0m Trial 17 finished with value: 0.062280883893234884 and parameters: {'booster': 'gblinear', 'lambda': 0.0005716187047453633, 'alpha': 0.005222346871900545, 'subsample': 0.325765130535815, 'colsample_bytree': 0.7399297586761682}. Best is trial 13 with value: 0.03343349120107893.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:35:01,810]\u001b[0m Trial 18 finished with value: 0.02518193138666009 and parameters: {'booster': 'dart', 'lambda': 5.0674245977664225e-05, 'alpha': 0.0007790125517518851, 'subsample': 0.8631935138612743, 'colsample_bytree': 0.664248693064166, 'max_depth': 5, 'min_child_weight': 2, 'eta': 0.31245872950124837, 'gamma': 0.4774624952152633, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.259280280948671e-07, 'skip_drop': 0.13971756011742997}. Best is trial 18 with value: 0.02518193138666009.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:35:03,224]\u001b[0m Trial 19 finished with value: 0.017964794828846636 and parameters: {'booster': 'dart', 'lambda': 8.369981693147654e-05, 'alpha': 0.0006194234216371741, 'subsample': 0.4996525638035797, 'colsample_bytree': 0.8392835840325292, 'max_depth': 5, 'min_child_weight': 2, 'eta': 0.521541583825951, 'gamma': 0.6083201443567936, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.1050106148540978e-07, 'skip_drop': 0.44535554454894416}. Best is trial 19 with value: 0.017964794828846636.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:35:04,661]\u001b[0m Trial 20 finished with value: 0.016561653997561022 and parameters: {'booster': 'dart', 'lambda': 0.00010417142483859116, 'alpha': 1.4349429822026006e-06, 'subsample': 0.6986741045116386, 'colsample_bytree': 0.8467235909911819, 'max_depth': 5, 'min_child_weight': 2, 'eta': 0.8306604908223607, 'gamma': 0.8186967573901243, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 9.250774557109592e-08, 'skip_drop': 0.5787071906182413}. Best is trial 20 with value: 0.016561653997561022.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:35:06,093]\u001b[0m Trial 21 finished with value: 0.02828318353549292 and parameters: {'booster': 'dart', 'lambda': 0.00011351031961853905, 'alpha': 7.09099271967708e-07, 'subsample': 0.6931397395499284, 'colsample_bytree': 0.8571781957313223, 'max_depth': 5, 'min_child_weight': 2, 'eta': 0.6751212772437367, 'gamma': 0.9534429196448874, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 8.078547380094086e-08, 'skip_drop': 0.8215410817059302}. Best is trial 20 with value: 0.016561653997561022.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:35:07,485]\u001b[0m Trial 22 finished with value: 0.0005077256485451697 and parameters: {'booster': 'dart', 'lambda': 0.0014381430424991696, 'alpha': 1.8242486217121133e-05, 'subsample': 0.8941684489021856, 'colsample_bytree': 0.9941332079632272, 'max_depth': 5, 'min_child_weight': 3, 'eta': 0.03398321996867651, 'gamma': 0.038457860509972866, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.8738357181302878e-06, 'skip_drop': 0.03350808263300832}. Best is trial 22 with value: 0.0005077256485451697.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:35:08,937]\u001b[0m Trial 23 finished with value: 0.18787536051016418 and parameters: {'booster': 'dart', 'lambda': 0.002486805784296067, 'alpha': 3.808767925781503e-06, 'subsample': 0.5622578670946812, 'colsample_bytree': 0.9933095829046642, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.013253052578027455, 'gamma': 0.012578135582606361, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 5.062581596160871e-06, 'skip_drop': 0.0157154757009284}. Best is trial 22 with value: 0.0005077256485451697.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:35:10,419]\u001b[0m Trial 24 finished with value: 0.00175623541009094 and parameters: {'booster': 'dart', 'lambda': 0.0010636641132683656, 'alpha': 3.0165254413489624e-05, 'subsample': 0.8953695342625336, 'colsample_bytree': 0.9224875541676572, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.040500923015050004, 'gamma': 0.03339547652294952, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 4.183348067738222e-06, 'skip_drop': 0.0013005006602414804}. Best is trial 22 with value: 0.0005077256485451697.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:35:11,853]\u001b[0m Trial 25 finished with value: 0.04364471566670294 and parameters: {'booster': 'dart', 'lambda': 0.005277467663953733, 'alpha': 3.5498827892240234e-07, 'subsample': 0.9952248502878589, 'colsample_bytree': 0.9374805736201107, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.014614080224421436, 'gamma': 0.014810108553600715, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 7.670678714459229e-06, 'skip_drop': 0.0013644761369970024}. Best is trial 22 with value: 0.0005077256485451697.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:35:13,313]\u001b[0m Trial 26 finished with value: 0.030188109339426894 and parameters: {'booster': 'dart', 'lambda': 0.09473756560515881, 'alpha': 2.1076684742658526e-05, 'subsample': 0.89220592582539, 'colsample_bytree': 0.9346231452598232, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.017647313584090177, 'gamma': 0.03435049583775872, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 9.065076681652758e-06, 'skip_drop': 0.0015882799332371667}. Best is trial 22 with value: 0.0005077256485451697.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:35:14,865]\u001b[0m Trial 27 finished with value: 0.003760411367828165 and parameters: {'booster': 'dart', 'lambda': 0.0013475881994893099, 'alpha': 3.315099138951473e-05, 'subsample': 0.8076695304760704, 'colsample_bytree': 0.7893878017565474, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.037074636623993705, 'gamma': 0.0005924194634261709, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.4542650525945363e-06, 'skip_drop': 0.006165902226386478}. Best is trial 22 with value: 0.0005077256485451697.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:35:16,449]\u001b[0m Trial 28 finished with value: 0.7349096748781982 and parameters: {'booster': 'dart', 'lambda': 0.0009111562932990971, 'alpha': 3.40884396249883e-05, 'subsample': 0.9197476609682165, 'colsample_bytree': 0.7858056199783975, 'max_depth': 7, 'min_child_weight': 5, 'eta': 0.0008709044557866838, 'gamma': 0.00043816675846649716, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 9.175077741263564e-05, 'skip_drop': 0.0002573505134507319}. Best is trial 22 with value: 0.0005077256485451697.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:35:17,893]\u001b[0m Trial 29 finished with value: 0.8372541071680564 and parameters: {'booster': 'dart', 'lambda': 0.020624366493627522, 'alpha': 6.379308689582358e-05, 'subsample': 0.8213486863601831, 'colsample_bytree': 0.9343281529801233, 'max_depth': 7, 'min_child_weight': 3, 'eta': 2.7000932059090474e-05, 'gamma': 3.378638066781015e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 2.3411259898508468e-06, 'skip_drop': 0.009597645763692278}. Best is trial 22 with value: 0.0005077256485451697.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:35:19,517]\u001b[0m Trial 30 finished with value: 0.14529187453416545 and parameters: {'booster': 'dart', 'lambda': 0.18276588484377296, 'alpha': 7.072127949564961e-06, 'subsample': 0.803817213290228, 'colsample_bytree': 0.9945638735238489, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.03521221881651268, 'gamma': 0.0018806875718520005, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.0002076240415218052, 'skip_drop': 2.4523783708510847e-05}. Best is trial 22 with value: 0.0005077256485451697.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:35:20,989]\u001b[0m Trial 31 finished with value: 0.003037421419726393 and parameters: {'booster': 'dart', 'lambda': 0.0003147746709412335, 'alpha': 1.8885650019017168e-07, 'subsample': 0.6920360670778146, 'colsample_bytree': 0.9137158653074321, 'max_depth': 5, 'min_child_weight': 3, 'eta': 0.11906393968838189, 'gamma': 0.06615181695170262, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 6.930365425516446e-07, 'skip_drop': 0.008312643133017416}. Best is trial 22 with value: 0.0005077256485451697.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:35:22,523]\u001b[0m Trial 32 finished with value: 0.002053454066471072 and parameters: {'booster': 'dart', 'lambda': 0.0014581016200189841, 'alpha': 1.6229438204398798e-07, 'subsample': 0.8494785656710749, 'colsample_bytree': 0.9150022680684345, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.07359681545948323, 'gamma': 0.07196362601946042, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 8.832886617811437e-07, 'skip_drop': 0.013046414133506667}. Best is trial 22 with value: 0.0005077256485451697.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:35:23,994]\u001b[0m Trial 33 finished with value: 0.005473635786836901 and parameters: {'booster': 'dart', 'lambda': 0.008937804205002267, 'alpha': 1.2115475839341626e-08, 'subsample': 0.8702589095724468, 'colsample_bytree': 0.9048945652656039, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.08043984801382201, 'gamma': 0.05506235262755242, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 7.56998751104347e-07, 'skip_drop': 0.04203834355368588}. Best is trial 22 with value: 0.0005077256485451697.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:35:24,318]\u001b[0m Trial 34 finished with value: 0.6017775309519661 and parameters: {'booster': 'gbtree', 'lambda': 0.0003349422952296312, 'alpha': 7.813443730147848e-08, 'subsample': 0.6512619727142899, 'colsample_bytree': 0.9565885645272422, 'max_depth': 7, 'min_child_weight': 5, 'eta': 0.002992618772936891, 'gamma': 0.08712378606637386, 'grow_policy': 'lossguide'}. Best is trial 22 with value: 0.0005077256485451697.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:35:25,844]\u001b[0m Trial 35 finished with value: 0.0034670925415330187 and parameters: {'booster': 'dart', 'lambda': 0.003590346575291491, 'alpha': 8.34006305942685e-08, 'subsample': 0.7299851787386524, 'colsample_bytree': 0.8868420209373481, 'max_depth': 5, 'min_child_weight': 3, 'eta': 0.10620425400561076, 'gamma': 0.10344609422526696, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 3.429693545397023e-05, 'skip_drop': 0.0006160876444376489}. Best is trial 22 with value: 0.0005077256485451697.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:35:27,318]\u001b[0m Trial 36 finished with value: 0.34293862401024283 and parameters: {'booster': 'dart', 'lambda': 0.04399493646550021, 'alpha': 2.713267396564381e-07, 'subsample': 0.9346262761985408, 'colsample_bytree': 0.9994131240249365, 'max_depth': 5, 'min_child_weight': 5, 'eta': 0.004787232065402045, 'gamma': 0.00666930799848057, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 2.812183093591045e-07, 'skip_drop': 0.03054228218578679}. Best is trial 22 with value: 0.0005077256485451697.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:35:29,017]\u001b[0m A new study created in memory with name: no-name-357102d6-9b5d-4e9c-8d3f-25a8af0ad380\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:35:29,387]\u001b[0m Trial 0 finished with value: 0.9590943683409437 and parameters: {'booster': 'gbtree', 'lambda': 1.0492997139033946e-05, 'alpha': 0.6408447216358253, 'subsample': 0.562249692071064, 'colsample_bytree': 0.6712562179938623, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.003872219171831552, 'gamma': 2.044073107065224e-05, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9590943683409437.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:35:29,854]\u001b[0m Trial 1 finished with value: 0.9590943683409437 and parameters: {'booster': 'gbtree', 'lambda': 0.009679994195368587, 'alpha': 0.0006901813094490398, 'subsample': 0.5096640022269883, 'colsample_bytree': 0.5826893596833603, 'max_depth': 3, 'min_child_weight': 10, 'eta': 5.438278783283983e-06, 'gamma': 2.0287361051772726e-08, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9590943683409437.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:35:30,195]\u001b[0m Trial 2 finished with value: 0.9590567405654978 and parameters: {'booster': 'gbtree', 'lambda': 0.006180746841245288, 'alpha': 3.185840454037308e-08, 'subsample': 0.4577322565960318, 'colsample_bytree': 0.46491239485024444, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.7569223603443853, 'gamma': 2.354942815590294e-06, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.9590943683409437.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:35:30,936]\u001b[0m Trial 3 finished with value: 0.9590943683409437 and parameters: {'booster': 'gblinear', 'lambda': 0.7147523003496472, 'alpha': 0.001188947829478152, 'subsample': 0.500557192558885, 'colsample_bytree': 0.7391123136388467}. Best is trial 0 with value: 0.9590943683409437.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:35:41,702]\u001b[0m Trial 4 finished with value: 0.9590943683409437 and parameters: {'booster': 'dart', 'lambda': 0.026478372951749318, 'alpha': 5.03411996964202e-07, 'subsample': 0.9981930257460185, 'colsample_bytree': 0.8481643274574067, 'max_depth': 9, 'min_child_weight': 9, 'eta': 7.367912203559723e-07, 'gamma': 0.4326372004327924, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.025153883690496783, 'skip_drop': 0.21197370367256235}. Best is trial 0 with value: 0.9590943683409437.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:35:52,173]\u001b[0m Trial 5 finished with value: 0.9590943683409437 and parameters: {'booster': 'dart', 'lambda': 0.005335555396962598, 'alpha': 0.050461457204132684, 'subsample': 0.6138357935080792, 'colsample_bytree': 0.7874620265296215, 'max_depth': 3, 'min_child_weight': 2, 'eta': 1.0835981244228902e-07, 'gamma': 0.08266462236703749, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 2.360099606298733e-08, 'skip_drop': 7.174611056591341e-06}. Best is trial 0 with value: 0.9590943683409437.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:35:53,055]\u001b[0m Trial 6 finished with value: 0.9590943683409437 and parameters: {'booster': 'gblinear', 'lambda': 0.13680286066177888, 'alpha': 9.901557918970711e-08, 'subsample': 0.8274411607165921, 'colsample_bytree': 0.8899456084037509}. Best is trial 0 with value: 0.9590943683409437.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:36:02,708]\u001b[0m Trial 7 finished with value: 0.9590943683409437 and parameters: {'booster': 'dart', 'lambda': 0.1341318793071457, 'alpha': 1.5345728201263883e-05, 'subsample': 0.5799658026876107, 'colsample_bytree': 0.7233155485505727, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.0001054937268004376, 'gamma': 2.2886098638095328e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.0863962274155912, 'skip_drop': 0.0010811150110337001}. Best is trial 0 with value: 0.9590943683409437.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:36:03,714]\u001b[0m A new study created in memory with name: no-name-432ee3f3-f4a0-4c5e-a07b-7b5f268f4174\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:36:11,825]\u001b[0m Trial 0 finished with value: 0.7445927235233465 and parameters: {'booster': 'dart', 'lambda': 0.004692975665335292, 'alpha': 3.390940598697605e-05, 'subsample': 0.9153294227741824, 'colsample_bytree': 0.8020620907684888, 'max_depth': 7, 'min_child_weight': 6, 'eta': 0.0011992722621521849, 'gamma': 1.1324742791008856e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.004349184240557363, 'skip_drop': 0.19858498000840352}. Best is trial 0 with value: 0.7445927235233465.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:36:12,391]\u001b[0m Trial 1 finished with value: 0.7561008311422944 and parameters: {'booster': 'gblinear', 'lambda': 1.475875227668903e-07, 'alpha': 8.697824027242151e-05, 'subsample': 0.577543713018889, 'colsample_bytree': 0.6931909261068783}. Best is trial 1 with value: 0.7561008311422944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:36:12,973]\u001b[0m Trial 2 finished with value: 0.7600335870520203 and parameters: {'booster': 'gblinear', 'lambda': 0.0008872491913012455, 'alpha': 5.3349502870188206e-05, 'subsample': 0.3300748341823444, 'colsample_bytree': 0.9102645381535268}. Best is trial 2 with value: 0.7600335870520203.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:36:20,245]\u001b[0m Trial 3 finished with value: 0.7634789467020153 and parameters: {'booster': 'dart', 'lambda': 4.061938620248222e-06, 'alpha': 0.0018470433034124471, 'subsample': 0.4789418490367884, 'colsample_bytree': 0.9919121698453512, 'max_depth': 5, 'min_child_weight': 3, 'eta': 0.6937185381682189, 'gamma': 0.23248415900443617, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.09112236473126735, 'skip_drop': 3.677760448630069e-07}. Best is trial 3 with value: 0.7634789467020153.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:36:20,892]\u001b[0m Trial 4 finished with value: 0.7455890410958904 and parameters: {'booster': 'gbtree', 'lambda': 0.0031511649788624994, 'alpha': 2.299294983100302e-07, 'subsample': 0.6329829809513468, 'colsample_bytree': 0.6955096751423657, 'max_depth': 5, 'min_child_weight': 6, 'eta': 4.387350879184602e-06, 'gamma': 0.43807403891857044, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 0.7634789467020153.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:36:28,758]\u001b[0m Trial 5 finished with value: 0.7048995932440036 and parameters: {'booster': 'dart', 'lambda': 0.0006113457729512418, 'alpha': 1.129629427911595e-07, 'subsample': 0.22373721167558644, 'colsample_bytree': 0.7590263666679369, 'max_depth': 7, 'min_child_weight': 9, 'eta': 3.3775271792106275e-08, 'gamma': 0.0003095262248867715, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 2.016464957969231e-08, 'skip_drop': 0.000223796851534268}. Best is trial 3 with value: 0.7634789467020153.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:36:29,524]\u001b[0m Trial 6 finished with value: 0.7435707901664771 and parameters: {'booster': 'gbtree', 'lambda': 2.0501903513962696e-07, 'alpha': 0.0004431454112902828, 'subsample': 0.5057439750920186, 'colsample_bytree': 0.7439245052997943, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.005018224601945434, 'gamma': 0.001861945031709122, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 0.7634789467020153.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:36:30,115]\u001b[0m Trial 7 finished with value: 0.7457593880943064 and parameters: {'booster': 'gblinear', 'lambda': 1.0451835571354085e-05, 'alpha': 2.921390457782066e-08, 'subsample': 0.3004780476664993, 'colsample_bytree': 0.5640054577518845}. Best is trial 3 with value: 0.7634789467020153.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:36:38,515]\u001b[0m Trial 8 finished with value: 0.73358943192461 and parameters: {'booster': 'dart', 'lambda': 8.752184086056375e-05, 'alpha': 1.646840604100227e-05, 'subsample': 0.37623051183619716, 'colsample_bytree': 0.9927119284324637, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.006519556264717315, 'gamma': 2.4179876714381797e-06, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.793004954146031e-05, 'skip_drop': 0.0001270389241827836}. Best is trial 3 with value: 0.7634789467020153.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:36:47,346]\u001b[0m A new study created in memory with name: no-name-21566cc4-945c-426d-9c3a-4c18fb353d8e\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:36:55,401]\u001b[0m Trial 0 finished with value: 0.8644350975374344 and parameters: {'booster': 'dart', 'lambda': 0.007003099399410431, 'alpha': 0.0007583413166146295, 'subsample': 0.7398500346363992, 'colsample_bytree': 0.8722993954990632, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.23296924030619864, 'gamma': 0.0027958422962131436, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.008664121091791864, 'skip_drop': 1.4990977131060635e-08}. Best is trial 0 with value: 0.8644350975374344.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:36:55,992]\u001b[0m Trial 1 finished with value: 0.8638993082540307 and parameters: {'booster': 'gblinear', 'lambda': 0.006454979612867256, 'alpha': 3.143581475175468e-08, 'subsample': 0.2969371122325667, 'colsample_bytree': 0.43962530045303344}. Best is trial 0 with value: 0.8644350975374344.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:37:04,015]\u001b[0m Trial 2 finished with value: 0.87102413568167 and parameters: {'booster': 'dart', 'lambda': 0.007906866159770154, 'alpha': 1.1351421739892535e-06, 'subsample': 0.8932122162912919, 'colsample_bytree': 0.9491919682867123, 'max_depth': 3, 'min_child_weight': 10, 'eta': 0.6604502662096328, 'gamma': 9.43793580143888e-07, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 7.45390869171984e-05, 'skip_drop': 6.982742289471529e-08}. Best is trial 2 with value: 0.87102413568167.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:37:11,186]\u001b[0m Trial 3 finished with value: 0.8600511793853218 and parameters: {'booster': 'dart', 'lambda': 1.7529822574990413e-05, 'alpha': 0.007228857809592688, 'subsample': 0.6381450053149194, 'colsample_bytree': 0.6157472890378755, 'max_depth': 5, 'min_child_weight': 8, 'eta': 3.471129495982386e-06, 'gamma': 1.9482330549990317e-07, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.21398776939122652, 'skip_drop': 0.04186939274107846}. Best is trial 2 with value: 0.87102413568167.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:37:11,544]\u001b[0m Trial 4 finished with value: 0.8626695251456824 and parameters: {'booster': 'gbtree', 'lambda': 0.000670244818276487, 'alpha': 3.1453945578748296e-06, 'subsample': 0.3981133001379766, 'colsample_bytree': 0.38845809374160034, 'max_depth': 3, 'min_child_weight': 8, 'eta': 2.074579243960912e-08, 'gamma': 4.974279847700406e-08, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 0.87102413568167.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:37:11,953]\u001b[0m Trial 5 finished with value: 0.8693112132115182 and parameters: {'booster': 'gblinear', 'lambda': 7.43344393085436e-08, 'alpha': 0.003566787057445321, 'subsample': 0.266845673292224, 'colsample_bytree': 0.28658825368853613}. Best is trial 2 with value: 0.87102413568167.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:37:19,990]\u001b[0m Trial 6 finished with value: 0.8626695251456824 and parameters: {'booster': 'dart', 'lambda': 0.5816912246376613, 'alpha': 3.69451661176634e-08, 'subsample': 0.2631132830798466, 'colsample_bytree': 0.9609235291570533, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.02202082286027387, 'gamma': 4.5403688176688407e-07, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 6.65794511527398e-07, 'skip_drop': 5.474774477455578e-06}. Best is trial 2 with value: 0.87102413568167.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:37:27,940]\u001b[0m Trial 7 finished with value: 0.8679820501889317 and parameters: {'booster': 'dart', 'lambda': 1.7190041728509635e-05, 'alpha': 0.00015039498492196035, 'subsample': 0.26449789254010814, 'colsample_bytree': 0.4128346990557253, 'max_depth': 7, 'min_child_weight': 9, 'eta': 1.8528352742563657e-05, 'gamma': 0.001467366201943141, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.0025029207997775724, 'skip_drop': 0.0006546323701623782}. Best is trial 2 with value: 0.87102413568167.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:37:37,063]\u001b[0m A new study created in memory with name: no-name-e6b46efa-946a-4d4c-9fe2-a4666b3bd3dc\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:37:37,738]\u001b[0m Trial 0 finished with value: 0.9146381473827733 and parameters: {'booster': 'gbtree', 'lambda': 0.008729456927913406, 'alpha': 2.5724438971279438e-05, 'subsample': 0.5230730674346389, 'colsample_bytree': 0.5093264607230203, 'max_depth': 7, 'min_child_weight': 2, 'eta': 3.426788150215863e-06, 'gamma': 0.03243580592196272, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9146381473827733.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:37:49,659]\u001b[0m Trial 1 finished with value: 0.9092336586291816 and parameters: {'booster': 'dart', 'lambda': 5.812234307850208e-05, 'alpha': 7.807502753300503e-06, 'subsample': 0.6669857937767152, 'colsample_bytree': 0.702862550783572, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.000663703863570494, 'gamma': 2.8958618186422174e-07, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.0475720600780513e-05, 'skip_drop': 0.0008967541974478416}. Best is trial 0 with value: 0.9146381473827733.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:37:49,878]\u001b[0m Trial 2 finished with value: 0.7839912458458297 and parameters: {'booster': 'gblinear', 'lambda': 1.797126936682202e-07, 'alpha': 1.0487983024020581e-07, 'subsample': 0.4367452299710906, 'colsample_bytree': 0.4324416847712595}. Best is trial 0 with value: 0.9146381473827733.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:37:50,510]\u001b[0m Trial 3 finished with value: 0.9050833714342009 and parameters: {'booster': 'gblinear', 'lambda': 4.874797589893767e-07, 'alpha': 0.001305744231793996, 'subsample': 0.5631010322436787, 'colsample_bytree': 0.5177375305055552}. Best is trial 0 with value: 0.9146381473827733.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:02,869]\u001b[0m Trial 4 finished with value: 0.9119181967514877 and parameters: {'booster': 'dart', 'lambda': 3.9532083765383197e-07, 'alpha': 0.0005708554678374808, 'subsample': 0.4970484822178633, 'colsample_bytree': 0.3089827312597384, 'max_depth': 5, 'min_child_weight': 3, 'eta': 0.03484656802248426, 'gamma': 1.254226439728018e-05, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 4.11877100047686e-08, 'skip_drop': 0.034944680727423114}. Best is trial 0 with value: 0.9146381473827733.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:38:15,844]\u001b[0m Trial 5 finished with value: 0.9119181967514877 and parameters: {'booster': 'dart', 'lambda': 0.006794929528982851, 'alpha': 0.0004139223601680298, 'subsample': 0.7629703523525435, 'colsample_bytree': 0.5469577570603357, 'max_depth': 3, 'min_child_weight': 7, 'eta': 3.253642340186282e-07, 'gamma': 7.375912387154826e-05, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 2.507801402007744e-07, 'skip_drop': 0.017877165982788833}. Best is trial 0 with value: 0.9146381473827733.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:38:17,346]\u001b[0m A new study created in memory with name: no-name-e6995625-f57e-4647-aa69-9fc76bd13202\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:17,525]\u001b[0m Trial 0 finished with value: 1.3356399819366107 and parameters: {'booster': 'gbtree', 'lambda': 0.013758273689213176, 'alpha': 0.4037307343612662, 'subsample': 0.7416041469537509, 'colsample_bytree': 0.5170703457494823, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.00023371793121301342, 'gamma': 4.1490182748137184e-07, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 1.3356399819366107.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:19,014]\u001b[0m Trial 1 finished with value: 1.0765058919095496 and parameters: {'booster': 'dart', 'lambda': 0.0031518857492826816, 'alpha': 8.600435499487329e-08, 'subsample': 0.35289907141749766, 'colsample_bytree': 0.24723308363584737, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.016896542882309018, 'gamma': 3.4196883152043705e-06, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.0002699862204879045, 'skip_drop': 1.3211011238801478e-08}. Best is trial 1 with value: 1.0765058919095496.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:19,135]\u001b[0m Trial 2 finished with value: 1.161812626263011 and parameters: {'booster': 'gblinear', 'lambda': 1.2158305219742648e-05, 'alpha': 6.600136050452701e-05, 'subsample': 0.8007336176915001, 'colsample_bytree': 0.490456990636236}. Best is trial 1 with value: 1.0765058919095496.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:20,525]\u001b[0m Trial 3 finished with value: 1.3477480951063157 and parameters: {'booster': 'dart', 'lambda': 1.009797879795625e-07, 'alpha': 0.3146237574577499, 'subsample': 0.34302908395615206, 'colsample_bytree': 0.9656327924015247, 'max_depth': 3, 'min_child_weight': 6, 'eta': 1.3109540102167327e-06, 'gamma': 4.0410176687755404e-05, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 1.2544413959095405e-07, 'skip_drop': 0.007968092619906872}. Best is trial 1 with value: 1.0765058919095496.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:20,645]\u001b[0m Trial 4 finished with value: 1.0660528488132763 and parameters: {'booster': 'gblinear', 'lambda': 0.0813874327049354, 'alpha': 5.005041471879005e-07, 'subsample': 0.672863854769957, 'colsample_bytree': 0.47471061760270594}. Best is trial 4 with value: 1.0660528488132763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:20,752]\u001b[0m Trial 5 finished with value: 1.0934818596952853 and parameters: {'booster': 'gblinear', 'lambda': 0.8710005601098808, 'alpha': 0.023276265385672273, 'subsample': 0.7744232365005745, 'colsample_bytree': 0.7020272567823318}. Best is trial 4 with value: 1.0660528488132763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:21,032]\u001b[0m Trial 6 finished with value: 1.3092841723185547 and parameters: {'booster': 'gbtree', 'lambda': 0.022204953276051865, 'alpha': 1.362668267928203e-07, 'subsample': 0.39261963631273444, 'colsample_bytree': 0.7243768194827513, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.13526990989385776, 'gamma': 6.308968660876517e-07, 'grow_policy': 'lossguide'}. Best is trial 4 with value: 1.0660528488132763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:21,234]\u001b[0m Trial 7 finished with value: 1.347399951843249 and parameters: {'booster': 'gbtree', 'lambda': 4.132978887747141e-07, 'alpha': 0.0008811343075038003, 'subsample': 0.8855602849510584, 'colsample_bytree': 0.4892270867792597, 'max_depth': 5, 'min_child_weight': 2, 'eta': 7.307989900549791e-06, 'gamma': 8.798306116456293e-08, 'grow_policy': 'depthwise'}. Best is trial 4 with value: 1.0660528488132763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:22,707]\u001b[0m Trial 8 finished with value: 1.3477983977029304 and parameters: {'booster': 'dart', 'lambda': 3.062880876476753e-07, 'alpha': 1.9166864008108317e-07, 'subsample': 0.33033987587569014, 'colsample_bytree': 0.6758199500142907, 'max_depth': 9, 'min_child_weight': 4, 'eta': 3.373156695824695e-07, 'gamma': 0.0069988970122261025, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.00014734671995383277, 'skip_drop': 0.014827085335945867}. Best is trial 4 with value: 1.0660528488132763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:22,893]\u001b[0m Trial 9 finished with value: 1.347789158643863 and parameters: {'booster': 'gbtree', 'lambda': 0.04039185999856461, 'alpha': 0.13905085039570408, 'subsample': 0.2308978655949206, 'colsample_bytree': 0.5751430893998637, 'max_depth': 7, 'min_child_weight': 8, 'eta': 5.242571354315135e-07, 'gamma': 4.09030635442191e-06, 'grow_policy': 'lossguide'}. Best is trial 4 with value: 1.0660528488132763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:23,028]\u001b[0m Trial 10 finished with value: 1.173534312457711 and parameters: {'booster': 'gblinear', 'lambda': 4.74944774552977e-05, 'alpha': 6.384963157732639e-06, 'subsample': 0.5742179859427894, 'colsample_bytree': 0.27386507069980204}. Best is trial 4 with value: 1.0660528488132763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:23,508]\u001b[0m Trial 11 finished with value: 1.1151916763068177 and parameters: {'booster': 'dart', 'lambda': 0.0009762654876130689, 'alpha': 1.0237294138182909e-08, 'subsample': 0.5532405095998146, 'colsample_bytree': 0.20273823312857386, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.13980746184800702, 'gamma': 0.16250357522146994, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.8025079532256663, 'skip_drop': 1.3702695926995763e-08}. Best is trial 4 with value: 1.0660528488132763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:24,979]\u001b[0m Trial 12 finished with value: 1.285553568391192 and parameters: {'booster': 'dart', 'lambda': 0.000995931038755417, 'alpha': 2.3633588354919995e-06, 'subsample': 0.498464895035682, 'colsample_bytree': 0.34969935688428605, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.0012217857743089333, 'gamma': 0.0008287269154776623, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.00047956036671842627, 'skip_drop': 1.3110511628175524e-08}. Best is trial 4 with value: 1.0660528488132763.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:25,115]\u001b[0m Trial 13 finished with value: 1.065669159709297 and parameters: {'booster': 'gblinear', 'lambda': 0.08617106435459301, 'alpha': 2.1857815084622218e-08, 'subsample': 0.6631153714513536, 'colsample_bytree': 0.3657645797688409}. Best is trial 13 with value: 1.065669159709297.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:25,251]\u001b[0m Trial 14 finished with value: 1.0712538530968705 and parameters: {'booster': 'gblinear', 'lambda': 0.8511939685581679, 'alpha': 1.0301351963507154e-08, 'subsample': 0.6772691801852445, 'colsample_bytree': 0.37576884334322064}. Best is trial 13 with value: 1.065669159709297.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:25,385]\u001b[0m Trial 15 finished with value: 1.0613606511861677 and parameters: {'booster': 'gblinear', 'lambda': 0.13279847133384703, 'alpha': 1.6863028903482334e-06, 'subsample': 0.9285641819193461, 'colsample_bytree': 0.39948125962938175}. Best is trial 15 with value: 1.0613606511861677.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:25,522]\u001b[0m Trial 16 finished with value: 1.06026848618753 and parameters: {'booster': 'gblinear', 'lambda': 0.16926681560677848, 'alpha': 2.9648627614760125e-05, 'subsample': 0.9917664691600495, 'colsample_bytree': 0.3696135033220751}. Best is trial 16 with value: 1.06026848618753.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:38:25,656]\u001b[0m Trial 17 finished with value: 1.1659191082992124 and parameters: {'booster': 'gblinear', 'lambda': 0.00013602242355341269, 'alpha': 0.00010777166807388726, 'subsample': 0.9991282021790329, 'colsample_bytree': 0.8418458703652912}. Best is trial 16 with value: 1.06026848618753.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:25,791]\u001b[0m Trial 18 finished with value: 1.1765556874061762 and parameters: {'booster': 'gblinear', 'lambda': 3.8035237857369274e-06, 'alpha': 1.7846549679654165e-05, 'subsample': 0.9777244812029723, 'colsample_bytree': 0.40512220416513595}. Best is trial 16 with value: 1.06026848618753.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:25,925]\u001b[0m Trial 19 finished with value: 1.0662425115656795 and parameters: {'booster': 'gblinear', 'lambda': 0.581565143982782, 'alpha': 0.0017620459596947324, 'subsample': 0.8948066761146217, 'colsample_bytree': 0.2909329536625183}. Best is trial 16 with value: 1.06026848618753.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:26,061]\u001b[0m Trial 20 finished with value: 1.1411718000659337 and parameters: {'booster': 'gblinear', 'lambda': 0.003102422304998164, 'alpha': 1.5518984897258495e-06, 'subsample': 0.875240078749584, 'colsample_bytree': 0.5990609312769183}. Best is trial 16 with value: 1.06026848618753.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:26,195]\u001b[0m Trial 21 finished with value: 1.0614869604325419 and parameters: {'booster': 'gblinear', 'lambda': 0.1304968935677526, 'alpha': 3.886332135380851e-05, 'subsample': 0.9454915725427664, 'colsample_bytree': 0.4094317253940901}. Best is trial 16 with value: 1.06026848618753.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:26,330]\u001b[0m Trial 22 finished with value: 1.0593878753612995 and parameters: {'booster': 'gblinear', 'lambda': 0.200410808519312, 'alpha': 0.0003673033837903123, 'subsample': 0.938094899427587, 'colsample_bytree': 0.4218009550539784}. Best is trial 22 with value: 1.0593878753612995.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:26,463]\u001b[0m Trial 23 finished with value: 1.0590868998618725 and parameters: {'booster': 'gblinear', 'lambda': 0.22335001521468148, 'alpha': 0.000724681782359388, 'subsample': 0.8393480399709456, 'colsample_bytree': 0.3079178469118315}. Best is trial 23 with value: 1.0590868998618725.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:26,597]\u001b[0m Trial 24 finished with value: 1.1050846874976215 and parameters: {'booster': 'gblinear', 'lambda': 0.008503542615352433, 'alpha': 0.0006383630373979931, 'subsample': 0.8332230412303105, 'colsample_bytree': 0.2945493676815943}. Best is trial 23 with value: 1.0590868998618725.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:26,732]\u001b[0m Trial 25 finished with value: 1.0575791347482655 and parameters: {'booster': 'gblinear', 'lambda': 0.17354974315596655, 'alpha': 0.0030120422224785273, 'subsample': 0.8524943071946106, 'colsample_bytree': 0.44782478223381006}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:26,864]\u001b[0m Trial 26 finished with value: 1.0634224494955868 and parameters: {'booster': 'gblinear', 'lambda': 0.0005281403092991863, 'alpha': 0.005690695033615384, 'subsample': 0.7366980613957295, 'colsample_bytree': 0.5354707872042005}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:26,999]\u001b[0m Trial 27 finished with value: 1.1196116131793636 and parameters: {'booster': 'gblinear', 'lambda': 0.004901852354606897, 'alpha': 0.00021063006877634032, 'subsample': 0.8381603506776996, 'colsample_bytree': 0.44038800312574955}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:27,122]\u001b[0m Trial 28 finished with value: 1.0740975447108179 and parameters: {'booster': 'gblinear', 'lambda': 0.3379497025885234, 'alpha': 0.018362284696938517, 'subsample': 0.8409332269730323, 'colsample_bytree': 0.32607333280062567}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:27,382]\u001b[0m Trial 29 finished with value: 1.3478180139987472 and parameters: {'booster': 'gbtree', 'lambda': 0.019340959900084633, 'alpha': 0.004584908530594347, 'subsample': 0.7359478320486714, 'colsample_bytree': 0.20816296643228613, 'max_depth': 9, 'min_child_weight': 5, 'eta': 1.4828817472749487e-08, 'gamma': 0.3414998062547451, 'grow_policy': 'depthwise'}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:27,691]\u001b[0m Trial 30 finished with value: 1.3478180093562513 and parameters: {'booster': 'gbtree', 'lambda': 0.03009135242360226, 'alpha': 0.00025696069089155965, 'subsample': 0.9192796535503212, 'colsample_bytree': 0.6418440055291831, 'max_depth': 7, 'min_child_weight': 2, 'eta': 1.7139677813094448e-08, 'gamma': 2.6775802092715774e-08, 'grow_policy': 'depthwise'}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:27,827]\u001b[0m Trial 31 finished with value: 1.06005492818045 and parameters: {'booster': 'gblinear', 'lambda': 0.1705083823649724, 'alpha': 1.4281496692402225e-05, 'subsample': 0.9943277371210147, 'colsample_bytree': 0.4468465971533264}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:27,958]\u001b[0m Trial 32 finished with value: 1.0860062617028259 and parameters: {'booster': 'gblinear', 'lambda': 1.0052022539062344e-08, 'alpha': 0.002892858374004874, 'subsample': 0.9279420820157686, 'colsample_bytree': 0.5344720283868152}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:28,077]\u001b[0m Trial 33 finished with value: 1.0751709946784633 and parameters: {'booster': 'gblinear', 'lambda': 0.31764342038842963, 'alpha': 0.02025315280625856, 'subsample': 0.7997052270992737, 'colsample_bytree': 0.44267175771585293}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:28,208]\u001b[0m Trial 34 finished with value: 1.0735254300399781 and parameters: {'booster': 'gblinear', 'lambda': 0.04444541047586116, 'alpha': 0.0004175611010208496, 'subsample': 0.9604190345349881, 'colsample_bytree': 0.45829485636213424}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:29,564]\u001b[0m Trial 35 finished with value: 1.2103330130976186 and parameters: {'booster': 'dart', 'lambda': 0.009619132452422, 'alpha': 7.812327724311558e-06, 'subsample': 0.8785257121779418, 'colsample_bytree': 0.31938771838061136, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.0035794334847887976, 'gamma': 0.010076772484426096, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.4266079316156418e-08, 'skip_drop': 2.0548869023629696e-05}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:29,696]\u001b[0m Trial 36 finished with value: 1.06020169423916 and parameters: {'booster': 'gblinear', 'lambda': 0.29829688325901355, 'alpha': 0.0001156078904075171, 'subsample': 0.7834406496612747, 'colsample_bytree': 0.25499845187194436}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:29,802]\u001b[0m Trial 37 finished with value: 1.1439165098426656 and parameters: {'booster': 'gblinear', 'lambda': 0.9811898027845818, 'alpha': 0.15822013240245278, 'subsample': 0.8465959261502778, 'colsample_bytree': 0.5471044964187882}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:29,901]\u001b[0m Trial 38 finished with value: 1.1439165098426656 and parameters: {'booster': 'gblinear', 'lambda': 0.0032454614326903196, 'alpha': 0.9929034492427947, 'subsample': 0.7197864283805312, 'colsample_bytree': 0.5036060432375846}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:31,322]\u001b[0m Trial 39 finished with value: 2.2504361315204466 and parameters: {'booster': 'dart', 'lambda': 0.06097592582805081, 'alpha': 0.001710295884406051, 'subsample': 0.6454163181610958, 'colsample_bytree': 0.7917381056715647, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.8608816287855986, 'gamma': 0.00010049402545777458, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.16535096010041392, 'skip_drop': 0.8119097364108062}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:31,665]\u001b[0m Trial 40 finished with value: 1.3467697265564949 and parameters: {'booster': 'gbtree', 'lambda': 0.014156199088739241, 'alpha': 0.009079760428631858, 'subsample': 0.9057160565676272, 'colsample_bytree': 0.9558618955508091, 'max_depth': 7, 'min_child_weight': 4, 'eta': 1.7639584425855832e-05, 'gamma': 0.009212391420762944, 'grow_policy': 'depthwise'}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:38:31,797]\u001b[0m Trial 41 finished with value: 1.0603230393168883 and parameters: {'booster': 'gblinear', 'lambda': 0.30814362769346243, 'alpha': 0.00011655697918096321, 'subsample': 0.7909985471876564, 'colsample_bytree': 0.24163553448382874}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:31,927]\u001b[0m Trial 42 finished with value: 1.0599178733035932 and parameters: {'booster': 'gblinear', 'lambda': 0.1459391118466274, 'alpha': 0.0008379622920684706, 'subsample': 0.7893633030445355, 'colsample_bytree': 0.2540783943628515}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:32,059]\u001b[0m Trial 43 finished with value: 1.0612217421716565 and parameters: {'booster': 'gblinear', 'lambda': 0.11088426853714727, 'alpha': 0.0008243567606447925, 'subsample': 0.9573000240034973, 'colsample_bytree': 0.3281120997566546}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:32,173]\u001b[0m Trial 44 finished with value: 1.0861203898768386 and parameters: {'booster': 'gblinear', 'lambda': 0.036548484008911496, 'alpha': 0.047005500434628006, 'subsample': 0.8605785447404296, 'colsample_bytree': 0.47972775924030475}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:32,304]\u001b[0m Trial 45 finished with value: 1.1152695758515319 and parameters: {'booster': 'gblinear', 'lambda': 3.7718081290315153e-06, 'alpha': 0.0012979215479853724, 'subsample': 0.7612726217576743, 'colsample_bytree': 0.23453899455725044}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:32,434]\u001b[0m Trial 46 finished with value: 1.0595902040106735 and parameters: {'booster': 'gblinear', 'lambda': 0.21428036466842296, 'alpha': 0.0003378971603495879, 'subsample': 0.45145456842795073, 'colsample_bytree': 0.42312738171900954}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:33,792]\u001b[0m Trial 47 finished with value: 1.3391507281975328 and parameters: {'booster': 'dart', 'lambda': 0.5720227548161665, 'alpha': 0.000292259416542619, 'subsample': 0.42956387800236334, 'colsample_bytree': 0.416017999081681, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.0001648093284857911, 'gamma': 1.392924252513522e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.4863477897191078e-06, 'skip_drop': 5.078789160129125e-06}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:33,906]\u001b[0m Trial 48 finished with value: 1.0875435560455866 and parameters: {'booster': 'gblinear', 'lambda': 0.06865192899897364, 'alpha': 0.04654572818156138, 'subsample': 0.2179808694003411, 'colsample_bytree': 0.2826341772461131}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:34,154]\u001b[0m Trial 49 finished with value: 1.3478135874926904 and parameters: {'booster': 'gbtree', 'lambda': 0.0014468352463246606, 'alpha': 4.660611277853982e-05, 'subsample': 0.47329570126818826, 'colsample_bytree': 0.37757574035289704, 'max_depth': 9, 'min_child_weight': 8, 'eta': 8.136662903063719e-08, 'gamma': 0.0001560709424617955, 'grow_policy': 'depthwise'}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:34,285]\u001b[0m Trial 50 finished with value: 1.0579796706715938 and parameters: {'booster': 'gblinear', 'lambda': 0.2077764309862084, 'alpha': 0.003244852025779028, 'subsample': 0.3248905882601937, 'colsample_bytree': 0.33941381326982173}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:34,415]\u001b[0m Trial 51 finished with value: 1.057909047052899 and parameters: {'booster': 'gblinear', 'lambda': 0.19062931853563977, 'alpha': 0.003015653477492598, 'subsample': 0.2751993813678023, 'colsample_bytree': 0.3405206041232178}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:34,553]\u001b[0m Trial 52 finished with value: 1.063310556188595 and parameters: {'booster': 'gblinear', 'lambda': 0.3444548363003653, 'alpha': 0.008076909421893807, 'subsample': 0.26769744720483474, 'colsample_bytree': 0.33272282353371474}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:34,684]\u001b[0m Trial 53 finished with value: 1.06969279404439 and parameters: {'booster': 'gblinear', 'lambda': 0.02279810192387968, 'alpha': 0.002900606989839127, 'subsample': 0.2849478162352478, 'colsample_bytree': 0.3599480328352097}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:34,814]\u001b[0m Trial 54 finished with value: 1.0612506154893466 and parameters: {'booster': 'gblinear', 'lambda': 0.0605764145642855, 'alpha': 0.002565645194641305, 'subsample': 0.3840627330088442, 'colsample_bytree': 0.39204751851530173}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:34,948]\u001b[0m Trial 55 finished with value: 1.059380121945647 and parameters: {'booster': 'gblinear', 'lambda': 0.20634764284975501, 'alpha': 0.0005084729781449208, 'subsample': 0.31736538296723105, 'colsample_bytree': 0.4219321703461968}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:35,071]\u001b[0m Trial 56 finished with value: 1.0792384611796122 and parameters: {'booster': 'gblinear', 'lambda': 0.5751243332357452, 'alpha': 0.015765161002534143, 'subsample': 0.3124159318211331, 'colsample_bytree': 0.3047442462501576}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:35,203]\u001b[0m Trial 57 finished with value: 1.0628254583697463 and parameters: {'booster': 'gblinear', 'lambda': 0.08871224914797896, 'alpha': 0.0007216285166859453, 'subsample': 0.35648166480538734, 'colsample_bytree': 0.35931497307498816}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:36,565]\u001b[0m Trial 58 finished with value: 1.346999562255175 and parameters: {'booster': 'dart', 'lambda': 0.0002044935775011867, 'alpha': 0.00018313392291488922, 'subsample': 0.27969539193919996, 'colsample_bytree': 0.4667845989471163, 'max_depth': 5, 'min_child_weight': 3, 'eta': 1.483411306531188e-05, 'gamma': 0.08672580408179753, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.011690862002640232, 'skip_drop': 1.4764943120728585e-06}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:36,681]\u001b[0m Trial 59 finished with value: 1.0754661624818442 and parameters: {'booster': 'gblinear', 'lambda': 4.503590090396195e-05, 'alpha': 0.036756319528172765, 'subsample': 0.246090202996821, 'colsample_bytree': 0.5041022129021364}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:36,812]\u001b[0m Trial 60 finished with value: 1.0643675014962672 and parameters: {'booster': 'gblinear', 'lambda': 0.007735492292823334, 'alpha': 0.004586191194538418, 'subsample': 0.32895043026572407, 'colsample_bytree': 0.3432823477566678}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:36,945]\u001b[0m Trial 61 finished with value: 1.0594498139600816 and parameters: {'booster': 'gblinear', 'lambda': 0.18205380859322265, 'alpha': 0.0004554271702118955, 'subsample': 0.20070826936409158, 'colsample_bytree': 0.4256304732047342}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:37,077]\u001b[0m Trial 62 finished with value: 1.064556491698426 and parameters: {'booster': 'gblinear', 'lambda': 0.5138319406891778, 'alpha': 0.0013497677013801963, 'subsample': 0.23647902863404352, 'colsample_bytree': 0.4211713682751972}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:37,209]\u001b[0m Trial 63 finished with value: 1.0594388138647413 and parameters: {'booster': 'gblinear', 'lambda': 0.22138410130696487, 'alpha': 0.0005689430346627013, 'subsample': 0.5460085753558356, 'colsample_bytree': 0.38541767669804494}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:37,340]\u001b[0m Trial 64 finished with value: 1.0749178315852927 and parameters: {'booster': 'gblinear', 'lambda': 0.9451551457134021, 'alpha': 0.0027241362138905583, 'subsample': 0.520105451221767, 'colsample_bytree': 0.38699388468408236}. Best is trial 25 with value: 1.0575791347482655.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:38:37,464]\u001b[0m Trial 65 finished with value: 1.0542600921565153 and parameters: {'booster': 'gblinear', 'lambda': 0.03330128291436794, 'alpha': 0.01035039215174698, 'subsample': 0.5941813845056176, 'colsample_bytree': 0.2837242186073249}. Best is trial 65 with value: 1.0542600921565153.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:37,795]\u001b[0m Trial 66 finished with value: 1.1178858685889743 and parameters: {'booster': 'gbtree', 'lambda': 0.031491354726052835, 'alpha': 0.011663940767630561, 'subsample': 0.5979613707236643, 'colsample_bytree': 0.31046470530971754, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.008711985827244683, 'gamma': 0.9759400606387483, 'grow_policy': 'depthwise'}. Best is trial 65 with value: 1.0542600921565153.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:37,953]\u001b[0m Trial 67 finished with value: 1.0559060993189655 and parameters: {'booster': 'gblinear', 'lambda': 0.08692111815735931, 'alpha': 0.00552613844822717, 'subsample': 0.4151416381904415, 'colsample_bytree': 0.34602088186523505}. Best is trial 65 with value: 1.0542600921565153.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:38,085]\u001b[0m Trial 68 finished with value: 1.0569177646897552 and parameters: {'booster': 'gblinear', 'lambda': 0.08354277724891704, 'alpha': 0.004532365636309776, 'subsample': 0.4066086165445938, 'colsample_bytree': 0.268729751587264}. Best is trial 65 with value: 1.0542600921565153.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:38,194]\u001b[0m Trial 69 finished with value: 1.1094021634876583 and parameters: {'booster': 'gblinear', 'lambda': 0.01981020969041392, 'alpha': 0.08214268255711185, 'subsample': 0.35142582925091037, 'colsample_bytree': 0.21994196715941491}. Best is trial 65 with value: 1.0542600921565153.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:38,322]\u001b[0m Trial 70 finished with value: 1.0553846869610204 and parameters: {'booster': 'gblinear', 'lambda': 0.08785146614999141, 'alpha': 0.005838281794867731, 'subsample': 0.42604290108696047, 'colsample_bytree': 0.2719201074782345}. Best is trial 65 with value: 1.0542600921565153.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:38,440]\u001b[0m Trial 71 finished with value: 1.0705781144822994 and parameters: {'booster': 'gblinear', 'lambda': 0.0750792014708977, 'alpha': 0.02890307725799757, 'subsample': 0.4288991631735719, 'colsample_bytree': 0.2741197496591237}. Best is trial 65 with value: 1.0542600921565153.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:38,569]\u001b[0m Trial 72 finished with value: 1.0549036884171479 and parameters: {'booster': 'gblinear', 'lambda': 0.043243976682985526, 'alpha': 0.006616302778355184, 'subsample': 0.3950321802918365, 'colsample_bytree': 0.26224891012694335}. Best is trial 65 with value: 1.0542600921565153.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:38,697]\u001b[0m Trial 73 finished with value: 1.0541624525044944 and parameters: {'booster': 'gblinear', 'lambda': 0.014062130143149281, 'alpha': 0.007833246981812599, 'subsample': 0.39172276503681197, 'colsample_bytree': 0.25612088212693324}. Best is trial 73 with value: 1.0541624525044944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:38,827]\u001b[0m Trial 74 finished with value: 1.0547092868911034 and parameters: {'booster': 'gblinear', 'lambda': 0.011769618209905302, 'alpha': 0.0074257710114677, 'subsample': 0.3824077088608746, 'colsample_bytree': 0.26559705539715384}. Best is trial 73 with value: 1.0541624525044944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:38,937]\u001b[0m Trial 75 finished with value: 1.1090062238238243 and parameters: {'booster': 'gblinear', 'lambda': 0.004726435478487789, 'alpha': 0.08253204880953063, 'subsample': 0.37713369388596707, 'colsample_bytree': 0.2663337803524612}. Best is trial 73 with value: 1.0541624525044944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:39,066]\u001b[0m Trial 76 finished with value: 1.0541197583048427 and parameters: {'booster': 'gblinear', 'lambda': 0.0018584881304181224, 'alpha': 0.011885208693753748, 'subsample': 0.4182325609318856, 'colsample_bytree': 0.2270970768995183}. Best is trial 76 with value: 1.0541197583048427.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:39,194]\u001b[0m Trial 77 finished with value: 1.0544760253373224 and parameters: {'booster': 'gblinear', 'lambda': 0.0009690301279163241, 'alpha': 0.008202595570165148, 'subsample': 0.42505866761388655, 'colsample_bytree': 0.2051027794856956}. Best is trial 76 with value: 1.0541197583048427.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:40,544]\u001b[0m Trial 78 finished with value: 1.3021164790217548 and parameters: {'booster': 'dart', 'lambda': 0.001928632926347973, 'alpha': 0.006793698543161367, 'subsample': 0.4873110159377436, 'colsample_bytree': 0.22427377630636888, 'max_depth': 3, 'min_child_weight': 9, 'eta': 0.0009463220164746106, 'gamma': 0.0011961747451090378, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.8695831192614222e-06, 'skip_drop': 0.0027367246715537903}. Best is trial 76 with value: 1.0541197583048427.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:40,669]\u001b[0m Trial 79 finished with value: 1.0541798725510723 and parameters: {'booster': 'gblinear', 'lambda': 0.00033598913048028654, 'alpha': 0.012659117803036595, 'subsample': 0.41024378705542874, 'colsample_bytree': 0.20102064450646173}. Best is trial 76 with value: 1.0541197583048427.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:40,796]\u001b[0m Trial 80 finished with value: 1.054175371095063 and parameters: {'booster': 'gblinear', 'lambda': 0.0003880176880281742, 'alpha': 0.011152762315382194, 'subsample': 0.46793962564040115, 'colsample_bytree': 0.2006973912533408}. Best is trial 76 with value: 1.0541197583048427.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:40,920]\u001b[0m Trial 81 finished with value: 1.054282843850953 and parameters: {'booster': 'gblinear', 'lambda': 0.0005866966385794319, 'alpha': 0.01298318233932687, 'subsample': 0.4627000619481534, 'colsample_bytree': 0.2187144659727286}. Best is trial 76 with value: 1.0541197583048427.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:41,045]\u001b[0m Trial 82 finished with value: 1.0541186579582473 and parameters: {'booster': 'gblinear', 'lambda': 0.0004680093294221994, 'alpha': 0.011686004714608879, 'subsample': 0.5126112541559366, 'colsample_bytree': 0.21363593556351304}. Best is trial 82 with value: 1.0541186579582473.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:41,170]\u001b[0m Trial 83 finished with value: 1.05419356858201 and parameters: {'booster': 'gblinear', 'lambda': 0.0003575522137352275, 'alpha': 0.011461485691808191, 'subsample': 0.5156718011135614, 'colsample_bytree': 0.20541902368085257}. Best is trial 82 with value: 1.0541186579582473.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:41,290]\u001b[0m Trial 84 finished with value: 1.0588604420581105 and parameters: {'booster': 'gblinear', 'lambda': 0.0003461244172648919, 'alpha': 0.02252498315937041, 'subsample': 0.5051800085859126, 'colsample_bytree': 0.20813595078733163}. Best is trial 82 with value: 1.0541186579582473.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:41,416]\u001b[0m Trial 85 finished with value: 1.0543948871172124 and parameters: {'booster': 'gblinear', 'lambda': 0.0007383646748210269, 'alpha': 0.01218355651552164, 'subsample': 0.4601361270224677, 'colsample_bytree': 0.20628569248896983}. Best is trial 82 with value: 1.0541186579582473.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:41,649]\u001b[0m Trial 86 finished with value: 1.3476727313704735 and parameters: {'booster': 'gbtree', 'lambda': 6.950157549040755e-05, 'alpha': 0.21963596660834805, 'subsample': 0.4624235569148264, 'colsample_bytree': 0.22898853171578645, 'max_depth': 9, 'min_child_weight': 5, 'eta': 2.695917157061617e-06, 'gamma': 1.329807591498163e-05, 'grow_policy': 'depthwise'}. Best is trial 82 with value: 1.0541186579582473.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:41,775]\u001b[0m Trial 87 finished with value: 1.0538020900942437 and parameters: {'booster': 'gblinear', 'lambda': 0.0005536101445803705, 'alpha': 0.01424671878499705, 'subsample': 0.5401172130275005, 'colsample_bytree': 0.24150722900672206}. Best is trial 87 with value: 1.0538020900942437.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:41,889]\u001b[0m Trial 88 finished with value: 1.0992003479630386 and parameters: {'booster': 'gblinear', 'lambda': 0.00030976491512726636, 'alpha': 0.06703010002154622, 'subsample': 0.5417656045995007, 'colsample_bytree': 0.24226370909034026}. Best is trial 87 with value: 1.0538020900942437.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:42,011]\u001b[0m Trial 89 finished with value: 1.0549483766171444 and parameters: {'booster': 'gblinear', 'lambda': 0.00012154097327094117, 'alpha': 0.016736800150415565, 'subsample': 0.5891664532827581, 'colsample_bytree': 0.2884700809895854}. Best is trial 87 with value: 1.0538020900942437.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:38:42,130]\u001b[0m Trial 90 finished with value: 1.0647348737958935 and parameters: {'booster': 'gblinear', 'lambda': 3.522936755469166e-05, 'alpha': 0.028606919734759484, 'subsample': 0.6338045369416104, 'colsample_bytree': 0.2443886241430644}. Best is trial 87 with value: 1.0538020900942437.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:42,235]\u001b[0m Trial 91 finished with value: 1.130139195884346 and parameters: {'booster': 'gblinear', 'lambda': 0.0006134844529848375, 'alpha': 0.12854191036633725, 'subsample': 0.5207287158903141, 'colsample_bytree': 0.20364839978143648}. Best is trial 87 with value: 1.0538020900942437.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:42,359]\u001b[0m Trial 92 finished with value: 1.054306083269777 and parameters: {'booster': 'gblinear', 'lambda': 0.0006215103399148844, 'alpha': 0.013180353573763216, 'subsample': 0.5659085360332271, 'colsample_bytree': 0.22251044567868927}. Best is trial 87 with value: 1.0538020900942437.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:42,485]\u001b[0m Trial 93 finished with value: 1.0546267107321528 and parameters: {'booster': 'gblinear', 'lambda': 0.0017849318931193112, 'alpha': 0.012089225346313182, 'subsample': 0.5723491894988625, 'colsample_bytree': 0.22581601172039498}. Best is trial 87 with value: 1.0538020900942437.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:42,605]\u001b[0m Trial 94 finished with value: 1.0742224608735802 and parameters: {'booster': 'gblinear', 'lambda': 0.00021072669705131638, 'alpha': 0.035918456287647074, 'subsample': 0.5669276446435088, 'colsample_bytree': 0.24278140637432907}. Best is trial 87 with value: 1.0538020900942437.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:42,717]\u001b[0m Trial 95 finished with value: 1.096137199783222 and parameters: {'booster': 'gblinear', 'lambda': 0.0004201367839402266, 'alpha': 0.06361355019598045, 'subsample': 0.4856405417852713, 'colsample_bytree': 0.298636784489871}. Best is trial 87 with value: 1.0538020900942437.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:42,839]\u001b[0m Trial 96 finished with value: 1.0557615562223055 and parameters: {'booster': 'gblinear', 'lambda': 8.314690072826821e-05, 'alpha': 0.01888948684943328, 'subsample': 0.4426927005061098, 'colsample_bytree': 0.22308704510897115}. Best is trial 87 with value: 1.0538020900942437.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:44,255]\u001b[0m Trial 97 finished with value: 1.3441388878561655 and parameters: {'booster': 'dart', 'lambda': 2.318507581382048e-05, 'alpha': 0.12542378243569677, 'subsample': 0.6323635313119444, 'colsample_bytree': 0.2486066546199578, 'max_depth': 7, 'min_child_weight': 7, 'eta': 7.078958618882308e-05, 'gamma': 0.0006517871356220889, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.012343246597726492, 'skip_drop': 0.0004122259433616909}. Best is trial 87 with value: 1.0538020900942437.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:44,355]\u001b[0m Trial 98 finished with value: 1.1439165098426656 and parameters: {'booster': 'gblinear', 'lambda': 0.0011670074826686924, 'alpha': 0.35102537802886546, 'subsample': 0.5218678772795426, 'colsample_bytree': 0.29034040491971935}. Best is trial 87 with value: 1.0538020900942437.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:44,480]\u001b[0m Trial 99 finished with value: 1.0539679166726532 and parameters: {'booster': 'gblinear', 'lambda': 0.00020043713289561458, 'alpha': 0.010192500065213841, 'subsample': 0.4981961127717354, 'colsample_bytree': 0.25449280702406507}. Best is trial 87 with value: 1.0538020900942437.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:44,630]\u001b[0m A new study created in memory with name: no-name-3bdd6e9f-3a5d-4c0c-acb5-083060174d56\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:44,751]\u001b[0m Trial 0 finished with value: 0.9917883486376637 and parameters: {'booster': 'gbtree', 'lambda': 0.007421268867580757, 'alpha': 2.6258374572794296e-06, 'subsample': 0.43312537632256004, 'colsample_bytree': 0.49182023452149704, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.3817337312012955, 'gamma': 0.02508179267593231, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:44,876]\u001b[0m Trial 1 finished with value: 0.9917883486376637 and parameters: {'booster': 'gbtree', 'lambda': 2.986174620931758e-07, 'alpha': 2.644729998698818e-05, 'subsample': 0.23462804190824338, 'colsample_bytree': 0.5035502184338606, 'max_depth': 7, 'min_child_weight': 6, 'eta': 3.740021700803348e-08, 'gamma': 0.00019675349113895996, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:45,020]\u001b[0m Trial 2 finished with value: 0.9917883486376637 and parameters: {'booster': 'gbtree', 'lambda': 0.00041616888374405923, 'alpha': 1.530933339676149e-05, 'subsample': 0.40974143218515285, 'colsample_bytree': 0.7168016284613692, 'max_depth': 5, 'min_child_weight': 2, 'eta': 0.001145589900152939, 'gamma': 0.00024226372393427317, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:45,171]\u001b[0m Trial 3 finished with value: 0.9917883486376637 and parameters: {'booster': 'gbtree', 'lambda': 1.3321172438626856e-08, 'alpha': 6.118514315952138e-05, 'subsample': 0.7979397189120696, 'colsample_bytree': 0.46412027107698384, 'max_depth': 7, 'min_child_weight': 5, 'eta': 0.0012595670064108006, 'gamma': 9.873189075244412e-05, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:45,303]\u001b[0m Trial 4 finished with value: 0.9917883486376637 and parameters: {'booster': 'gbtree', 'lambda': 0.07384755974248984, 'alpha': 7.122024299119776e-06, 'subsample': 0.5993178055460177, 'colsample_bytree': 0.32663602375055883, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.0033173263926912257, 'gamma': 0.5862861268532429, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:45,829]\u001b[0m Trial 5 finished with value: 0.9917883486376637 and parameters: {'booster': 'dart', 'lambda': 4.3436648506289546e-08, 'alpha': 1.617467391951859e-07, 'subsample': 0.7365158234561906, 'colsample_bytree': 0.8685095680405792, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.08584189659538777, 'gamma': 0.35205616500928855, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.752756463288657, 'skip_drop': 7.083481876279577e-06}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:45,946]\u001b[0m Trial 6 finished with value: 0.9904166117088428 and parameters: {'booster': 'gblinear', 'lambda': 7.187118447547771e-07, 'alpha': 2.9033677511841695e-05, 'subsample': 0.36400067705037453, 'colsample_bytree': 0.7607795214218998}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:46,063]\u001b[0m Trial 7 finished with value: 0.9917883486376637 and parameters: {'booster': 'gblinear', 'lambda': 0.024946620184993978, 'alpha': 5.218109727605495e-07, 'subsample': 0.217297523334263, 'colsample_bytree': 0.3890344567148132}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:47,395]\u001b[0m Trial 8 finished with value: 0.9917883486376637 and parameters: {'booster': 'dart', 'lambda': 1.7873544217791573e-07, 'alpha': 4.6319495196412664e-07, 'subsample': 0.4645713504587162, 'colsample_bytree': 0.8324413734726783, 'max_depth': 7, 'min_child_weight': 7, 'eta': 1.1880610318834727e-07, 'gamma': 3.8806178347818364e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.002355571653591921, 'skip_drop': 3.9033837547239674e-06}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:48,733]\u001b[0m Trial 9 finished with value: 0.9917883486376637 and parameters: {'booster': 'dart', 'lambda': 0.005820323258490825, 'alpha': 0.0005614710487189546, 'subsample': 0.4831468086404506, 'colsample_bytree': 0.9647841263618429, 'max_depth': 3, 'min_child_weight': 9, 'eta': 1.527483027335799e-06, 'gamma': 0.0016136098363901262, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 2.575845934972232e-07, 'skip_drop': 3.914701659723168e-06}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:48,878]\u001b[0m Trial 10 finished with value: 0.9917883486376637 and parameters: {'booster': 'gbtree', 'lambda': 2.46613775665595e-05, 'alpha': 0.16835003100122684, 'subsample': 0.9188679481439161, 'colsample_bytree': 0.21743103333469999, 'max_depth': 3, 'min_child_weight': 10, 'eta': 0.635748980049857, 'gamma': 0.016536597293054057, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:38:49,038]\u001b[0m Trial 11 finished with value: 0.9917883486376637 and parameters: {'booster': 'gbtree', 'lambda': 1.033674037815852e-05, 'alpha': 0.002555874088180004, 'subsample': 0.23296403777724087, 'colsample_bytree': 0.5429460204808138, 'max_depth': 9, 'min_child_weight': 8, 'eta': 8.614081688485985e-06, 'gamma': 3.320617655500998e-06, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:49,193]\u001b[0m Trial 12 finished with value: 0.9917883486376637 and parameters: {'booster': 'gbtree', 'lambda': 0.7891739079002904, 'alpha': 1.142498510327393e-08, 'subsample': 0.31395397192675933, 'colsample_bytree': 0.6196649741744482, 'max_depth': 9, 'min_child_weight': 7, 'eta': 4.840409951511183e-08, 'gamma': 7.53059713894201e-06, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:49,372]\u001b[0m Trial 13 finished with value: 0.9917883486376637 and parameters: {'booster': 'gbtree', 'lambda': 0.0006350867786260044, 'alpha': 0.0029787530463502563, 'subsample': 0.5890444639446409, 'colsample_bytree': 0.5812685804190695, 'max_depth': 7, 'min_child_weight': 4, 'eta': 9.76859810700843e-06, 'gamma': 0.011653001919802343, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:49,537]\u001b[0m Trial 14 finished with value: 0.9917883486376637 and parameters: {'booster': 'gbtree', 'lambda': 1.5285205428859914e-06, 'alpha': 1.8006872209311427e-06, 'subsample': 0.3002309175694952, 'colsample_bytree': 0.4474461113769651, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.03866323398992104, 'gamma': 0.020823104823137425, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:49,669]\u001b[0m Trial 15 finished with value: 0.9917883486376637 and parameters: {'booster': 'gblinear', 'lambda': 0.0020071501554191455, 'alpha': 2.0839376908933754e-08, 'subsample': 0.5221128134622033, 'colsample_bytree': 0.2863194744506442}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:49,824]\u001b[0m Trial 16 finished with value: 0.9917883486376637 and parameters: {'booster': 'gbtree', 'lambda': 7.688625145668332e-05, 'alpha': 0.0002442569923083207, 'subsample': 0.20222489748895436, 'colsample_bytree': 0.6549726572513415, 'max_depth': 7, 'min_child_weight': 8, 'eta': 9.691912669044423e-05, 'gamma': 6.9333877687304e-06, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:49,988]\u001b[0m Trial 17 finished with value: 0.9917883486376637 and parameters: {'booster': 'gbtree', 'lambda': 1.160723472072378e-05, 'alpha': 4.900042547117732e-06, 'subsample': 0.3552920556098186, 'colsample_bytree': 0.450309011510838, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.04870049335578244, 'gamma': 0.036118191493700616, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:50,122]\u001b[0m Trial 18 finished with value: 0.9917883486376637 and parameters: {'booster': 'gblinear', 'lambda': 0.0020262427615872765, 'alpha': 1.4626182477934453e-08, 'subsample': 0.530908504658431, 'colsample_bytree': 0.2024643283223752}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:51,458]\u001b[0m Trial 19 finished with value: 0.9917883486376637 and parameters: {'booster': 'dart', 'lambda': 0.16625055387058557, 'alpha': 0.02686764211023003, 'subsample': 0.7052694628042001, 'colsample_bytree': 0.6387246309917481, 'max_depth': 9, 'min_child_weight': 8, 'eta': 5.325410969021955e-05, 'gamma': 2.9455534934574945e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.0898274013741922e-08, 'skip_drop': 0.7741793718637472}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:51,605]\u001b[0m Trial 20 finished with value: 0.9917883486376637 and parameters: {'booster': 'gbtree', 'lambda': 5.5885467925143085e-06, 'alpha': 3.2607935607166578e-06, 'subsample': 0.4118607025788379, 'colsample_bytree': 0.38664396684991276, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.7652741046985001, 'gamma': 0.07626332999073121, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:51,739]\u001b[0m Trial 21 finished with value: 0.9917883486376637 and parameters: {'booster': 'gblinear', 'lambda': 0.011434172965043102, 'alpha': 5.35521650501992e-08, 'subsample': 0.5415306045756814, 'colsample_bytree': 0.20709037645082035}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:53,086]\u001b[0m Trial 22 finished with value: 0.9917883486376637 and parameters: {'booster': 'dart', 'lambda': 0.27040845908889793, 'alpha': 0.18743136815980124, 'subsample': 0.6844274988209738, 'colsample_bytree': 0.6950219372900324, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.00012487317915886372, 'gamma': 1.886757876662766e-08, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.7350125129561766e-08, 'skip_drop': 0.9785127344773374}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:54,442]\u001b[0m Trial 23 finished with value: 0.9917883486376637 and parameters: {'booster': 'dart', 'lambda': 0.07929536604414794, 'alpha': 0.7852018559777304, 'subsample': 0.8583618663606652, 'colsample_bytree': 0.36801528742973677, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.44150412759672264, 'gamma': 4.43980870924763e-07, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 5.992588740539414e-06, 'skip_drop': 0.3406784580246255}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:54,578]\u001b[0m Trial 24 finished with value: 0.9917883486376637 and parameters: {'booster': 'gblinear', 'lambda': 0.01008751604404795, 'alpha': 1.6636379105068497e-07, 'subsample': 0.44578282308139794, 'colsample_bytree': 0.2818289171045267}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:55,952]\u001b[0m Trial 25 finished with value: 0.9917883486376637 and parameters: {'booster': 'dart', 'lambda': 0.16009165665939576, 'alpha': 5.1430280179003375e-08, 'subsample': 0.6744732702708927, 'colsample_bytree': 0.6907489827442019, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.004515924847808581, 'gamma': 3.988787139628885e-08, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.00028488104511012257, 'skip_drop': 0.00564492720234484}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:57,322]\u001b[0m Trial 26 finished with value: 0.9917883486376637 and parameters: {'booster': 'dart', 'lambda': 0.9194817566660576, 'alpha': 0.7919173999957543, 'subsample': 0.9812144032623106, 'colsample_bytree': 0.5596502077419774, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.20979003473818533, 'gamma': 1.1473771307419655e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.7875448860150548e-06, 'skip_drop': 0.7236250718584366}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:57,458]\u001b[0m Trial 27 finished with value: 0.9917883486376637 and parameters: {'booster': 'gblinear', 'lambda': 0.03218284314498708, 'alpha': 6.657599807670986e-07, 'subsample': 0.8417465687996181, 'colsample_bytree': 0.301340155543139}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:57,594]\u001b[0m Trial 28 finished with value: 0.9917883486376637 and parameters: {'booster': 'gblinear', 'lambda': 0.004339848258189893, 'alpha': 8.231893081726323e-08, 'subsample': 0.6463053517742767, 'colsample_bytree': 0.7969007879043926}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:58,993]\u001b[0m Trial 29 finished with value: 0.9917883486376637 and parameters: {'booster': 'dart', 'lambda': 0.7615124233855448, 'alpha': 0.009027296584052099, 'subsample': 0.9649100974467292, 'colsample_bytree': 0.5306058578631205, 'max_depth': 5, 'min_child_weight': 3, 'eta': 0.008334986788932245, 'gamma': 1.0617087346155479e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.0002626479404536418, 'skip_drop': 0.0014114437620919343}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:38:59,131]\u001b[0m Trial 30 finished with value: 0.9917883486376637 and parameters: {'booster': 'gblinear', 'lambda': 0.05627837338815114, 'alpha': 8.333238773281942e-07, 'subsample': 0.988476914576248, 'colsample_bytree': 0.48862328373891306}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:59,269]\u001b[0m Trial 31 finished with value: 0.9904166117088428 and parameters: {'booster': 'gblinear', 'lambda': 0.0003686828378535039, 'alpha': 1.1699858133062145e-07, 'subsample': 0.8778336182064123, 'colsample_bytree': 0.9828229880037569}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:59,408]\u001b[0m Trial 32 finished with value: 0.9917883486376637 and parameters: {'booster': 'gblinear', 'lambda': 0.020694332424890955, 'alpha': 1.7245983274055752e-05, 'subsample': 0.7958073395386895, 'colsample_bytree': 0.5239198165310253}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:59,543]\u001b[0m Trial 33 finished with value: 0.9917883486376637 and parameters: {'booster': 'gblinear', 'lambda': 0.004050611981536142, 'alpha': 9.13937953579912e-05, 'subsample': 0.9846906581974807, 'colsample_bytree': 0.5015775313040267}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:59,691]\u001b[0m Trial 34 finished with value: 0.9904166117088428 and parameters: {'booster': 'gblinear', 'lambda': 0.0007014442337125337, 'alpha': 1.2575404316266575e-06, 'subsample': 0.9337633713495792, 'colsample_bytree': 0.48504782255961193}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:38:59,863]\u001b[0m Trial 35 finished with value: 0.9917883486376637 and parameters: {'booster': 'gblinear', 'lambda': 0.034515594478791586, 'alpha': 1.5153363794926455e-05, 'subsample': 0.7773708482492774, 'colsample_bytree': 0.5390250995938737}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:00,030]\u001b[0m Trial 36 finished with value: 0.9904166117088428 and parameters: {'booster': 'gblinear', 'lambda': 0.00013144990741226532, 'alpha': 7.895947931876345e-05, 'subsample': 0.8017784991549172, 'colsample_bytree': 0.4676758578646973}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:00,200]\u001b[0m Trial 37 finished with value: 0.9917883486376637 and parameters: {'booster': 'gbtree', 'lambda': 3.488326253243852e-06, 'alpha': 4.174355388789205e-06, 'subsample': 0.41593699402952977, 'colsample_bytree': 0.39200333563364154, 'max_depth': 3, 'min_child_weight': 8, 'eta': 0.0003655604192259282, 'gamma': 0.122950186632984, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:00,364]\u001b[0m Trial 38 finished with value: 0.9917883486376637 and parameters: {'booster': 'gbtree', 'lambda': 0.2689872528290165, 'alpha': 2.7578628512393558e-06, 'subsample': 0.5568506559946952, 'colsample_bytree': 0.7294009650865798, 'max_depth': 3, 'min_child_weight': 9, 'eta': 0.9328287509416947, 'gamma': 0.0011615007144941821, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:00,539]\u001b[0m Trial 39 finished with value: 0.9917883486376637 and parameters: {'booster': 'gbtree', 'lambda': 6.963462171323421e-08, 'alpha': 0.00035469873655993465, 'subsample': 0.621058543332637, 'colsample_bytree': 0.4143668047704771, 'max_depth': 5, 'min_child_weight': 5, 'eta': 3.479428926772861e-07, 'gamma': 0.00270471162982795, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:01,933]\u001b[0m Trial 40 finished with value: 0.9917883486376637 and parameters: {'booster': 'dart', 'lambda': 0.00012734432234593919, 'alpha': 2.4329245541107643e-07, 'subsample': 0.3803876226987993, 'colsample_bytree': 0.3434648807630605, 'max_depth': 3, 'min_child_weight': 9, 'eta': 0.01635144336424805, 'gamma': 0.9900053845866779, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 1.1707065958455942e-08, 'skip_drop': 3.168896146298909e-08}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:03,302]\u001b[0m Trial 41 finished with value: 0.9917883486376637 and parameters: {'booster': 'dart', 'lambda': 0.011617081683285941, 'alpha': 0.6530588428866272, 'subsample': 0.47699616021464064, 'colsample_bytree': 0.26816179484796016, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.11643863727914178, 'gamma': 6.815172962476394e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 2.3072980534332183e-06, 'skip_drop': 0.026520052531458078}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:04,682]\u001b[0m Trial 42 finished with value: 0.9917883486376637 and parameters: {'booster': 'dart', 'lambda': 0.011425649436132604, 'alpha': 0.11910258100226111, 'subsample': 0.44437157841719344, 'colsample_bytree': 0.24680911621469556, 'max_depth': 9, 'min_child_weight': 10, 'eta': 1.1059988274120196e-08, 'gamma': 1.9465156915312245e-07, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.3329569434789956e-05, 'skip_drop': 0.06541881584931072}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:06,049]\u001b[0m Trial 43 finished with value: 0.9917883486376637 and parameters: {'booster': 'dart', 'lambda': 0.14915957646763794, 'alpha': 0.21284689264160336, 'subsample': 0.6776256238647741, 'colsample_bytree': 0.7009712472754509, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.00035870898056059654, 'gamma': 1.1077480198400956e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.001969622934313817, 'skip_drop': 0.0066303935796919195}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:07,457]\u001b[0m Trial 44 finished with value: 0.9917883486376637 and parameters: {'booster': 'dart', 'lambda': 0.10019495118224772, 'alpha': 2.728157542438104e-07, 'subsample': 0.7510975028553873, 'colsample_bytree': 0.894045097601964, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.008652650769587591, 'gamma': 3.372565049370805e-08, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.00013635463171634632, 'skip_drop': 0.0008788480645487392}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:08,825]\u001b[0m Trial 45 finished with value: 0.9917883486376637 and parameters: {'booster': 'dart', 'lambda': 0.47280539643787683, 'alpha': 0.49918306524423767, 'subsample': 0.8734684187338627, 'colsample_bytree': 0.32483205850835023, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.22885224282730116, 'gamma': 7.530020154714963e-07, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 3.681661655233811e-06, 'skip_drop': 0.1770921771172027}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:10,189]\u001b[0m Trial 46 finished with value: 0.9917883486376637 and parameters: {'booster': 'dart', 'lambda': 0.06551558100106061, 'alpha': 0.04841686929289282, 'subsample': 0.27812998602518335, 'colsample_bytree': 0.5895553742977707, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.1931215000430982, 'gamma': 8.596970416440538e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 3.9249629812299365e-07, 'skip_drop': 0.014670488402289279}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:10,327]\u001b[0m Trial 47 finished with value: 0.9917883486376637 and parameters: {'booster': 'gblinear', 'lambda': 0.31053655696783017, 'alpha': 3.154590432654428e-08, 'subsample': 0.8201398819341857, 'colsample_bytree': 0.31767026070437965}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:11,380]\u001b[0m Trial 48 finished with value: 0.9917883486376637 and parameters: {'booster': 'dart', 'lambda': 0.035116263687933344, 'alpha': 5.267247957319226e-07, 'subsample': 0.9138719312749168, 'colsample_bytree': 0.7452626208515594, 'max_depth': 7, 'min_child_weight': 5, 'eta': 0.002330057854897837, 'gamma': 8.27968865227673e-05, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.31443913612735686, 'skip_drop': 0.00011050875456848276}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:39:11,518]\u001b[0m Trial 49 finished with value: 0.9917883486376637 and parameters: {'booster': 'gblinear', 'lambda': 0.9721048201536676, 'alpha': 4.998247433552436e-08, 'subsample': 0.6422685703047746, 'colsample_bytree': 0.7924578151087089}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:12,903]\u001b[0m Trial 50 finished with value: 0.9917883486376637 and parameters: {'booster': 'dart', 'lambda': 0.0020393873485550474, 'alpha': 1.0380212832825583e-07, 'subsample': 0.8360959763695122, 'colsample_bytree': 0.8016860224210964, 'max_depth': 5, 'min_child_weight': 5, 'eta': 0.028534314697686566, 'gamma': 3.257619540444611e-05, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.02665137326887132, 'skip_drop': 0.0010665205034753188}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:13,034]\u001b[0m Trial 51 finished with value: 0.9917883486376637 and parameters: {'booster': 'gblinear', 'lambda': 0.053127522633128255, 'alpha': 0.005434581245069659, 'subsample': 0.9873172522768093, 'colsample_bytree': 0.5742060834188742}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:13,178]\u001b[0m Trial 52 finished with value: 0.9917883486376637 and parameters: {'booster': 'gblinear', 'lambda': 0.5755742874565669, 'alpha': 1.000809232422746e-06, 'subsample': 0.954503329379859, 'colsample_bytree': 0.5639269456768632}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:13,321]\u001b[0m Trial 53 finished with value: 0.9917883486376637 and parameters: {'booster': 'gblinear', 'lambda': 0.028907716494719068, 'alpha': 1.407174077911603e-05, 'subsample': 0.9016369971653441, 'colsample_bytree': 0.5243045509210545}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:13,464]\u001b[0m Trial 54 finished with value: 0.9917883486376637 and parameters: {'booster': 'gblinear', 'lambda': 0.004586400712184067, 'alpha': 8.576412456594491e-07, 'subsample': 0.9481787536492066, 'colsample_bytree': 0.4327108872371421}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:13,606]\u001b[0m Trial 55 finished with value: 0.9917883486376637 and parameters: {'booster': 'gblinear', 'lambda': 0.0037336475295391574, 'alpha': 2.5660284271622868e-05, 'subsample': 0.9956213059555886, 'colsample_bytree': 0.5015315155556928}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:13,746]\u001b[0m Trial 56 finished with value: 0.9917883486376637 and parameters: {'booster': 'gblinear', 'lambda': 0.0013694811308033298, 'alpha': 0.0008271387570140724, 'subsample': 0.9529046065311116, 'colsample_bytree': 0.5037294426222512}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:13,889]\u001b[0m Trial 57 finished with value: 0.9917883486376637 and parameters: {'booster': 'gblinear', 'lambda': 0.017331875642800813, 'alpha': 1.0205083994034582e-05, 'subsample': 0.7490419420691209, 'colsample_bytree': 0.5355585394779568}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:14,031]\u001b[0m Trial 58 finished with value: 0.9917883486376637 and parameters: {'booster': 'gblinear', 'lambda': 0.04952835430314068, 'alpha': 5.21482346259342e-05, 'subsample': 0.8971240440730138, 'colsample_bytree': 0.6117455920637352}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:14,220]\u001b[0m Trial 59 finished with value: 0.9917883486376637 and parameters: {'booster': 'gbtree', 'lambda': 1.0971532543641737e-08, 'alpha': 5.307161010704083e-06, 'subsample': 0.780322265335361, 'colsample_bytree': 0.41414559101059545, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.0005341072581963882, 'gamma': 0.2103674722095073, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:14,408]\u001b[0m Trial 60 finished with value: 0.9917883486376637 and parameters: {'booster': 'gbtree', 'lambda': 1.5487516874826759e-06, 'alpha': 0.0001341510505607334, 'subsample': 0.5062647962431569, 'colsample_bytree': 0.6531665083630271, 'max_depth': 3, 'min_child_weight': 7, 'eta': 1.0305009600567622e-05, 'gamma': 0.0004284150930562174, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:14,590]\u001b[0m Trial 61 finished with value: 0.9917883486376637 and parameters: {'booster': 'gbtree', 'lambda': 3.7080764787858654e-08, 'alpha': 2.793139832080704e-06, 'subsample': 0.5767780692091786, 'colsample_bytree': 0.4127932093636868, 'max_depth': 3, 'min_child_weight': 8, 'eta': 7.658270711595806e-07, 'gamma': 0.002397063348320729, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:14,768]\u001b[0m Trial 62 finished with value: 0.9917883486376637 and parameters: {'booster': 'gbtree', 'lambda': 2.2300852768610832e-07, 'alpha': 3.0344681533301534e-05, 'subsample': 0.5544137169057073, 'colsample_bytree': 0.3756407788428344, 'max_depth': 3, 'min_child_weight': 9, 'eta': 3.431370153272539e-07, 'gamma': 0.003097725994658702, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:14,950]\u001b[0m Trial 63 finished with value: 0.9917883486376637 and parameters: {'booster': 'gbtree', 'lambda': 4.928244445678165e-07, 'alpha': 0.00034871666850483835, 'subsample': 0.6249265895660876, 'colsample_bytree': 0.46316055398667333, 'max_depth': 5, 'min_child_weight': 6, 'eta': 3.3479515433202687e-06, 'gamma': 0.0004842148008694203, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:15,124]\u001b[0m Trial 64 finished with value: 0.9917883486376637 and parameters: {'booster': 'gbtree', 'lambda': 3.946275256063647e-05, 'alpha': 2.3688067300537626e-06, 'subsample': 0.353831618006327, 'colsample_bytree': 0.407754464437848, 'max_depth': 3, 'min_child_weight': 9, 'eta': 0.022579294803192457, 'gamma': 0.8603633209377963, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:15,288]\u001b[0m Trial 65 finished with value: 0.9917883486376637 and parameters: {'booster': 'gbtree', 'lambda': 5.8335019522543395e-08, 'alpha': 8.468053412712518e-06, 'subsample': 0.39704744855028196, 'colsample_bytree': 0.34367957190557075, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.10201009362777153, 'gamma': 0.1331994054448635, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:15,457]\u001b[0m Trial 66 finished with value: 0.9917883486376637 and parameters: {'booster': 'gbtree', 'lambda': 3.526321643450259e-06, 'alpha': 3.373539933939256e-07, 'subsample': 0.4918034859747127, 'colsample_bytree': 0.35875702153150074, 'max_depth': 3, 'min_child_weight': 8, 'eta': 0.0949685522545774, 'gamma': 0.005333132006603188, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:15,613]\u001b[0m Trial 67 finished with value: 0.9917883486376637 and parameters: {'booster': 'gbtree', 'lambda': 1.100507409551911e-07, 'alpha': 3.6075613596411808e-06, 'subsample': 0.3888225396800923, 'colsample_bytree': 0.27024822372711005, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.9434309599840008, 'gamma': 0.06791394125432254, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:15,775]\u001b[0m Trial 68 finished with value: 0.9917883486376637 and parameters: {'booster': 'gbtree', 'lambda': 0.000144180549543302, 'alpha': 0.04415948755670001, 'subsample': 0.44952643962784583, 'colsample_bytree': 0.24356167968775105, 'max_depth': 5, 'min_child_weight': 9, 'eta': 1.2063420741969924e-07, 'gamma': 0.0012157313556062821, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:17,284]\u001b[0m Trial 69 finished with value: 0.9917883486376637 and parameters: {'booster': 'dart', 'lambda': 0.00025145844853583887, 'alpha': 0.40376697307134174, 'subsample': 0.45810981975625975, 'colsample_bytree': 0.24851961150422552, 'max_depth': 3, 'min_child_weight': 8, 'eta': 3.956068013895416e-08, 'gamma': 0.36600004748339715, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 2.9514672621354958e-05, 'skip_drop': 1.1237227433980488e-07}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:39:17,474]\u001b[0m Trial 70 finished with value: 0.9917883486376637 and parameters: {'booster': 'gbtree', 'lambda': 0.008098380871370133, 'alpha': 0.0012330862153747972, 'subsample': 0.42748526964010236, 'colsample_bytree': 0.22905544896996452, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.32569499472194197, 'gamma': 0.9113842808659681, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:18,903]\u001b[0m Trial 71 finished with value: 0.9917883486376637 and parameters: {'booster': 'dart', 'lambda': 0.11235805800809136, 'alpha': 0.13597750001501166, 'subsample': 0.7132043172478452, 'colsample_bytree': 0.8985186218126162, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.012456802705617618, 'gamma': 1.4199050534875848e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.0011929069181793692, 'skip_drop': 0.025779403712684324}. Best is trial 0 with value: 0.9917883486376637.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:39:19,259]\u001b[0m A new study created in memory with name: no-name-33bb4b99-aff5-455c-9855-a6cd7a5c6bb3\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:19,427]\u001b[0m Trial 0 finished with value: 1.2563708014327128 and parameters: {'booster': 'gbtree', 'lambda': 9.12083068178989e-05, 'alpha': 4.4770344681327766e-08, 'subsample': 0.9651642130321358, 'colsample_bytree': 0.4907647927342801, 'max_depth': 3, 'min_child_weight': 2, 'eta': 1.0234092848687636e-07, 'gamma': 0.0004136726344927262, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 1.2563708014327128.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:19,553]\u001b[0m Trial 1 finished with value: 0.24362814418754136 and parameters: {'booster': 'gblinear', 'lambda': 4.508163042356536e-07, 'alpha': 1.6972916362867073e-05, 'subsample': 0.21089113561701034, 'colsample_bytree': 0.2631457731910331}. Best is trial 1 with value: 0.24362814418754136.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:19,747]\u001b[0m Trial 2 finished with value: 0.24645624014643952 and parameters: {'booster': 'gbtree', 'lambda': 1.6748504805941993e-08, 'alpha': 3.077503987487575e-08, 'subsample': 0.7739756146933883, 'colsample_bytree': 0.8445536961456275, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.02149628544859726, 'gamma': 5.1929530822174916e-05, 'grow_policy': 'depthwise'}. Best is trial 1 with value: 0.24362814418754136.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:19,869]\u001b[0m Trial 3 finished with value: 0.22507714599924522 and parameters: {'booster': 'gblinear', 'lambda': 0.0011764053146885286, 'alpha': 0.00164584939789488, 'subsample': 0.29798125975357126, 'colsample_bytree': 0.9774632099356106}. Best is trial 3 with value: 0.22507714599924522.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:21,408]\u001b[0m Trial 4 finished with value: 1.2484985574865057 and parameters: {'booster': 'dart', 'lambda': 0.21014509004845586, 'alpha': 2.161743806290023e-06, 'subsample': 0.3532184078795658, 'colsample_bytree': 0.7137117364312164, 'max_depth': 7, 'min_child_weight': 5, 'eta': 4.052197016046352e-05, 'gamma': 0.8722887932110693, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.0031633102604167462, 'skip_drop': 0.6269019790543947}. Best is trial 3 with value: 0.22507714599924522.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:21,648]\u001b[0m Trial 5 finished with value: 1.242182782651902 and parameters: {'booster': 'gbtree', 'lambda': 0.21071028176564793, 'alpha': 1.7338572603906063e-08, 'subsample': 0.9569888567008624, 'colsample_bytree': 0.539191320316895, 'max_depth': 5, 'min_child_weight': 4, 'eta': 7.369429241600457e-05, 'gamma': 3.8169780683964e-08, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 0.22507714599924522.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:22,719]\u001b[0m Trial 6 finished with value: 1.2563131247561923 and parameters: {'booster': 'dart', 'lambda': 0.4578746414601856, 'alpha': 5.144979073258126e-05, 'subsample': 0.26935898549759796, 'colsample_bytree': 0.3224023665025361, 'max_depth': 5, 'min_child_weight': 6, 'eta': 4.7234856628797474e-07, 'gamma': 3.489676872444094e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.33186813404096965, 'skip_drop': 0.10058352060557627}. Best is trial 3 with value: 0.22507714599924522.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:22,884]\u001b[0m Trial 7 finished with value: 1.256367686123986 and parameters: {'booster': 'gbtree', 'lambda': 3.2257488676738316e-08, 'alpha': 3.705569966379058e-08, 'subsample': 0.7466271758078329, 'colsample_bytree': 0.4035233101397928, 'max_depth': 3, 'min_child_weight': 10, 'eta': 1.2647853373249022e-07, 'gamma': 0.054314223113093786, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 0.22507714599924522.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:24,292]\u001b[0m Trial 8 finished with value: 1.2306488260890662 and parameters: {'booster': 'dart', 'lambda': 0.001021299518985618, 'alpha': 0.3194878456240065, 'subsample': 0.25142125511578, 'colsample_bytree': 0.8870102792428318, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.00013931059411404064, 'gamma': 0.2643123514404702, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 2.5239231941340697e-07, 'skip_drop': 1.8497406352191077e-07}. Best is trial 3 with value: 0.22507714599924522.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:25,649]\u001b[0m Trial 9 finished with value: 0.23590877921354336 and parameters: {'booster': 'dart', 'lambda': 1.9298146629556284e-08, 'alpha': 0.04096998706867974, 'subsample': 0.625641548625494, 'colsample_bytree': 0.639520676257837, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.33707205138406876, 'gamma': 2.5081947311043947e-06, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.009883403048338553, 'skip_drop': 4.7678930011624386e-08}. Best is trial 3 with value: 0.22507714599924522.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:25,782]\u001b[0m Trial 10 finished with value: 0.22464844794998037 and parameters: {'booster': 'gblinear', 'lambda': 0.0012118691918298556, 'alpha': 0.004293931436094741, 'subsample': 0.41860874861898784, 'colsample_bytree': 0.9875724776104712}. Best is trial 10 with value: 0.22464844794998037.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:25,914]\u001b[0m Trial 11 finished with value: 0.22385665659068288 and parameters: {'booster': 'gblinear', 'lambda': 0.0007957199604264025, 'alpha': 0.007182361947599346, 'subsample': 0.4046072190419665, 'colsample_bytree': 0.9941876429309472}. Best is trial 11 with value: 0.22385665659068288.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:26,047]\u001b[0m Trial 12 finished with value: 0.22491611820918245 and parameters: {'booster': 'gblinear', 'lambda': 6.69303534753331e-05, 'alpha': 0.0023986227793351576, 'subsample': 0.44926080404482416, 'colsample_bytree': 0.9801296048668697}. Best is trial 11 with value: 0.22385665659068288.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:26,180]\u001b[0m Trial 13 finished with value: 0.2240193084866901 and parameters: {'booster': 'gblinear', 'lambda': 0.004249219549211977, 'alpha': 0.0018634994524239226, 'subsample': 0.46457234333702513, 'colsample_bytree': 0.7806219211240115}. Best is trial 11 with value: 0.22385665659068288.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:26,318]\u001b[0m Trial 14 finished with value: 0.22090994290701013 and parameters: {'booster': 'gblinear', 'lambda': 0.009398919719588712, 'alpha': 0.03260436310656601, 'subsample': 0.5131216389959834, 'colsample_bytree': 0.7696466182253487}. Best is trial 14 with value: 0.22090994290701013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:26,445]\u001b[0m Trial 15 finished with value: 0.7058906822296437 and parameters: {'booster': 'gblinear', 'lambda': 0.015829529356227286, 'alpha': 0.6939010597518044, 'subsample': 0.630517838531406, 'colsample_bytree': 0.7008064694883507}. Best is trial 14 with value: 0.22090994290701013.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:26,590]\u001b[0m Trial 16 finished with value: 0.22080997205594716 and parameters: {'booster': 'gblinear', 'lambda': 6.774013410237306e-06, 'alpha': 0.03433881075364304, 'subsample': 0.5463583628650436, 'colsample_bytree': 0.8616295367637881}. Best is trial 16 with value: 0.22080997205594716.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:39:26,735]\u001b[0m Trial 17 finished with value: 0.22600079206318627 and parameters: {'booster': 'gblinear', 'lambda': 6.5817225467718955e-06, 'alpha': 0.061239042947505214, 'subsample': 0.5387665646097064, 'colsample_bytree': 0.8471969151124895}. Best is trial 16 with value: 0.22080997205594716.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:26,891]\u001b[0m Trial 18 finished with value: 0.23910085619531068 and parameters: {'booster': 'gblinear', 'lambda': 9.676921226787812e-07, 'alpha': 0.00029002324963366295, 'subsample': 0.7312989135128036, 'colsample_bytree': 0.7676618400910964}. Best is trial 16 with value: 0.22080997205594716.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:27,037]\u001b[0m Trial 19 finished with value: 0.22570109278490258 and parameters: {'booster': 'gblinear', 'lambda': 0.027773574532104876, 'alpha': 0.05470654942276427, 'subsample': 0.5426282460083057, 'colsample_bytree': 0.594447445882045}. Best is trial 16 with value: 0.22080997205594716.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:27,176]\u001b[0m Trial 20 finished with value: 0.24079272701115248 and parameters: {'booster': 'gblinear', 'lambda': 1.8671514519950233e-05, 'alpha': 2.2925717463757744e-06, 'subsample': 0.8220695248459826, 'colsample_bytree': 0.8828784406133903}. Best is trial 16 with value: 0.22080997205594716.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:27,304]\u001b[0m Trial 21 finished with value: 0.22200539886193763 and parameters: {'booster': 'gblinear', 'lambda': 0.00026733405602255474, 'alpha': 0.015022970882702692, 'subsample': 0.5389127858206367, 'colsample_bytree': 0.9143096369435955}. Best is trial 16 with value: 0.22080997205594716.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:27,432]\u001b[0m Trial 22 finished with value: 0.22203595692779038 and parameters: {'booster': 'gblinear', 'lambda': 2.860851400454888e-06, 'alpha': 0.014954347925144731, 'subsample': 0.5561641808229852, 'colsample_bytree': 0.7854290163451292}. Best is trial 16 with value: 0.22080997205594716.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:27,567]\u001b[0m Trial 23 finished with value: 0.23724032812948678 and parameters: {'booster': 'gblinear', 'lambda': 0.00020469364305905315, 'alpha': 0.00036504773366565787, 'subsample': 0.6381434911869667, 'colsample_bytree': 0.8984950744401528}. Best is trial 16 with value: 0.22080997205594716.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:27,674]\u001b[0m Trial 24 finished with value: 0.31759799151447554 and parameters: {'booster': 'gblinear', 'lambda': 0.019153406539560214, 'alpha': 0.27012971878503284, 'subsample': 0.5030507615292483, 'colsample_bytree': 0.7089515018137033}. Best is trial 16 with value: 0.22080997205594716.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:27,785]\u001b[0m Trial 25 finished with value: 0.2443330408106414 and parameters: {'booster': 'gblinear', 'lambda': 1.886410443632244e-07, 'alpha': 0.12686177651774877, 'subsample': 0.5866621932928942, 'colsample_bytree': 0.8204363380083582}. Best is trial 16 with value: 0.22080997205594716.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:27,905]\u001b[0m Trial 26 finished with value: 0.22038901757436738 and parameters: {'booster': 'gblinear', 'lambda': 1.869059770107707e-05, 'alpha': 0.020033906761575303, 'subsample': 0.6961276356536348, 'colsample_bytree': 0.9071109180750841}. Best is trial 26 with value: 0.22038901757436738.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:28,241]\u001b[0m Trial 27 finished with value: 0.5045288029727596 and parameters: {'booster': 'gbtree', 'lambda': 2.3950023491800017e-05, 'alpha': 0.9910176922501972, 'subsample': 0.7083052810110411, 'colsample_bytree': 0.6389220896962032, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.007031656724807323, 'gamma': 0.00748778799334314, 'grow_policy': 'depthwise'}. Best is trial 26 with value: 0.22038901757436738.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:28,399]\u001b[0m Trial 28 finished with value: 0.23305606398019565 and parameters: {'booster': 'gblinear', 'lambda': 3.980684217400724e-06, 'alpha': 0.0006082795055489477, 'subsample': 0.6794070095457612, 'colsample_bytree': 0.7448868280576286}. Best is trial 26 with value: 0.22038901757436738.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:30,156]\u001b[0m Trial 29 finished with value: 1.2557640859982149 and parameters: {'booster': 'dart', 'lambda': 5.2065818227499736e-05, 'alpha': 0.019859989882397285, 'subsample': 0.8471052530454363, 'colsample_bytree': 0.45581076976971924, 'max_depth': 9, 'min_child_weight': 9, 'eta': 3.2355813669325176e-06, 'gamma': 1.1922569074939808e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.4569234005097446e-08, 'skip_drop': 0.00026473020170968516}. Best is trial 26 with value: 0.22038901757436738.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:30,495]\u001b[0m Trial 30 finished with value: 2.9492419877294447 and parameters: {'booster': 'gbtree', 'lambda': 8.378235086186866e-08, 'alpha': 7.985761058623292e-05, 'subsample': 0.3684053263109649, 'colsample_bytree': 0.9275507743935371, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.7878279751475227, 'gamma': 4.688636213084694e-05, 'grow_policy': 'depthwise'}. Best is trial 26 with value: 0.22038901757436738.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:30,630]\u001b[0m Trial 31 finished with value: 0.22341935672280883 and parameters: {'booster': 'gblinear', 'lambda': 0.00035868108761464873, 'alpha': 0.01136147848370567, 'subsample': 0.4927307866465726, 'colsample_bytree': 0.9019925957091892}. Best is trial 26 with value: 0.22038901757436738.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:30,755]\u001b[0m Trial 32 finished with value: 0.2410927446636326 and parameters: {'booster': 'gblinear', 'lambda': 8.10419057364119e-07, 'alpha': 0.11847387195254862, 'subsample': 0.675229671233762, 'colsample_bytree': 0.9348711472637329}. Best is trial 26 with value: 0.22038901757436738.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:30,888]\u001b[0m Trial 33 finished with value: 0.21989806682416566 and parameters: {'booster': 'gblinear', 'lambda': 1.2536232892462764e-05, 'alpha': 0.03001105118056766, 'subsample': 0.5778720716069139, 'colsample_bytree': 0.8277816512647921}. Best is trial 33 with value: 0.21989806682416566.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:31,028]\u001b[0m Trial 34 finished with value: 0.24195357955034213 and parameters: {'booster': 'gblinear', 'lambda': 1.2213037725393764e-05, 'alpha': 9.012133548023556e-06, 'subsample': 0.590012074043804, 'colsample_bytree': 0.8352941872401142}. Best is trial 33 with value: 0.21989806682416566.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:31,174]\u001b[0m Trial 35 finished with value: 0.24430113502632722 and parameters: {'booster': 'gblinear', 'lambda': 1.7718120700337774e-06, 'alpha': 1.9212536786693284e-07, 'subsample': 0.8271264516061472, 'colsample_bytree': 0.8345258491162517}. Best is trial 33 with value: 0.21989806682416566.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:31,312]\u001b[0m Trial 36 finished with value: 0.23014288715885473 and parameters: {'booster': 'gblinear', 'lambda': 2.9309882607760373e-05, 'alpha': 0.0010192813451579416, 'subsample': 0.7803455823449474, 'colsample_bytree': 0.6597595824701696}. Best is trial 33 with value: 0.21989806682416566.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:31,703]\u001b[0m Trial 37 finished with value: 1.2563850410710657 and parameters: {'booster': 'gbtree', 'lambda': 3.0845209917311514e-07, 'alpha': 0.004348913031450482, 'subsample': 0.8889688503044353, 'colsample_bytree': 0.8007309258342207, 'max_depth': 7, 'min_child_weight': 7, 'eta': 1.9601631691633967e-08, 'gamma': 0.0005417809872405449, 'grow_policy': 'lossguide'}. Best is trial 33 with value: 0.21989806682416566.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:31,814]\u001b[0m Trial 38 finished with value: 0.26838436270415245 and parameters: {'booster': 'gblinear', 'lambda': 7.85203580025065e-06, 'alpha': 0.18222030480926424, 'subsample': 0.6673423925708593, 'colsample_bytree': 0.5775626230876926}. Best is trial 33 with value: 0.21989806682416566.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:33,326]\u001b[0m Trial 39 finished with value: 0.8367120519496619 and parameters: {'booster': 'dart', 'lambda': 0.00014925457795557652, 'alpha': 0.042859618534933676, 'subsample': 0.5856062148771222, 'colsample_bytree': 0.7391127537908592, 'max_depth': 5, 'min_child_weight': 2, 'eta': 0.0026991802596131793, 'gamma': 3.384370148951884e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 6.919795903064196e-06, 'skip_drop': 6.062128038009501e-05}. Best is trial 33 with value: 0.21989806682416566.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:39:33,461]\u001b[0m Trial 40 finished with value: 0.22621875610454473 and parameters: {'booster': 'gblinear', 'lambda': 0.07534255601307147, 'alpha': 0.00020190992264036402, 'subsample': 0.5113692114014095, 'colsample_bytree': 0.8610436170936883}. Best is trial 33 with value: 0.21989806682416566.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:33,591]\u001b[0m Trial 41 finished with value: 0.2200354554466315 and parameters: {'booster': 'gblinear', 'lambda': 0.0050766366200718, 'alpha': 0.026360636096133427, 'subsample': 0.46944367316359337, 'colsample_bytree': 0.9392553698024054}. Best is trial 33 with value: 0.21989806682416566.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:33,718]\u001b[0m Trial 42 finished with value: 0.22318922101442287 and parameters: {'booster': 'gblinear', 'lambda': 0.06459326470201314, 'alpha': 0.025762530440763626, 'subsample': 0.32574662895223283, 'colsample_bytree': 0.9393441693880329}. Best is trial 33 with value: 0.21989806682416566.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:33,824]\u001b[0m Trial 43 finished with value: 0.3964325779264182 and parameters: {'booster': 'gblinear', 'lambda': 0.005019732790519335, 'alpha': 0.37420778991059894, 'subsample': 0.4513071947189531, 'colsample_bytree': 0.9455786287923105}. Best is trial 33 with value: 0.21989806682416566.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:33,953]\u001b[0m Trial 44 finished with value: 0.22406898531526945 and parameters: {'booster': 'gblinear', 'lambda': 0.0023395440509296934, 'alpha': 0.006883100892896305, 'subsample': 0.4890278237560851, 'colsample_bytree': 0.8683471482195282}. Best is trial 33 with value: 0.21989806682416566.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:35,422]\u001b[0m Trial 45 finished with value: 1.2557753358151857 and parameters: {'booster': 'dart', 'lambda': 7.006888914481991e-05, 'alpha': 0.0723082012246117, 'subsample': 0.4079638398431699, 'colsample_bytree': 0.2995780647966094, 'max_depth': 9, 'min_child_weight': 10, 'eta': 3.5002392260556244e-06, 'gamma': 0.007413569332396083, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 8.326205380236635e-05, 'skip_drop': 0.000414174474613436}. Best is trial 33 with value: 0.21989806682416566.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:35,739]\u001b[0m Trial 46 finished with value: 1.0930785711466648 and parameters: {'booster': 'gbtree', 'lambda': 0.007724059248434964, 'alpha': 0.0031755807707684433, 'subsample': 0.3726752508275386, 'colsample_bytree': 0.9528399525739486, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.000883701730917184, 'gamma': 2.534320395468098e-07, 'grow_policy': 'depthwise'}. Best is trial 33 with value: 0.21989806682416566.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:35,860]\u001b[0m Trial 47 finished with value: 0.25946434826659937 and parameters: {'booster': 'gblinear', 'lambda': 0.6404228229288057, 'alpha': 0.026891551389150573, 'subsample': 0.9965417871061901, 'colsample_bytree': 0.8017412763764337}. Best is trial 33 with value: 0.21989806682416566.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:35,987]\u001b[0m Trial 48 finished with value: 0.22390560081260213 and parameters: {'booster': 'gblinear', 'lambda': 0.00045870654125341754, 'alpha': 0.0076367157129185155, 'subsample': 0.6295856038447738, 'colsample_bytree': 0.9828920770132221}. Best is trial 33 with value: 0.21989806682416566.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:36,117]\u001b[0m Trial 49 finished with value: 0.2294935566627943 and parameters: {'booster': 'gblinear', 'lambda': 4.733034090199607e-05, 'alpha': 0.0010246126355951688, 'subsample': 0.42888399929222704, 'colsample_bytree': 0.20564645099512957}. Best is trial 33 with value: 0.21989806682416566.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:36,968]\u001b[0m Trial 50 finished with value: 0.230875546893855 and parameters: {'booster': 'dart', 'lambda': 0.0020651184041187262, 'alpha': 0.4806110734397316, 'subsample': 0.5537266968924532, 'colsample_bytree': 0.6797319378325268, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.06203160981529324, 'gamma': 6.0681808283748876e-06, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.5410519289643573, 'skip_drop': 4.529721450620289e-06}. Best is trial 33 with value: 0.21989806682416566.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:37,082]\u001b[0m Trial 51 finished with value: 0.22973579953376552 and parameters: {'booster': 'gblinear', 'lambda': 0.00019192741386867454, 'alpha': 0.08116114426676378, 'subsample': 0.4807570990002784, 'colsample_bytree': 0.9048941860130106}. Best is trial 33 with value: 0.21989806682416566.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:37,205]\u001b[0m Trial 52 finished with value: 0.22233839665627464 and parameters: {'booster': 'gblinear', 'lambda': 1.0358083928719583e-05, 'alpha': 0.013483463875271261, 'subsample': 0.5783512272694248, 'colsample_bytree': 0.8685893936161038}. Best is trial 33 with value: 0.21989806682416566.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:37,310]\u001b[0m Trial 53 finished with value: 0.2660611892903505 and parameters: {'booster': 'gblinear', 'lambda': 0.0005659387435793562, 'alpha': 0.17633185838781557, 'subsample': 0.5357288064342488, 'colsample_bytree': 0.9053520544369875}. Best is trial 33 with value: 0.21989806682416566.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:37,431]\u001b[0m Trial 54 finished with value: 0.21992316926656844 and parameters: {'booster': 'gblinear', 'lambda': 2.1409365375547397e-06, 'alpha': 0.023482894771979793, 'subsample': 0.6520586143369687, 'colsample_bytree': 0.8233427608165254}. Best is trial 33 with value: 0.21989806682416566.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:37,546]\u001b[0m Trial 55 finished with value: 0.22168562558500135 and parameters: {'booster': 'gblinear', 'lambda': 1.3033583992131316e-06, 'alpha': 0.03832938902182555, 'subsample': 0.7593492013330145, 'colsample_bytree': 0.7538204944069705}. Best is trial 33 with value: 0.21989806682416566.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:37,675]\u001b[0m Trial 56 finished with value: 0.22395484708397306 and parameters: {'booster': 'gblinear', 'lambda': 3.7165958618126174e-06, 'alpha': 0.005947286045168573, 'subsample': 0.7132809936713945, 'colsample_bytree': 0.814723710903582}. Best is trial 33 with value: 0.21989806682416566.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:37,805]\u001b[0m Trial 57 finished with value: 0.22522217929404867 and parameters: {'booster': 'gblinear', 'lambda': 1.7245749925700953e-05, 'alpha': 0.0018615193941227068, 'subsample': 0.6477777668452956, 'colsample_bytree': 0.9570178973613435}. Best is trial 33 with value: 0.21989806682416566.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:37,924]\u001b[0m Trial 58 finished with value: 0.2198496214810568 and parameters: {'booster': 'gblinear', 'lambda': 5.338366717601217e-06, 'alpha': 0.029513788569763846, 'subsample': 0.6098698153140933, 'colsample_bytree': 0.8489666130737105}. Best is trial 58 with value: 0.2198496214810568.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:38,325]\u001b[0m Trial 59 finished with value: 1.2552768088161872 and parameters: {'booster': 'gbtree', 'lambda': 5.237147856884593e-07, 'alpha': 0.06871431430621448, 'subsample': 0.60528709310418, 'colsample_bytree': 0.8490539726449883, 'max_depth': 9, 'min_child_weight': 8, 'eta': 5.441348290380471e-06, 'gamma': 0.003728278748295667, 'grow_policy': 'depthwise'}. Best is trial 58 with value: 0.2198496214810568.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:38,430]\u001b[0m Trial 60 finished with value: 0.305177729856678 and parameters: {'booster': 'gblinear', 'lambda': 2.5290146621418986e-06, 'alpha': 0.2547639715270868, 'subsample': 0.6974273031453864, 'colsample_bytree': 0.8792497733104262}. Best is trial 58 with value: 0.2198496214810568.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:38,554]\u001b[0m Trial 61 finished with value: 0.21971535400326161 and parameters: {'booster': 'gblinear', 'lambda': 5.3336533460183995e-06, 'alpha': 0.027998123195504248, 'subsample': 0.6151921658152932, 'colsample_bytree': 0.7765119552527451}. Best is trial 61 with value: 0.21971535400326161.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:38,674]\u001b[0m Trial 62 finished with value: 0.21988051516415505 and parameters: {'booster': 'gblinear', 'lambda': 5.379876908751986e-06, 'alpha': 0.023915687125465417, 'subsample': 0.6103827465295998, 'colsample_bytree': 0.778730878452027}. Best is trial 61 with value: 0.21971535400326161.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:38,795]\u001b[0m Trial 63 finished with value: 0.22072643203373243 and parameters: {'booster': 'gblinear', 'lambda': 4.91474859051791e-06, 'alpha': 0.019067437402244012, 'subsample': 0.610192006959641, 'colsample_bytree': 0.7276772300670387}. Best is trial 61 with value: 0.21971535400326161.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:39:38,923]\u001b[0m Trial 64 finished with value: 0.22373403271560063 and parameters: {'booster': 'gblinear', 'lambda': 3.2205200732894087e-05, 'alpha': 0.009684730343177534, 'subsample': 0.6541450100025802, 'colsample_bytree': 0.7813210823940633}. Best is trial 61 with value: 0.21971535400326161.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:39,054]\u001b[0m Trial 65 finished with value: 0.2254161410093207 and parameters: {'booster': 'gblinear', 'lambda': 1.6373227221516835e-06, 'alpha': 0.0034931002968853733, 'subsample': 0.7322963399922747, 'colsample_bytree': 0.8230235094646678}. Best is trial 61 with value: 0.21971535400326161.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:39,167]\u001b[0m Trial 66 finished with value: 0.23352075935338168 and parameters: {'booster': 'gblinear', 'lambda': 1.6274101239574087e-05, 'alpha': 0.09554927933018138, 'subsample': 0.6191464657761672, 'colsample_bytree': 0.7921141275240947}. Best is trial 61 with value: 0.21971535400326161.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:39,282]\u001b[0m Trial 67 finished with value: 0.2224839375203389 and parameters: {'booster': 'gblinear', 'lambda': 1.2610528852057074e-07, 'alpha': 0.04295298325800723, 'subsample': 0.7817593846333488, 'colsample_bytree': 0.7005235482345049}. Best is trial 61 with value: 0.21971535400326161.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:39,413]\u001b[0m Trial 68 finished with value: 0.24386597388990325 and parameters: {'booster': 'gblinear', 'lambda': 7.660839547233616e-07, 'alpha': 1.531842255452316e-07, 'subsample': 0.5637803773361082, 'colsample_bytree': 0.761501623102422}. Best is trial 61 with value: 0.21971535400326161.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:41,003]\u001b[0m Trial 69 finished with value: 1.2563863234275336 and parameters: {'booster': 'dart', 'lambda': 0.00011434001639138449, 'alpha': 2.1031778666219e-05, 'subsample': 0.6972156279096452, 'colsample_bytree': 0.9995606451581837, 'max_depth': 7, 'min_child_weight': 5, 'eta': 1.4585947505968888e-08, 'gamma': 0.07078281877258415, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 2.5253033840559243e-06, 'skip_drop': 0.006965037324471328}. Best is trial 61 with value: 0.21971535400326161.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:41,126]\u001b[0m Trial 70 finished with value: 0.22076475881049784 and parameters: {'booster': 'gblinear', 'lambda': 6.545800060035581e-06, 'alpha': 0.019422473524313557, 'subsample': 0.6673090530462236, 'colsample_bytree': 0.37742877032258537}. Best is trial 61 with value: 0.21971535400326161.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:41,251]\u001b[0m Trial 71 finished with value: 0.22220587793341726 and parameters: {'booster': 'gblinear', 'lambda': 5.1237076067223095e-06, 'alpha': 0.013873674045286279, 'subsample': 0.5950506488880033, 'colsample_bytree': 0.8334375055229304}. Best is trial 61 with value: 0.21971535400326161.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:41,358]\u001b[0m Trial 72 finished with value: 0.2550687908695486 and parameters: {'booster': 'gblinear', 'lambda': 2.8417014443474122e-06, 'alpha': 0.1510144636358396, 'subsample': 0.6133902508501986, 'colsample_bytree': 0.7340898189074851}. Best is trial 61 with value: 0.21971535400326161.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:41,478]\u001b[0m Trial 73 finished with value: 0.21998255642063397 and parameters: {'booster': 'gblinear', 'lambda': 1.0530353441599151e-05, 'alpha': 0.022621607585711415, 'subsample': 0.526300434301961, 'colsample_bytree': 0.7171245494093892}. Best is trial 61 with value: 0.21971535400326161.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:41,607]\u001b[0m Trial 74 finished with value: 0.22446498438421358 and parameters: {'booster': 'gblinear', 'lambda': 1.1155308351449149e-05, 'alpha': 0.005356596344249266, 'subsample': 0.5137611834244432, 'colsample_bytree': 0.5363154697813993}. Best is trial 61 with value: 0.21971535400326161.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:41,727]\u001b[0m Trial 75 finished with value: 0.21979348989699388 and parameters: {'booster': 'gblinear', 'lambda': 3.987232658283193e-05, 'alpha': 0.025378627299517915, 'subsample': 0.4640366735699497, 'colsample_bytree': 0.6320741486159198}. Best is trial 61 with value: 0.21971535400326161.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:41,841]\u001b[0m Trial 76 finished with value: 0.22309099281826517 and parameters: {'booster': 'gblinear', 'lambda': 4.1394013579482525e-07, 'alpha': 0.045998013096271446, 'subsample': 0.46295159557284754, 'colsample_bytree': 0.7138277571846238}. Best is trial 61 with value: 0.21971535400326161.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:41,972]\u001b[0m Trial 77 finished with value: 0.22927605953723676 and parameters: {'booster': 'gblinear', 'lambda': 3.9521290839044325e-05, 'alpha': 0.0010964078004931158, 'subsample': 0.22352197431439863, 'colsample_bytree': 0.6133243169218381}. Best is trial 61 with value: 0.21971535400326161.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:42,089]\u001b[0m Trial 78 finished with value: 0.2197116140958062 and parameters: {'booster': 'gblinear', 'lambda': 2.0981752962045934e-06, 'alpha': 0.02730603993724793, 'subsample': 0.5696577058479474, 'colsample_bytree': 0.6658951529085371}. Best is trial 78 with value: 0.2197116140958062.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:42,350]\u001b[0m Trial 79 finished with value: 1.1175602566702867 and parameters: {'booster': 'gbtree', 'lambda': 1.7925198703834682e-06, 'alpha': 0.0027280019609267903, 'subsample': 0.5216697897976293, 'colsample_bytree': 0.6689837360159301, 'max_depth': 5, 'min_child_weight': 3, 'eta': 0.0007576172144986493, 'gamma': 1.5726975524635907e-07, 'grow_policy': 'depthwise'}. Best is trial 78 with value: 0.2197116140958062.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:42,477]\u001b[0m Trial 80 finished with value: 0.22379957311226795 and parameters: {'booster': 'gblinear', 'lambda': 7.89582713586404e-06, 'alpha': 0.009800674735819205, 'subsample': 0.5319862545436491, 'colsample_bytree': 0.6525487441345919}. Best is trial 78 with value: 0.2197116140958062.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:42,596]\u001b[0m Trial 81 finished with value: 0.2197472123948626 and parameters: {'booster': 'gblinear', 'lambda': 3.4784427074411263e-06, 'alpha': 0.026790843030649925, 'subsample': 0.5629306865147703, 'colsample_bytree': 0.6252718136308109}. Best is trial 78 with value: 0.2197116140958062.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:42,707]\u001b[0m Trial 82 finished with value: 0.23779965169076983 and parameters: {'booster': 'gblinear', 'lambda': 2.496796232140802e-06, 'alpha': 0.10918991966423228, 'subsample': 0.5689260527662907, 'colsample_bytree': 0.614793053151952}. Best is trial 78 with value: 0.2197116140958062.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:42,821]\u001b[0m Trial 83 finished with value: 0.225350892744351 and parameters: {'booster': 'gblinear', 'lambda': 1.0410996263171382e-06, 'alpha': 0.05714447123817089, 'subsample': 0.6422070458115547, 'colsample_bytree': 0.6889675732361283}. Best is trial 78 with value: 0.2197116140958062.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:42,939]\u001b[0m Trial 84 finished with value: 0.22092179510081053 and parameters: {'booster': 'gblinear', 'lambda': 7.573646963830669e-05, 'alpha': 0.03483163222795055, 'subsample': 0.5708229473322917, 'colsample_bytree': 0.636985818574801}. Best is trial 78 with value: 0.2197116140958062.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:43,068]\u001b[0m Trial 85 finished with value: 0.2237014162908552 and parameters: {'booster': 'gblinear', 'lambda': 2.1554484140938555e-05, 'alpha': 0.00970676539681799, 'subsample': 0.5996184162717014, 'colsample_bytree': 0.5525761222870842}. Best is trial 78 with value: 0.2197116140958062.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:43,170]\u001b[0m Trial 86 finished with value: 0.6682190330179876 and parameters: {'booster': 'gblinear', 'lambda': 3.8139873565165488e-06, 'alpha': 0.6610934122222493, 'subsample': 0.6308572147831386, 'colsample_bytree': 0.5847115552591088}. Best is trial 78 with value: 0.2197116140958062.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:43,277]\u001b[0m Trial 87 finished with value: 0.2736121094994753 and parameters: {'booster': 'gblinear', 'lambda': 1.0488685947702844e-05, 'alpha': 0.1944198831372767, 'subsample': 0.4994639266909892, 'colsample_bytree': 0.7678738408302657}. Best is trial 78 with value: 0.2197116140958062.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:44,826]\u001b[0m Trial 88 finished with value: 0.20640736261413656 and parameters: {'booster': 'dart', 'lambda': 5.711763878315979e-07, 'alpha': 0.02186600733272884, 'subsample': 0.5543577126406126, 'colsample_bytree': 0.719167618845578, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.08544931918575989, 'gamma': 0.0005853622556196205, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.007912681232228623, 'skip_drop': 1.1620576050674324e-08}. Best is trial 88 with value: 0.20640736261413656.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:39:46,355]\u001b[0m Trial 89 finished with value: 0.2112011243584237 and parameters: {'booster': 'dart', 'lambda': 2.9357423133295245e-07, 'alpha': 0.004814612469018057, 'subsample': 0.5488951549423414, 'colsample_bytree': 0.5562163945745925, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.07232555046373225, 'gamma': 0.0005876979403208347, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.0037934464401563235, 'skip_drop': 6.074787965233486e-07}. Best is trial 88 with value: 0.20640736261413656.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:47,953]\u001b[0m Trial 90 finished with value: 0.22945779019064028 and parameters: {'booster': 'dart', 'lambda': 3.587857832751616e-08, 'alpha': 0.08474405244094048, 'subsample': 0.5526911126613776, 'colsample_bytree': 0.511692597264734, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.11352097213663435, 'gamma': 0.0005039794658027277, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.0029209966449426743, 'skip_drop': 1.1142164162647916e-08}. Best is trial 88 with value: 0.20640736261413656.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:49,535]\u001b[0m Trial 91 finished with value: 0.35941987453346763 and parameters: {'booster': 'dart', 'lambda': 1.889419683383427e-07, 'alpha': 0.013166382687414518, 'subsample': 0.5806549933574658, 'colsample_bytree': 0.5621929862542285, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.015606438845064354, 'gamma': 0.0018385656593747609, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.03809429627659734, 'skip_drop': 8.872788543640548e-07}. Best is trial 88 with value: 0.20640736261413656.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:51,113]\u001b[0m Trial 92 finished with value: 0.2252428726423275 and parameters: {'booster': 'dart', 'lambda': 6.587524710595904e-07, 'alpha': 0.03173740577323913, 'subsample': 0.6611214658905913, 'colsample_bytree': 0.6209243015127305, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.14693443997890443, 'gamma': 1.9903069507095313e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.0003114289223252132, 'skip_drop': 5.2941277644614536e-06}. Best is trial 88 with value: 0.20640736261413656.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:52,617]\u001b[0m Trial 93 finished with value: 0.8297029843488081 and parameters: {'booster': 'dart', 'lambda': 3.4102054532047823e-07, 'alpha': 0.005670391155818256, 'subsample': 0.5557834065302438, 'colsample_bytree': 0.6865805494424615, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.002762538093415045, 'gamma': 0.02045225349967885, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.00024778576204434764, 'skip_drop': 1.1565149607395886e-08}. Best is trial 88 with value: 0.20640736261413656.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:54,318]\u001b[0m A new study created in memory with name: no-name-cc8f3593-da89-4464-9e98-9d9bd37ff808\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:54,716]\u001b[0m Trial 0 finished with value: 1.105559258088434 and parameters: {'booster': 'gbtree', 'lambda': 0.7539694004811477, 'alpha': 8.619615279019297e-07, 'subsample': 0.9416202924759205, 'colsample_bytree': 0.8698496466303598, 'max_depth': 9, 'min_child_weight': 6, 'eta': 8.641803489329142e-05, 'gamma': 0.027565975354701056, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 1.105559258088434.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:54,856]\u001b[0m Trial 1 finished with value: 1.1146030585922901 and parameters: {'booster': 'gbtree', 'lambda': 6.356703445296483e-08, 'alpha': 0.14543991133831585, 'subsample': 0.41125495456334255, 'colsample_bytree': 0.2252006763365147, 'max_depth': 3, 'min_child_weight': 9, 'eta': 5.7689983462676066e-05, 'gamma': 9.161498177132793e-07, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 1.105559258088434.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:54,944]\u001b[0m Trial 2 finished with value: 0.6381091132936018 and parameters: {'booster': 'gblinear', 'lambda': 6.340249927525532e-05, 'alpha': 0.5993809425271786, 'subsample': 0.888757259209179, 'colsample_bytree': 0.5699147652091623}. Best is trial 2 with value: 0.6381091132936018.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:55,064]\u001b[0m Trial 3 finished with value: 0.0017142086991627113 and parameters: {'booster': 'gblinear', 'lambda': 1.3628934967312842e-06, 'alpha': 0.0001506627723346396, 'subsample': 0.6029442176985811, 'colsample_bytree': 0.2922810270551741}. Best is trial 3 with value: 0.0017142086991627113.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:55,241]\u001b[0m Trial 4 finished with value: 0.5668169564905551 and parameters: {'booster': 'gbtree', 'lambda': 0.5534431505351406, 'alpha': 0.029076096305786066, 'subsample': 0.8789230017046712, 'colsample_bytree': 0.7058725964523209, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.004922613546877385, 'gamma': 0.21044784493572982, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 0.0017142086991627113.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:56,760]\u001b[0m Trial 5 finished with value: 1.1216940892304976 and parameters: {'booster': 'dart', 'lambda': 0.14655107896610026, 'alpha': 0.1647712336070065, 'subsample': 0.24267296184031295, 'colsample_bytree': 0.9256416751708951, 'max_depth': 5, 'min_child_weight': 3, 'eta': 5.512815751741012e-06, 'gamma': 0.0027730042882997815, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 2.1406698155852066e-06, 'skip_drop': 0.0017978712997753904}. Best is trial 3 with value: 0.0017142086991627113.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:57,036]\u001b[0m Trial 6 finished with value: 0.07176796163059748 and parameters: {'booster': 'gbtree', 'lambda': 0.00028755713556516025, 'alpha': 0.00023859271049716925, 'subsample': 0.6113667904183178, 'colsample_bytree': 0.9243279836139016, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.21055706416250217, 'gamma': 8.584196219555535e-05, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 0.0017142086991627113.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:58,419]\u001b[0m Trial 7 finished with value: 1.1212013500086124 and parameters: {'booster': 'dart', 'lambda': 0.05315390734806678, 'alpha': 0.04111977578185212, 'subsample': 0.9541963669070865, 'colsample_bytree': 0.4089326020301412, 'max_depth': 5, 'min_child_weight': 5, 'eta': 9.253744657421884e-06, 'gamma': 0.020502083090926222, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.019914816462032636, 'skip_drop': 1.9264408657027513e-08}. Best is trial 3 with value: 0.0017142086991627113.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:58,541]\u001b[0m Trial 8 finished with value: 0.0031987462762486703 and parameters: {'booster': 'gblinear', 'lambda': 3.838495275177864e-07, 'alpha': 1.0158582283180642e-08, 'subsample': 0.9329818582287521, 'colsample_bytree': 0.20673346169123424}. Best is trial 3 with value: 0.0017142086991627113.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:58,660]\u001b[0m Trial 9 finished with value: 0.08166438287405499 and parameters: {'booster': 'gblinear', 'lambda': 0.2769166469719873, 'alpha': 8.736523611850509e-06, 'subsample': 0.9018004370604915, 'colsample_bytree': 0.7092744775258186}. Best is trial 3 with value: 0.0017142086991627113.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:58,795]\u001b[0m Trial 10 finished with value: 0.0007887481852551303 and parameters: {'booster': 'gblinear', 'lambda': 4.706400365805844e-06, 'alpha': 0.0003828279389203721, 'subsample': 0.6510965987275205, 'colsample_bytree': 0.39614908803680093}. Best is trial 10 with value: 0.0007887481852551303.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:58,930]\u001b[0m Trial 11 finished with value: 0.001149150413209506 and parameters: {'booster': 'gblinear', 'lambda': 4.127584284695661e-06, 'alpha': 0.0002866299426929938, 'subsample': 0.6569710762721794, 'colsample_bytree': 0.3976796513781629}. Best is trial 10 with value: 0.0007887481852551303.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:59,065]\u001b[0m Trial 12 finished with value: 0.00018516361328061584 and parameters: {'booster': 'gblinear', 'lambda': 2.4503307618152802e-05, 'alpha': 0.0031052862645772465, 'subsample': 0.7386936441634896, 'colsample_bytree': 0.4460901608644835}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:59,197]\u001b[0m Trial 13 finished with value: 0.0002286080267167178 and parameters: {'booster': 'gblinear', 'lambda': 0.00021494742359248308, 'alpha': 0.003329670835968006, 'subsample': 0.7435932460165342, 'colsample_bytree': 0.4863498507843138}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:39:59,329]\u001b[0m Trial 14 finished with value: 0.000942499009768111 and parameters: {'booster': 'gblinear', 'lambda': 0.003677024645395192, 'alpha': 0.005290223433162151, 'subsample': 0.7688080992013802, 'colsample_bytree': 0.5518491485674263}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:39:59,461]\u001b[0m Trial 15 finished with value: 0.00030480416713842256 and parameters: {'booster': 'gblinear', 'lambda': 0.00013616374985142324, 'alpha': 0.004191627938267912, 'subsample': 0.7499682927442767, 'colsample_bytree': 0.4887054748263095}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:01,108]\u001b[0m Trial 16 finished with value: 1.1227050420270803 and parameters: {'booster': 'dart', 'lambda': 0.0017537459050878477, 'alpha': 0.002983922941558032, 'subsample': 0.4543540000872567, 'colsample_bytree': 0.6818077159617406, 'max_depth': 9, 'min_child_weight': 2, 'eta': 1.5694498258159123e-08, 'gamma': 1.3012544771083194e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 3.9255457246456663e-08, 'skip_drop': 0.9940875802390595}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:01,243]\u001b[0m Trial 17 finished with value: 0.0026783385980905356 and parameters: {'booster': 'gblinear', 'lambda': 2.4772136536095953e-05, 'alpha': 1.2402271587069571e-05, 'subsample': 0.7643616169592868, 'colsample_bytree': 0.47361087897872844}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:01,379]\u001b[0m Trial 18 finished with value: 0.002691606068317073 and parameters: {'booster': 'gblinear', 'lambda': 0.005718694293225587, 'alpha': 1.058557350189679e-05, 'subsample': 0.45966593259389443, 'colsample_bytree': 0.3227901937119382}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:02,564]\u001b[0m Trial 19 finished with value: 1.122706860755822 and parameters: {'booster': 'dart', 'lambda': 1.4187897119796635e-08, 'alpha': 0.001663895721722785, 'subsample': 0.8227128262391534, 'colsample_bytree': 0.6223420916706649, 'max_depth': 7, 'min_child_weight': 10, 'eta': 1.0939075991828027e-08, 'gamma': 2.9562290655601284e-05, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.3109268927691884, 'skip_drop': 1.535645172743351e-08}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:02,693]\u001b[0m Trial 20 finished with value: 0.0018350972124856727 and parameters: {'booster': 'gblinear', 'lambda': 0.00038516080687029313, 'alpha': 0.014068966478694595, 'subsample': 0.5201274431480953, 'colsample_bytree': 0.8079756438776271}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:02,828]\u001b[0m Trial 21 finished with value: 0.0011297770801359174 and parameters: {'booster': 'gblinear', 'lambda': 2.232595505760194e-05, 'alpha': 0.0009256966305070684, 'subsample': 0.7431372730190623, 'colsample_bytree': 0.4945583603617787}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:02,960]\u001b[0m Trial 22 finished with value: 0.0004944473681818097 and parameters: {'booster': 'gblinear', 'lambda': 0.00044930228803507404, 'alpha': 0.006571556570357672, 'subsample': 0.7047075320934635, 'colsample_bytree': 0.47969518506318554}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:03,075]\u001b[0m Trial 23 finished with value: 0.05536908089475984 and parameters: {'booster': 'gblinear', 'lambda': 0.023300056822257553, 'alpha': 0.06586034525782364, 'subsample': 0.8197402004534777, 'colsample_bytree': 0.6184768977602513}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:03,214]\u001b[0m Trial 24 finished with value: 0.002735380820208136 and parameters: {'booster': 'gblinear', 'lambda': 5.831029144790914e-05, 'alpha': 3.323629750097384e-05, 'subsample': 0.5466758680429857, 'colsample_bytree': 0.3131567318903189}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:03,348]\u001b[0m Trial 25 finished with value: 0.00031275270331693704 and parameters: {'booster': 'gblinear', 'lambda': 1.455949811701656e-05, 'alpha': 0.0012701211411371832, 'subsample': 0.7046630513395225, 'colsample_bytree': 0.53207096255906}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:03,484]\u001b[0m Trial 26 finished with value: 0.0024774153601800947 and parameters: {'booster': 'gblinear', 'lambda': 0.0010594135930854353, 'alpha': 1.1977320574392096e-06, 'subsample': 0.8234557335726513, 'colsample_bytree': 0.43655415406316017}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:03,733]\u001b[0m Trial 27 finished with value: 0.33894148165569665 and parameters: {'booster': 'gbtree', 'lambda': 0.00013141951806052929, 'alpha': 0.6104370198984733, 'subsample': 0.686708161614354, 'colsample_bytree': 0.35028346627607443, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.9940159158071616, 'gamma': 1.5028285388212536e-08, 'grow_policy': 'lossguide'}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:03,858]\u001b[0m Trial 28 finished with value: 0.001398993994237011 and parameters: {'booster': 'gblinear', 'lambda': 2.690640639953953e-06, 'alpha': 0.01262875266495254, 'subsample': 0.7768920308377617, 'colsample_bytree': 0.5138618071791083}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:05,495]\u001b[0m Trial 29 finished with value: 0.28385628557198433 and parameters: {'booster': 'dart', 'lambda': 0.006857665557993075, 'alpha': 6.548203093388093e-05, 'subsample': 0.5708330087737761, 'colsample_bytree': 0.7900342603529323, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.008564003941176127, 'gamma': 1.4319285536040206e-06, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.00023487096643636315, 'skip_drop': 4.007050737891646e-05}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:05,824]\u001b[0m Trial 30 finished with value: 1.1225110946977974 and parameters: {'booster': 'gbtree', 'lambda': 3.5028821819758197e-07, 'alpha': 1.2717320478500431e-08, 'subsample': 0.9974121161772367, 'colsample_bytree': 0.6046395387935299, 'max_depth': 7, 'min_child_weight': 7, 'eta': 9.971100717342496e-07, 'gamma': 0.0005997708315342622, 'grow_policy': 'depthwise'}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:05,958]\u001b[0m Trial 31 finished with value: 0.0004121783150641408 and parameters: {'booster': 'gblinear', 'lambda': 1.5118694742705075e-05, 'alpha': 0.0017614153751993116, 'subsample': 0.7094602673709137, 'colsample_bytree': 0.5502927484092421}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:06,092]\u001b[0m Trial 32 finished with value: 0.0003951023662605187 and parameters: {'booster': 'gblinear', 'lambda': 9.472684720309952e-06, 'alpha': 0.0009081341005581996, 'subsample': 0.8195047209633858, 'colsample_bytree': 0.44550447901542134}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:06,206]\u001b[0m Trial 33 finished with value: 0.13078020951573477 and parameters: {'booster': 'gblinear', 'lambda': 9.681998901960568e-05, 'alpha': 0.1240185339053494, 'subsample': 0.6444724218813469, 'colsample_bytree': 0.5263470499796006}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:06,335]\u001b[0m Trial 34 finished with value: 0.0006802073107570358 and parameters: {'booster': 'gblinear', 'lambda': 1.0807398430610786e-06, 'alpha': 0.008656648106587325, 'subsample': 0.7234907280481179, 'colsample_bytree': 0.2612466987550778}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:06,468]\u001b[0m Trial 35 finished with value: 0.0004658407856458652 and parameters: {'booster': 'gblinear', 'lambda': 4.771977945232957e-05, 'alpha': 0.0007863902443813394, 'subsample': 0.8490053560626694, 'colsample_bytree': 0.3634059573217244}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:06,667]\u001b[0m Trial 36 finished with value: 0.7486029186138203 and parameters: {'booster': 'gbtree', 'lambda': 0.000190373995882639, 'alpha': 7.779828345527004e-05, 'subsample': 0.7794438701882344, 'colsample_bytree': 0.5912890629747732, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.0028006895413468266, 'gamma': 0.580702318093304, 'grow_policy': 'lossguide'}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:40:06,788]\u001b[0m Trial 37 finished with value: 0.005784129183377505 and parameters: {'booster': 'gblinear', 'lambda': 0.0008172948361957949, 'alpha': 0.025113660090807007, 'subsample': 0.2886240359151342, 'colsample_bytree': 0.6523209301722596}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:06,921]\u001b[0m Trial 38 finished with value: 0.0002039210519647161 and parameters: {'booster': 'gblinear', 'lambda': 7.171192030112451e-07, 'alpha': 0.003176369709547308, 'subsample': 0.6288381396146475, 'colsample_bytree': 0.9932836249470749}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:07,212]\u001b[0m Trial 39 finished with value: 1.1226874277260104 and parameters: {'booster': 'gbtree', 'lambda': 1.804019271571213e-07, 'alpha': 0.0035552957137761324, 'subsample': 0.6046530709347511, 'colsample_bytree': 0.9856377955695139, 'max_depth': 5, 'min_child_weight': 4, 'eta': 1.045864913311624e-07, 'gamma': 5.454395744963248e-07, 'grow_policy': 'depthwise'}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:08,677]\u001b[0m Trial 40 finished with value: 1.0125168842577006 and parameters: {'booster': 'dart', 'lambda': 4.1903116006801395e-08, 'alpha': 0.2039775227582029, 'subsample': 0.5171925640512764, 'colsample_bytree': 0.2661994495354699, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.0006736736634375636, 'gamma': 1.9764421870713404e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.0005308261832859077, 'skip_drop': 2.145443745033071e-05}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:08,812]\u001b[0m Trial 41 finished with value: 0.0009046932603541734 and parameters: {'booster': 'gblinear', 'lambda': 8.785506410317761e-06, 'alpha': 0.00036886001719401394, 'subsample': 0.6709431439350667, 'colsample_bytree': 0.45206971494975107}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:08,946]\u001b[0m Trial 42 finished with value: 0.00021113384348110624 and parameters: {'booster': 'gblinear', 'lambda': 6.499596427327731e-07, 'alpha': 0.002084964620456574, 'subsample': 0.7314506146118009, 'colsample_bytree': 0.7599589241161991}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:09,069]\u001b[0m Trial 43 finished with value: 0.00438716206800073 and parameters: {'booster': 'gblinear', 'lambda': 9.989922213052007e-07, 'alpha': 0.02258612386043691, 'subsample': 0.6263401828758757, 'colsample_bytree': 0.7720619917254421}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:09,185]\u001b[0m Trial 44 finished with value: 0.04418008243161845 and parameters: {'booster': 'gblinear', 'lambda': 9.178561021098844e-08, 'alpha': 0.07204613726383821, 'subsample': 0.8785967870782203, 'colsample_bytree': 0.9978117706105124}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:09,317]\u001b[0m Trial 45 finished with value: 0.0002500386729372018 and parameters: {'booster': 'gblinear', 'lambda': 5.381358390050646e-07, 'alpha': 0.003711757101716931, 'subsample': 0.7351728648301252, 'colsample_bytree': 0.8694725866426563}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:09,452]\u001b[0m Trial 46 finished with value: 0.002047764523786431 and parameters: {'booster': 'gblinear', 'lambda': 1.963368457723242e-06, 'alpha': 0.00014579270266704264, 'subsample': 0.6727488493713532, 'colsample_bytree': 0.9087777574865387}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:09,586]\u001b[0m Trial 47 finished with value: 0.0010215471456014485 and parameters: {'booster': 'gblinear', 'lambda': 4.49302971173617e-07, 'alpha': 0.00031168686084670575, 'subsample': 0.5896179999300938, 'colsample_bytree': 0.8931221043048411}. Best is trial 12 with value: 0.00018516361328061584.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:09,723]\u001b[0m Trial 48 finished with value: 0.0001619547566703018 and parameters: {'booster': 'gblinear', 'lambda': 2.8326929177302892e-08, 'alpha': 0.0025193382067927547, 'subsample': 0.7372529297491066, 'colsample_bytree': 0.8430439578505011}. Best is trial 48 with value: 0.0001619547566703018.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:11,152]\u001b[0m Trial 49 finished with value: 0.10579465237543367 and parameters: {'booster': 'dart', 'lambda': 1.376558903672623e-08, 'alpha': 0.0005226881621521776, 'subsample': 0.7955505676105099, 'colsample_bytree': 0.84524137235894, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.04606856402233775, 'gamma': 1.3535574052874557e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 4.497120487401442e-08, 'skip_drop': 0.7790640090715268}. Best is trial 48 with value: 0.0001619547566703018.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:11,287]\u001b[0m Trial 50 finished with value: 0.00020240556925491787 and parameters: {'booster': 'gblinear', 'lambda': 7.485978551601864e-08, 'alpha': 0.0023049712966860484, 'subsample': 0.8630786153652742, 'colsample_bytree': 0.9631642741721607}. Best is trial 48 with value: 0.0001619547566703018.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:11,421]\u001b[0m Trial 51 finished with value: 0.00015204737745907817 and parameters: {'booster': 'gblinear', 'lambda': 3.387198380263993e-08, 'alpha': 0.0022059609796129544, 'subsample': 0.9179295297302842, 'colsample_bytree': 0.9631185839231777}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:11,555]\u001b[0m Trial 52 finished with value: 0.0002325828644112996 and parameters: {'booster': 'gblinear', 'lambda': 4.0460610536074734e-08, 'alpha': 0.001964093982555997, 'subsample': 0.9297162634654974, 'colsample_bytree': 0.9350591875468524}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:11,684]\u001b[0m Trial 53 finished with value: 0.001205988629641602 and parameters: {'booster': 'gblinear', 'lambda': 1.245249879697518e-07, 'alpha': 0.011694237733246675, 'subsample': 0.8648021101535148, 'colsample_bytree': 0.9588461377360524}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:11,817]\u001b[0m Trial 54 finished with value: 0.0004481298873413563 and parameters: {'booster': 'gblinear', 'lambda': 3.342523542583486e-08, 'alpha': 0.006539347267642913, 'subsample': 0.9907449015556922, 'colsample_bytree': 0.7372722698800647}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:11,951]\u001b[0m Trial 55 finished with value: 0.0019024135940699455 and parameters: {'booster': 'gblinear', 'lambda': 1.9959475926161609e-07, 'alpha': 0.00017834415602734717, 'subsample': 0.9132684302723572, 'colsample_bytree': 0.9623822075815985}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:12,069]\u001b[0m Trial 56 finished with value: 0.018298689206086488 and parameters: {'booster': 'gblinear', 'lambda': 2.4063197341132486e-08, 'alpha': 0.046317558787950276, 'subsample': 0.9733132062740493, 'colsample_bytree': 0.8730876510891827}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:12,202]\u001b[0m Trial 57 finished with value: 0.00019044562998094786 and parameters: {'booster': 'gblinear', 'lambda': 1.0252801642164507e-08, 'alpha': 0.0021997970269866714, 'subsample': 0.8551402009615621, 'colsample_bytree': 0.9400894447605885}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:12,338]\u001b[0m Trial 58 finished with value: 0.00043471762682794496 and parameters: {'booster': 'gblinear', 'lambda': 1.1222592273549702e-08, 'alpha': 0.0005342017552453092, 'subsample': 0.8964859543744996, 'colsample_bytree': 0.9498564377403088}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:12,768]\u001b[0m Trial 59 finished with value: 1.122636820887966 and parameters: {'booster': 'gbtree', 'lambda': 6.232719961814333e-08, 'alpha': 0.3106951436283163, 'subsample': 0.9494921257391244, 'colsample_bytree': 0.8325765588315045, 'max_depth': 9, 'min_child_weight': 4, 'eta': 3.413072904218044e-07, 'gamma': 0.0009529021375046826, 'grow_policy': 'lossguide'}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:40:12,904]\u001b[0m Trial 60 finished with value: 0.003419714491719687 and parameters: {'booster': 'gblinear', 'lambda': 1.8696588807553496e-08, 'alpha': 2.4565145788350003e-05, 'subsample': 0.8562677435859782, 'colsample_bytree': 0.9122679101901499}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:13,038]\u001b[0m Trial 61 finished with value: 0.0002684415472118078 and parameters: {'booster': 'gblinear', 'lambda': 7.769440306537893e-08, 'alpha': 0.0016638281340957569, 'subsample': 0.8000629261800991, 'colsample_bytree': 0.9672561315887406}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:13,173]\u001b[0m Trial 62 finished with value: 0.00020795360856619473 and parameters: {'booster': 'gblinear', 'lambda': 1.471712739672223e-07, 'alpha': 0.00250272334913579, 'subsample': 0.8397551510307464, 'colsample_bytree': 0.8348630179803994}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:13,299]\u001b[0m Trial 63 finished with value: 0.002194336326162742 and parameters: {'booster': 'gblinear', 'lambda': 1.9793814306797077e-07, 'alpha': 0.01589637390653398, 'subsample': 0.9121836295396643, 'colsample_bytree': 0.931561899742002}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:13,431]\u001b[0m Trial 64 finished with value: 0.0004085697886692642 and parameters: {'booster': 'gblinear', 'lambda': 4.167671579559991e-08, 'alpha': 0.006176945635633475, 'subsample': 0.8483023119638193, 'colsample_bytree': 0.8750895093683599}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:13,564]\u001b[0m Trial 65 finished with value: 0.0018697961508483683 and parameters: {'booster': 'gblinear', 'lambda': 2.5027566224930644e-07, 'alpha': 0.0008270505149087148, 'subsample': 0.8860468659971842, 'colsample_bytree': 0.8366607602188271}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:15,080]\u001b[0m Trial 66 finished with value: 1.0167079189007007 and parameters: {'booster': 'dart', 'lambda': 2.6342660355896206e-08, 'alpha': 0.0024853978879395286, 'subsample': 0.8252986998513265, 'colsample_bytree': 0.99876515933649, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.0005880326576523651, 'gamma': 1.2416388072008738e-05, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.3234051974877841e-05, 'skip_drop': 0.00678513921346447}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:15,212]\u001b[0m Trial 67 finished with value: 0.00036375941290762797 and parameters: {'booster': 'gblinear', 'lambda': 1.2252741499693233e-07, 'alpha': 0.005792412373854539, 'subsample': 0.9279834500403971, 'colsample_bytree': 0.9060264439682016}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:15,336]\u001b[0m Trial 68 finished with value: 0.011230227635874938 and parameters: {'booster': 'gblinear', 'lambda': 5.1098030258949905e-08, 'alpha': 0.03625188186370409, 'subsample': 0.966558409605522, 'colsample_bytree': 0.9467213719580319}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:15,478]\u001b[0m Trial 69 finished with value: 0.0029111193335540856 and parameters: {'booster': 'gblinear', 'lambda': 1.2917801931578821e-08, 'alpha': 3.326458759205703e-08, 'subsample': 0.76104667431497, 'colsample_bytree': 0.8048432227449751}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:15,612]\u001b[0m Trial 70 finished with value: 0.0004139168298818875 and parameters: {'booster': 'gblinear', 'lambda': 3.3625060778234256e-06, 'alpha': 0.00112332342068265, 'subsample': 0.34820599915004036, 'colsample_bytree': 0.9718099775848335}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:15,745]\u001b[0m Trial 71 finished with value: 0.0001874467393200004 and parameters: {'booster': 'gblinear', 'lambda': 8.036015466396404e-07, 'alpha': 0.002695494015524552, 'subsample': 0.7913294803140006, 'colsample_bytree': 0.7325440486747276}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:15,879]\u001b[0m Trial 72 finished with value: 0.00022277925277235694 and parameters: {'booster': 'gblinear', 'lambda': 1.0686059945845159e-07, 'alpha': 0.003973509187899618, 'subsample': 0.7906740822937599, 'colsample_bytree': 0.7235844621854629}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:16,009]\u001b[0m Trial 73 finished with value: 0.0007513057848399221 and parameters: {'booster': 'gblinear', 'lambda': 2.2101226154281638e-08, 'alpha': 0.009141212516394026, 'subsample': 0.8339100174055103, 'colsample_bytree': 0.8547487194888671}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:16,144]\u001b[0m Trial 74 finished with value: 0.0010768714038741592 and parameters: {'booster': 'gblinear', 'lambda': 8.068769973420377e-07, 'alpha': 0.00047250550620920397, 'subsample': 0.8727708196494308, 'colsample_bytree': 0.6852967437806124}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:16,277]\u001b[0m Trial 75 finished with value: 0.0002172722278967508 and parameters: {'booster': 'gblinear', 'lambda': 2.519133896348054e-07, 'alpha': 0.0025382258612196376, 'subsample': 0.8045255102389766, 'colsample_bytree': 0.8173101378892953}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:16,675]\u001b[0m Trial 76 finished with value: 1.1214483558803179 and parameters: {'booster': 'gbtree', 'lambda': 1.0242648627894795e-08, 'alpha': 0.0012394106977124558, 'subsample': 0.841388619071718, 'colsample_bytree': 0.8901194816185048, 'max_depth': 7, 'min_child_weight': 5, 'eta': 6.120037966856761e-06, 'gamma': 0.025251789953355173, 'grow_policy': 'lossguide'}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:16,800]\u001b[0m Trial 77 finished with value: 0.0032303012334467893 and parameters: {'booster': 'gblinear', 'lambda': 1.4042756061130622e-06, 'alpha': 0.01934515134635338, 'subsample': 0.7525441514376163, 'colsample_bytree': 0.9296439756385302}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:16,936]\u001b[0m Trial 78 finished with value: 0.0004986751966358814 and parameters: {'booster': 'gblinear', 'lambda': 5.915289067391799e-06, 'alpha': 0.0007448555756341722, 'subsample': 0.6960738889432215, 'colsample_bytree': 0.7773780257789489}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:18,338]\u001b[0m Trial 79 finished with value: 0.0751756839862942 and parameters: {'booster': 'dart', 'lambda': 3.7590821914481376e-07, 'alpha': 0.00019199579949071143, 'subsample': 0.6380343025880225, 'colsample_bytree': 0.6429380393358566, 'max_depth': 3, 'min_child_weight': 8, 'eta': 0.06575210909406722, 'gamma': 4.124079939606212e-06, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.009548306598907102, 'skip_drop': 8.686840063733442e-07}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:18,475]\u001b[0m Trial 80 finished with value: 0.0029612277655725024 and parameters: {'booster': 'gblinear', 'lambda': 6.816426917072775e-08, 'alpha': 2.5810455496964757e-06, 'subsample': 0.7692241728924571, 'colsample_bytree': 0.9784159611875937}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:18,610]\u001b[0m Trial 81 finished with value: 0.00016587028303960443 and parameters: {'booster': 'gblinear', 'lambda': 6.285611949959734e-07, 'alpha': 0.0025956663096201944, 'subsample': 0.7139041103150372, 'colsample_bytree': 0.7480680755621911}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:18,744]\u001b[0m Trial 82 finished with value: 0.0002678129248868524 and parameters: {'booster': 'gblinear', 'lambda': 1.3813170747587892e-07, 'alpha': 0.004575113926836642, 'subsample': 0.6918222598673598, 'colsample_bytree': 0.6975045808365673}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:18,879]\u001b[0m Trial 83 finished with value: 0.0002086283702995149 and parameters: {'booster': 'gblinear', 'lambda': 2.1094238370786856e-06, 'alpha': 0.002841202971921344, 'subsample': 0.6643701271912268, 'colsample_bytree': 0.7925913408120774}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:40:19,011]\u001b[0m Trial 84 finished with value: 0.0008168722945868386 and parameters: {'booster': 'gblinear', 'lambda': 3.073091621824884e-07, 'alpha': 0.009526254725750869, 'subsample': 0.7246880758588601, 'colsample_bytree': 0.7459622968772459}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:19,145]\u001b[0m Trial 85 finished with value: 0.00029925428625616953 and parameters: {'booster': 'gblinear', 'lambda': 6.666214637971905e-07, 'alpha': 0.0016061915998790645, 'subsample': 0.8117084539995433, 'colsample_bytree': 0.8913265029568879}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:19,281]\u001b[0m Trial 86 finished with value: 0.0005986292463927283 and parameters: {'booster': 'gblinear', 'lambda': 3.122562687013643e-05, 'alpha': 0.0006047971863411577, 'subsample': 0.5531242638118365, 'colsample_bytree': 0.6607451152664383}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:19,417]\u001b[0m Trial 87 finished with value: 0.001979312508522414 and parameters: {'booster': 'gblinear', 'lambda': 1.6046393313808003e-06, 'alpha': 0.00010950903179351008, 'subsample': 0.786000348125338, 'colsample_bytree': 0.8576053756019776}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:19,551]\u001b[0m Trial 88 finished with value: 0.00031681547901302133 and parameters: {'booster': 'gblinear', 'lambda': 1.8032780191721123e-08, 'alpha': 0.004596630258195701, 'subsample': 0.7434126164025158, 'colsample_bytree': 0.8260311758904284}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:19,997]\u001b[0m Trial 89 finished with value: 1.1226957255963121 and parameters: {'booster': 'gbtree', 'lambda': 0.519978710128382, 'alpha': 0.001238523821195989, 'subsample': 0.7152574188453343, 'colsample_bytree': 0.9444288412869613, 'max_depth': 9, 'min_child_weight': 3, 'eta': 6.12112698116583e-08, 'gamma': 1.0959470709688219e-07, 'grow_policy': 'lossguide'}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:20,132]\u001b[0m Trial 90 finished with value: 0.0013067156281519187 and parameters: {'booster': 'gblinear', 'lambda': 3.241301892732262e-08, 'alpha': 0.0002948568026887629, 'subsample': 0.8719348233807828, 'colsample_bytree': 0.9160223683867817}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:20,266]\u001b[0m Trial 91 finished with value: 0.00017323926472474356 and parameters: {'booster': 'gblinear', 'lambda': 2.0285269810264762e-06, 'alpha': 0.0026590794667023148, 'subsample': 0.6648357111335619, 'colsample_bytree': 0.794164158900561}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:20,401]\u001b[0m Trial 92 finished with value: 0.00017229267018628098 and parameters: {'booster': 'gblinear', 'lambda': 4.878672805638436e-06, 'alpha': 0.0031853633911852917, 'subsample': 0.6503685620133759, 'colsample_bytree': 0.7566701334824129}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:20,528]\u001b[0m Trial 93 finished with value: 0.0010072635808650039 and parameters: {'booster': 'gblinear', 'lambda': 7.9988872152463e-06, 'alpha': 0.010650123283600078, 'subsample': 0.5869926170943289, 'colsample_bytree': 0.719034295558606}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:20,662]\u001b[0m Trial 94 finished with value: 0.0004071254626209173 and parameters: {'booster': 'gblinear', 'lambda': 1.5352070193650237e-05, 'alpha': 0.006159147962861149, 'subsample': 0.6770248183407124, 'colsample_bytree': 0.8008931869397982}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:20,795]\u001b[0m Trial 95 finished with value: 0.00019335008068108295 and parameters: {'booster': 'gblinear', 'lambda': 4.43060850920203e-06, 'alpha': 0.0030439277301673676, 'subsample': 0.6239522160826279, 'colsample_bytree': 0.750490362817423}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:20,934]\u001b[0m Trial 96 finished with value: 0.0002241273554658374 and parameters: {'booster': 'gblinear', 'lambda': 3.460140660820533e-05, 'alpha': 0.0016665409805746159, 'subsample': 0.6179302449247911, 'colsample_bytree': 0.7593677496424499}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:21,069]\u001b[0m Trial 97 finished with value: 0.00035650596929597493 and parameters: {'booster': 'gblinear', 'lambda': 5.6866585455645525e-06, 'alpha': 0.0010182952092795943, 'subsample': 0.6525223705115373, 'colsample_bytree': 0.7678080921501196}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:22,640]\u001b[0m Trial 98 finished with value: 1.0375768541050812 and parameters: {'booster': 'dart', 'lambda': 2.3141093530559588e-06, 'alpha': 0.01485714142164689, 'subsample': 0.7079598867760317, 'colsample_bytree': 0.7378291574797718, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.0004473343323393038, 'gamma': 0.0002677628668044908, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.1857334280913056e-06, 'skip_drop': 0.011216508216429187}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:22,773]\u001b[0m Trial 99 finished with value: 0.0005418707643542517 and parameters: {'booster': 'gblinear', 'lambda': 8.200907528213927e-05, 'alpha': 0.007543661118783851, 'subsample': 0.6870914533859767, 'colsample_bytree': 0.7020579630796822}. Best is trial 51 with value: 0.00015204737745907817.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:22,934]\u001b[0m A new study created in memory with name: no-name-11a5f7a4-73dd-438e-9d99-c7f9f45415b1\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:24,245]\u001b[0m Trial 0 finished with value: 1.0 and parameters: {'booster': 'dart', 'lambda': 0.08914143835289776, 'alpha': 7.191535171163739e-06, 'subsample': 0.7418707529221171, 'colsample_bytree': 0.37372446978162066, 'max_depth': 3, 'min_child_weight': 8, 'eta': 4.6830032898018034e-07, 'gamma': 1.1936664946265134e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.00018003266316405964, 'skip_drop': 0.0001700535257882358}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:24,365]\u001b[0m Trial 1 finished with value: 1.0 and parameters: {'booster': 'gblinear', 'lambda': 2.3443477519255076e-08, 'alpha': 0.00016991025070663246, 'subsample': 0.4344630555415607, 'colsample_bytree': 0.6792427547494806}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:25,057]\u001b[0m Trial 2 finished with value: 1.0 and parameters: {'booster': 'dart', 'lambda': 3.050195082444371e-08, 'alpha': 5.098591769727981e-06, 'subsample': 0.9704298162680505, 'colsample_bytree': 0.21195668758713027, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.00010603537643877606, 'gamma': 1.1555696454014234e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.9041056343467853, 'skip_drop': 0.00012839333762505362}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:25,188]\u001b[0m Trial 3 finished with value: 1.0 and parameters: {'booster': 'gbtree', 'lambda': 1.9742143310933664e-07, 'alpha': 0.054308559452976496, 'subsample': 0.2731625268791139, 'colsample_bytree': 0.6984474830725942, 'max_depth': 7, 'min_child_weight': 2, 'eta': 0.00199170944433645, 'gamma': 7.516424100909614e-05, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:25,322]\u001b[0m Trial 4 finished with value: 1.0 and parameters: {'booster': 'gbtree', 'lambda': 0.0010258223606108697, 'alpha': 0.06844715185060142, 'subsample': 0.4635866863489754, 'colsample_bytree': 0.9318961298256103, 'max_depth': 3, 'min_child_weight': 9, 'eta': 2.9107414639249043e-07, 'gamma': 0.00498154336409249, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:25,444]\u001b[0m Trial 5 finished with value: 1.0 and parameters: {'booster': 'gblinear', 'lambda': 7.660560069881343e-05, 'alpha': 4.9891418202275666e-05, 'subsample': 0.5131807358702587, 'colsample_bytree': 0.6105273394734034}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:25,564]\u001b[0m Trial 6 finished with value: 1.0 and parameters: {'booster': 'gblinear', 'lambda': 3.5514102735613574e-06, 'alpha': 0.0007671528797780145, 'subsample': 0.7056873317708796, 'colsample_bytree': 0.4065649620249473}. Best is trial 0 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:40:26,873]\u001b[0m Trial 7 finished with value: 1.0 and parameters: {'booster': 'dart', 'lambda': 0.000524744052895727, 'alpha': 1.791191486662552e-07, 'subsample': 0.44786905994958853, 'colsample_bytree': 0.6935798123711576, 'max_depth': 5, 'min_child_weight': 5, 'eta': 1.829545496551207e-05, 'gamma': 1.830282631381492e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.016606771731292377, 'skip_drop': 2.3742222209009016e-07}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:26,994]\u001b[0m Trial 8 finished with value: 1.0 and parameters: {'booster': 'gblinear', 'lambda': 0.24790999502224115, 'alpha': 1.3170640912321157e-08, 'subsample': 0.3851570304412307, 'colsample_bytree': 0.5003004244538675}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:27,085]\u001b[0m Trial 9 finished with value: 1.0 and parameters: {'booster': 'gblinear', 'lambda': 7.895329092616549e-07, 'alpha': 0.2541445947285768, 'subsample': 0.31044625233444506, 'colsample_bytree': 0.9138768824986059}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:28,442]\u001b[0m Trial 10 finished with value: 1.0 and parameters: {'booster': 'dart', 'lambda': 0.2840583067100194, 'alpha': 1.1947905260850801e-06, 'subsample': 0.7500555915739953, 'colsample_bytree': 0.21843827281202266, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.9391164679136743, 'gamma': 7.698871364871776e-06, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 3.382970819207696e-07, 'skip_drop': 0.04042574819207868}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:29,844]\u001b[0m Trial 11 finished with value: 1.0 and parameters: {'booster': 'dart', 'lambda': 0.012131831052812896, 'alpha': 0.002331262043584448, 'subsample': 0.6698509957177617, 'colsample_bytree': 0.43666068331662683, 'max_depth': 3, 'min_child_weight': 6, 'eta': 2.997950182568851e-08, 'gamma': 0.8273239581088994, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 2.556518114226722e-05, 'skip_drop': 0.00016618650387852915}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:31,235]\u001b[0m Trial 12 finished with value: 1.0 and parameters: {'booster': 'dart', 'lambda': 1.6696617048759863e-05, 'alpha': 5.15361155476097e-05, 'subsample': 0.8455183718358865, 'colsample_bytree': 0.7980361423460135, 'max_depth': 3, 'min_child_weight': 8, 'eta': 1.1301277137157319e-06, 'gamma': 1.2795582619474126e-06, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.00021894870441916604, 'skip_drop': 0.3562041359410943}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:31,370]\u001b[0m Trial 13 finished with value: 1.0 and parameters: {'booster': 'gblinear', 'lambda': 1.432050621177075e-08, 'alpha': 0.0009722513070539915, 'subsample': 0.5928479200135439, 'colsample_bytree': 0.3406954746675416}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:31,547]\u001b[0m Trial 14 finished with value: 1.0 and parameters: {'booster': 'gbtree', 'lambda': 0.01004571638928392, 'alpha': 4.776376639862809e-06, 'subsample': 0.854222280903319, 'colsample_bytree': 0.5419390860807205, 'max_depth': 7, 'min_child_weight': 4, 'eta': 1.023283686639747e-08, 'gamma': 4.869176381486791e-07, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:32,916]\u001b[0m Trial 15 finished with value: 1.0 and parameters: {'booster': 'dart', 'lambda': 0.021249787006420343, 'alpha': 0.00024217524564026108, 'subsample': 0.6003943388432242, 'colsample_bytree': 0.3266918780599186, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.012208587272301756, 'gamma': 0.004339996939073935, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 1.534010393592595e-08, 'skip_drop': 6.15707921013147e-08}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:33,101]\u001b[0m Trial 16 finished with value: 1.0 and parameters: {'booster': 'gblinear', 'lambda': 0.0007661898513734449, 'alpha': 0.014422585417597642, 'subsample': 0.5790191292746093, 'colsample_bytree': 0.7717656791606371}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:33,304]\u001b[0m Trial 17 finished with value: 1.0 and parameters: {'booster': 'gbtree', 'lambda': 0.023151516061133835, 'alpha': 4.026293387928919e-06, 'subsample': 0.8629554261094738, 'colsample_bytree': 0.5243312546558875, 'max_depth': 7, 'min_child_weight': 4, 'eta': 1.4990850045248083e-08, 'gamma': 5.921111269735046e-07, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:34,669]\u001b[0m Trial 18 finished with value: 1.0 and parameters: {'booster': 'dart', 'lambda': 0.07561452948079518, 'alpha': 6.768375577185982e-07, 'subsample': 0.764829950479831, 'colsample_bytree': 0.31928238532556935, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.027005812940675958, 'gamma': 0.0048103003332757065, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 2.5848293615305963e-08, 'skip_drop': 1.1164946514331318e-08}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:34,794]\u001b[0m Trial 19 finished with value: 1.0 and parameters: {'booster': 'gblinear', 'lambda': 0.0012812650203708749, 'alpha': 0.009631037122786252, 'subsample': 0.6016502971086438, 'colsample_bytree': 0.8082901982631889}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:34,952]\u001b[0m Trial 20 finished with value: 1.0 and parameters: {'booster': 'gbtree', 'lambda': 0.3763988875592631, 'alpha': 4.115853462815055e-08, 'subsample': 0.9786788598498092, 'colsample_bytree': 0.5194623730650029, 'max_depth': 9, 'min_child_weight': 4, 'eta': 5.761324420242236e-07, 'gamma': 2.169574687519514e-07, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:36,321]\u001b[0m Trial 21 finished with value: 1.0 and parameters: {'booster': 'dart', 'lambda': 0.036829132555022355, 'alpha': 5.927705210404857e-07, 'subsample': 0.8271465638527973, 'colsample_bytree': 0.3083545617199623, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.022521827711177746, 'gamma': 0.0009100619595362173, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 2.4378236943580583e-05, 'skip_drop': 2.9391737502507523e-06}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:37,677]\u001b[0m Trial 22 finished with value: 1.0 and parameters: {'booster': 'dart', 'lambda': 0.0013074640878373096, 'alpha': 2.030469200443383e-05, 'subsample': 0.7643358045188541, 'colsample_bytree': 0.39065321091797545, 'max_depth': 3, 'min_child_weight': 9, 'eta': 0.6822611131428288, 'gamma': 0.08603900556728815, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.0008064928791061331, 'skip_drop': 0.0020310832203141653}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:37,842]\u001b[0m Trial 23 finished with value: 1.0 and parameters: {'booster': 'gbtree', 'lambda': 0.6832257570848861, 'alpha': 0.8027630277631996, 'subsample': 0.9681557467566209, 'colsample_bytree': 0.8549501071232729, 'max_depth': 9, 'min_child_weight': 2, 'eta': 3.432119153413948e-06, 'gamma': 1.384590100067506e-07, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:37,992]\u001b[0m Trial 24 finished with value: 1.0 and parameters: {'booster': 'gbtree', 'lambda': 0.805820159205565, 'alpha': 2.2673822438398268e-08, 'subsample': 0.9053577421921364, 'colsample_bytree': 0.2754732291316645, 'max_depth': 9, 'min_child_weight': 7, 'eta': 8.911998978024013e-05, 'gamma': 9.590496888375176e-05, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:39,355]\u001b[0m Trial 25 finished with value: 1.0 and parameters: {'booster': 'dart', 'lambda': 0.003244649510783602, 'alpha': 1.859629865041496e-05, 'subsample': 0.7803968659775294, 'colsample_bytree': 0.42178430758791763, 'max_depth': 3, 'min_child_weight': 8, 'eta': 0.4719560670024896, 'gamma': 0.40449674252294454, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.0001936988160801125, 'skip_drop': 9.546717215360933e-06}. Best is trial 0 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:40:40,725]\u001b[0m Trial 26 finished with value: 1.0 and parameters: {'booster': 'dart', 'lambda': 0.1251893679574703, 'alpha': 0.6066860576276686, 'subsample': 0.6820647921374249, 'colsample_bytree': 0.9911923755859118, 'max_depth': 3, 'min_child_weight': 2, 'eta': 6.599494393843361e-06, 'gamma': 0.06813113692961846, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.005431166202522259, 'skip_drop': 0.002349368285996114}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:40,875]\u001b[0m Trial 27 finished with value: 1.0 and parameters: {'booster': 'gbtree', 'lambda': 0.6825079723456215, 'alpha': 1.0796198353956789e-07, 'subsample': 0.9189898312857608, 'colsample_bytree': 0.26039089530959986, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.00013795703826383147, 'gamma': 1.1600596982978067e-05, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:42,252]\u001b[0m Trial 28 finished with value: 1.0 and parameters: {'booster': 'dart', 'lambda': 0.005008235381834577, 'alpha': 1.5722975707064713e-05, 'subsample': 0.9109627384788535, 'colsample_bytree': 0.4472392202359638, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.0009592693005035974, 'gamma': 0.00018012945134433925, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 1.7263505922171704e-06, 'skip_drop': 7.88210181595092e-06}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:43,619]\u001b[0m Trial 29 finished with value: 1.0 and parameters: {'booster': 'dart', 'lambda': 0.09597062173986007, 'alpha': 0.00017963630154437137, 'subsample': 0.6609420974642228, 'colsample_bytree': 0.9890284665657736, 'max_depth': 3, 'min_child_weight': 8, 'eta': 7.794684637749239e-06, 'gamma': 0.6710149038893228, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.004836183793328357, 'skip_drop': 0.001602946454976563}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:43,780]\u001b[0m Trial 30 finished with value: 1.0 and parameters: {'booster': 'gbtree', 'lambda': 0.07096150248267785, 'alpha': 1.1211708897258362e-07, 'subsample': 0.6782417880220193, 'colsample_bytree': 0.6295937994712953, 'max_depth': 3, 'min_child_weight': 6, 'eta': 1.6367283131866945e-07, 'gamma': 9.923269437239197e-06, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:45,134]\u001b[0m Trial 31 finished with value: 1.0 and parameters: {'booster': 'dart', 'lambda': 0.14565675320914792, 'alpha': 1.9329654963964574e-07, 'subsample': 0.9201076885046016, 'colsample_bytree': 0.25685487210960206, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.0005325337484082407, 'gamma': 8.838581600891605e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 9.161556007960918e-07, 'skip_drop': 8.313105890930639e-06}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:46,514]\u001b[0m Trial 32 finished with value: 1.0 and parameters: {'booster': 'dart', 'lambda': 0.005093889111992772, 'alpha': 0.00020820783768225336, 'subsample': 0.9072680237545945, 'colsample_bytree': 0.47106416046354166, 'max_depth': 5, 'min_child_weight': 7, 'eta': 6.224105869223776e-05, 'gamma': 0.0005455795443313605, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 4.923967217380384e-06, 'skip_drop': 0.0014013321691842856}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:47,856]\u001b[0m Trial 33 finished with value: 1.0 and parameters: {'booster': 'dart', 'lambda': 0.0549947019581698, 'alpha': 1.1523805161892892e-05, 'subsample': 0.6364528218928736, 'colsample_bytree': 0.7386806646071238, 'max_depth': 3, 'min_child_weight': 6, 'eta': 1.0875339963141761e-07, 'gamma': 4.724417136805438e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.024256054061881773, 'skip_drop': 4.230616991775477e-05}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:49,217]\u001b[0m Trial 34 finished with value: 1.0 and parameters: {'booster': 'dart', 'lambda': 0.09980703214824255, 'alpha': 2.486388883450686e-07, 'subsample': 0.516937918551644, 'colsample_bytree': 0.6170071648118537, 'max_depth': 3, 'min_child_weight': 6, 'eta': 1.0244879858882004e-07, 'gamma': 5.536789532570359e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.0020877763647230347, 'skip_drop': 1.202537134087719e-06}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:49,356]\u001b[0m Trial 35 finished with value: 1.0 and parameters: {'booster': 'gblinear', 'lambda': 0.00019488559657454083, 'alpha': 1.2245068306886366e-06, 'subsample': 0.8086569746464872, 'colsample_bytree': 0.36731334824048023}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:49,512]\u001b[0m Trial 36 finished with value: 1.0 and parameters: {'booster': 'gbtree', 'lambda': 4.078573781530203e-05, 'alpha': 6.20943968483927e-07, 'subsample': 0.9962948804516628, 'colsample_bytree': 0.3801996412853997, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.12421196268299531, 'gamma': 0.12275234134524016, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:50,872]\u001b[0m Trial 37 finished with value: 1.0 and parameters: {'booster': 'dart', 'lambda': 0.04068954714748788, 'alpha': 2.6829976319176872e-08, 'subsample': 0.816180194126328, 'colsample_bytree': 0.5613669156317308, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.14162011488325144, 'gamma': 0.023554997918351115, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 2.9107869419377384e-05, 'skip_drop': 0.014211652163675181}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:52,258]\u001b[0m Trial 38 finished with value: 1.0 and parameters: {'booster': 'dart', 'lambda': 0.002131374243780978, 'alpha': 2.4380645699578872e-06, 'subsample': 0.7355894686666664, 'colsample_bytree': 0.8823991619581666, 'max_depth': 9, 'min_child_weight': 9, 'eta': 1.464349079549278e-06, 'gamma': 1.2112073378962767e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.0005587762341299446, 'skip_drop': 0.00027788003728683317}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:52,418]\u001b[0m Trial 39 finished with value: 1.0 and parameters: {'booster': 'gbtree', 'lambda': 0.00035568490236275043, 'alpha': 3.0259693747601788e-05, 'subsample': 0.7318474788990845, 'colsample_bytree': 0.2036808708672072, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.011836630253049896, 'gamma': 1.0414728690557699e-08, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:52,567]\u001b[0m Trial 40 finished with value: 1.0 and parameters: {'booster': 'gbtree', 'lambda': 0.6500648675187662, 'alpha': 0.05040176164399088, 'subsample': 0.9413033838873014, 'colsample_bytree': 0.25809645204444287, 'max_depth': 9, 'min_child_weight': 5, 'eta': 3.145025096048475e-06, 'gamma': 5.8105560679758e-05, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:52,722]\u001b[0m Trial 41 finished with value: 1.0 and parameters: {'booster': 'gbtree', 'lambda': 0.9806634877594781, 'alpha': 1.3742685709174236e-05, 'subsample': 0.7804913140543326, 'colsample_bytree': 0.41741399831790477, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.9430549776138093, 'gamma': 0.19988893611854766, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:52,891]\u001b[0m Trial 42 finished with value: 1.0 and parameters: {'booster': 'gbtree', 'lambda': 0.21931858611751426, 'alpha': 0.9619268804115875, 'subsample': 0.8788750307264579, 'colsample_bytree': 0.969509960340402, 'max_depth': 3, 'min_child_weight': 2, 'eta': 1.8929877441450425e-05, 'gamma': 0.02406117102308628, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:53,055]\u001b[0m Trial 43 finished with value: 1.0 and parameters: {'booster': 'gbtree', 'lambda': 0.3374051348112361, 'alpha': 0.2257667362048921, 'subsample': 0.8000794875249922, 'colsample_bytree': 0.8980902232696425, 'max_depth': 3, 'min_child_weight': 2, 'eta': 9.946074642939395e-05, 'gamma': 1.1429371340205301e-07, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:40:54,292]\u001b[0m Trial 44 finished with value: 1.0 and parameters: {'booster': 'dart', 'lambda': 0.9706447881735812, 'alpha': 5.98126400400729e-08, 'subsample': 0.7227584797010734, 'colsample_bytree': 0.27445248213034024, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.0002009329845723058, 'gamma': 3.626555497478554e-05, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.06583241166075146, 'skip_drop': 3.9301796084127786e-05}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:54,449]\u001b[0m Trial 45 finished with value: 1.0 and parameters: {'booster': 'gbtree', 'lambda': 0.005633276574481681, 'alpha': 1.6304394209841413e-08, 'subsample': 0.7007447228717866, 'colsample_bytree': 0.2959645883224171, 'max_depth': 3, 'min_child_weight': 8, 'eta': 2.8791925132642744e-05, 'gamma': 0.00018626362608486488, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:55,792]\u001b[0m Trial 46 finished with value: 1.0 and parameters: {'booster': 'dart', 'lambda': 0.005693320706716365, 'alpha': 6.10335931237936e-05, 'subsample': 0.8993111099767227, 'colsample_bytree': 0.4435434881759892, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.0013116341611974119, 'gamma': 0.02311196477819993, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.00012991836955814282, 'skip_drop': 1.2290997986642008e-05}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:57,115]\u001b[0m Trial 47 finished with value: 1.0 and parameters: {'booster': 'dart', 'lambda': 0.018535841304718637, 'alpha': 7.08810641798639e-06, 'subsample': 0.9506897229960903, 'colsample_bytree': 0.47784001785857294, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.0007168996874051965, 'gamma': 3.1844518265040372e-06, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 2.9439189932892716e-06, 'skip_drop': 1.5397491259180252e-06}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "/Users/nicholasteague/opt/anaconda3/envs/mlinfill/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-11-15 17:40:58,605]\u001b[0m A new study created in memory with name: no-name-84600321-a72f-4182-a6d3-12bb71756c5c\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:58,696]\u001b[0m Trial 0 finished with value: 0.8308386323822657 and parameters: {'booster': 'gblinear', 'lambda': 0.00010904815942452011, 'alpha': 0.12950891373667883, 'subsample': 0.24343187110417697, 'colsample_bytree': 0.8621586325434585}. Best is trial 0 with value: 0.8308386323822657.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:58,811]\u001b[0m Trial 1 finished with value: 0.9320355599055334 and parameters: {'booster': 'gblinear', 'lambda': 8.565175401692147e-07, 'alpha': 7.275136108661037e-07, 'subsample': 0.8407822639269267, 'colsample_bytree': 0.6555564654836268}. Best is trial 0 with value: 0.8308386323822657.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:59,063]\u001b[0m Trial 2 finished with value: 1.155019687915822 and parameters: {'booster': 'gbtree', 'lambda': 1.0741990728011665e-07, 'alpha': 1.6161630575264958e-06, 'subsample': 0.29166441484452266, 'colsample_bytree': 0.8117779075777081, 'max_depth': 7, 'min_child_weight': 3, 'eta': 1.2230338001903418e-08, 'gamma': 1.082097295353589e-07, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.8308386323822657.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:40:59,403]\u001b[0m Trial 3 finished with value: 1.0780800177080543 and parameters: {'booster': 'gbtree', 'lambda': 0.057123242824627024, 'alpha': 0.00014656349591996877, 'subsample': 0.4846849983150767, 'colsample_bytree': 0.9231357246031948, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.0010233656281346227, 'gamma': 3.1282240623706516e-07, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.8308386323822657.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:00,923]\u001b[0m Trial 4 finished with value: 1.1347361000106038 and parameters: {'booster': 'dart', 'lambda': 0.44760156091867515, 'alpha': 1.1408798157647226e-06, 'subsample': 0.68446104029476, 'colsample_bytree': 0.9660607315119816, 'max_depth': 7, 'min_child_weight': 5, 'eta': 0.0002450825281496833, 'gamma': 0.03194373968084038, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.1690225863024027e-08, 'skip_drop': 0.00010360164800800068}. Best is trial 0 with value: 0.8308386323822657.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:02,367]\u001b[0m Trial 5 finished with value: 0.8721242294610029 and parameters: {'booster': 'dart', 'lambda': 0.5288758672856381, 'alpha': 0.004849285865046433, 'subsample': 0.8410932904038477, 'colsample_bytree': 0.409625364792276, 'max_depth': 7, 'min_child_weight': 5, 'eta': 0.006236718244731761, 'gamma': 0.004824641393925516, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.0011441294250937606, 'skip_drop': 1.8175771162780082e-08}. Best is trial 0 with value: 0.8308386323822657.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:02,576]\u001b[0m Trial 6 finished with value: 1.0071604363291295 and parameters: {'booster': 'gbtree', 'lambda': 4.377864836201921e-08, 'alpha': 3.989298677320021e-06, 'subsample': 0.30192109460463795, 'colsample_bytree': 0.2860246646831288, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.002536851844398517, 'gamma': 0.00011356673689937785, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.8308386323822657.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:02,674]\u001b[0m Trial 7 finished with value: 0.8169708251775742 and parameters: {'booster': 'gblinear', 'lambda': 0.6570896240534687, 'alpha': 0.08145729903324538, 'subsample': 0.32735628236450864, 'colsample_bytree': 0.3303570187612701}. Best is trial 7 with value: 0.8169708251775742.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:02,792]\u001b[0m Trial 8 finished with value: 0.9356625342161541 and parameters: {'booster': 'gblinear', 'lambda': 2.0939241476188457e-08, 'alpha': 5.569022487833753e-06, 'subsample': 0.6265003573355862, 'colsample_bytree': 0.9246524117647912}. Best is trial 7 with value: 0.8169708251775742.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:03,037]\u001b[0m Trial 9 finished with value: 0.7722376505722386 and parameters: {'booster': 'gbtree', 'lambda': 0.0001994929727491633, 'alpha': 0.001294744258452571, 'subsample': 0.905385524766162, 'colsample_bytree': 0.8129754565769336, 'max_depth': 5, 'min_child_weight': 5, 'eta': 0.05806657383984317, 'gamma': 7.131522584268909e-06, 'grow_policy': 'lossguide'}. Best is trial 9 with value: 0.7722376505722386.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:03,238]\u001b[0m Trial 10 finished with value: 1.2395422803106477 and parameters: {'booster': 'gbtree', 'lambda': 0.0007180538599837302, 'alpha': 1.6766720793341968e-08, 'subsample': 0.9897195333121547, 'colsample_bytree': 0.6356221815457339, 'max_depth': 3, 'min_child_weight': 10, 'eta': 0.9547989016625952, 'gamma': 8.124043017839469e-06, 'grow_policy': 'lossguide'}. Best is trial 9 with value: 0.7722376505722386.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:03,338]\u001b[0m Trial 11 finished with value: 0.8940498212231693 and parameters: {'booster': 'gblinear', 'lambda': 0.0036332421019609185, 'alpha': 0.7357335266434688, 'subsample': 0.470107508947378, 'colsample_bytree': 0.4500703977704382}. Best is trial 9 with value: 0.7722376505722386.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:03,466]\u001b[0m Trial 12 finished with value: 0.7845914996459277 and parameters: {'booster': 'gblinear', 'lambda': 6.31246647377912e-06, 'alpha': 0.006985100433050237, 'subsample': 0.45139359402707524, 'colsample_bytree': 0.22233316322887556}. Best is trial 9 with value: 0.7722376505722386.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:03,666]\u001b[0m Trial 13 finished with value: 1.2490716840358156 and parameters: {'booster': 'gbtree', 'lambda': 2.565569089835532e-06, 'alpha': 0.0005297697023143085, 'subsample': 0.4762534416434637, 'colsample_bytree': 0.7544895901853015, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.5965086867947602, 'gamma': 0.0002213290666226557, 'grow_policy': 'lossguide'}. Best is trial 9 with value: 0.7722376505722386.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:41:04,806]\u001b[0m Trial 14 finished with value: 1.1549050454272027 and parameters: {'booster': 'dart', 'lambda': 9.090665246443764e-06, 'alpha': 0.005562017981869019, 'subsample': 0.7485350647826378, 'colsample_bytree': 0.5086623434089379, 'max_depth': 5, 'min_child_weight': 2, 'eta': 2.6668336000133183e-06, 'gamma': 0.7727204803591959, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.46154945735190805, 'skip_drop': 0.4764781481672655}. Best is trial 9 with value: 0.7722376505722386.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:05,083]\u001b[0m Trial 15 finished with value: 1.154453264023794 and parameters: {'booster': 'gbtree', 'lambda': 2.7131833785434767e-05, 'alpha': 0.0028102601389182794, 'subsample': 0.9985463453686384, 'colsample_bytree': 0.7416603220477905, 'max_depth': 5, 'min_child_weight': 5, 'eta': 6.675746227814243e-06, 'gamma': 3.4868818205693554e-06, 'grow_policy': 'lossguide'}. Best is trial 9 with value: 0.7722376505722386.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:05,213]\u001b[0m Trial 16 finished with value: 0.9295702247570093 and parameters: {'booster': 'gblinear', 'lambda': 0.00039687252657112144, 'alpha': 6.763142589702605e-05, 'subsample': 0.5418427065089483, 'colsample_bytree': 0.2302655693643463}. Best is trial 9 with value: 0.7722376505722386.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:05,332]\u001b[0m Trial 17 finished with value: 0.7932370932091183 and parameters: {'booster': 'gblinear', 'lambda': 0.013465324949759131, 'alpha': 0.03352686705497367, 'subsample': 0.3739383122071846, 'colsample_bytree': 0.5504663558600688}. Best is trial 9 with value: 0.7722376505722386.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:05,794]\u001b[0m Trial 18 finished with value: 0.7743604272229178 and parameters: {'booster': 'gbtree', 'lambda': 1.0600772428770815e-06, 'alpha': 4.343002718602965e-05, 'subsample': 0.8795781952270217, 'colsample_bytree': 0.6781860324392465, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.026783031931644503, 'gamma': 1.0756236000585425e-08, 'grow_policy': 'lossguide'}. Best is trial 9 with value: 0.7722376505722386.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:06,198]\u001b[0m Trial 19 finished with value: 0.7725050440915983 and parameters: {'booster': 'gbtree', 'lambda': 1.853460465676278e-07, 'alpha': 5.782679099604036e-05, 'subsample': 0.8887641486193845, 'colsample_bytree': 0.7092679442920321, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.03069425517207706, 'gamma': 1.0288590784280659e-08, 'grow_policy': 'lossguide'}. Best is trial 9 with value: 0.7722376505722386.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:06,468]\u001b[0m Trial 20 finished with value: 0.7842395180780588 and parameters: {'booster': 'gbtree', 'lambda': 6.202569241765848e-05, 'alpha': 3.5257261915314764e-08, 'subsample': 0.9305524967437985, 'colsample_bytree': 0.8098097902384666, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.07109051229302553, 'gamma': 1.0329517915145545e-08, 'grow_policy': 'lossguide'}. Best is trial 9 with value: 0.7722376505722386.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:06,836]\u001b[0m Trial 21 finished with value: 0.7649386940207871 and parameters: {'booster': 'gbtree', 'lambda': 4.632862705988899e-07, 'alpha': 3.5592257214259177e-05, 'subsample': 0.8518221258171129, 'colsample_bytree': 0.6923096757210916, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.03928152207857091, 'gamma': 1.3860608181268707e-08, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 0.7649386940207871.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:07,204]\u001b[0m Trial 22 finished with value: 0.8012231932534402 and parameters: {'booster': 'gbtree', 'lambda': 1.2704666512695678e-07, 'alpha': 0.0004640340955046259, 'subsample': 0.7773977791868576, 'colsample_bytree': 0.7330581102555191, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.06080908501285176, 'gamma': 3.331167268808716e-07, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 0.7649386940207871.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:07,543]\u001b[0m Trial 23 finished with value: 0.8286851905936439 and parameters: {'booster': 'gbtree', 'lambda': 5.764146178057638e-07, 'alpha': 1.961766653815981e-05, 'subsample': 0.7616443708419811, 'colsample_bytree': 0.5872511425026788, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.06891276574860314, 'gamma': 5.372871777261178e-06, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 0.7649386940207871.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:08,004]\u001b[0m Trial 24 finished with value: 1.1521027437845237 and parameters: {'booster': 'gbtree', 'lambda': 3.680449304391e-07, 'alpha': 0.0003941147991939346, 'subsample': 0.9173075351355806, 'colsample_bytree': 0.8277233995517722, 'max_depth': 9, 'min_child_weight': 6, 'eta': 3.393937166737991e-05, 'gamma': 6.43410828690599e-08, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 0.7649386940207871.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:08,267]\u001b[0m Trial 25 finished with value: 0.8555078503058626 and parameters: {'booster': 'gbtree', 'lambda': 0.0004944911636918215, 'alpha': 1.0780502935985715e-07, 'subsample': 0.7080529678375485, 'colsample_bytree': 0.6968973665037174, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.0067027845160541576, 'gamma': 8.868356562471785e-07, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 0.7649386940207871.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:08,610]\u001b[0m Trial 26 finished with value: 0.8362051125686648 and parameters: {'booster': 'gbtree', 'lambda': 1.4995090283477455e-08, 'alpha': 1.918523586478534e-05, 'subsample': 0.8242136097424861, 'colsample_bytree': 0.8749077295570528, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.18015785261535555, 'gamma': 4.1609637501791834e-08, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 0.7649386940207871.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:10,240]\u001b[0m Trial 27 finished with value: 1.1287154227385032 and parameters: {'booster': 'dart', 'lambda': 1.0336298008885304e-05, 'alpha': 0.0010663397253780967, 'subsample': 0.9182094234733366, 'colsample_bytree': 0.6013762491054819, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.0003193281949064038, 'gamma': 2.827155440413021e-05, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 2.224117293267253e-08, 'skip_drop': 1.9514827815232472e-08}. Best is trial 21 with value: 0.7649386940207871.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:10,468]\u001b[0m Trial 28 finished with value: 0.8011874430702909 and parameters: {'booster': 'gbtree', 'lambda': 1.5550697651521211e-07, 'alpha': 0.00012341540471428423, 'subsample': 0.6313257676407678, 'colsample_bytree': 0.9987043087756186, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.012453169559924112, 'gamma': 0.0007535846391849369, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 0.7649386940207871.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:10,740]\u001b[0m Trial 29 finished with value: 0.8659367404534464 and parameters: {'booster': 'gbtree', 'lambda': 0.00019277747758967117, 'alpha': 0.025192927453553674, 'subsample': 0.9528204419703978, 'colsample_bytree': 0.7661978035847505, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.23015518582723365, 'gamma': 8.098778498255974e-07, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 0.7649386940207871.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:11,109]\u001b[0m Trial 30 finished with value: 1.0180244959214095 and parameters: {'booster': 'gbtree', 'lambda': 0.0022949760043019627, 'alpha': 8.500464849373942e-06, 'subsample': 0.8052703757393147, 'colsample_bytree': 0.8917368762431701, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.0019347361810739558, 'gamma': 2.4241932422323346e-08, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.7649386940207871.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:11,503]\u001b[0m Trial 31 finished with value: 0.7754577347212321 and parameters: {'booster': 'gbtree', 'lambda': 2.342647182125897e-06, 'alpha': 4.5810862271804675e-05, 'subsample': 0.8827357440801358, 'colsample_bytree': 0.6772245318297598, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.01664862847012303, 'gamma': 2.3290968911361235e-08, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 0.7649386940207871.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:11,887]\u001b[0m Trial 32 finished with value: 0.7713296435144035 and parameters: {'booster': 'gbtree', 'lambda': 1.2543216105361545e-06, 'alpha': 2.1398778463226526e-07, 'subsample': 0.8627667420508595, 'colsample_bytree': 0.6956994785457763, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.027341726018569223, 'gamma': 1.0627895600497338e-08, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 0.7649386940207871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:41:12,278]\u001b[0m Trial 33 finished with value: 0.8523223001012615 and parameters: {'booster': 'gbtree', 'lambda': 4.0002272205696406e-05, 'alpha': 2.4617959306604994e-07, 'subsample': 0.8690880482642439, 'colsample_bytree': 0.8028529115958126, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.21858762724618366, 'gamma': 1.3352197250169206e-07, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 0.7649386940207871.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:12,639]\u001b[0m Trial 34 finished with value: 0.7805883871320711 and parameters: {'booster': 'gbtree', 'lambda': 6.364743112000819e-08, 'alpha': 3.1110413341585785e-07, 'subsample': 0.6886160481265144, 'colsample_bytree': 0.7123460251734743, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.04084567456812147, 'gamma': 8.788008885796795e-08, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 0.7649386940207871.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:13,036]\u001b[0m Trial 35 finished with value: 1.0176243286239295 and parameters: {'booster': 'gbtree', 'lambda': 3.455736414377679e-07, 'alpha': 0.00114023714628573, 'subsample': 0.9573466219210814, 'colsample_bytree': 0.6247256058253552, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.0019551674435462144, 'gamma': 1.4134561888321063e-06, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 0.7649386940207871.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:14,578]\u001b[0m Trial 36 finished with value: 1.1549969835950915 and parameters: {'booster': 'dart', 'lambda': 2.0450238388610926e-06, 'alpha': 0.00018461793560317337, 'subsample': 0.8565962500865574, 'colsample_bytree': 0.5617818831112407, 'max_depth': 7, 'min_child_weight': 7, 'eta': 2.786778759742944e-07, 'gamma': 1.809025866958276e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 2.023315541973656e-05, 'skip_drop': 0.7843155679785113}. Best is trial 21 with value: 0.7649386940207871.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:14,887]\u001b[0m Trial 37 finished with value: 0.8459684807489558 and parameters: {'booster': 'gbtree', 'lambda': 1.9421893582808303e-05, 'alpha': 2.015987270911581e-06, 'subsample': 0.22980450732238888, 'colsample_bytree': 0.8395030846120682, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.007728185673833332, 'gamma': 2.2253251248121353e-07, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 0.7649386940207871.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:15,189]\u001b[0m Trial 38 finished with value: 1.1550160565412573 and parameters: {'booster': 'gbtree', 'lambda': 2.2097549667055552e-07, 'alpha': 7.271324300643733e-07, 'subsample': 0.8076346884485373, 'colsample_bytree': 0.5012380018629711, 'max_depth': 7, 'min_child_weight': 10, 'eta': 5.619051447742242e-08, 'gamma': 1.0272785172776731e-08, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.7649386940207871.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:16,015]\u001b[0m Trial 39 finished with value: 0.7635286549813709 and parameters: {'booster': 'dart', 'lambda': 3.6460638314101855e-08, 'alpha': 1.5555619954104992e-05, 'subsample': 0.7261573055493354, 'colsample_bytree': 0.6603367735045382, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.2803530634476228, 'gamma': 5.5781602306507284e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.6493114347832025, 'skip_drop': 0.0002515456344730845}. Best is trial 39 with value: 0.7635286549813709.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:16,654]\u001b[0m Trial 40 finished with value: 0.7663903549447957 and parameters: {'booster': 'dart', 'lambda': 3.6590563629364614e-08, 'alpha': 8.930726173236371e-06, 'subsample': 0.7277564331463457, 'colsample_bytree': 0.7742246017020806, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.37582445125783165, 'gamma': 3.3731602835086137e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.8489196273585254, 'skip_drop': 0.00014180072019900572}. Best is trial 39 with value: 0.7635286549813709.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:17,346]\u001b[0m Trial 41 finished with value: 0.7672342012573643 and parameters: {'booster': 'dart', 'lambda': 3.0193781766506086e-08, 'alpha': 1.0955380835667993e-05, 'subsample': 0.744547488931351, 'colsample_bytree': 0.7827054057693529, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.2718269956135025, 'gamma': 3.3469322837673315e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.8736462818013383, 'skip_drop': 0.00014129664484064793}. Best is trial 39 with value: 0.7635286549813709.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:18,047]\u001b[0m Trial 42 finished with value: 0.7657376672885177 and parameters: {'booster': 'dart', 'lambda': 3.342103122736305e-08, 'alpha': 1.3181759323851673e-05, 'subsample': 0.7461300573149485, 'colsample_bytree': 0.7787892325720289, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.29347409098262117, 'gamma': 2.7017760958518384e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.8326435103109587, 'skip_drop': 0.0001600206999956925}. Best is trial 39 with value: 0.7635286549813709.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:18,640]\u001b[0m Trial 43 finished with value: 0.7679960270319608 and parameters: {'booster': 'dart', 'lambda': 1.0348113825949676e-08, 'alpha': 1.3085756484622336e-05, 'subsample': 0.7228718147928648, 'colsample_bytree': 0.7806310800517431, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.36630524064347947, 'gamma': 3.468830684592813e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.9976588470887553, 'skip_drop': 0.00015326760242910176}. Best is trial 39 with value: 0.7635286549813709.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:19,040]\u001b[0m Trial 44 finished with value: 0.7727275820312992 and parameters: {'booster': 'dart', 'lambda': 3.5437157036229236e-08, 'alpha': 3.3360621469176258e-06, 'subsample': 0.6524017528954359, 'colsample_bytree': 0.6494224430051864, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.8491314396836845, 'gamma': 1.1070489073449126e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.9419529061590117, 'skip_drop': 0.0007784705700740606}. Best is trial 39 with value: 0.7635286549813709.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:20,560]\u001b[0m Trial 45 finished with value: 0.9018626845112023 and parameters: {'booster': 'dart', 'lambda': 5.430649309875905e-08, 'alpha': 1.2543529350007978e-06, 'subsample': 0.5933322555437862, 'colsample_bytree': 0.8982996582247291, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.18099606841933674, 'gamma': 1.533860968040993e-06, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.023919499686217146, 'skip_drop': 0.001597348498269853}. Best is trial 39 with value: 0.7635286549813709.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:22,033]\u001b[0m Trial 46 finished with value: 0.810891385745322 and parameters: {'booster': 'dart', 'lambda': 2.5659789685274918e-08, 'alpha': 4.609357219626148e-06, 'subsample': 0.581359982878396, 'colsample_bytree': 0.8536980987063923, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.14274042164053044, 'gamma': 3.538313311755679e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.05531331489402786, 'skip_drop': 5.9687129739345514e-06}. Best is trial 39 with value: 0.7635286549813709.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:23,455]\u001b[0m Trial 47 finished with value: 0.8237615210303424 and parameters: {'booster': 'dart', 'lambda': 7.362190202317826e-08, 'alpha': 2.5604670163450366e-05, 'subsample': 0.7402366055144279, 'colsample_bytree': 0.7803969302485071, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.6090260985504063, 'gamma': 3.326371302321371e-08, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.038342915370359845, 'skip_drop': 8.414052987802323e-06}. Best is trial 39 with value: 0.7635286549813709.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:24,921]\u001b[0m Trial 48 finished with value: 0.7764505753270428 and parameters: {'booster': 'dart', 'lambda': 1.044682811432228e-08, 'alpha': 1.1114967832869565e-05, 'subsample': 0.6534815236472068, 'colsample_bytree': 0.9479029931054801, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.9605657029483798, 'gamma': 2.6023137435314895e-06, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.0743405602892206, 'skip_drop': 0.00909344168284748}. Best is trial 39 with value: 0.7635286549813709.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:41:25,646]\u001b[0m Trial 49 finished with value: 0.8564071480946813 and parameters: {'booster': 'dart', 'lambda': 2.2223702103225594e-08, 'alpha': 2.5259459279511334e-06, 'subsample': 0.7717609378795603, 'colsample_bytree': 0.7377916479806922, 'max_depth': 3, 'min_child_weight': 8, 'eta': 0.09064286737612952, 'gamma': 6.595410805284107e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.9576714539288351, 'skip_drop': 1.1090116708042186e-05}. Best is trial 39 with value: 0.7635286549813709.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:27,145]\u001b[0m Trial 50 finished with value: 0.838065719996871 and parameters: {'booster': 'dart', 'lambda': 1.014212517767205e-07, 'alpha': 0.00023501246593829662, 'subsample': 0.6902564843502118, 'colsample_bytree': 0.661650955083018, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.35030305181576843, 'gamma': 0.07535409488885692, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.014677294562397664, 'skip_drop': 0.002761015395175015}. Best is trial 39 with value: 0.7635286549813709.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:27,788]\u001b[0m Trial 51 finished with value: 0.7662341583033426 and parameters: {'booster': 'dart', 'lambda': 1.0092443276762426e-08, 'alpha': 8.847072919818033e-06, 'subsample': 0.7053570006940515, 'colsample_bytree': 0.777581506859042, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.4225860393143214, 'gamma': 1.919661963731859e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.8380779086028782, 'skip_drop': 6.832165056087355e-05}. Best is trial 39 with value: 0.7635286549813709.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:29,226]\u001b[0m Trial 52 finished with value: 0.7685660630167236 and parameters: {'booster': 'dart', 'lambda': 3.457771161491241e-08, 'alpha': 3.1754470328959035e-05, 'subsample': 0.8001982437710289, 'colsample_bytree': 0.7789466820426469, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.46512174797716765, 'gamma': 8.438053157182724e-08, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.17337224785783437, 'skip_drop': 5.904597597148181e-05}. Best is trial 39 with value: 0.7635286549813709.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:30,551]\u001b[0m Trial 53 finished with value: 0.7616722381177141 and parameters: {'booster': 'dart', 'lambda': 2.1108743122810948e-08, 'alpha': 9.068804732579815e-06, 'subsample': 0.7264008420916452, 'colsample_bytree': 0.7256527763262697, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.13020509903937477, 'gamma': 1.9047157263819191e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.19184365713525686, 'skip_drop': 0.00020443703620459148}. Best is trial 53 with value: 0.7616722381177141.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:32,158]\u001b[0m Trial 54 finished with value: 0.8083703746075024 and parameters: {'booster': 'dart', 'lambda': 1.636146773256145e-08, 'alpha': 5.2201290164024385e-06, 'subsample': 0.6592039080141177, 'colsample_bytree': 0.7263155992805802, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.12417376696982353, 'gamma': 1.5837902539914782e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.006384114959352574, 'skip_drop': 0.0004303647974697861}. Best is trial 53 with value: 0.7616722381177141.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:33,526]\u001b[0m A new study created in memory with name: no-name-e0c6e452-20c3-4bb4-9e8e-1355587c3ff2\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:33,678]\u001b[0m Trial 0 finished with value: 1.339704731278625 and parameters: {'booster': 'gbtree', 'lambda': 4.352717357840099e-08, 'alpha': 0.042928692149164706, 'subsample': 0.7307017195751648, 'colsample_bytree': 0.25896624937586926, 'max_depth': 3, 'min_child_weight': 9, 'eta': 3.451232365004047e-05, 'gamma': 0.0001451824042693043, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 1.339704731278625.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:33,804]\u001b[0m Trial 1 finished with value: 0.13487114975815415 and parameters: {'booster': 'gblinear', 'lambda': 0.005406569796011978, 'alpha': 2.68918804998704e-08, 'subsample': 0.5910292474887526, 'colsample_bytree': 0.7707557757248351}. Best is trial 1 with value: 0.13487114975815415.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:35,234]\u001b[0m Trial 2 finished with value: 1.346258997487969 and parameters: {'booster': 'dart', 'lambda': 9.843483015947154e-07, 'alpha': 0.011370397093894858, 'subsample': 0.8975471800210768, 'colsample_bytree': 0.7109787433185115, 'max_depth': 3, 'min_child_weight': 2, 'eta': 3.306378956638125e-08, 'gamma': 2.737593441372241e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 4.562424167432634e-05, 'skip_drop': 3.1273830671422455e-08}. Best is trial 1 with value: 0.13487114975815415.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:36,833]\u001b[0m Trial 3 finished with value: 0.15420419407282493 and parameters: {'booster': 'dart', 'lambda': 0.09339007713627735, 'alpha': 1.496829136201648e-08, 'subsample': 0.4083310626022907, 'colsample_bytree': 0.5628310640903118, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.3575278516546138, 'gamma': 0.0033987876344847294, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.004166554772176553, 'skip_drop': 1.6837702002610065e-08}. Best is trial 1 with value: 0.13487114975815415.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:37,700]\u001b[0m Trial 4 finished with value: 1.2519559844500734 and parameters: {'booster': 'dart', 'lambda': 1.813173887062825e-07, 'alpha': 7.584729099601551e-05, 'subsample': 0.2812762325962256, 'colsample_bytree': 0.2550833511811834, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.0005168647393397878, 'gamma': 0.0005195053187377497, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.4153624071347472, 'skip_drop': 0.004535901631108234}. Best is trial 1 with value: 0.13487114975815415.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:39,221]\u001b[0m Trial 5 finished with value: 1.3462590268440842 and parameters: {'booster': 'dart', 'lambda': 0.08680753065199459, 'alpha': 1.0953128128975998e-07, 'subsample': 0.6024809120375225, 'colsample_bytree': 0.6250231925775982, 'max_depth': 7, 'min_child_weight': 3, 'eta': 3.0644637501481893e-08, 'gamma': 4.187616946021611e-06, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.0606761553544054e-06, 'skip_drop': 0.005541694606314915}. Best is trial 1 with value: 0.13487114975815415.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:39,341]\u001b[0m Trial 6 finished with value: 0.13250372597960705 and parameters: {'booster': 'gblinear', 'lambda': 0.044292174881125315, 'alpha': 0.0006029542465432333, 'subsample': 0.2330566783272392, 'colsample_bytree': 0.9847838287062014}. Best is trial 6 with value: 0.13250372597960705.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:39,494]\u001b[0m Trial 7 finished with value: 0.14169392024598618 and parameters: {'booster': 'gblinear', 'lambda': 2.0453425488575767e-06, 'alpha': 4.3740293423440683e-07, 'subsample': 0.9720378324660426, 'colsample_bytree': 0.5903845117360782}. Best is trial 6 with value: 0.13250372597960705.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:39,731]\u001b[0m Trial 8 finished with value: 1.3462054591478085 and parameters: {'booster': 'gbtree', 'lambda': 0.9172844105204833, 'alpha': 0.00016787912037913587, 'subsample': 0.2685049941640048, 'colsample_bytree': 0.3474715499380732, 'max_depth': 5, 'min_child_weight': 7, 'eta': 3.067620256085439e-07, 'gamma': 0.11266457145066885, 'grow_policy': 'depthwise'}. Best is trial 6 with value: 0.13250372597960705.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:41,217]\u001b[0m Trial 9 finished with value: 0.8163354813819318 and parameters: {'booster': 'dart', 'lambda': 0.009361798106263686, 'alpha': 1.6445921003040896e-07, 'subsample': 0.5783485842362319, 'colsample_bytree': 0.5422346804286302, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.0030717737411377656, 'gamma': 2.075226107062962e-08, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.000346456654352075, 'skip_drop': 0.6224132009187439}. Best is trial 6 with value: 0.13250372597960705.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:41,352]\u001b[0m Trial 10 finished with value: 0.13755316695944755 and parameters: {'booster': 'gblinear', 'lambda': 0.00022355051766145777, 'alpha': 0.0003411816935090249, 'subsample': 0.41264328916650406, 'colsample_bytree': 0.993306482069608}. Best is trial 6 with value: 0.13250372597960705.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:41:41,487]\u001b[0m Trial 11 finished with value: 0.14101102654264558 and parameters: {'booster': 'gblinear', 'lambda': 0.0007713541140903697, 'alpha': 7.575761003720673e-06, 'subsample': 0.7351647778264314, 'colsample_bytree': 0.9839609705004255}. Best is trial 6 with value: 0.13250372597960705.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:41,590]\u001b[0m Trial 12 finished with value: 1.0537128742325927 and parameters: {'booster': 'gblinear', 'lambda': 0.0018867057311096936, 'alpha': 0.9466644723146059, 'subsample': 0.4565459467661465, 'colsample_bytree': 0.8226795567298435}. Best is trial 6 with value: 0.13250372597960705.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:41,726]\u001b[0m Trial 13 finished with value: 0.14196688367437083 and parameters: {'booster': 'gblinear', 'lambda': 3.5709489737715245e-05, 'alpha': 5.9527591152868435e-06, 'subsample': 0.21928387748875822, 'colsample_bytree': 0.8506093291251274}. Best is trial 6 with value: 0.13250372597960705.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:41,859]\u001b[0m Trial 14 finished with value: 0.14336730816575943 and parameters: {'booster': 'gblinear', 'lambda': 0.015162198552925056, 'alpha': 0.005869713256607825, 'subsample': 0.5629095538935862, 'colsample_bytree': 0.8348200442587472}. Best is trial 6 with value: 0.13250372597960705.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:41,994]\u001b[0m Trial 15 finished with value: 0.14073793038787374 and parameters: {'booster': 'gblinear', 'lambda': 0.14632090853403468, 'alpha': 7.338371489904637e-06, 'subsample': 0.7973727021784213, 'colsample_bytree': 0.7328716146779423}. Best is trial 6 with value: 0.13250372597960705.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:42,127]\u001b[0m Trial 16 finished with value: 0.13223000805197344 and parameters: {'booster': 'gblinear', 'lambda': 4.296042809027752e-05, 'alpha': 0.0018885366557122674, 'subsample': 0.34450011903810673, 'colsample_bytree': 0.8941205316023806}. Best is trial 16 with value: 0.13223000805197344.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:42,464]\u001b[0m Trial 17 finished with value: 687.7516416269877 and parameters: {'booster': 'gbtree', 'lambda': 2.5693979988003852e-05, 'alpha': 0.0018062284509439723, 'subsample': 0.3328302809385233, 'colsample_bytree': 0.940644357634644, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.9646517678310438, 'gamma': 1.590377015941397e-08, 'grow_policy': 'lossguide'}. Best is trial 16 with value: 0.13223000805197344.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:42,573]\u001b[0m Trial 18 finished with value: 0.3627844782647099 and parameters: {'booster': 'gblinear', 'lambda': 6.281847297768735e-06, 'alpha': 0.12872785146431875, 'subsample': 0.20491981548266078, 'colsample_bytree': 0.8794192415083683}. Best is trial 16 with value: 0.13223000805197344.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:42,708]\u001b[0m Trial 19 finished with value: 0.13306263159899434 and parameters: {'booster': 'gblinear', 'lambda': 0.0001940962772985228, 'alpha': 0.0010415294304184982, 'subsample': 0.47232973013432505, 'colsample_bytree': 0.44664101591501093}. Best is trial 16 with value: 0.13223000805197344.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:42,966]\u001b[0m Trial 20 finished with value: 1.3443750216508752 and parameters: {'booster': 'gbtree', 'lambda': 0.0007323817528286529, 'alpha': 4.251212166379055e-05, 'subsample': 0.3477749780324262, 'colsample_bytree': 0.9192263358297148, 'max_depth': 5, 'min_child_weight': 10, 'eta': 8.461576321959032e-06, 'gamma': 0.5080390243503535, 'grow_policy': 'depthwise'}. Best is trial 16 with value: 0.13223000805197344.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:43,100]\u001b[0m Trial 21 finished with value: 0.13334064113741448 and parameters: {'booster': 'gblinear', 'lambda': 0.00018583011154090463, 'alpha': 0.0011795882313223043, 'subsample': 0.49174055677458656, 'colsample_bytree': 0.44476714351468744}. Best is trial 16 with value: 0.13223000805197344.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:43,235]\u001b[0m Trial 22 finished with value: 0.13233144601848032 and parameters: {'booster': 'gblinear', 'lambda': 1.732746283299053e-05, 'alpha': 0.0011031082739974953, 'subsample': 0.3471618841536895, 'colsample_bytree': 0.46952202212957844}. Best is trial 16 with value: 0.13223000805197344.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:43,370]\u001b[0m Trial 23 finished with value: 0.14049221265753503 and parameters: {'booster': 'gblinear', 'lambda': 1.155660035799454e-05, 'alpha': 0.005560112401868685, 'subsample': 0.33380540334206477, 'colsample_bytree': 0.66534422056114}. Best is trial 16 with value: 0.13223000805197344.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:43,491]\u001b[0m Trial 24 finished with value: 0.2511605158156022 and parameters: {'booster': 'gblinear', 'lambda': 7.467997718041437e-07, 'alpha': 0.040121383197219085, 'subsample': 0.2883896362710701, 'colsample_bytree': 0.5055805661764858}. Best is trial 16 with value: 0.13223000805197344.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:43,624]\u001b[0m Trial 25 finished with value: 0.14251977359846482 and parameters: {'booster': 'gblinear', 'lambda': 3.2888807397812895e-05, 'alpha': 2.2676809663878692e-05, 'subsample': 0.38678122861846415, 'colsample_bytree': 0.3338686536199591}. Best is trial 16 with value: 0.13223000805197344.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:43,759]\u001b[0m Trial 26 finished with value: 0.13787664715089995 and parameters: {'booster': 'gblinear', 'lambda': 1.2299718545503252e-08, 'alpha': 0.00035154762714772206, 'subsample': 0.2436324488699818, 'colsample_bytree': 0.9073338762350757}. Best is trial 16 with value: 0.13223000805197344.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:43,891]\u001b[0m Trial 27 finished with value: 0.1320314104291381 and parameters: {'booster': 'gblinear', 'lambda': 8.984051887723714e-06, 'alpha': 0.0020800406952398063, 'subsample': 0.5211865926011137, 'colsample_bytree': 0.7946903849301467}. Best is trial 27 with value: 0.1320314104291381.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:44,182]\u001b[0m Trial 28 finished with value: 0.10002545517008717 and parameters: {'booster': 'gbtree', 'lambda': 2.2989385794804093e-07, 'alpha': 0.45165592570072444, 'subsample': 0.5290577583708429, 'colsample_bytree': 0.7862316168058019, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.027623042665088932, 'gamma': 6.869816039558147e-07, 'grow_policy': 'lossguide'}. Best is trial 28 with value: 0.10002545517008717.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:44,470]\u001b[0m Trial 29 finished with value: 0.3488085486144493 and parameters: {'booster': 'gbtree', 'lambda': 1.0690268183800025e-07, 'alpha': 0.8866648019182286, 'subsample': 0.6621821612011884, 'colsample_bytree': 0.7828877912256559, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.009054331618951156, 'gamma': 2.7091468739525706e-07, 'grow_policy': 'lossguide'}. Best is trial 28 with value: 0.10002545517008717.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:44,820]\u001b[0m Trial 30 finished with value: 0.08693171165881468 and parameters: {'booster': 'gbtree', 'lambda': 3.2718913256173648e-06, 'alpha': 0.15137314519001702, 'subsample': 0.6676430755988281, 'colsample_bytree': 0.6742599194564275, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.03564019773473928, 'gamma': 7.283454517030606e-07, 'grow_policy': 'lossguide'}. Best is trial 30 with value: 0.08693171165881468.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:45,147]\u001b[0m Trial 31 finished with value: 0.07828109525098226 and parameters: {'booster': 'gbtree', 'lambda': 2.7584319287594175e-06, 'alpha': 0.1681387219958259, 'subsample': 0.5244091194868219, 'colsample_bytree': 0.6722471643255279, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.04752178645543352, 'gamma': 1.3709640514078396e-06, 'grow_policy': 'lossguide'}. Best is trial 31 with value: 0.07828109525098226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:45,468]\u001b[0m Trial 32 finished with value: 0.08457261104862811 and parameters: {'booster': 'gbtree', 'lambda': 3.108736951555769e-06, 'alpha': 0.22099787685512134, 'subsample': 0.5215636953843507, 'colsample_bytree': 0.67731062206324, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.036952756630232626, 'gamma': 6.915915147121234e-07, 'grow_policy': 'lossguide'}. Best is trial 31 with value: 0.07828109525098226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:45,808]\u001b[0m Trial 33 finished with value: 0.08944604303170454 and parameters: {'booster': 'gbtree', 'lambda': 3.7181916118716917e-07, 'alpha': 0.19755282459076143, 'subsample': 0.6408055035111888, 'colsample_bytree': 0.6828620609550037, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.03740577855251186, 'gamma': 1.0818272511380986e-06, 'grow_policy': 'lossguide'}. Best is trial 31 with value: 0.07828109525098226.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:41:46,166]\u001b[0m Trial 34 finished with value: 0.0804829542555329 and parameters: {'booster': 'gbtree', 'lambda': 2.394567247645463e-06, 'alpha': 0.05301278560306863, 'subsample': 0.6526121355861731, 'colsample_bytree': 0.6894113109414093, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.060020061618686046, 'gamma': 6.980975771509543e-07, 'grow_policy': 'lossguide'}. Best is trial 31 with value: 0.07828109525098226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:46,526]\u001b[0m Trial 35 finished with value: 0.08618211626630905 and parameters: {'booster': 'gbtree', 'lambda': 2.688599789852749e-06, 'alpha': 0.030852772878866244, 'subsample': 0.7200124167380135, 'colsample_bytree': 0.6436729804236558, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.07759237654454688, 'gamma': 1.955846772732019e-07, 'grow_policy': 'lossguide'}. Best is trial 31 with value: 0.07828109525098226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:46,920]\u001b[0m Trial 36 finished with value: 0.09095169850005594 and parameters: {'booster': 'gbtree', 'lambda': 4.608510275984793e-08, 'alpha': 0.017175570516961648, 'subsample': 0.7627060825180814, 'colsample_bytree': 0.7248371230656755, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.15929419964394423, 'gamma': 9.011972574894309e-08, 'grow_policy': 'lossguide'}. Best is trial 31 with value: 0.07828109525098226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:47,298]\u001b[0m Trial 37 finished with value: 1.0769967396144717 and parameters: {'booster': 'gbtree', 'lambda': 1.4568562917859014e-06, 'alpha': 0.04973747696738229, 'subsample': 0.8632863783727341, 'colsample_bytree': 0.6108889595389081, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.0012968495715272427, 'gamma': 7.089639604525955e-06, 'grow_policy': 'lossguide'}. Best is trial 31 with value: 0.07828109525098226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:47,658]\u001b[0m Trial 38 finished with value: 0.0829534643366666 and parameters: {'booster': 'gbtree', 'lambda': 6.698222884953095e-07, 'alpha': 0.050140167796514264, 'subsample': 0.8163556651179227, 'colsample_bytree': 0.6315521344120868, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.10397078058362852, 'gamma': 1.110298852008636e-07, 'grow_policy': 'lossguide'}. Best is trial 31 with value: 0.07828109525098226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:47,997]\u001b[0m Trial 39 finished with value: 0.344124408289197 and parameters: {'booster': 'gbtree', 'lambda': 2.968301417159294e-08, 'alpha': 0.09363266670976989, 'subsample': 0.8309834063506266, 'colsample_bytree': 0.5628461260348913, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.008729201766961623, 'gamma': 4.589104836827229e-06, 'grow_policy': 'lossguide'}. Best is trial 31 with value: 0.07828109525098226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:48,342]\u001b[0m Trial 40 finished with value: 0.10116382260088246 and parameters: {'booster': 'gbtree', 'lambda': 6.651807561676512e-07, 'alpha': 0.32842590788782805, 'subsample': 0.9286333707704856, 'colsample_bytree': 0.7401276988869955, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.2627254724548947, 'gamma': 5.163286411207746e-08, 'grow_policy': 'lossguide'}. Best is trial 31 with value: 0.07828109525098226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:48,695]\u001b[0m Trial 41 finished with value: 0.0855210576411812 and parameters: {'booster': 'gbtree', 'lambda': 4.990389618644701e-06, 'alpha': 0.016406331703451668, 'subsample': 0.692912256833912, 'colsample_bytree': 0.6435374384494231, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.09436594404817435, 'gamma': 1.4841960113925895e-07, 'grow_policy': 'lossguide'}. Best is trial 31 with value: 0.07828109525098226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:49,062]\u001b[0m Trial 42 finished with value: 0.16544003572036292 and parameters: {'booster': 'gbtree', 'lambda': 5.320075050388948e-06, 'alpha': 0.01160766765690843, 'subsample': 0.6124343335187149, 'colsample_bytree': 0.6105763585833798, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.01536942435967754, 'gamma': 1.719663278237234e-07, 'grow_policy': 'lossguide'}. Best is trial 31 with value: 0.07828109525098226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:49,410]\u001b[0m Trial 43 finished with value: 0.08157525785468725 and parameters: {'booster': 'gbtree', 'lambda': 1.0832540543727497e-07, 'alpha': 0.06665751286266544, 'subsample': 0.6955527022998736, 'colsample_bytree': 0.5750370766880988, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.13493114895356864, 'gamma': 2.4449285722512947e-06, 'grow_policy': 'lossguide'}. Best is trial 31 with value: 0.07828109525098226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:50,882]\u001b[0m Trial 44 finished with value: 0.24344198502246792 and parameters: {'booster': 'dart', 'lambda': 7.75015668354843e-08, 'alpha': 0.4201349206962654, 'subsample': 0.5631474270970813, 'colsample_bytree': 0.5706833291027286, 'max_depth': 7, 'min_child_weight': 6, 'eta': 0.824909040177639, 'gamma': 2.0128767038575854e-06, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.2412699589699504e-08, 'skip_drop': 5.694084734740005e-06}. Best is trial 31 with value: 0.07828109525098226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:51,219]\u001b[0m Trial 45 finished with value: 0.8389259673142471 and parameters: {'booster': 'gbtree', 'lambda': 4.7397945178711276e-07, 'alpha': 0.06754309371485837, 'subsample': 0.6227033698870081, 'colsample_bytree': 0.5231668441246096, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.0028604488345347324, 'gamma': 1.4560583893000706e-05, 'grow_policy': 'lossguide'}. Best is trial 31 with value: 0.07828109525098226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:51,586]\u001b[0m Trial 46 finished with value: 0.08084013862969872 and parameters: {'booster': 'gbtree', 'lambda': 1.647882592770283e-07, 'alpha': 0.004478015677923398, 'subsample': 0.7669883492689609, 'colsample_bytree': 0.698189712411018, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.0993747970523807, 'gamma': 7.657359611076392e-07, 'grow_policy': 'lossguide'}. Best is trial 31 with value: 0.07828109525098226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:51,903]\u001b[0m Trial 47 finished with value: 0.08724586083260172 and parameters: {'booster': 'gbtree', 'lambda': 1.1694047904840094e-07, 'alpha': 0.0033512065496563233, 'subsample': 0.7732332552740657, 'colsample_bytree': 0.7045806626481571, 'max_depth': 7, 'min_child_weight': 6, 'eta': 0.20520351539976264, 'gamma': 4.408391025767915e-05, 'grow_policy': 'lossguide'}. Best is trial 31 with value: 0.07828109525098226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:52,902]\u001b[0m Trial 48 finished with value: 0.1856615528159554 and parameters: {'booster': 'dart', 'lambda': 1.4526933347924423e-08, 'alpha': 0.023726506263311367, 'subsample': 0.820373840431726, 'colsample_bytree': 0.7541222747888666, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.1240328512385856, 'gamma': 1.9427215241568055e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.5038135345375032, 'skip_drop': 9.279850550636944e-06}. Best is trial 31 with value: 0.07828109525098226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:53,285]\u001b[0m Trial 49 finished with value: 1.2997783289460043 and parameters: {'booster': 'gbtree', 'lambda': 2.8189839972287234e-07, 'alpha': 0.007793082466562493, 'subsample': 0.884978110988224, 'colsample_bytree': 0.5853786940897472, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.00020255393806644463, 'gamma': 4.116533847897908e-07, 'grow_policy': 'lossguide'}. Best is trial 31 with value: 0.07828109525098226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:53,592]\u001b[0m Trial 50 finished with value: 1.3418971544459473 and parameters: {'booster': 'gbtree', 'lambda': 1.278314375246639e-06, 'alpha': 0.05550390887798771, 'subsample': 0.719349985683402, 'colsample_bytree': 0.6366438346119909, 'max_depth': 7, 'min_child_weight': 7, 'eta': 1.896317068862513e-05, 'gamma': 6.637402736290841e-08, 'grow_policy': 'lossguide'}. Best is trial 31 with value: 0.07828109525098226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:53,943]\u001b[0m Trial 51 finished with value: 0.08202449847113824 and parameters: {'booster': 'gbtree', 'lambda': 1.730311509820905e-06, 'alpha': 0.2109492409271827, 'subsample': 0.690722387091477, 'colsample_bytree': 0.703353674727852, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.04294965948910993, 'gamma': 1.337816872169877e-06, 'grow_policy': 'lossguide'}. Best is trial 31 with value: 0.07828109525098226.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:41:54,255]\u001b[0m Trial 52 finished with value: 0.41537656228012726 and parameters: {'booster': 'gbtree', 'lambda': 4.8773173462455917e-08, 'alpha': 0.6941527225160331, 'subsample': 0.7534319776411115, 'colsample_bytree': 0.7003636325419961, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.007632436548444721, 'gamma': 0.0001278291064192302, 'grow_policy': 'lossguide'}. Best is trial 31 with value: 0.07828109525098226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:54,585]\u001b[0m Trial 53 finished with value: 0.10798185496917305 and parameters: {'booster': 'gbtree', 'lambda': 1.6780553784407522e-07, 'alpha': 0.07063538571539997, 'subsample': 0.692740905324809, 'colsample_bytree': 0.5370639733988058, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.38596999855520875, 'gamma': 2.430562973253454e-06, 'grow_policy': 'lossguide'}. Best is trial 31 with value: 0.07828109525098226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:54,976]\u001b[0m Trial 54 finished with value: 0.08937319137152822 and parameters: {'booster': 'gbtree', 'lambda': 7.15553639111697e-05, 'alpha': 0.12582309777562203, 'subsample': 0.7953885972069674, 'colsample_bytree': 0.7563010856879244, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.04888207599514164, 'gamma': 1.737154866930543e-05, 'grow_policy': 'lossguide'}. Best is trial 31 with value: 0.07828109525098226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:55,308]\u001b[0m Trial 55 finished with value: 0.1301429917244174 and parameters: {'booster': 'gbtree', 'lambda': 1.0926129593744953e-06, 'alpha': 0.02571278052365816, 'subsample': 0.696322313136821, 'colsample_bytree': 0.4881503712631985, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.39653746409383733, 'gamma': 7.4721558289003465e-06, 'grow_policy': 'lossguide'}. Best is trial 31 with value: 0.07828109525098226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:56,880]\u001b[0m Trial 56 finished with value: 0.08865612692975143 and parameters: {'booster': 'dart', 'lambda': 4.4134513576134503e-07, 'alpha': 0.27131210474700446, 'subsample': 0.9375556386887727, 'colsample_bytree': 0.5962117409509694, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.08812598928688085, 'gamma': 0.0005221877997750202, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.2391574003397286e-08, 'skip_drop': 0.2728108637080472}. Best is trial 31 with value: 0.07828109525098226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:57,148]\u001b[0m Trial 57 finished with value: 0.18101899652508166 and parameters: {'booster': 'gbtree', 'lambda': 2.0743960492337944e-08, 'alpha': 0.009972922113407385, 'subsample': 0.5908978312488232, 'colsample_bytree': 0.21582731627763918, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.016455352939488428, 'gamma': 1.314848607574595e-06, 'grow_policy': 'lossguide'}. Best is trial 31 with value: 0.07828109525098226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:57,361]\u001b[0m Trial 58 finished with value: 0.789380541813667 and parameters: {'booster': 'gbtree', 'lambda': 1.7154556600407658e-06, 'alpha': 0.0048289191781226235, 'subsample': 0.8463177305489235, 'colsample_bytree': 0.81029566384808, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.0034142687098321703, 'gamma': 2.7722461297636925e-08, 'grow_policy': 'depthwise'}. Best is trial 31 with value: 0.07828109525098226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:57,617]\u001b[0m Trial 59 finished with value: 0.1085668834739506 and parameters: {'booster': 'gbtree', 'lambda': 1.9910291928227818e-07, 'alpha': 1.1707147525280378e-06, 'subsample': 0.7389335271485811, 'colsample_bytree': 0.707921559811835, 'max_depth': 5, 'min_child_weight': 5, 'eta': 0.4646048370339117, 'gamma': 3.759555356420834e-07, 'grow_policy': 'lossguide'}. Best is trial 31 with value: 0.07828109525098226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:57,922]\u001b[0m Trial 60 finished with value: 1.3459784605289071 and parameters: {'booster': 'gbtree', 'lambda': 6.349594261281495e-08, 'alpha': 0.10347607987729929, 'subsample': 0.6477618520543853, 'colsample_bytree': 0.6561910175110234, 'max_depth': 7, 'min_child_weight': 6, 'eta': 1.2446480992741613e-06, 'gamma': 0.012546497142447006, 'grow_policy': 'depthwise'}. Best is trial 31 with value: 0.07828109525098226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:58,251]\u001b[0m Trial 61 finished with value: 0.0825786374787407 and parameters: {'booster': 'gbtree', 'lambda': 2.875977779519264e-06, 'alpha': 0.22288420732367778, 'subsample': 0.5279066793996099, 'colsample_bytree': 0.6869287645554688, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.045131928049621545, 'gamma': 6.739384595965256e-07, 'grow_policy': 'lossguide'}. Best is trial 31 with value: 0.07828109525098226.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:58,581]\u001b[0m Trial 62 finished with value: 0.07693108947142341 and parameters: {'booster': 'gbtree', 'lambda': 9.863696835228985e-07, 'alpha': 0.4249559972193367, 'subsample': 0.5517465312155193, 'colsample_bytree': 0.6856876285129289, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.12628468284587804, 'gamma': 4.015523674494394e-06, 'grow_policy': 'lossguide'}. Best is trial 62 with value: 0.07693108947142341.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:58,854]\u001b[0m Trial 63 finished with value: 0.1367478653161185 and parameters: {'booster': 'gbtree', 'lambda': 1.7073020615875947e-05, 'alpha': 0.7641394796710737, 'subsample': 0.43641942983185267, 'colsample_bytree': 0.6854454896922545, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.020288779130535124, 'gamma': 3.7688028265924336e-06, 'grow_policy': 'lossguide'}. Best is trial 62 with value: 0.07693108947142341.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:59,190]\u001b[0m Trial 64 finished with value: 0.09402439597163355 and parameters: {'booster': 'gbtree', 'lambda': 1.1001741483498526e-05, 'alpha': 0.3862837510492036, 'subsample': 0.49366697838824797, 'colsample_bytree': 0.7273370041528457, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.19859512630088916, 'gamma': 3.6651661363070935e-05, 'grow_policy': 'lossguide'}. Best is trial 62 with value: 0.07693108947142341.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:59,545]\u001b[0m Trial 65 finished with value: 0.08030651127617251 and parameters: {'booster': 'gbtree', 'lambda': 2.8279374858961274e-06, 'alpha': 0.19412461436640843, 'subsample': 0.5777581491049226, 'colsample_bytree': 0.7722545032833743, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.05116873718451569, 'gamma': 5.467551102863627e-07, 'grow_policy': 'lossguide'}. Best is trial 62 with value: 0.07693108947142341.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:41:59,899]\u001b[0m Trial 66 finished with value: 0.44133596820385973 and parameters: {'booster': 'gbtree', 'lambda': 8.825171852006479e-07, 'alpha': 0.13259015661521834, 'subsample': 0.5670377596951742, 'colsample_bytree': 0.84885172369569, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.006908630262630519, 'gamma': 1.2042550397320472e-05, 'grow_policy': 'depthwise'}. Best is trial 62 with value: 0.07693108947142341.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:01,451]\u001b[0m Trial 67 finished with value: 0.1601048135831222 and parameters: {'booster': 'dart', 'lambda': 5.997902780639692e-06, 'alpha': 0.9652307527324259, 'subsample': 0.5964664588831016, 'colsample_bytree': 0.7739176465536209, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.7528810298327652, 'gamma': 4.124775733137031e-07, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 4.600855155628341e-06, 'skip_drop': 7.992683314854876e-07}. Best is trial 62 with value: 0.07693108947142341.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:01,765]\u001b[0m Trial 68 finished with value: 0.0767488898808987 and parameters: {'booster': 'gbtree', 'lambda': 0.7762763772798381, 'alpha': 1.1678837331765932e-08, 'subsample': 0.5488711070686015, 'colsample_bytree': 0.7579909363110482, 'max_depth': 7, 'min_child_weight': 5, 'eta': 0.06299037371716855, 'gamma': 1.298748250450909e-06, 'grow_policy': 'lossguide'}. Best is trial 68 with value: 0.0767488898808987.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:02,117]\u001b[0m Trial 69 finished with value: 1.3462479477255356 and parameters: {'booster': 'gbtree', 'lambda': 0.010388036153963727, 'alpha': 1.429199229261298e-08, 'subsample': 0.5543666649806093, 'colsample_bytree': 0.7480217041351342, 'max_depth': 7, 'min_child_weight': 4, 'eta': 7.384177348959464e-08, 'gamma': 3.5246491741112167e-06, 'grow_policy': 'lossguide'}. Best is trial 68 with value: 0.0767488898808987.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:42:02,389]\u001b[0m Trial 70 finished with value: 1.0746850865800892 and parameters: {'booster': 'gbtree', 'lambda': 0.32330863730536535, 'alpha': 3.070893347583297e-08, 'subsample': 0.47831211761185294, 'colsample_bytree': 0.8182540538696488, 'max_depth': 5, 'min_child_weight': 2, 'eta': 0.0013460212282141296, 'gamma': 8.783876679704007e-07, 'grow_policy': 'lossguide'}. Best is trial 68 with value: 0.0767488898808987.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:02,807]\u001b[0m Trial 71 finished with value: 0.1404651988204131 and parameters: {'booster': 'gbtree', 'lambda': 0.0024249485178122277, 'alpha': 0.0001465838610004192, 'subsample': 0.640148096150312, 'colsample_bytree': 0.7159958900555881, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.01770970144553788, 'gamma': 1.164145075113267e-06, 'grow_policy': 'lossguide'}. Best is trial 68 with value: 0.0767488898808987.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:03,128]\u001b[0m Trial 72 finished with value: 0.08110408310783279 and parameters: {'booster': 'gbtree', 'lambda': 0.03729276706763083, 'alpha': 1.7752690393871085e-06, 'subsample': 0.5446792193236023, 'colsample_bytree': 0.7605576844138532, 'max_depth': 7, 'min_child_weight': 5, 'eta': 0.06543737977925719, 'gamma': 3.375408856650225e-07, 'grow_policy': 'lossguide'}. Best is trial 68 with value: 0.0767488898808987.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:03,446]\u001b[0m Trial 73 finished with value: 0.0866281092951494 and parameters: {'booster': 'gbtree', 'lambda': 0.058653758129925175, 'alpha': 2.079952639019444e-06, 'subsample': 0.5385793266129428, 'colsample_bytree': 0.7667622249832851, 'max_depth': 7, 'min_child_weight': 5, 'eta': 0.09011842705885917, 'gamma': 4.099428984119939e-07, 'grow_policy': 'lossguide'}. Best is trial 68 with value: 0.0767488898808987.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:03,769]\u001b[0m Trial 74 finished with value: 0.07347138908273461 and parameters: {'booster': 'gbtree', 'lambda': 0.5807053161909373, 'alpha': 9.03186223156328e-08, 'subsample': 0.4974387801736645, 'colsample_bytree': 0.8740522491919119, 'max_depth': 7, 'min_child_weight': 6, 'eta': 0.055786716466972024, 'gamma': 2.5433591115766304e-07, 'grow_policy': 'lossguide'}. Best is trial 74 with value: 0.07347138908273461.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:04,078]\u001b[0m Trial 75 finished with value: 0.07554423303304064 and parameters: {'booster': 'gbtree', 'lambda': 0.8639305056228678, 'alpha': 6.848656954394555e-08, 'subsample': 0.4385935762919432, 'colsample_bytree': 0.8816143602550792, 'max_depth': 7, 'min_child_weight': 6, 'eta': 0.06519803963663633, 'gamma': 1.0754564605358026e-08, 'grow_policy': 'lossguide'}. Best is trial 74 with value: 0.07347138908273461.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:04,428]\u001b[0m Trial 76 finished with value: 0.10949406294286834 and parameters: {'booster': 'gbtree', 'lambda': 0.21615122663293682, 'alpha': 4.233389500483682e-08, 'subsample': 0.5067015879633886, 'colsample_bytree': 0.9570119216402845, 'max_depth': 7, 'min_child_weight': 6, 'eta': 0.022878803337223905, 'gamma': 6.90959830792341e-08, 'grow_policy': 'lossguide'}. Best is trial 74 with value: 0.07347138908273461.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:04,718]\u001b[0m Trial 77 finished with value: 0.28137870551885064 and parameters: {'booster': 'gbtree', 'lambda': 0.900986184364929, 'alpha': 7.605327849789621e-08, 'subsample': 0.44951531609706646, 'colsample_bytree': 0.8565129121231256, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.0111043682254406, 'gamma': 2.853867296816284e-08, 'grow_policy': 'depthwise'}. Best is trial 74 with value: 0.07347138908273461.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:05,015]\u001b[0m Trial 78 finished with value: 0.0825272147613775 and parameters: {'booster': 'gbtree', 'lambda': 0.6974675986591226, 'alpha': 3.027485688341471e-07, 'subsample': 0.3952361253175882, 'colsample_bytree': 0.8910383720951919, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.2618237536993548, 'gamma': 1.368186800733575e-07, 'grow_policy': 'lossguide'}. Best is trial 74 with value: 0.07347138908273461.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:05,321]\u001b[0m Trial 79 finished with value: 0.6998845463576527 and parameters: {'booster': 'gbtree', 'lambda': 0.5535449613712432, 'alpha': 1.5704609873110842e-07, 'subsample': 0.4145876722344958, 'colsample_bytree': 0.9359029469564364, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.004106024165875546, 'gamma': 1.1801502315155366e-08, 'grow_policy': 'lossguide'}. Best is trial 74 with value: 0.07347138908273461.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:06,862]\u001b[0m Trial 80 finished with value: 0.08745469975851994 and parameters: {'booster': 'dart', 'lambda': 0.10438031049286298, 'alpha': 1.0383163770390175e-08, 'subsample': 0.4663641078464769, 'colsample_bytree': 0.802234702648749, 'max_depth': 7, 'min_child_weight': 6, 'eta': 0.03690337549603587, 'gamma': 6.586095706674229e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.006802916907977565, 'skip_drop': 0.001190147745536569}. Best is trial 74 with value: 0.07347138908273461.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:07,247]\u001b[0m A new study created in memory with name: no-name-735a6ff7-0c74-409b-a649-1c72df5612b5\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:08,728]\u001b[0m Trial 0 finished with value: 1.2864785089702182 and parameters: {'booster': 'dart', 'lambda': 2.2536662911814278e-05, 'alpha': 0.45658727181829795, 'subsample': 0.4270713099456731, 'colsample_bytree': 0.6257968311243329, 'max_depth': 9, 'min_child_weight': 7, 'eta': 1.8990019112604965e-05, 'gamma': 0.06465388341450277, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 0.00027167990040877416, 'skip_drop': 5.036282663003903e-08}. Best is trial 0 with value: 1.2864785089702182.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:08,848]\u001b[0m Trial 1 finished with value: 0.40217894887819056 and parameters: {'booster': 'gblinear', 'lambda': 4.1684002022991935e-06, 'alpha': 3.0681975230875215e-05, 'subsample': 0.7748276070673612, 'colsample_bytree': 0.3639152293315053}. Best is trial 1 with value: 0.40217894887819056.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:10,047]\u001b[0m Trial 2 finished with value: 1.1691550888388267 and parameters: {'booster': 'dart', 'lambda': 1.489514196184651e-07, 'alpha': 0.012745550246253465, 'subsample': 0.2952698258247608, 'colsample_bytree': 0.6350596608528836, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.0006736398931548714, 'gamma': 5.280255392967253e-05, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.2506548719399752, 'skip_drop': 1.433437625432611e-05}. Best is trial 1 with value: 0.40217894887819056.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:10,138]\u001b[0m Trial 3 finished with value: 0.7428993588325051 and parameters: {'booster': 'gblinear', 'lambda': 0.0807034418882783, 'alpha': 0.40232550654789934, 'subsample': 0.7579250675006441, 'colsample_bytree': 0.9723110290081098}. Best is trial 1 with value: 0.40217894887819056.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:11,490]\u001b[0m Trial 4 finished with value: 1.2898211691258 and parameters: {'booster': 'dart', 'lambda': 2.704673471163255e-05, 'alpha': 1.6973023871682978e-07, 'subsample': 0.9444244115148772, 'colsample_bytree': 0.31700449638450445, 'max_depth': 3, 'min_child_weight': 6, 'eta': 1.0983912789842257e-06, 'gamma': 4.2438060610184726e-07, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.000309931220113469, 'skip_drop': 0.021108262960727885}. Best is trial 1 with value: 0.40217894887819056.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:11,753]\u001b[0m Trial 5 finished with value: 1.289849183141855 and parameters: {'booster': 'gbtree', 'lambda': 3.712660059295197e-06, 'alpha': 3.897351896598687e-06, 'subsample': 0.9533109270064124, 'colsample_bytree': 0.7665306741970264, 'max_depth': 5, 'min_child_weight': 2, 'eta': 7.934737204170344e-07, 'gamma': 0.0013452530567573137, 'grow_policy': 'depthwise'}. Best is trial 1 with value: 0.40217894887819056.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:13,141]\u001b[0m Trial 6 finished with value: 0.32407929757494225 and parameters: {'booster': 'dart', 'lambda': 2.935697335798478e-07, 'alpha': 0.0002533714917149467, 'subsample': 0.5711916738593554, 'colsample_bytree': 0.74736176111736, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.054685287029548627, 'gamma': 3.9522436320186105e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 4.956513004137891e-06, 'skip_drop': 1.0747308137642074e-05}. Best is trial 6 with value: 0.32407929757494225.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:42:13,382]\u001b[0m Trial 7 finished with value: 1.7507591288708657 and parameters: {'booster': 'gbtree', 'lambda': 0.03563778039264554, 'alpha': 1.7321176296430236e-06, 'subsample': 0.2023809763291828, 'colsample_bytree': 0.7987808962484704, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.4641279789283497, 'gamma': 0.02729110306181355, 'grow_policy': 'lossguide'}. Best is trial 6 with value: 0.32407929757494225.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:13,502]\u001b[0m Trial 8 finished with value: 0.4039150931183525 and parameters: {'booster': 'gblinear', 'lambda': 1.2209639993561865e-06, 'alpha': 7.569686345683957e-05, 'subsample': 0.305912855412074, 'colsample_bytree': 0.41204873377779844}. Best is trial 6 with value: 0.32407929757494225.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:14,990]\u001b[0m Trial 9 finished with value: 1.2899674893413426 and parameters: {'booster': 'dart', 'lambda': 0.6287208408327983, 'alpha': 6.3898970567589906e-06, 'subsample': 0.37583783721225883, 'colsample_bytree': 0.2322770150070099, 'max_depth': 5, 'min_child_weight': 10, 'eta': 2.1782485441114257e-07, 'gamma': 0.339363787276528, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 6.864971901554332e-06, 'skip_drop': 9.789680490550241e-08}. Best is trial 6 with value: 0.32407929757494225.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:16,454]\u001b[0m Trial 10 finished with value: 0.39664987073013197 and parameters: {'booster': 'dart', 'lambda': 1.7237135527090753e-08, 'alpha': 0.0018898951109809227, 'subsample': 0.5741229881650439, 'colsample_bytree': 0.9356217012449748, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.2831415916011409, 'gamma': 1.057825610149736e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.523969025194142e-08, 'skip_drop': 0.0003747110865053157}. Best is trial 6 with value: 0.32407929757494225.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:17,904]\u001b[0m Trial 11 finished with value: 0.576989704577781 and parameters: {'booster': 'dart', 'lambda': 1.946801697572848e-08, 'alpha': 0.0019183805550890096, 'subsample': 0.5618568381929264, 'colsample_bytree': 0.9727543030534813, 'max_depth': 3, 'min_child_weight': 3, 'eta': 0.6669712400242136, 'gamma': 1.285111998151732e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.2788240814816564e-08, 'skip_drop': 0.0005374675698842495}. Best is trial 6 with value: 0.32407929757494225.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:19,334]\u001b[0m Trial 12 finished with value: 0.6150599981513881 and parameters: {'booster': 'dart', 'lambda': 1.0341628128686443e-08, 'alpha': 0.0016020120462642508, 'subsample': 0.570231762619127, 'colsample_bytree': 0.8234571201260384, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.0061063529581497486, 'gamma': 1.3275592326277548e-08, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 4.145535679326872e-08, 'skip_drop': 3.249551823048555e-05}. Best is trial 6 with value: 0.32407929757494225.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:20,864]\u001b[0m Trial 13 finished with value: 0.3638703533884722 and parameters: {'booster': 'dart', 'lambda': 0.0006723001653904039, 'alpha': 0.0015935232545620948, 'subsample': 0.6934637903829581, 'colsample_bytree': 0.8803972523573829, 'max_depth': 5, 'min_child_weight': 2, 'eta': 0.014262802027338251, 'gamma': 1.6392058828249807e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 8.471817351125902e-07, 'skip_drop': 0.0014713446168284235}. Best is trial 6 with value: 0.32407929757494225.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:22,342]\u001b[0m Trial 14 finished with value: 0.4884015310768694 and parameters: {'booster': 'dart', 'lambda': 0.00046765873921465143, 'alpha': 0.029912475494490217, 'subsample': 0.7344151051269848, 'colsample_bytree': 0.502540893029561, 'max_depth': 5, 'min_child_weight': 2, 'eta': 0.009187580874928873, 'gamma': 2.1437522986805936e-06, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 7.429755116042684e-06, 'skip_drop': 0.25997102562685176}. Best is trial 6 with value: 0.32407929757494225.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:22,722]\u001b[0m Trial 15 finished with value: 0.34692579192149364 and parameters: {'booster': 'gbtree', 'lambda': 0.00036197725600943146, 'alpha': 2.461565848251485e-08, 'subsample': 0.6765665092370472, 'colsample_bytree': 0.7690967047068644, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.016684145382260256, 'gamma': 1.1128542159662014e-06, 'grow_policy': 'lossguide'}. Best is trial 6 with value: 0.32407929757494225.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:23,087]\u001b[0m Trial 16 finished with value: 1.2582306915156867 and parameters: {'booster': 'gbtree', 'lambda': 0.003636182297436881, 'alpha': 2.020443248601828e-08, 'subsample': 0.46321958224117343, 'colsample_bytree': 0.7093797051584009, 'max_depth': 7, 'min_child_weight': 5, 'eta': 0.0001684480008064557, 'gamma': 2.469675292052469e-07, 'grow_policy': 'lossguide'}. Best is trial 6 with value: 0.32407929757494225.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:23,427]\u001b[0m Trial 17 finished with value: 0.32771993105376923 and parameters: {'booster': 'gbtree', 'lambda': 2.9473072278086323e-07, 'alpha': 1.4295512822448608e-08, 'subsample': 0.8436565259183593, 'colsample_bytree': 0.5321487458910173, 'max_depth': 7, 'min_child_weight': 4, 'eta': 0.05743215356778342, 'gamma': 3.419449916793492e-05, 'grow_policy': 'lossguide'}. Best is trial 6 with value: 0.32407929757494225.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:23,774]\u001b[0m Trial 18 finished with value: 1.2899997512547607 and parameters: {'booster': 'gbtree', 'lambda': 2.1569659963494146e-07, 'alpha': 3.933440501703579e-07, 'subsample': 0.8549069328609309, 'colsample_bytree': 0.5025947290448811, 'max_depth': 7, 'min_child_weight': 5, 'eta': 1.1722124701229573e-08, 'gamma': 0.00014412444255235298, 'grow_policy': 'depthwise'}. Best is trial 6 with value: 0.32407929757494225.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:24,081]\u001b[0m Trial 19 finished with value: 0.3111721117231381 and parameters: {'booster': 'gbtree', 'lambda': 2.0153348887240683e-07, 'alpha': 0.0002872515293886239, 'subsample': 0.8428156815124386, 'colsample_bytree': 0.5257040828474635, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.0703259994361694, 'gamma': 5.080518164453152e-05, 'grow_policy': 'lossguide'}. Best is trial 19 with value: 0.3111721117231381.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:24,351]\u001b[0m Trial 20 finished with value: 1.1089194577679868 and parameters: {'booster': 'gbtree', 'lambda': 9.60615070814442e-07, 'alpha': 0.000180471902305276, 'subsample': 0.6477495243642304, 'colsample_bytree': 0.6918651525650716, 'max_depth': 5, 'min_child_weight': 9, 'eta': 0.0010517164042133955, 'gamma': 0.002307139583378078, 'grow_policy': 'lossguide'}. Best is trial 19 with value: 0.3111721117231381.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:24,690]\u001b[0m Trial 21 finished with value: 0.3346099679564882 and parameters: {'booster': 'gbtree', 'lambda': 1.1028031116293631e-07, 'alpha': 0.00026320712713528, 'subsample': 0.8454542139117874, 'colsample_bytree': 0.5297855458093846, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.1342721693226852, 'gamma': 3.4793565079928607e-05, 'grow_policy': 'lossguide'}. Best is trial 19 with value: 0.3111721117231381.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:25,103]\u001b[0m Trial 22 finished with value: 0.305449834320621 and parameters: {'booster': 'gbtree', 'lambda': 4.0393730735786356e-07, 'alpha': 3.3072037800176405e-05, 'subsample': 0.8610916187536937, 'colsample_bytree': 0.5570657247093274, 'max_depth': 7, 'min_child_weight': 6, 'eta': 0.06817884219707761, 'gamma': 1.14876162775074e-05, 'grow_policy': 'lossguide'}. Best is trial 22 with value: 0.305449834320621.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:25,548]\u001b[0m Trial 23 finished with value: 1.0202282818256456 and parameters: {'booster': 'gbtree', 'lambda': 1.4304859552172859e-05, 'alpha': 8.787247407913108e-06, 'subsample': 0.8870834851337404, 'colsample_bytree': 0.5781023722185477, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.0016817723372903107, 'gamma': 6.005040951998306e-06, 'grow_policy': 'lossguide'}. Best is trial 22 with value: 0.305449834320621.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:26,091]\u001b[0m Trial 24 finished with value: 0.3442308945478988 and parameters: {'booster': 'gbtree', 'lambda': 8.769891759015227e-07, 'alpha': 3.832654241740205e-05, 'subsample': 0.9696802674241817, 'colsample_bytree': 0.4132123917291503, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.04841466966679642, 'gamma': 0.0005526817883470845, 'grow_policy': 'lossguide'}. Best is trial 22 with value: 0.305449834320621.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:42:26,234]\u001b[0m Trial 25 finished with value: 0.3926644127239543 and parameters: {'booster': 'gblinear', 'lambda': 5.81643742566801e-08, 'alpha': 0.000388906908902819, 'subsample': 0.4968298073270958, 'colsample_bytree': 0.7100750696864718}. Best is trial 22 with value: 0.305449834320621.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:26,623]\u001b[0m Trial 26 finished with value: 1.283883311330847 and parameters: {'booster': 'gbtree', 'lambda': 3.940870626846898e-06, 'alpha': 0.006209558514425576, 'subsample': 0.7956024543549123, 'colsample_bytree': 0.45238894063331797, 'max_depth': 7, 'min_child_weight': 8, 'eta': 3.403264669553304e-05, 'gamma': 6.788472114290998e-08, 'grow_policy': 'depthwise'}. Best is trial 22 with value: 0.305449834320621.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:26,937]\u001b[0m Trial 27 finished with value: 0.31767582539108613 and parameters: {'booster': 'gbtree', 'lambda': 9.321858284888647e-05, 'alpha': 0.0483659448624483, 'subsample': 0.8977640660138323, 'colsample_bytree': 0.589890179433816, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.07457197281245136, 'gamma': 0.006877368858587805, 'grow_policy': 'lossguide'}. Best is trial 22 with value: 0.305449834320621.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:27,232]\u001b[0m Trial 28 finished with value: 0.6138817927920585 and parameters: {'booster': 'gbtree', 'lambda': 0.0001223837604707073, 'alpha': 0.09023278163630871, 'subsample': 0.8874195077882338, 'colsample_bytree': 0.5744058981271523, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.8572213217540277, 'gamma': 0.005784264475693484, 'grow_policy': 'lossguide'}. Best is trial 22 with value: 0.305449834320621.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:27,616]\u001b[0m Trial 29 finished with value: 0.7685851972108362 and parameters: {'booster': 'gbtree', 'lambda': 1.9516063518002453e-05, 'alpha': 0.6518981549241749, 'subsample': 0.9206512173446761, 'colsample_bytree': 0.6458013593025862, 'max_depth': 7, 'min_child_weight': 8, 'eta': 0.004031761187364096, 'gamma': 8.15495420669792e-06, 'grow_policy': 'lossguide'}. Best is trial 22 with value: 0.305449834320621.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:27,902]\u001b[0m Trial 30 finished with value: 0.3295515908068982 and parameters: {'booster': 'gbtree', 'lambda': 0.0037745160226566312, 'alpha': 0.03470314259097931, 'subsample': 0.9864159241217458, 'colsample_bytree': 0.6072424697586731, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.11022602908379928, 'gamma': 0.0002493890136703903, 'grow_policy': 'depthwise'}. Best is trial 22 with value: 0.305449834320621.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:28,116]\u001b[0m Trial 31 finished with value: 0.31958998350911183 and parameters: {'booster': 'gbtree', 'lambda': 4.73457985538052e-08, 'alpha': 1.7238040929277776e-05, 'subsample': 0.6233561848432707, 'colsample_bytree': 0.6701020628353186, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.06048179992836102, 'gamma': 0.010513965303939977, 'grow_policy': 'lossguide'}. Best is trial 22 with value: 0.305449834320621.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:28,480]\u001b[0m Trial 32 finished with value: 0.330505716085901 and parameters: {'booster': 'gbtree', 'lambda': 5.00952944392517e-08, 'alpha': 2.1399430070873963e-05, 'subsample': 0.8021219330973062, 'colsample_bytree': 0.6644739147208416, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.03575254956296507, 'gamma': 0.011473334111117136, 'grow_policy': 'lossguide'}. Best is trial 22 with value: 0.305449834320621.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:28,692]\u001b[0m Trial 33 finished with value: 0.36466002618439863 and parameters: {'booster': 'gbtree', 'lambda': 5.034113668484061e-08, 'alpha': 7.20506612829303e-07, 'subsample': 0.7195225705732051, 'colsample_bytree': 0.5718600801483563, 'max_depth': 3, 'min_child_weight': 8, 'eta': 0.1779066905946025, 'gamma': 0.19499299943672188, 'grow_policy': 'lossguide'}. Best is trial 22 with value: 0.305449834320621.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:28,835]\u001b[0m Trial 34 finished with value: 0.4015046654985689 and parameters: {'booster': 'gblinear', 'lambda': 5.896273044074085e-07, 'alpha': 1.717973661570989e-05, 'subsample': 0.6404420271496942, 'colsample_bytree': 0.46410169217404484}. Best is trial 22 with value: 0.305449834320621.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:29,211]\u001b[0m Trial 35 finished with value: 0.9149587324930029 and parameters: {'booster': 'gbtree', 'lambda': 7.778154457321779e-06, 'alpha': 0.15454954664147566, 'subsample': 0.7984026881438269, 'colsample_bytree': 0.3296437634132913, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.0027808417455202398, 'gamma': 0.05848047342054547, 'grow_policy': 'lossguide'}. Best is trial 22 with value: 0.305449834320621.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:29,517]\u001b[0m Trial 36 finished with value: 1.2491961084306171 and parameters: {'booster': 'gbtree', 'lambda': 0.00013175098835864393, 'alpha': 7.146529116805971e-05, 'subsample': 0.916017019092315, 'colsample_bytree': 0.6324174274222634, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.00022424714999557467, 'gamma': 0.7740394481400377, 'grow_policy': 'lossguide'}. Best is trial 22 with value: 0.305449834320621.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:29,982]\u001b[0m Trial 37 finished with value: 0.338953245749047 and parameters: {'booster': 'gbtree', 'lambda': 1.6009533325483508e-06, 'alpha': 1.7481936692164657e-06, 'subsample': 0.9971425125169568, 'colsample_bytree': 0.5290874903795107, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.020121241385579854, 'gamma': 1.0455888859377136e-05, 'grow_policy': 'lossguide'}. Best is trial 22 with value: 0.305449834320621.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:30,132]\u001b[0m Trial 38 finished with value: 0.3893649782668092 and parameters: {'booster': 'gblinear', 'lambda': 4.367902751258913e-05, 'alpha': 0.0006706837440632913, 'subsample': 0.7729219116307059, 'colsample_bytree': 0.6097914818305217}. Best is trial 22 with value: 0.305449834320621.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:30,500]\u001b[0m Trial 39 finished with value: 1.2110173454715454 and parameters: {'booster': 'gbtree', 'lambda': 3.227300052447983e-06, 'alpha': 0.006312579258629153, 'subsample': 0.8777450529497132, 'colsample_bytree': 0.44830874553334116, 'max_depth': 7, 'min_child_weight': 5, 'eta': 0.0004534421337602535, 'gamma': 0.0011061575312828519, 'grow_policy': 'lossguide'}. Best is trial 22 with value: 0.305449834320621.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:30,719]\u001b[0m Trial 40 finished with value: 1.2801901067545087 and parameters: {'booster': 'gbtree', 'lambda': 1.0557979580463447e-07, 'alpha': 7.67657363102232e-05, 'subsample': 0.8230519620694161, 'colsample_bytree': 0.38474816227288544, 'max_depth': 3, 'min_child_weight': 7, 'eta': 5.8851027169705e-05, 'gamma': 0.004914845397308963, 'grow_policy': 'depthwise'}. Best is trial 22 with value: 0.305449834320621.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:32,299]\u001b[0m Trial 41 finished with value: 0.3204295023711644 and parameters: {'booster': 'dart', 'lambda': 3.4725113003482667e-07, 'alpha': 3.2801627460842117e-06, 'subsample': 0.6318176204316714, 'colsample_bytree': 0.7484646587782551, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.06934206628215012, 'gamma': 0.0002594063370433379, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.021202749424716606, 'skip_drop': 1.2594274861787556e-06}. Best is trial 22 with value: 0.305449834320621.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:33,744]\u001b[0m Trial 42 finished with value: 0.31358351487873004 and parameters: {'booster': 'dart', 'lambda': 2.4326562108441496e-07, 'alpha': 2.5921869240063052e-06, 'subsample': 0.5323814537409814, 'colsample_bytree': 0.8285705658140484, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.10912442657958438, 'gamma': 6.125924865304098e-05, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.08559016051931784, 'skip_drop': 6.863704888139548e-07}. Best is trial 22 with value: 0.305449834320621.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:35,289]\u001b[0m Trial 43 finished with value: 0.3363465438211218 and parameters: {'booster': 'dart', 'lambda': 2.950550802815401e-08, 'alpha': 1.1710294218627786e-05, 'subsample': 0.939088795199882, 'colsample_bytree': 0.8336670261470509, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.2574262668897946, 'gamma': 5.4980494602529775e-05, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.007098327281513118, 'skip_drop': 1.3901459760187633e-08}. Best is trial 22 with value: 0.305449834320621.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:42:35,447]\u001b[0m Trial 44 finished with value: 0.4018168998702412 and parameters: {'booster': 'gblinear', 'lambda': 1.4306735398270976e-07, 'alpha': 2.2102264202110338e-07, 'subsample': 0.5151522620520688, 'colsample_bytree': 0.8761931486671896}. Best is trial 22 with value: 0.305449834320621.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:36,546]\u001b[0m Trial 45 finished with value: 1.2898491543202724 and parameters: {'booster': 'dart', 'lambda': 0.10375250513328003, 'alpha': 3.634466754242259e-06, 'subsample': 0.36993573040023964, 'colsample_bytree': 0.6777358620603227, 'max_depth': 3, 'min_child_weight': 7, 'eta': 7.626778397268466e-06, 'gamma': 1.6000314143383364e-05, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.6300723277108085, 'skip_drop': 3.430184684203007e-06}. Best is trial 22 with value: 0.305449834320621.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:36,938]\u001b[0m Trial 46 finished with value: 0.4290536537962921 and parameters: {'booster': 'gbtree', 'lambda': 1.1270734727857389e-08, 'alpha': 1.0933661852905594e-06, 'subsample': 0.4259302140412361, 'colsample_bytree': 0.9284958496544531, 'max_depth': 5, 'min_child_weight': 5, 'eta': 0.31410980399954996, 'gamma': 8.697910493520977e-05, 'grow_policy': 'lossguide'}. Best is trial 22 with value: 0.305449834320621.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:38,665]\u001b[0m Trial 47 finished with value: 0.36388661778823844 and parameters: {'booster': 'dart', 'lambda': 2.6545662839128497e-06, 'alpha': 5.789746880372994e-08, 'subsample': 0.7416429091507224, 'colsample_bytree': 0.2018881374128405, 'max_depth': 3, 'min_child_weight': 5, 'eta': 0.02735476328892013, 'gamma': 0.03495894427617, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.005446104446312043, 'skip_drop': 6.734698089759739e-07}. Best is trial 22 with value: 0.305449834320621.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:39,012]\u001b[0m Trial 48 finished with value: 0.5673127976675044 and parameters: {'booster': 'gbtree', 'lambda': 4.2269686062442844e-07, 'alpha': 4.431136235667132e-05, 'subsample': 0.5258513667152892, 'colsample_bytree': 0.55662696261572, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.007160759571551745, 'gamma': 0.0007757297235636504, 'grow_policy': 'lossguide'}. Best is trial 22 with value: 0.305449834320621.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:40,624]\u001b[0m Trial 49 finished with value: 0.32791596715383375 and parameters: {'booster': 'dart', 'lambda': 2.4776119603927405e-08, 'alpha': 0.00012340571260758334, 'subsample': 0.6011243612251027, 'colsample_bytree': 0.4916281801636016, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.5197509238041381, 'gamma': 0.011001130344302525, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.0738008002375647, 'skip_drop': 3.66064837175202e-07}. Best is trial 22 with value: 0.305449834320621.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:41,132]\u001b[0m A new study created in memory with name: no-name-4731392b-8da9-4134-b992-76db6a34a5f9\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:41,275]\u001b[0m Trial 0 finished with value: 0.9489730356405611 and parameters: {'booster': 'gblinear', 'lambda': 1.3223582911526206e-06, 'alpha': 1.765619145175423e-05, 'subsample': 0.39375862244988324, 'colsample_bytree': 0.8491523186127004}. Best is trial 0 with value: 0.9489730356405611.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:41,415]\u001b[0m Trial 1 finished with value: 0.9490450011648762 and parameters: {'booster': 'gblinear', 'lambda': 6.506141249203549e-05, 'alpha': 1.5012295868680606e-06, 'subsample': 0.465244536348294, 'colsample_bytree': 0.945124548587055}. Best is trial 0 with value: 0.9489730356405611.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:43,276]\u001b[0m Trial 2 finished with value: 1.1679326288098708 and parameters: {'booster': 'dart', 'lambda': 6.39956198908157e-05, 'alpha': 6.26858094605877e-08, 'subsample': 0.9759108941291257, 'colsample_bytree': 0.25865842071759276, 'max_depth': 5, 'min_child_weight': 9, 'eta': 2.5503966345452257e-07, 'gamma': 0.009830583690917542, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.1299620819691067e-06, 'skip_drop': 2.352616629222869e-08}. Best is trial 0 with value: 0.9489730356405611.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:43,420]\u001b[0m Trial 3 finished with value: 0.9117158503137651 and parameters: {'booster': 'gblinear', 'lambda': 0.02228756442409267, 'alpha': 2.6400333495777743e-08, 'subsample': 0.9672616394976579, 'colsample_bytree': 0.8744832127562043}. Best is trial 3 with value: 0.9117158503137651.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:43,662]\u001b[0m Trial 4 finished with value: 1.0903312491771526 and parameters: {'booster': 'gbtree', 'lambda': 3.056148312653441e-07, 'alpha': 0.0035496789301213065, 'subsample': 0.8458175319247976, 'colsample_bytree': 0.7851267877865944, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.0012711327392810397, 'gamma': 0.0001400290500076077, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 0.9117158503137651.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:45,370]\u001b[0m Trial 5 finished with value: 1.1678349685330458 and parameters: {'booster': 'dart', 'lambda': 3.448443156634386e-08, 'alpha': 4.2733818791847514e-05, 'subsample': 0.33678247722870336, 'colsample_bytree': 0.9546327881932897, 'max_depth': 3, 'min_child_weight': 2, 'eta': 1.8058323956543654e-06, 'gamma': 0.01827203664023482, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 1.8968747992036902e-06, 'skip_drop': 2.0315581820476836e-07}. Best is trial 3 with value: 0.9117158503137651.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:46,996]\u001b[0m Trial 6 finished with value: 1.1679281748796073 and parameters: {'booster': 'dart', 'lambda': 2.28645688302947e-06, 'alpha': 2.2710446489582403e-08, 'subsample': 0.6935156413695589, 'colsample_bytree': 0.5614172289785492, 'max_depth': 3, 'min_child_weight': 4, 'eta': 3.07455155585405e-07, 'gamma': 0.019848068873484476, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.031410069299037315, 'skip_drop': 0.0013480467446582473}. Best is trial 3 with value: 0.9117158503137651.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:47,140]\u001b[0m Trial 7 finished with value: 0.9319147828225325 and parameters: {'booster': 'gblinear', 'lambda': 0.0068124343067616664, 'alpha': 1.917440620061551e-06, 'subsample': 0.7390561162623399, 'colsample_bytree': 0.8244817822977286}. Best is trial 3 with value: 0.9117158503137651.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:47,431]\u001b[0m Trial 8 finished with value: 1.167948050733444 and parameters: {'booster': 'gbtree', 'lambda': 3.7355355126715877e-07, 'alpha': 1.3524127664887667e-05, 'subsample': 0.23798964183764354, 'colsample_bytree': 0.26626277824381916, 'max_depth': 7, 'min_child_weight': 8, 'eta': 1.0937203321008936e-08, 'gamma': 0.5288896453412367, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 0.9117158503137651.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:47,617]\u001b[0m Trial 9 finished with value: 1.082500146463089 and parameters: {'booster': 'gbtree', 'lambda': 0.0004699082895824028, 'alpha': 0.6257835331089262, 'subsample': 0.5297211001674205, 'colsample_bytree': 0.2380740872107966, 'max_depth': 3, 'min_child_weight': 8, 'eta': 0.0018021062461215443, 'gamma': 0.30249099189166806, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 0.9117158503137651.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:47,773]\u001b[0m Trial 10 finished with value: 0.8932021848734089 and parameters: {'booster': 'gblinear', 'lambda': 0.224625103871187, 'alpha': 0.004273057019784492, 'subsample': 0.9420247043133521, 'colsample_bytree': 0.5853785342547035}. Best is trial 10 with value: 0.8932021848734089.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:47,933]\u001b[0m Trial 11 finished with value: 0.9038643213031262 and parameters: {'booster': 'gblinear', 'lambda': 0.6084883231375195, 'alpha': 0.0023358556838445356, 'subsample': 0.9958736168731687, 'colsample_bytree': 0.6026052023489366}. Best is trial 10 with value: 0.8932021848734089.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:48,089]\u001b[0m Trial 12 finished with value: 0.9027149899813824 and parameters: {'booster': 'gblinear', 'lambda': 0.36357550413218687, 'alpha': 0.007634772218244461, 'subsample': 0.866326700340607, 'colsample_bytree': 0.5690350608102634}. Best is trial 10 with value: 0.8932021848734089.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:42:48,235]\u001b[0m Trial 13 finished with value: 0.9208669658407495 and parameters: {'booster': 'gblinear', 'lambda': 0.9339766605099896, 'alpha': 0.013429684311349993, 'subsample': 0.8279998920772826, 'colsample_bytree': 0.5345218718379348}. Best is trial 10 with value: 0.8932021848734089.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:48,371]\u001b[0m Trial 14 finished with value: 0.9371592033004582 and parameters: {'booster': 'gblinear', 'lambda': 0.07591853332415104, 'alpha': 0.08838798625871971, 'subsample': 0.8567476665148308, 'colsample_bytree': 0.43652567099491185}. Best is trial 10 with value: 0.8932021848734089.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:48,535]\u001b[0m Trial 15 finished with value: 0.9334372799224869 and parameters: {'booster': 'gblinear', 'lambda': 0.002064149709677103, 'alpha': 0.0005876156293568303, 'subsample': 0.6331495070581461, 'colsample_bytree': 0.7026837703691904}. Best is trial 10 with value: 0.8932021848734089.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:48,675]\u001b[0m Trial 16 finished with value: 0.9338846986594687 and parameters: {'booster': 'gblinear', 'lambda': 0.21451357219555894, 'alpha': 0.052676062004913975, 'subsample': 0.7391005805637232, 'colsample_bytree': 0.4583521874988992}. Best is trial 10 with value: 0.8932021848734089.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:48,833]\u001b[0m Trial 17 finished with value: 0.9008187777110298 and parameters: {'booster': 'gblinear', 'lambda': 0.03717904903224652, 'alpha': 0.0003823351121825178, 'subsample': 0.8932613833509965, 'colsample_bytree': 0.6714485825824043}. Best is trial 10 with value: 0.8932021848734089.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:50,823]\u001b[0m Trial 18 finished with value: 0.9042339738842666 and parameters: {'booster': 'dart', 'lambda': 0.034207490124643414, 'alpha': 0.0005298552197177625, 'subsample': 0.9255991022690504, 'colsample_bytree': 0.7025878187383897, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.2055895878960612, 'gamma': 1.4467680894582966e-08, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 0.6297666795281129, 'skip_drop': 0.8515354723272361}. Best is trial 10 with value: 0.8932021848734089.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:51,336]\u001b[0m Trial 19 finished with value: 2.7930558254321753 and parameters: {'booster': 'gbtree', 'lambda': 0.0007497853172104536, 'alpha': 0.0003231107417893718, 'subsample': 0.5816061422730376, 'colsample_bytree': 0.6914283942514327, 'max_depth': 9, 'min_child_weight': 6, 'eta': 0.8555884489311586, 'gamma': 1.1453208801214512e-08, 'grow_policy': 'lossguide'}. Best is trial 10 with value: 0.8932021848734089.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:51,495]\u001b[0m Trial 20 finished with value: 0.9319772511228765 and parameters: {'booster': 'gblinear', 'lambda': 0.006016715532063585, 'alpha': 0.0001208261624006737, 'subsample': 0.7771670683510415, 'colsample_bytree': 0.4075990354931364}. Best is trial 10 with value: 0.8932021848734089.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:51,650]\u001b[0m Trial 21 finished with value: 0.8899666238267707 and parameters: {'booster': 'gblinear', 'lambda': 0.09389287416896695, 'alpha': 0.006616126657828785, 'subsample': 0.9180153652995732, 'colsample_bytree': 0.6208109260090271}. Best is trial 21 with value: 0.8899666238267707.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:51,787]\u001b[0m Trial 22 finished with value: 0.9331944689640189 and parameters: {'booster': 'gblinear', 'lambda': 0.08827094886934812, 'alpha': 0.06453832358546814, 'subsample': 0.9147994514441926, 'colsample_bytree': 0.6424575824823298}. Best is trial 21 with value: 0.8899666238267707.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:51,914]\u001b[0m Trial 23 finished with value: 0.9501772989320322 and parameters: {'booster': 'gblinear', 'lambda': 0.02115830294775849, 'alpha': 0.558800063757555, 'subsample': 0.7950543861933995, 'colsample_bytree': 0.7566155490828627}. Best is trial 21 with value: 0.8899666238267707.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:52,071]\u001b[0m Trial 24 finished with value: 0.8892009131552795 and parameters: {'booster': 'gblinear', 'lambda': 0.11537277645542766, 'alpha': 0.000885323012783174, 'subsample': 0.9119134364813452, 'colsample_bytree': 0.5044696193852861}. Best is trial 24 with value: 0.8892009131552795.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:52,229]\u001b[0m Trial 25 finished with value: 0.8894550481773272 and parameters: {'booster': 'gblinear', 'lambda': 0.17721520813035935, 'alpha': 0.0018641083350541205, 'subsample': 0.6903092892187163, 'colsample_bytree': 0.35952737719771155}. Best is trial 24 with value: 0.8892009131552795.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:52,369]\u001b[0m Trial 26 finished with value: 0.9163794974966051 and parameters: {'booster': 'gblinear', 'lambda': 1.539111462624359e-05, 'alpha': 0.025256734705723594, 'subsample': 0.6647322530440074, 'colsample_bytree': 0.3415874620888049}. Best is trial 24 with value: 0.8892009131552795.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:54,196]\u001b[0m Trial 27 finished with value: 1.1654329619600179 and parameters: {'booster': 'dart', 'lambda': 0.005387821894274778, 'alpha': 0.001141673174500594, 'subsample': 0.5853502080870928, 'colsample_bytree': 0.5054922447573159, 'max_depth': 7, 'min_child_weight': 2, 'eta': 3.922147043294447e-05, 'gamma': 1.283389889135765e-06, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.00063701218500305, 'skip_drop': 0.00013830402290141122}. Best is trial 24 with value: 0.8892009131552795.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:54,357]\u001b[0m Trial 28 finished with value: 0.9460935463295649 and parameters: {'booster': 'gblinear', 'lambda': 0.0009057784784444314, 'alpha': 0.00010471494812826562, 'subsample': 0.7387118223141671, 'colsample_bytree': 0.36471590339541904}. Best is trial 24 with value: 0.8892009131552795.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:54,645]\u001b[0m Trial 29 finished with value: 0.8599294474861969 and parameters: {'booster': 'gbtree', 'lambda': 0.09749088584708102, 'alpha': 8.40781466640031e-06, 'subsample': 0.42903273540457504, 'colsample_bytree': 0.48861556560563335, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.018667685812361164, 'gamma': 6.1218466740678745e-06, 'grow_policy': 'lossguide'}. Best is trial 29 with value: 0.8599294474861969.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:54,912]\u001b[0m Trial 30 finished with value: 0.8823066525719839 and parameters: {'booster': 'gbtree', 'lambda': 0.005312474733888621, 'alpha': 9.589439237786793e-07, 'subsample': 0.40164670134745156, 'colsample_bytree': 0.31527896675819145, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.014316922522539471, 'gamma': 6.822443549231758e-06, 'grow_policy': 'lossguide'}. Best is trial 29 with value: 0.8599294474861969.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:55,175]\u001b[0m Trial 31 finished with value: 0.8751847295124244 and parameters: {'booster': 'gbtree', 'lambda': 0.011870023909945104, 'alpha': 1.3943394425433598e-06, 'subsample': 0.39819316567447494, 'colsample_bytree': 0.3179461658768956, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.015415685182824655, 'gamma': 7.755675550649071e-06, 'grow_policy': 'lossguide'}. Best is trial 29 with value: 0.8599294474861969.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:55,435]\u001b[0m Trial 32 finished with value: 0.879485950765193 and parameters: {'booster': 'gbtree', 'lambda': 0.007183025893786965, 'alpha': 3.744074442571758e-07, 'subsample': 0.4010323784598331, 'colsample_bytree': 0.2922921849022554, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.01834198984766923, 'gamma': 6.114063816247963e-06, 'grow_policy': 'lossguide'}. Best is trial 29 with value: 0.8599294474861969.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:55,690]\u001b[0m Trial 33 finished with value: 0.8641276460540482 and parameters: {'booster': 'gbtree', 'lambda': 0.0003129400606636914, 'alpha': 2.6078110820893844e-07, 'subsample': 0.4055270183625951, 'colsample_bytree': 0.3070724139914942, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.03053839590677, 'gamma': 6.649396275693856e-06, 'grow_policy': 'lossguide'}. Best is trial 29 with value: 0.8599294474861969.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:55,954]\u001b[0m Trial 34 finished with value: 0.8668881174506645 and parameters: {'booster': 'gbtree', 'lambda': 9.243562017043228e-05, 'alpha': 2.42985277494229e-07, 'subsample': 0.4455999225241425, 'colsample_bytree': 0.2031282320033801, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.03916673078740869, 'gamma': 7.902932180001638e-06, 'grow_policy': 'lossguide'}. Best is trial 29 with value: 0.8599294474861969.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:42:56,224]\u001b[0m Trial 35 finished with value: 0.8829830328567001 and parameters: {'booster': 'gbtree', 'lambda': 0.00014966106370231316, 'alpha': 1.8384193832238804e-07, 'subsample': 0.461624110516178, 'colsample_bytree': 0.23526454110319422, 'max_depth': 5, 'min_child_weight': 5, 'eta': 0.03412063681231572, 'gamma': 5.9199976636364086e-05, 'grow_policy': 'lossguide'}. Best is trial 29 with value: 0.8599294474861969.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:56,482]\u001b[0m Trial 36 finished with value: 1.0850658901723218 and parameters: {'booster': 'gbtree', 'lambda': 2.3965895090615226e-05, 'alpha': 7.072337736223714e-06, 'subsample': 0.32550793597517397, 'colsample_bytree': 0.20464467093661193, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.001795307488229678, 'gamma': 5.301544183327724e-07, 'grow_policy': 'lossguide'}. Best is trial 29 with value: 0.8599294474861969.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:56,852]\u001b[0m Trial 37 finished with value: 0.9700895718165586 and parameters: {'booster': 'gbtree', 'lambda': 0.00012628501871150363, 'alpha': 3.7337815906116248e-06, 'subsample': 0.5102138608774247, 'colsample_bytree': 0.40716546743563653, 'max_depth': 7, 'min_child_weight': 5, 'eta': 0.09890870618226245, 'gamma': 4.0779039325221075e-05, 'grow_policy': 'lossguide'}. Best is trial 29 with value: 0.8599294474861969.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:57,129]\u001b[0m Trial 38 finished with value: 0.9761894877716053 and parameters: {'booster': 'gbtree', 'lambda': 1.5196018976228512e-05, 'alpha': 1.802842024286432e-07, 'subsample': 0.31336822618581567, 'colsample_bytree': 0.29190498229617623, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.005163337412206044, 'gamma': 3.0284889341892603e-07, 'grow_policy': 'lossguide'}. Best is trial 29 with value: 0.8599294474861969.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:57,387]\u001b[0m Trial 39 finished with value: 1.1586482399579787 and parameters: {'booster': 'gbtree', 'lambda': 5.208210555147464e-06, 'alpha': 3.854756419360382e-08, 'subsample': 0.44086383957767794, 'colsample_bytree': 0.200964873431362, 'max_depth': 5, 'min_child_weight': 5, 'eta': 0.00016964748554661445, 'gamma': 6.583874488237305e-06, 'grow_policy': 'lossguide'}. Best is trial 29 with value: 0.8599294474861969.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:57,656]\u001b[0m Trial 40 finished with value: 1.6529936921701995 and parameters: {'booster': 'gbtree', 'lambda': 0.00028846627548913614, 'alpha': 7.173100430532287e-07, 'subsample': 0.26136011231304335, 'colsample_bytree': 0.4003801837526961, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.28155094345592424, 'gamma': 0.00018843552120664258, 'grow_policy': 'lossguide'}. Best is trial 29 with value: 0.8599294474861969.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:57,928]\u001b[0m Trial 41 finished with value: 0.8687161724266141 and parameters: {'booster': 'gbtree', 'lambda': 0.001798645153386053, 'alpha': 1.1282741357702374e-08, 'subsample': 0.3784221541129134, 'colsample_bytree': 0.28274850981187655, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.025878471314866914, 'gamma': 6.779390882503405e-06, 'grow_policy': 'lossguide'}. Best is trial 29 with value: 0.8599294474861969.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:58,222]\u001b[0m Trial 42 finished with value: 0.8938269048089164 and parameters: {'booster': 'gbtree', 'lambda': 0.002220917962415759, 'alpha': 6.97397852647718e-08, 'subsample': 0.3653094659474586, 'colsample_bytree': 0.2754922184209116, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.04184568266105421, 'gamma': 1.368758256957967e-05, 'grow_policy': 'lossguide'}. Best is trial 29 with value: 0.8599294474861969.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:58,512]\u001b[0m Trial 43 finished with value: 0.9127713127583842 and parameters: {'booster': 'gbtree', 'lambda': 0.0015437653265874068, 'alpha': 1.1682224240643991e-08, 'subsample': 0.5315559311694882, 'colsample_bytree': 0.32289252113030903, 'max_depth': 7, 'min_child_weight': 6, 'eta': 0.008856101716041157, 'gamma': 1.8112353178931658e-06, 'grow_policy': 'lossguide'}. Best is trial 29 with value: 0.8599294474861969.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:58,737]\u001b[0m Trial 44 finished with value: 1.1513691712179392 and parameters: {'booster': 'gbtree', 'lambda': 3.823446803020389e-05, 'alpha': 2.508317154853351e-05, 'subsample': 0.43351678809368577, 'colsample_bytree': 0.23787506970142475, 'max_depth': 5, 'min_child_weight': 5, 'eta': 0.0002972917985209592, 'gamma': 0.0007259310861656217, 'grow_policy': 'lossguide'}. Best is trial 29 with value: 0.8599294474861969.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:58,932]\u001b[0m Trial 45 finished with value: 0.9799991646537776 and parameters: {'booster': 'gbtree', 'lambda': 0.00027592009902897873, 'alpha': 2.4631253333363865e-06, 'subsample': 0.2044494563752836, 'colsample_bytree': 0.37250424378932734, 'max_depth': 5, 'min_child_weight': 7, 'eta': 0.08080301187011946, 'gamma': 1.3974312004366346e-07, 'grow_policy': 'lossguide'}. Best is trial 29 with value: 0.8599294474861969.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:59,179]\u001b[0m Trial 46 finished with value: 0.9905988474142385 and parameters: {'booster': 'gbtree', 'lambda': 3.869026648544952e-08, 'alpha': 1.0246061989283708e-07, 'subsample': 0.2935745078045764, 'colsample_bytree': 0.916851453851523, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.004145225653533814, 'gamma': 2.7801456888386815e-05, 'grow_policy': 'lossguide'}. Best is trial 29 with value: 0.8599294474861969.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:59,519]\u001b[0m Trial 47 finished with value: 1.8417184308568066 and parameters: {'booster': 'gbtree', 'lambda': 0.01457978822587008, 'alpha': 4.6213988223744285e-07, 'subsample': 0.492764128833505, 'colsample_bytree': 0.4521429076903639, 'max_depth': 7, 'min_child_weight': 6, 'eta': 0.5636713199550724, 'gamma': 2.480239284842801e-06, 'grow_policy': 'lossguide'}. Best is trial 29 with value: 0.8599294474861969.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:59,730]\u001b[0m Trial 48 finished with value: 0.8836583391571777 and parameters: {'booster': 'gbtree', 'lambda': 6.992928188960624e-05, 'alpha': 1.16258053417948e-08, 'subsample': 0.3655830487639784, 'colsample_bytree': 0.257124236360125, 'max_depth': 5, 'min_child_weight': 5, 'eta': 0.051017167698004434, 'gamma': 0.00034248588998626655, 'grow_policy': 'lossguide'}. Best is trial 29 with value: 0.8599294474861969.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:42:59,913]\u001b[0m Trial 49 finished with value: 1.134189139293795 and parameters: {'booster': 'gbtree', 'lambda': 5.051483425306117e-06, 'alpha': 7.152387952496239e-06, 'subsample': 0.35888754150401747, 'colsample_bytree': 0.31648454412888677, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.0006338693211203064, 'gamma': 1.4302087641640515e-05, 'grow_policy': 'lossguide'}. Best is trial 29 with value: 0.8599294474861969.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:43:01,365]\u001b[0m Trial 50 finished with value: 0.8770902023157012 and parameters: {'booster': 'dart', 'lambda': 0.012340508648276776, 'alpha': 1.418175446178901e-06, 'subsample': 0.5509017365114907, 'colsample_bytree': 0.4847672134272455, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.010847118515611638, 'gamma': 1.096819769676117e-07, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 5.672601005556279e-08, 'skip_drop': 0.9541126168909825}. Best is trial 29 with value: 0.8599294474861969.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:43:02,807]\u001b[0m Trial 51 finished with value: 0.8735603764692706 and parameters: {'booster': 'dart', 'lambda': 0.0029768532946720556, 'alpha': 1.5684240331435267e-06, 'subsample': 0.4201819381507309, 'colsample_bytree': 0.48771117847888107, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.011701098779754985, 'gamma': 7.513455389613809e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.068785173581557e-08, 'skip_drop': 0.5224119978854699}. Best is trial 29 with value: 0.8599294474861969.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:43:04,230]\u001b[0m Trial 52 finished with value: 0.9504723648691518 and parameters: {'booster': 'dart', 'lambda': 0.002643926744529139, 'alpha': 1.6430965597132538e-07, 'subsample': 0.42084943580678913, 'colsample_bytree': 0.219434682291467, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.1404027676743133, 'gamma': 1.3556952374009074e-06, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.3026390054391986e-08, 'skip_drop': 0.011390970857347367}. Best is trial 29 with value: 0.8599294474861969.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 17:43:05,658]\u001b[0m Trial 53 finished with value: 0.8404347502794798 and parameters: {'booster': 'dart', 'lambda': 0.0009270179371405744, 'alpha': 3.3200765276601586e-07, 'subsample': 0.4868300216391145, 'colsample_bytree': 0.25811462138744024, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.024942056749746852, 'gamma': 0.0010139784847433598, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.00010822395331748998, 'skip_drop': 3.232211363036789e-06}. Best is trial 53 with value: 0.8404347502794798.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:43:07,090]\u001b[0m Trial 54 finished with value: 1.1657754390776414 and parameters: {'booster': 'dart', 'lambda': 0.0005141813212145734, 'alpha': 2.8252324420611853e-08, 'subsample': 0.47526640993337294, 'colsample_bytree': 0.2642633322225173, 'max_depth': 5, 'min_child_weight': 10, 'eta': 3.596800393968516e-05, 'gamma': 4.2392527392090624e-08, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.00018145324268754466, 'skip_drop': 3.3498344926855214e-06}. Best is trial 53 with value: 0.8404347502794798.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:43:08,499]\u001b[0m Trial 55 finished with value: 1.0070484581660535 and parameters: {'booster': 'dart', 'lambda': 0.00023941880419341133, 'alpha': 3.815479425165346e-07, 'subsample': 0.44933488373406305, 'colsample_bytree': 0.529344795858947, 'max_depth': 3, 'min_child_weight': 9, 'eta': 0.003549941652039157, 'gamma': 0.0022453591870417017, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 6.562170104467852e-06, 'skip_drop': 5.28839603975633e-06}. Best is trial 53 with value: 0.8404347502794798.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:43:09,939]\u001b[0m Trial 56 finished with value: 0.8700563887252961 and parameters: {'booster': 'dart', 'lambda': 0.0011970388446720316, 'alpha': 4.77568389693851e-06, 'subsample': 0.481428626501136, 'colsample_bytree': 0.4285639152626195, 'max_depth': 5, 'min_child_weight': 8, 'eta': 0.028300785634624466, 'gamma': 0.0031250989405592184, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.002815620868044227, 'skip_drop': 0.0113957536833518}. Best is trial 53 with value: 0.8404347502794798.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:43:11,371]\u001b[0m Trial 57 finished with value: 0.9021768101653569 and parameters: {'booster': 'dart', 'lambda': 0.0010604254801006485, 'alpha': 3.714231116424486e-05, 'subsample': 0.5470957209851697, 'colsample_bytree': 0.38744065490568114, 'max_depth': 7, 'min_child_weight': 9, 'eta': 0.041553485826960494, 'gamma': 0.004375495948068702, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.0034918503378741925, 'skip_drop': 0.01143144604100561}. Best is trial 53 with value: 0.8404347502794798.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:43:12,720]\u001b[0m Trial 58 finished with value: 1.1616139809156865 and parameters: {'booster': 'dart', 'lambda': 4.935276178123686e-05, 'alpha': 8.212310862488232e-06, 'subsample': 0.496411073651439, 'colsample_bytree': 0.4251068785113334, 'max_depth': 3, 'min_child_weight': 9, 'eta': 0.3614352322374421, 'gamma': 0.03375794781195316, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.01153319924555362, 'skip_drop': 1.3623919374497927e-05}. Best is trial 53 with value: 0.8404347502794798.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:43:14,089]\u001b[0m Trial 59 finished with value: 1.1239955435636475 and parameters: {'booster': 'dart', 'lambda': 0.0005182930014374825, 'alpha': 3.441745873091589e-06, 'subsample': 0.2797827839063345, 'colsample_bytree': 0.2831221575264917, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.0008434855774760955, 'gamma': 0.0012339324690076414, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 2.215163929185046e-05, 'skip_drop': 0.00013458241333540646}. Best is trial 53 with value: 0.8404347502794798.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 17:43:15,257]\u001b[0m Trial 60 finished with value: 1.1676210734831776 and parameters: {'booster': 'dart', 'lambda': 0.00010456487145507012, 'alpha': 4.931456070396672e-08, 'subsample': 0.6156239792063887, 'colsample_bytree': 0.25296073486210247, 'max_depth': 3, 'min_child_weight': 7, 'eta': 5.503167586293801e-06, 'gamma': 0.00011387854692450172, 'grow_policy': 'lossguide', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.15512324218266293, 'skip_drop': 0.022386381333686027}. Best is trial 53 with value: 0.8404347502794798.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea_nmbr</th>\n",
       "      <th>LotArea_NArw</th>\n",
       "      <th>Neighborhood_NArw</th>\n",
       "      <th>Neighborhood_1010_0</th>\n",
       "      <th>Neighborhood_1010_1</th>\n",
       "      <th>Neighborhood_1010_2</th>\n",
       "      <th>Neighborhood_1010_3</th>\n",
       "      <th>Neighborhood_1010_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.023285</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.140595</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.062997</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.096582</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.172645</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LotArea_nmbr  LotArea_NArw  Neighborhood_NArw  Neighborhood_1010_0  \\\n",
       "0     -0.023285             1                  0                    0   \n",
       "1      0.140595             1                  1                    1   \n",
       "2      0.062997             0                  1                    0   \n",
       "3     -0.096582             0                  1                    0   \n",
       "4      0.172645             1                  0                    1   \n",
       "\n",
       "   Neighborhood_1010_1  Neighborhood_1010_2  Neighborhood_1010_3  \\\n",
       "0                    0                    1                    1   \n",
       "1                    0                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    0                    0   \n",
       "4                    0                    0                    0   \n",
       "\n",
       "   Neighborhood_1010_4  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This shows ML infill with XGBoost, using the optuna library for hyperparameter tuning\n",
    "\n",
    "#here we're activating hyperparameter tuning with optuna library\n",
    "#with tuning parameters passed to optuna_n_iter and optuna_timeout\n",
    "#the ML_cmnd['xgboost_gpu_id'] can be used to designate training on GPU\n",
    "\n",
    "#can also pass specific parameters through MLinfill_cmnd\n",
    "#here the setting of XGBoost predictor parameter designates that inference will take place on CPU\n",
    "#as may be desired for some production scenarios when training took place on a GPU\n",
    "\n",
    "ML_cmnd = {'autoML_type'      : 'xgboost',\n",
    "           'MLinfill_cmnd'    : {'xgboost_classifier_fit'   : {'predictor' : 'cpu_predictor' },\n",
    "                                 'xgboost_regressor_fit'    : {'predictor' : 'cpu_predictor' }},\n",
    "#            'xgboost_gpu_id'   : 0,\n",
    "           'hyperparam_tuner' : 'optuna_XG1',\n",
    "           'optuna_n_iter'    : 100,\n",
    "           'optuna_timeout'   : 33}\n",
    "\n",
    "train, train_ID, labels, \\\n",
    "val, val_ID, val_labels, \\\n",
    "test, test_ID, test_labels, \\\n",
    "postprocess_dict \\\n",
    "= am.automunge(df_train,\n",
    "               labels_column = labels_column,\n",
    "               trainID_column = trainID_column,\n",
    "               assignnan = assignnan,\n",
    "               ML_cmnd = ML_cmnd,\n",
    "               NArw_marker = True,\n",
    "               shuffletrain = False, \n",
    "               MLinfill = True,\n",
    "               printstatus = False\n",
    "              )\n",
    "\n",
    "train[postprocess_dict['column_map']['LotArea'] + \\\n",
    "      postprocess_dict['column_map']['Neighborhood']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
