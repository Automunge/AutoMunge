{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a companion to the essay [Custom Transformations with Automunge](https://medium.com/automunge/custom-transformations-with-automunge-ae694c635a7e), and demonstrates user-defined transformation functions for integration into the platform. We recommend reading this notebook after reading the essay.\n",
    "\n",
    "The language presented will be similar to the essay, but will replace the code demonstrations with the full transformation function templates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automunge is available now for pip install:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Automunge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or to upgrade (we currently roll out upgrades pretty frequently):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Automunge --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once installed, run this in a local session to initialize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Automunge import *\n",
    "am = AutoMunge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll apply these transformations to the titanic data set, which is a well known tabular benchmark available on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#titanic set\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the demonstrations below, we'll target applying the custom transformations to the 'Fare' feature which is a continuous numeric set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetcolumn = 'Fare'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to offer introduction to a newly streamlined standard for Automunge custom transformation functions. To be a little more precise, custom transformation functions are for user defined operations to be applied to transform the entries found in a column in a tabular data set, with support for basing those operations on properties of the entries in a designated “training set” for consistent basis on additional data applied with a separate corresponding “test set” custom transformation function. By implementing custom transformations through the platform, a user can then integrate such operations within a set of transformations with order of operations defined by our family tree primitives, and with the set potentially mixed with transforms available in our internal library. The integration of custom transformations comes with built in support for auto ML derived missing data infill and pushbutton aggregate inversions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new streamlined convention was rolled out in version 6.41, and served the purpose of abstracting away almost all of the complexity from prior conventions, where by complexity am referring to accommodating and populating various data structures passed alongside transformations. In the new convention, which we refer to in the documentation as the 'custom_train' convention, operations can be defined independent of data structures, which are all managed separately in a wrapper function. A user simply defines a function for a received training set dataframe (df), target column (column), and dictionary for received parameters (normalization_dict), and returns the resulting transformed dataframe (df) along with the same dictionary (normalization_dict) logging any properties from the train set needed to consistently prepare additional data. And since this is targeting a column in a Pandas dataframe, may include Pandas or Numpy operations for instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we’ll define a custom_train_template that applies an operation similar to z-score normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_train_template(df, column, normalization_dict):\n",
    "  \"\"\"\n",
    "  #Template for a custom_train transformation function to be applied to a train feature set.\n",
    "  \n",
    "  #Where if a custom_test entry is not defined then custom_train will be applied to any \n",
    "  #corresponding test feature sets as well (as may be ok when processing the feature in df_test \n",
    "  #doesn't require accessing any train data properties from the normalization_dict).\n",
    "\n",
    "  #Receives a df as a pandas dataframe\n",
    "  #Where df will generally be from df_train (or may also be from df_test when custom_test not specified)\n",
    "\n",
    "  #column is the target column of transform\n",
    "  #which will already have the suffix appender incorporated when this is applied\n",
    "\n",
    "  #normalization_dict is a dictionary pre-populated with any parameters passed in assignparam\n",
    "  #(and also parameters designated in any defaultparams for the associated processdict entry)\n",
    "\n",
    "  #returns the resulting transformed dataframe as df\n",
    "\n",
    "  #returns normalization_dict, which is a dictionary for storing properties derived from train data\n",
    "  #that may then be accessed to consistently transform test data\n",
    "  #note that any desired drift statistics can also be stored in normalization_dict\n",
    "  #e.g. normalization_dict.update({'property' : property})\n",
    "\n",
    "  #note that prior to this function call \n",
    "  #a datatype casting based on the NArowtype processdict entry may have been performed\n",
    "  #as well as a default infill of adjinfill \n",
    "  #unless infill type otherwise specified in a defaultinfill processdict entry\n",
    "  #note that this default infill is a precursor to ML infill\n",
    "  \n",
    "  #note that if this same custom_train is to be applied to both train and test data \n",
    "  #(when custom_test not defined) then the quantity, headers, and order of returned columns \n",
    "  #will need to be consistent independent of data properties\n",
    "  \n",
    "  #Note that the assumptions for data type of recieved data\n",
    "  #Should align with the NArowtype specified in processdict\n",
    "  \n",
    "  #Note that the data types and quantity of returned columns \n",
    "  #Will need to align with the MLinfilltype specified in processdict\n",
    "  \n",
    "  #note that following this function call a dtype conversion will take place based on MLinfilltype\n",
    "  #unless deactivated with a dtype_convert processdict entry \n",
    "  \"\"\"\n",
    "\n",
    "  #As an example, here is the application of z-score normalization \n",
    "  #derived based on the training set mean and standard deviation\n",
    "  \n",
    "  #which can accept any kind of numeric data \n",
    "  #so corresponding NArowtype processdict entry can be 'numeric'\n",
    "  #and returns a single column of continuous numeric data \n",
    "  #so corresponding MLinfilltype processdict entry will need to be 'numeric'\n",
    "\n",
    "  #where we'll include the option for a parameter 'muiltiplier'\n",
    "  #which is an arbitrary example to demonstrate accessing parameters\n",
    "  \n",
    "  #basically we check if that parameter had been passed in assignparam or defaultparams\n",
    "  if 'multiplier' in normalization_dict:\n",
    "    multiplier = normalization_dict['multiplier']\n",
    "    \n",
    "  #or otherwise assign and save a default value\n",
    "  else:\n",
    "    multiplier = 1\n",
    "    normalization_dict.update({'multiplier' : multiplier})\n",
    "\n",
    "  #Now we measure any properties of the train data used for the transformation\n",
    "  mean = df[column].mean()\n",
    "  stdev = df[column].std()\n",
    "  \n",
    "  #It's good practice to ensure numbers used in derivation haven't been derived as nan\n",
    "  #or would result in dividing by zero\n",
    "  if mean != mean:\n",
    "    mean = 0\n",
    "  if stdev != stdev or stdev == 0:\n",
    "    stdev = 1\n",
    "    \n",
    "  #In general if that same basis will be needed to process test data we'll store in normalization_dict\n",
    "  normalization_dict.update({'mean' : mean,\n",
    "                             'stdev': stdev})\n",
    "\n",
    "  #Optionally we can measure additional drift stats for a postmunge driftreport\n",
    "  #we will also save those in the normalization_dict\n",
    "  minimum = df[column].min()\n",
    "  maximum = df[column].max()\n",
    "  normalization_dict.update({'minimum' : minimum,\n",
    "                             'maximum' : maximum})\n",
    "\n",
    "  #Now we can apply the transformation\n",
    "  \n",
    "  #The generic formula for z-score normalization is (x - mean) / stdev\n",
    "  #here we incorporate an additional variable as the multiplier parameter (defaults to 1)\n",
    "  df[column] = (df[column] - mean) * multiplier / stdev\n",
    "  \n",
    "  #A few clarifications on column management for reference:\n",
    "  \n",
    "  #Note that it is ok to return multiple columns\n",
    "  #we recommend naming additional columns as a function of the received column header \n",
    "  #e.g. newcolumn = column + '_' + str(int)\n",
    "  #returned column headers should be strings\n",
    "  \n",
    "  #when columns are conditionally created as a function of data properties \n",
    "  #will need to save headers for reference in custom_test\n",
    "  # e.g. normalization_dict.update('newcolumns_list' : [newcolumn]}\n",
    "  \n",
    "  #Note that it is ok to delete the received column from dataframe as part of transform if desired\n",
    "  #If any other temporary columns were created as part of transform that aren't returned\n",
    "  #their column headers should be logged as a normalization_dict entry under 'tempcolumns'\n",
    "  # e.g. normalization_dict.update('tempcolumns' : [tempcolumn]}\n",
    "\n",
    "  return df, normalization_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For additional data, what we refer to as test data, a user can either allow the same function to be applied as was applied to the training set (as may be appropriate when operations are independent of training set properties), or alternatively may define a corresponding custom transformation that applies transformations to the test data column based on properties accessed form the corresponding training data column which were logged in the returned dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of a corresponding operation using properties derived from the train data to conduct a form of z-score normalization on a consistent basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_test_template(df, column, normalization_dict):\n",
    "  \"\"\"\n",
    "  #This transform will be applied to a test data feature set\n",
    "  #on a basis of a corresponding custom_train entry\n",
    "  #Such as test data passed to either automunge(.) or postmunge(.)\n",
    "  #Using properties from the train set basis stored in the normalization_dict\n",
    "\n",
    "  #Note that when a custom_test entry is not defined, \n",
    "  #The custom_train entry will instead be applied to both train and test data\n",
    "\n",
    "  #Receives df as a pandas dataframe of test data\n",
    "  #and a string column header (column) \n",
    "  #which will correspond to the column (with suffix appender already included) \n",
    "  #that was passed to custom_train\n",
    "\n",
    "  #Also receives a normalization_dict dictionary\n",
    "  #Which will be the dictionary populated in and returned from custom_train\n",
    "\n",
    "  #note that prior to this function call \n",
    "  #a datatype casting based on the NArowtype processdict entry may have been performed\n",
    "  #as well as a default infill of adjinfill \n",
    "  #unless infill type otherwise specified in a defaultinfill processdict entry\n",
    "  \n",
    "  #where convention is that the quantity, headers, and order of returned columns\n",
    "  #will need to match those returned from the corresponding custom_train\n",
    "  \"\"\"\n",
    "\n",
    "  #As an example, here is the corresponding z-score normalization \n",
    "  #derived based on the training set mean and standard deviation\n",
    "  #which was populated in a normalization_dict in the custom_train example given above\n",
    "\n",
    "  #Basically the workflow is we access any values needed from the normalization_dict\n",
    "  #apply the transform\n",
    "  #and return the transformed dataframe\n",
    "\n",
    "  #access the train set properties from normalization_dict\n",
    "  mean = normalization_dict['mean']\n",
    "  stdev = normalization_dict['stdev']\n",
    "  multiplier = normalization_dict['multiplier']\n",
    "\n",
    "  #then apply the transformation and return the dataframe\n",
    "  df[column] = (df[column] - mean) * multiplier / stdev\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custom_train convention has even streamlined the specification of a corresponding custom inversion operation, which may be defined with a similar simple template or otherwise omitted when inversion support is not needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is an example of a corresponding inversion operation for the same operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_inversion_template(df, returnedcolumn_list, inputcolumn, normalization_dict):\n",
    "  \"\"\"\n",
    "  #User also has the option to define a custom inversion function\n",
    "  #Corresponding to custom_train and custom_test\n",
    "\n",
    "  #Where the function receives a dataframe df \n",
    "  #Containing a post-transform configuration of one or more columns whose headers are \n",
    "  #recorded in returnedcolumn_list\n",
    "  #And this function is for purposes of creating a new column with header inputcolumn\n",
    "  #Which inverts that transformation originally applied to produce those \n",
    "  #columns in returnedcolumn_list\n",
    "\n",
    "  #Here normalization_dict is the same as populated and returned from a corresponding custom_train\n",
    "  #as applied to the train set\n",
    "\n",
    "  #Returns the transformed dataframe df with the addition of a new column as df[inputcolumn]\n",
    "  \n",
    "  #Note that the returned dataframe should retain the columns in returnedcolumn_list\n",
    "  #Whose retention will be managed elsewhere\n",
    "  \"\"\"\n",
    "\n",
    "  #As an example, here we'll be inverting the z-score normalization \n",
    "  #derived based on the training set mean and standard deviation\n",
    "  #which corresponds to the examples given above\n",
    "\n",
    "  #Basically the workflow is we access any values needed from the normalization_dict\n",
    "  #Initialize the new column inputcolumn\n",
    "  #And use values in the set from returnedcolumn_list to recover values for inputcolumn\n",
    "\n",
    "  #First let's access the values we'll need from the normalization_dict\n",
    "  mean = normalization_dict['mean']\n",
    "  stdev = normalization_dict['stdev']\n",
    "  multiplier = normalization_dict['multiplier']\n",
    "\n",
    "  #Now initialize the inputcolumn\n",
    "  df[inputcolumn] = 0\n",
    "\n",
    "  #So for the example of z-score normalization, we know returnedcolumn_list will only have one entry\n",
    "  #In some other cases transforms may have returned multiple columns\n",
    "  returnedcolumn = returnedcolumn_list[0]\n",
    "\n",
    "  #now we perform the inversion\n",
    "  df[inputcolumn] = (df[returnedcolumn] * stdev / multiplier) + mean\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined our custom transformation functions, we can then pass them to an automunge(.) call by way of populating two corresponding data structures, the processdict and the transformdict. These data structures are for defining properties of “transformation categories” which can then be assigned to a column to apply the transformation functions. Each of these data structures are addressed in some detail in the recent essay [Data Structure](https://medium.com/automunge/data-structure-59e52f141dd6)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The processdict is for defining properties associated with a “transformation category”, including various properties like what kind of received data is considered valid input, the form and structure of returned data from the transform (e.g. integers, floats, or boolean integers in one or multiple returned columns), as well as the associated transformation functions, which as used here will be our custom transformation functions defined in the “custom_train” convention. (The bulk of the internal library has transformations defined in an alternate convention.) \n",
    "\n",
    "Here we demonstrate populating a processdict entry for a new transformation category we’ll refer to as ‘newt’. This string, in addition to serving as a transformation category identifier, will also be included as a suffix appender on the returned column (thus an input column with header ‘targetcolumn’ would be returned as ‘targetcolumn_newt’). Note that if we’re not sure what processdict entries to apply for other properties, we can just copy entries from another category from the library, here we’ll match our other entries to the ‘nmbr’ category by way of a functionpointer entry, which will populate entries corresponding to ‘nmbr’ for processdict entries not already specified. (Note that if we omit the entry for ‘custom_test’ or designate as None, the same custom_train_template will be applied to both training and test data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "processdict = \\\n",
    "{'newt' :\n",
    " {'custom_train' : custom_train_template,\n",
    "  'custom_test' : custom_test_template,\n",
    "  'custom_inversion' : custom_inversion_template,\n",
    "  'functionpointer' : 'nmbr',\n",
    " }}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformdict is for defining sets of transformation categories to be associated with a root transformation category by populating as entries to the Automunge family tree primitives. Thus, when the root category is assigned to a column, the transformation functions associated with the transformation category entries to the family tree primitives will be applied to that column. \n",
    "\n",
    "Here we demonstrate populating a root category set for the ‘newt’ category we just specified in the processdict, which will have transformation functions applied based on the family tree entries of a ‘newt’ category to apply our custom transformation functions as well as the ‘NArw’ category to populate markers for missing data. (Using these same primitives, it is possible to define sets of transformations that include generations and branches of derivations.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformdict = \\\n",
    "{'newt' :\n",
    " {'parents'       : [],\n",
    "  'siblings'      : [],\n",
    "  'auntsuncles'   : ['newt'],\n",
    "  'cousins'       : ['NArw'],\n",
    "  'children'      : [],\n",
    "  'niecesnephews' : [],\n",
    "  'coworkers'     : [],\n",
    "  'friends'       : [],\n",
    " }}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we’ve defined transformation category properties to the new category 'newt' including our custom transformation functions and populated a family tree for the use of 'newt' as a root category, we can then assign the root category to a target column with the automunge(.) assigncat parameter. Note that when assigning the same root category to multiple target columns, the columns can be entered as a list of headers (using [list] brackets) instead of a single string value as shown here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assigncat = \\\n",
    "{'newt' : targetcolumn}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if we want to pass parameters to our custom transformation function we can do so with an additional parameter known as assignparam.\n",
    "\n",
    "Here we'll demonsrtate assigning a multiplier to the output with the 'multiplier' parameter defined in our custom_train_template function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignparam = \\\n",
    "{'newt' : \n",
    " {targetcolumn :\n",
    "  {'multiplier' : 10}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it all together for an automunge(.) call to prepare a training data set df_train would look something like this.\n",
    "\n",
    "(Here we'll also turn off shuffling for visualization purposes and designate our labels_column since it won't be included in df_test.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labelctgy processdict entry wasn't provided for  newt\n",
      "selecting arbitrary entry based on family tree\n",
      "labelctgy selected as  newt\n",
      "\n",
      "_______________\n",
      "Begin Automunge\n",
      "\n",
      "evaluating column:  PassengerId\n",
      "processing column:  PassengerId\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['PassengerId_nmbr', 'PassengerId_NArw']\n",
      "\n",
      "evaluating column:  Pclass\n",
      "processing column:  Pclass\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['Pclass_nmbr', 'Pclass_NArw']\n",
      "\n",
      "evaluating column:  Name\n",
      "processing column:  Name\n",
      "    root category:  hsh2\n",
      " returned columns:\n",
      "['Name_hsh2', 'Name_NArw']\n",
      "\n",
      "evaluating column:  Sex\n",
      "processing column:  Sex\n",
      "    root category:  bnry\n",
      " returned columns:\n",
      "['Sex_bnry', 'Sex_NArw']\n",
      "\n",
      "evaluating column:  Age\n",
      "processing column:  Age\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['Age_nmbr', 'Age_NArw']\n",
      "\n",
      "evaluating column:  SibSp\n",
      "processing column:  SibSp\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['SibSp_nmbr', 'SibSp_NArw']\n",
      "\n",
      "evaluating column:  Parch\n",
      "processing column:  Parch\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['Parch_nmbr', 'Parch_NArw']\n",
      "\n",
      "evaluating column:  Ticket\n",
      "processing column:  Ticket\n",
      "    root category:  hsh2\n",
      " returned columns:\n",
      "['Ticket_hsh2', 'Ticket_NArw']\n",
      "\n",
      "evaluating column:  Fare\n",
      "processing column:  Fare\n",
      "    root category:  newt\n",
      " returned columns:\n",
      "['Fare_newt', 'Fare_NArw']\n",
      "\n",
      "evaluating column:  Cabin\n",
      "processing column:  Cabin\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Cabin_NArw', 'Cabin_1010_0', 'Cabin_1010_1', 'Cabin_1010_2', 'Cabin_1010_3', 'Cabin_1010_4', 'Cabin_1010_5', 'Cabin_1010_6', 'Cabin_1010_7']\n",
      "\n",
      "evaluating column:  Embarked\n",
      "processing column:  Embarked\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Embarked_NArw', 'Embarked_1010_0', 'Embarked_1010_1']\n",
      "\n",
      "______\n",
      "\n",
      "evaluating label column:  Survived\n",
      "processing label column:  Survived\n",
      "    root label category:  lbnb\n",
      "\n",
      " returned columns:\n",
      "['Survived_nmbr']\n",
      "\n",
      "______\n",
      "\n",
      "infill to column:  Cabin_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Cabin_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Cabin_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Cabin_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Cabin_1010_4\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Cabin_1010_5\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Cabin_1010_6\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Cabin_1010_7\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Age_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Embarked_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Embarked_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Fare_newt\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Parch_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  PassengerId_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Pclass_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Sex_bnry\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  SibSp_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "______\n",
      "\n",
      "versioning serial stamp:\n",
      "_6.79_537653204429_2021-09-02T20:58:35.776014\n",
      "\n",
      "Automunge returned ID column set: \n",
      "['Automunge_index']\n",
      "\n",
      "Automunge returned train column set: \n",
      "['PassengerId_nmbr', 'Pclass_nmbr', 'Name_hsh2', 'Sex_bnry', 'Age_nmbr', 'SibSp_nmbr', 'Parch_nmbr', 'Ticket_hsh2', 'Fare_newt', 'PassengerId_NArw', 'Pclass_NArw', 'Name_NArw', 'Sex_NArw', 'Age_NArw', 'SibSp_NArw', 'Parch_NArw', 'Ticket_NArw', 'Fare_NArw', 'Cabin_NArw', 'Cabin_1010_0', 'Cabin_1010_1', 'Cabin_1010_2', 'Cabin_1010_3', 'Cabin_1010_4', 'Cabin_1010_5', 'Cabin_1010_6', 'Cabin_1010_7', 'Embarked_NArw', 'Embarked_1010_0', 'Embarked_1010_1']\n",
      "\n",
      "Automunge returned label column set: \n",
      "['Survived_nmbr']\n",
      "\n",
      "_______________\n",
      "Automunge Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train, train_ID, labels, \\\n",
    "val, val_ID, val_labels, \\\n",
    "test, test_ID, test_labels, \\\n",
    "postprocess_dict = \\\n",
    "am.automunge(\n",
    "  df_train,\n",
    "  labels_column = 'Survived',\n",
    "  shuffletrain=False,\n",
    "  assigncat = assigncat,\n",
    "  assignparam = assignparam,\n",
    "  processdict = processdict,\n",
    "  transformdict = transformdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId_nmbr</th>\n",
       "      <th>Pclass_nmbr</th>\n",
       "      <th>Name_hsh2</th>\n",
       "      <th>Sex_bnry</th>\n",
       "      <th>Age_nmbr</th>\n",
       "      <th>SibSp_nmbr</th>\n",
       "      <th>Parch_nmbr</th>\n",
       "      <th>Ticket_hsh2</th>\n",
       "      <th>Fare_newt</th>\n",
       "      <th>PassengerId_NArw</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_1010_1</th>\n",
       "      <th>Cabin_1010_2</th>\n",
       "      <th>Cabin_1010_3</th>\n",
       "      <th>Cabin_1010_4</th>\n",
       "      <th>Cabin_1010_5</th>\n",
       "      <th>Cabin_1010_6</th>\n",
       "      <th>Cabin_1010_7</th>\n",
       "      <th>Embarked_NArw</th>\n",
       "      <th>Embarked_1010_0</th>\n",
       "      <th>Embarked_1010_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.729137</td>\n",
       "      <td>0.826913</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.530005</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>403</td>\n",
       "      <td>-5.021631</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.725251</td>\n",
       "      <td>-1.565228</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571430</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>611</td>\n",
       "      <td>7.864036</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.721365</td>\n",
       "      <td>0.826913</td>\n",
       "      <td>962</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.254646</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>310</td>\n",
       "      <td>-4.885798</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.717480</td>\n",
       "      <td>-1.565228</td>\n",
       "      <td>796</td>\n",
       "      <td>0</td>\n",
       "      <td>0.364911</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>761</td>\n",
       "      <td>4.204941</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.713594</td>\n",
       "      <td>0.826913</td>\n",
       "      <td>894</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364911</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>190</td>\n",
       "      <td>-4.860644</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId_nmbr  Pclass_nmbr  Name_hsh2  Sex_bnry  Age_nmbr  SibSp_nmbr  \\\n",
       "0         -1.729137     0.826913        200         1 -0.530005    0.432550   \n",
       "1         -1.725251    -1.565228        164         0  0.571430    0.432550   \n",
       "2         -1.721365     0.826913        962         0 -0.254646   -0.474279   \n",
       "3         -1.717480    -1.565228        796         0  0.364911    0.432550   \n",
       "4         -1.713594     0.826913        894         1  0.364911   -0.474279   \n",
       "\n",
       "   Parch_nmbr  Ticket_hsh2  Fare_newt  PassengerId_NArw  ...  Cabin_1010_1  \\\n",
       "0   -0.473408          403  -5.021631                 0  ...             0   \n",
       "1   -0.473408          611   7.864036                 0  ...             1   \n",
       "2   -0.473408          310  -4.885798                 0  ...             0   \n",
       "3   -0.473408          761   4.204941                 0  ...             0   \n",
       "4   -0.473408          190  -4.860644                 0  ...             0   \n",
       "\n",
       "   Cabin_1010_2  Cabin_1010_3  Cabin_1010_4  Cabin_1010_5  Cabin_1010_6  \\\n",
       "0             0             1             0             0             0   \n",
       "1             0             1             0             0             1   \n",
       "2             0             0             0             0             0   \n",
       "3             1             1             1             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   Cabin_1010_7  Embarked_NArw  Embarked_1010_0  Embarked_1010_1  \n",
       "0             0              0                1                1  \n",
       "1             0              0                0                1  \n",
       "2             0              0                1                1  \n",
       "3             0              0                1                1  \n",
       "4             0              0                1                1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the form of the data returned from our custom transformation set as applied to the target feature 'Fare', we can use the column_map saved in the returned dictionary postprocess_dict to access from the returned dataframe train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare_newt</th>\n",
       "      <th>Fare_NArw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.021631</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.864036</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.885798</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.204941</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.860644</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fare_newt  Fare_NArw\n",
       "0  -5.021631          0\n",
       "1   7.864036          0\n",
       "2  -4.885798          0\n",
       "3   4.204941          0\n",
       "4  -4.860644          0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[postprocess_dict['column_map']['Fare']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having populated our postprocess_dict through the automunge call which logs all of the steps and parameters of transformations (you did remember to save it, right?), we can then prepare additional df_test data in a pushbutton operation with a postmunge(.) call which will apply transformations and imputations to corresponding data on a consistent basis. Note that we’ll need to initialize our custom functions again if this is taking place in a separate notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________\n",
      "Begin Postmunge\n",
      "\n",
      "______\n",
      "\n",
      "processing column:  PassengerId\n",
      "    root category:  nmbr\n",
      "\n",
      " returned columns:\n",
      "['PassengerId_nmbr', 'PassengerId_NArw']\n",
      "\n",
      "______\n",
      "\n",
      "processing column:  Pclass\n",
      "    root category:  nmbr\n",
      "\n",
      " returned columns:\n",
      "['Pclass_nmbr', 'Pclass_NArw']\n",
      "\n",
      "______\n",
      "\n",
      "processing column:  Name\n",
      "    root category:  hsh2\n",
      "\n",
      " returned columns:\n",
      "['Name_hsh2', 'Name_NArw']\n",
      "\n",
      "______\n",
      "\n",
      "processing column:  Sex\n",
      "    root category:  bnry\n",
      "\n",
      " returned columns:\n",
      "['Sex_bnry', 'Sex_NArw']\n",
      "\n",
      "______\n",
      "\n",
      "processing column:  Age\n",
      "    root category:  nmbr\n",
      "\n",
      " returned columns:\n",
      "['Age_nmbr', 'Age_NArw']\n",
      "\n",
      "______\n",
      "\n",
      "processing column:  SibSp\n",
      "    root category:  nmbr\n",
      "\n",
      " returned columns:\n",
      "['SibSp_nmbr', 'SibSp_NArw']\n",
      "\n",
      "______\n",
      "\n",
      "processing column:  Parch\n",
      "    root category:  nmbr\n",
      "\n",
      " returned columns:\n",
      "['Parch_nmbr', 'Parch_NArw']\n",
      "\n",
      "______\n",
      "\n",
      "processing column:  Ticket\n",
      "    root category:  hsh2\n",
      "\n",
      " returned columns:\n",
      "['Ticket_hsh2', 'Ticket_NArw']\n",
      "\n",
      "______\n",
      "\n",
      "processing column:  Fare\n",
      "    root category:  newt\n",
      "\n",
      " returned columns:\n",
      "['Fare_newt', 'Fare_NArw']\n",
      "\n",
      "______\n",
      "\n",
      "processing column:  Cabin\n",
      "    root category:  1010\n",
      "\n",
      " returned columns:\n",
      "['Cabin_NArw', 'Cabin_1010_0', 'Cabin_1010_1', 'Cabin_1010_2', 'Cabin_1010_3', 'Cabin_1010_4', 'Cabin_1010_5', 'Cabin_1010_6', 'Cabin_1010_7']\n",
      "\n",
      "______\n",
      "\n",
      "processing column:  Embarked\n",
      "    root category:  1010\n",
      "\n",
      " returned columns:\n",
      "['Embarked_NArw', 'Embarked_1010_0', 'Embarked_1010_1']\n",
      "\n",
      "______\n",
      "\n",
      "infill to column:  Cabin_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Cabin_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Cabin_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Cabin_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Cabin_1010_4\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Cabin_1010_5\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Cabin_1010_6\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Cabin_1010_7\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Age_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Embarked_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Embarked_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Fare_newt\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Parch_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  PassengerId_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Pclass_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Sex_bnry\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  SibSp_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "_______________\n",
      "Postmunge returned ID column set: \n",
      "['Automunge_index']\n",
      "\n",
      "Postmunge returned test column set: \n",
      "['PassengerId_nmbr', 'Pclass_nmbr', 'Name_hsh2', 'Sex_bnry', 'Age_nmbr', 'SibSp_nmbr', 'Parch_nmbr', 'Ticket_hsh2', 'Fare_newt', 'PassengerId_NArw', 'Pclass_NArw', 'Name_NArw', 'Sex_NArw', 'Age_NArw', 'SibSp_NArw', 'Parch_NArw', 'Ticket_NArw', 'Fare_NArw', 'Cabin_NArw', 'Cabin_1010_0', 'Cabin_1010_1', 'Cabin_1010_2', 'Cabin_1010_3', 'Cabin_1010_4', 'Cabin_1010_5', 'Cabin_1010_6', 'Cabin_1010_7', 'Embarked_NArw', 'Embarked_1010_0', 'Embarked_1010_1']\n",
      "\n",
      "_______________\n",
      "Postmunge Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test, test_ID, test_labels, \\\n",
    "postreports_dict = \\\n",
    "am.postmunge(\n",
    "  postprocess_dict,\n",
    "  df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId_nmbr</th>\n",
       "      <th>Pclass_nmbr</th>\n",
       "      <th>Name_hsh2</th>\n",
       "      <th>Sex_bnry</th>\n",
       "      <th>Age_nmbr</th>\n",
       "      <th>SibSp_nmbr</th>\n",
       "      <th>Parch_nmbr</th>\n",
       "      <th>Ticket_hsh2</th>\n",
       "      <th>Fare_newt</th>\n",
       "      <th>PassengerId_NArw</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_1010_1</th>\n",
       "      <th>Cabin_1010_2</th>\n",
       "      <th>Cabin_1010_3</th>\n",
       "      <th>Cabin_1010_4</th>\n",
       "      <th>Cabin_1010_5</th>\n",
       "      <th>Cabin_1010_6</th>\n",
       "      <th>Cabin_1010_7</th>\n",
       "      <th>Embarked_NArw</th>\n",
       "      <th>Embarked_1010_0</th>\n",
       "      <th>Embarked_1010_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.733022</td>\n",
       "      <td>0.826913</td>\n",
       "      <td>927</td>\n",
       "      <td>1</td>\n",
       "      <td>0.330491</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>953</td>\n",
       "      <td>-4.905077</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.736908</td>\n",
       "      <td>0.826913</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>1.190988</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>123</td>\n",
       "      <td>-5.071940</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.740794</td>\n",
       "      <td>-0.369157</td>\n",
       "      <td>846</td>\n",
       "      <td>1</td>\n",
       "      <td>2.223584</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>197</td>\n",
       "      <td>-4.531124</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.744680</td>\n",
       "      <td>0.826913</td>\n",
       "      <td>472</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.185806</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>305</td>\n",
       "      <td>-4.737389</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.748565</td>\n",
       "      <td>0.826913</td>\n",
       "      <td>739</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.530005</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>0.767199</td>\n",
       "      <td>849</td>\n",
       "      <td>-4.007916</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId_nmbr  Pclass_nmbr  Name_hsh2  Sex_bnry  Age_nmbr  SibSp_nmbr  \\\n",
       "0          1.733022     0.826913        927         1  0.330491   -0.474279   \n",
       "1          1.736908     0.826913        183         0  1.190988    0.432550   \n",
       "2          1.740794    -0.369157        846         1  2.223584   -0.474279   \n",
       "3          1.744680     0.826913        472         1 -0.185806   -0.474279   \n",
       "4          1.748565     0.826913        739         0 -0.530005    0.432550   \n",
       "\n",
       "   Parch_nmbr  Ticket_hsh2  Fare_newt  PassengerId_NArw  ...  Cabin_1010_1  \\\n",
       "0   -0.473408          953  -4.905077                 0  ...             0   \n",
       "1   -0.473408          123  -5.071940                 0  ...             0   \n",
       "2   -0.473408          197  -4.531124                 0  ...             0   \n",
       "3   -0.473408          305  -4.737389                 0  ...             0   \n",
       "4    0.767199          849  -4.007916                 0  ...             0   \n",
       "\n",
       "   Cabin_1010_2  Cabin_1010_3  Cabin_1010_4  Cabin_1010_5  Cabin_1010_6  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   Cabin_1010_7  Embarked_NArw  Embarked_1010_0  Embarked_1010_1  \n",
       "0             0              0                1                0  \n",
       "1             0              0                1                1  \n",
       "2             0              0                1                0  \n",
       "3             0              0                1                1  \n",
       "4             0              0                1                1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can use the postprocess_dict returned from automunge(.) to invert transformations. Shown here for the test set that was just prepared (test), inversions could also be performed separately to invert predictions after an inference operation and recover the original form of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________\n",
      "Begin Postmunge\n",
      "\n",
      "Evaluating inversion paths for columns derived from:  PassengerId\n",
      "Inversion path selected based on returned column  PassengerId_nmbr\n",
      "With full recovery.\n",
      "Recovered source column:  PassengerId\n",
      "\n",
      "Evaluating inversion paths for columns derived from:  Pclass\n",
      "Inversion path selected based on returned column  Pclass_nmbr\n",
      "With full recovery.\n",
      "Recovered source column:  Pclass\n",
      "\n",
      "Evaluating inversion paths for columns derived from:  Name\n",
      "No inversion path available for source column:  Name\n",
      "\n",
      "Evaluating inversion paths for columns derived from:  Sex\n",
      "Inversion path selected based on returned column  Sex_bnry\n",
      "With full recovery.\n",
      "Recovered source column:  Sex\n",
      "\n",
      "Evaluating inversion paths for columns derived from:  Age\n",
      "Inversion path selected based on returned column  Age_nmbr\n",
      "With full recovery.\n",
      "Recovered source column:  Age\n",
      "\n",
      "Evaluating inversion paths for columns derived from:  SibSp\n",
      "Inversion path selected based on returned column  SibSp_nmbr\n",
      "With full recovery.\n",
      "Recovered source column:  SibSp\n",
      "\n",
      "Evaluating inversion paths for columns derived from:  Parch\n",
      "Inversion path selected based on returned column  Parch_nmbr\n",
      "With full recovery.\n",
      "Recovered source column:  Parch\n",
      "\n",
      "Evaluating inversion paths for columns derived from:  Ticket\n",
      "No inversion path available for source column:  Ticket\n",
      "\n",
      "Evaluating inversion paths for columns derived from:  Fare\n",
      "Inversion path selected based on returned column  Fare_newt\n",
      "With full recovery.\n",
      "Recovered source column:  Fare\n",
      "\n",
      "Evaluating inversion paths for columns derived from:  Cabin\n",
      "Inversion path selected based on returned column  Cabin_1010_0\n",
      "With full recovery.\n",
      "Recovered source column:  Cabin\n",
      "\n",
      "Evaluating inversion paths for columns derived from:  Embarked\n",
      "Inversion path selected based on returned column  Embarked_1010_0\n",
      "With full recovery.\n",
      "Recovered source column:  Embarked\n",
      "\n",
      "Inversion succeeded in recovering original form for columns:\n",
      "['PassengerId', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_invert, recovered_list, \\\n",
    "inversion_info_dict = \\\n",
    "am.postmunge(\n",
    "  postprocess_dict,\n",
    "  test,\n",
    "  inversion='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that an inversion will not recover input form for transforms that do not support inversion, such as the transforms applied to 'Name' and 'Ticket'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>5.960464e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.829203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>5.960464e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.687502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.960464e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.662500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.287500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass     Sex   Age         SibSp  Parch       Fare Cabin  \\\n",
       "0        892.0     3.0    male  34.5  5.960464e-08    0.0   7.829203   NaN   \n",
       "1        893.0     3.0  female  47.0  1.000000e+00    0.0   7.000000   NaN   \n",
       "2        894.0     2.0    male  62.0  5.960464e-08    0.0   9.687502   NaN   \n",
       "3        895.0     3.0    male  27.0  5.960464e-08    0.0   8.662500   NaN   \n",
       "4        896.0     3.0  female  22.0  1.000000e+00    1.0  12.287500   NaN   \n",
       "\n",
       "  Embarked  \n",
       "0        Q  \n",
       "1        S  \n",
       "2        Q  \n",
       "3        S  \n",
       "4        S  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_invert.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have all you need to define custom transformations for integration into an Automunge data pipeline. Remember, with great power comes great responsibility. Don’t forget to have fun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
