{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automunge Noise Injection Demonstrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automunge has a suite of options for injecting noise into tabular features. We expect noise injections may serve several potential benefits such as a resource for data augmentation, bias mitigation, differential privacy, model perturbation for aggregation of ensembles, and non-determinism. Noise injections were introduced in the paper [Numeric Encoding Options with Automunge](https://medium.com/automunge/a-numbers-game-b68ac261c40d) and discussed in more depth in the essay [Noise Injections with Automunge](https://medium.com/automunge/noise-injections-with-automunge-7ebb672216e2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Automunge import *\n",
    "am = AutoMunge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll demonstrate feature importance on the [Titanic](https://www.kaggle.com/c/titanic/data) set, a common benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#titanic set\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "#titanic set\n",
    "labels_column = 'Survived'\n",
    "trainID_column = 'PassengerId'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DP transformation categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DP family of transforms are surveyed in the README's library of transformations as [Differential Privacy Noise Injections](https://github.com/Automunge/AutoMunge/blob/master/README.md#differential-privacy-noise-injections). \n",
    "\n",
    "The noise injections are performed in conjunction with numeric normalizations or categoric encodings. Here is a quick survey of options available as of version 7.59:\n",
    "\n",
    "### Numeric Injections:\n",
    "- **DPnb**: z-score normalization with Gaussian noise\n",
    "- **DPmm**: min-max scaling with scaled Gaussian noise\n",
    "- **DPrt**: retain normalization with scaled Gaussian noise\n",
    "- **DLnb / DLmm / DLrt**: similar to three preceding with default to Laplace distributed noise instead of Gaussian\n",
    "- **DPqt**: distribution conversion by quantile transform with Gaussian noise\n",
    "- **DPbx**: distribution conversion by box-cox transform with Gaussian noise\n",
    "- **DPns**: z-score normalization with swap-noise injection\n",
    "- **DPne**: pass-through as numeric with noise, no normalization or infill\n",
    "\n",
    "### Categoric Injections:\n",
    "- **DPbn**: boolean integer encoding with weighted activation flips\n",
    "- **DPod**: ordinal encoding with weighted activation flips\n",
    "- **DPoh**: one hot encoding with weighted activation flips\n",
    "- **DP10**: binarization with weighted activation set flips\n",
    "- **DP1s**: binarization with swap-noise injection\n",
    "- **DPhs**: multi column hash encoding (like hash) with weighted activation flips\n",
    "- **DPh2**: single column hash encoding (like hsh2) with weighted activation flips\n",
    "- **DPh1**: multi column hash binarization (like hs10) with weighted activation set flips\n",
    "- **DPse**: pass-through as cateogric with swap noise, no encoding or infill\n",
    "\n",
    "Here is an example of assigning some of these root categories to received features with headers 'column1', 'column2', 'column3'. DTnb is z-score normalization with Gaussian noise to test data, shown here assigned to column1. DBod is ordinal encoding with weighted activation flips to both train and test data, shown here assigned to column2 and column3. (To just inject to train data the identifier string for that default configuration replaces the DT or DB prefix with DP.)\n",
    "```\n",
    "assigncat = {\n",
    "  'DTnb' : 'column1',\n",
    "  'DBod' : ['column2', 'column3'],\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DP parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these transformations accepts optional parameter specifications to vary from the defaults. Parameters are passed to transformations through the automunge(.) assignparam parameter. As we described in Appendix F, parameter assignments through assignparam can be conducted in three ways, where global_assignparam passes the setting to every transform applied to every column, default_assignparam pass the same setting to every instance of a specific transformation's tree category identifier applied to any column, or in the third option a parameter setting can be assigned to a specific transformation tree category identifier passed to a specific column (where that column may be an input column or a derived column with suffix appender passed to the transform). Note that the difference between a tree category and a root category is that a root category is the identifier of the family tree of transformation categories assigned to a column in the assigncat parameter, and a tree category is an entry to one of those family tree primitives which is used to access the transformation function. To restate for clarity, the (column) string designates one of either the input column header (before suffixes are applied) or an intermediate column header with suffixes that serves as input to the target transformation.\n",
    "```\n",
    "assignparam = {\n",
    "  'global_assignparam'  : {'(parameter)': 42},\n",
    "  'default_assignparam' : {'(category)' : {'(parameter)' : 42}},\n",
    "  '(category)' : {'(column)'   : {'(parameter)' : 42}},\n",
    "}\n",
    "```\n",
    "For noise injections that are performed in conjunction with a normalization or encoding, the noise transform is generally applied in a different tree category than the encoding transform, so if parameters are desired to be passed to the encoding, assignparam will need to target a different tree category for the encoding than for the noise. Generally speaking, the noise transform family trees have been configured so that the noise tree category matches the root category, which was intentional for simplicity of paramter assignment (with an exception for DPhs for esoteric reasons). To view the full family tree such as to inspect the encoding tree category, the set of family trees associated with various root categories are provided in the code repository as FamilyTrees.md.\n",
    "\n",
    "As noted in Appendix D, for subsequent data passed to postmunge(.), the data can also be treated as test data or train data, and in both cases also have noise deactivated. The postmunge(.) traindata parameter defaults to False to prepare postmunge(.) as test data and accepts entries of {False, True, 'test\\_no\\_noise', 'train\\_no\\_noise'\\}.\n",
    "\n",
    "Note that assignparam can also be used to deviate from the default train or test noise injection settings. As noted above, the convention for the string identifiers of noise root categories is that 'DP' injects noise to train and not test data, 'DT' injects noise to test and not train data, and 'DB' injects noise to both train and test data. These are the defaults, but each of these can be updated by parameter assignment with assignparam specification of 'trainnoise' or 'testnoise' parameters. \n",
    "\n",
    "As further illustrated in Table 2 of [Noise Injections with Automunge](https://medium.com/automunge/noise-injections-with-automunge-7ebb672216e2), the trainnoise and testnoise parameters can be used in conjunction with the postmunge(.) traindata parameter to target noise towards train and/or test data.\n",
    "\n",
    "Most of the noise injection transforms share common parameters between those targeting numeric or categoric entries. Here is a summary.\n",
    "\n",
    "### Numeric Parameters:\n",
    "- **trainnoise**: activates noise injection to train data (defaults True for DP or DB and False for DT)\n",
    "- **testnoise**: activates noise injection to test data (defaults True for DT or DB and False for DP)\n",
    "- **flip_prob**: ratio of train entries receiving injection\n",
    "- **test_flip_prob**: ratio of test entries receiving injection\n",
    "- **sigma**: scale of train noise distribution\n",
    "- **test_sigma**: scale of test noise distribution\n",
    "- **mu**: mean of train noise distribution (before any scaling)\n",
    "- **test_mu**: mean of test noise distribution (before any scaling)\n",
    "- **noisedistribution**: train noise distribution, defaults to 'normal' (Gaussian), accepts one of {'normal', 'laplace', 'uniform', 'abs_normal', 'abs_laplace', 'abs_uniform', 'negabs_normal', 'negabs_laplace', 'negabs_uniform'}, where abs refers to all positive signed noise and negabs refers to all negative signed noise\n",
    "- **test_noisedistribution**:  test noise distribution, comparable options supported\n",
    "- **rescale_sigmas**: for min-max normalization (DPmm) or retain normalization (DPrt), this activates the mean adjustment noted in Appendix H, defaults to True\n",
    "- **retain_basis**: for cases where distribution parameters passed as list or distribution, activating retain_basis means the basis sampled in automunge is carried through to postmunge or the default of False means a unique basis is sampled in automunge and postmunge\n",
    "\n",
    "### Categoric and Swap Parameters:\n",
    "- **trainnoise**: activates noise injection to train data (defaults True for DP or DB and False for DT)\n",
    "- **testnoise**: activates noise injection to test data (defaults True for DT or DB and False for DP)\n",
    "- **flip_prob**: ratio of train entries receiving injection\n",
    "- **test_flip_prob**: ratio of test entries receiving injection\n",
    "- **weighted**: weighted vs uniform sampling of activation flips to train data\n",
    "- **test_weighted**: weighted vs uniform sampling of activation flips to test data\n",
    "- **retain_basis**: for cases where distribution parameters passed as list or distribution, activating retain_basis means the basis sampled in automunge is carried through to postmunge or the default of False means a unique basis is sampled in automunge and postmunge\n",
    "\n",
    "Here is an example of assignparam specification to: \n",
    "- set an all positive noise distribution for category DPmm as applied to an input column with header 'column1', noting that for scaled noise like DPmm all positive or all negative noise should be performed with a deactivated noise_scaling_bias_offset.\n",
    "- update the flip_prob parameter to 0.1 for all cases of DPnb injections via default_assignparam\n",
    "- apply testnoise injections to all noise transforms via global_assignparam\n",
    "```\n",
    "#assumes DPmm and DPnb have been assigned in assigncat\n",
    "assignparam = {\n",
    "  'DPmm' : {'inputcolumn': {'noisedistribution'         : 'abs_normal',\n",
    "                            'noise_scaling_bias_offset' : False}},\n",
    "  'default_assignparam' : {'DPnb' : {'flip_prob' : 0.1}},\n",
    "  'global_assignparam'  : {'testnoise': True},\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise injection under automation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The automunge(.) powertransform parameter can be used to select between alternate sets of default transformations applied under automation. We currently have two scenarios for default encodings with noise, inlcuding powertransform passed as one of {'DP1', 'DP2'}. DP2 differs from DP1 in that numerical defaults to retain normalization instead of z-score and categoric defaults to ordinal instead of binarization. (Or DT and DB equivalents DT1/DT2/DB1/DB2 for different default train and test noise configurations.)\n",
    "\n",
    "**'DP1'** \n",
    "- numerical receives DPnb\n",
    "- categoric receives DP10\n",
    "- binary receives DPbn\n",
    "- hash receives DPhs, \n",
    "- hsh2 receives DPh2 \n",
    "- (labels do not receive noise)\n",
    "\n",
    "**'DP2'**\n",
    "- numerical receives DPrt\n",
    "- categoric receives DPod\n",
    "- binary receives DPbn\n",
    "- hash receives DPhs, \n",
    "- hsh2 receives DPh2 \n",
    "- (labels do not receive noise)\n",
    "\n",
    "An example specification:\n",
    "```\n",
    "powertransform = 'DP2'\n",
    "```\n",
    "\n",
    "Otherwise noise can just be manually assigned in the assigncat parameter as demonstrated above, which specificaitons will take precedence over what would otherwise be performed under automation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation with Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation refers to increasing the size of a training set with manipulations to increase variety. In the image modality it is common to achieve data augmentation by way of adjustments like image cropping, rotations, color shift, etc. Here we are simply adding noise for similar effect. In a deep learning benchmark performed in our paper [Numeric Encoding Options with Automunge](https://medium.com/automunge/a-numbers-game-b68ac261c40d) we found that this type of data augmentation was fairly benign with a fully represented data set, but was increasingly beneficial with underserved training data.\n",
    "\n",
    "Data augmentation can be realized by assigning noise transforms in conjunction with the automunge(.) noise_augment parameter, which accepts integers of number of additional duplicates to prepare, e.g. noise_augment=1 would double the size of the training set returned from automunge(.). For cases where too much duplication starts to run into memory constraints additional duplicates can also be prepared with postmunge(.), which also has a noise_augment parameter option and accepts the traindata parameter to distinguish whether a data set is to be treated as train or test data.\n",
    "\n",
    "Under the default configuration when noise_augment is received as an integer dtype, one of the duplicates will be prepared without noise. If noise_augment is received as a float(int) type, all of the duplicates will be prepared with noise.\n",
    "\n",
    "Here is an example of preparing data augmentation for the Titanic set loaded earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of rows in original training data\n",
    "df_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, train_ID, labels, \\\n",
    "val, val_ID, val_labels, \\\n",
    "test, test_ID, test_labels, \\\n",
    "postprocess_dict = \\\n",
    "am.automunge(df_train,\n",
    "             powertransform = 'DP2',\n",
    "             noise_augment = 2.0,\n",
    "             printstatus = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2673"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of rows in training data after noise_augment\n",
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternate random samplers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random sampling for noise injection defaults to numpy's PCG64, which is based on the [PCG pseudo random number generator](https://www.pcg-random.org/index.html). On its own this generator is not truly random, it relies on seedings of entropy provided by the operating system which are then enhanced through use. To support integration of enhanced randomness profiles, both automunge(.) and postmunge(.) accept parameters for entropy_seeds and random_generator.\n",
    "\n",
    "entropy_seeds accepts an integer or list/array of integers which may serve as a supplemental source of entropy for the numpy.random generator to enhance randomness properties.\n",
    "\n",
    "random_generator accepts input of a numpy.random.Generator formatted random sampler. An example could be numpy.random.MT19937 for Mersenne Twister, or could even be an external library with a numpy.random formatted generator, such as for example could be used to sample with the support of quantum circuits.\n",
    "\n",
    "If an alternate library does not have a numpy.random formatted generator, their output can be channeled to entropy_seeds for similar benefit.\n",
    "\n",
    "Specifications of entropy_seeds and random_generator are specific to an automunge(.) or postmunge(.) call, in other words they are not returned in the populated postprocess_dict.\n",
    "\n",
    "The two parameters can also be passed in tangent, for sampling with a custom generator with custom supplemental entropy seeds.\n",
    "\n",
    "Here is an example of specifying an alternate generator and supplemental entropy seedings.\n",
    "```\n",
    "random_generator = numpy.random.MT19937\n",
    "entropy_seeds = [4,5,6]\n",
    "```\n",
    "In the default case the same bank of entropy seeds is fed to each sampling operation with a shuffle. The library also supports different types of sampling scenarios that can be supported by entropy seedings. Alternate sampling scenarios can be specified to automunge(.) or postmunge(.) by the sampling_dict parameter. Here are a few scenarios to illustrate.\n",
    "\n",
    "1) In one scenario, instead of passing externally sampled supplemental entropy seeds, a user can pass a custom generator for internal sampling of entropy seeds. Here is an example of using a custom generator to sampling entropy seeds and the default generator PCG64 for sampling applied in the transformations. The sampling_type bulk_seeds means that a unique seed will be generated for each sampled entry.\n",
    "```\n",
    "random_generator = (custom numpy formatted generator)\n",
    "entropy_seeds = False\n",
    "sampling_dict = \\\n",
    "{'sampling_type' : 'bulk_seeds',\n",
    " 'extra_seed_generator' : 'custom',\n",
    " 'sampling_generator' : 'PCG64',\n",
    " }\n",
    "```\n",
    "\n",
    "2) In another scenario a user may want to reduce their sampling budget by only accessing one entropy seed for each set of entries. This is accessed with the sampling_type of sampling_seed.\n",
    "```\n",
    "random_generator = (custom numpy formatted generator)\n",
    "entropy_seeds = False\n",
    "sampling_dict = \\\n",
    "{'sampling_type' : 'sampling_seed',\n",
    " 'extra_seed_generator' : 'custom',\n",
    " 'sampling_generator' : 'PCG64',\n",
    " }\n",
    "```\n",
    "\n",
    "3) There may be a case where a source of supplemental entropy seeds isn't available as a numpy.random formatted generator. In this case, in order to apply one of the alternate sampling_type scenarios, a user may desire to know a budget of how many seeds are required for externally sampled seeds passed through the entropy_seeds parameter. This can be accomplished by first running the automunge(.) call without entropy seeding specifications to generate the report returned as postprocess_dict['sampling_report_dict']. (note that if sampling seeds internally with a custom generator this isn't needed.) Note that the sampling_report_dict will report requirements separately for train and test data and in the bulk_seeds case will have a row count basis. (If not passing test data to automunge(.) the test budget can be omitted. For postmunge the use of train or test budget should align with the postmunge traindata parameter.) For example, if a user wishes to derive a set of entropy seeds to support a bulk_seeds sampling type, they can produce a report and derive as follows:\n",
    "```\n",
    "#first run automunge(.) to populate postprocess_dict (not shown)\n",
    "#using comparable category and parameter assignments\n",
    "#we recommend running initially with default sampling_type\n",
    "#which will populate sampling_report_dict for test data even if df_test not provided\n",
    "\n",
    "#access the sampling_report_dict in the returned postprocess_dict\n",
    "sampling_report_dict = postprocess_dict['sampling_report_dict']\n",
    "\n",
    "#a bulk_seeds sampling_type budget will need to take account for row counts\n",
    "rowcount_train = df_train.shape[0]\n",
    "rowcount_test = df_test.shape[0]\n",
    "\n",
    "#the budget can be derived as\n",
    "train_budget = \\\n",
    "sampling_report_dict['bulk_seeds_total_train'] * rowcount_train \\\n",
    "/ sampling_report_dict['rowcount_basis_train']\n",
    "\n",
    "test_budget = \\\n",
    "sampling_report_dict['bulk_seeds_total_test'] * rowcount_test \\\n",
    "/ sampling_report_dict['rowcount_basis_test']\n",
    "\n",
    "#number of external seeds needed for bulk seeds case:\n",
    "seed_count = \\\n",
    "train_budget + test_budget\n",
    "\n",
    "#this number of seeds can then be passed to the entropy_seeds parameter\n",
    "\n",
    "random_generator = False\n",
    "entropy_seeds = externally_sampled_seeds_list\n",
    "sampling_dict = \\\n",
    "{'sampling_type' : 'bulk_seeds',\n",
    " 'extra_seed_generator' : 'PCG64',\n",
    " 'sampling_generator' : 'PCG64',\n",
    " }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QRAND library sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sample noise from a quantum circuit, a user can either pass externally sampled entropy_seeds or make use of an external library with a numpy.random formatted generator. Here's an example of using the [QRAND](https://github.com/pedrorrivero/qrand) library to sample from a quantum circuit, based on a tutorial provided in their read me which makes use of Qiskit for access to cloud resources.\n",
    "\n",
    "To sample noise from a quantum circuit, a user can either pass externally sampled entropy_seeds or make use of an external library with a numpy.random formatted generator. Here's an example of using the [QRAND](https://github.com/pedrorrivero/qrand) library to sample from a quantum circuit, based on a tutorial provided in their read me which makes use of [Qiskit](https://www.ibm.com/quantum-computing/) for access to cloud resources.\n",
    "\n",
    "```\n",
    "from qrand import QuantumBitGenerator\n",
    "from qrand.platforms import QiskitPlatform\n",
    "from qrand.protocols import HadamardProtocol\n",
    "from numpy.random import Generator\n",
    "from qiskit import IBMQ\n",
    "\n",
    "provider = IBMQ.load_account()\n",
    "platform = QiskitPlatform(provider)\n",
    "protocol = HadamardProtocol()\n",
    "bitgen = QuantumBitGenerator(platform, protocol)\n",
    "# gen = Generator(bitgen)\n",
    "\n",
    "#then can initialize automunge(.) or postmunge(.) parameters as\n",
    "random_generator = bitgen\n",
    "entropy_seeds = False\n",
    "sampling_dict = \\\n",
    "{'sampling_type' : 'default',\n",
    " 'extra_seed_generator' : 'off',\n",
    " 'sampling_generator' : 'custom',\n",
    " }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Together Now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a quick demonstration tieing it all together.\n",
    "\n",
    "Here we'll apply the powertransform = 'DP2' option for noise under augmentation, override a few of the default transforms with assigncat, assign a few deviations to transformation parameters via assignparam, add some additional entropy seeds from some other resource, and prepare a few additional training data duplicates for data augmentation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "powertransform = 'DP2'\n",
    "\n",
    "assigncat = {'DPh2' : 'Name'}\n",
    "\n",
    "noise_augment = 2.\n",
    "\n",
    "entropy_seeds = [432,6,243,561232,89]\n",
    "\n",
    "#(Age is a feature header in the Titanic data set)\n",
    "assignparam = {\n",
    "    'DPrt' : {'Age': {'noisedistribution'         : 'abs_normal',\n",
    "                      'noise_scaling_bias_offset' : False}},\n",
    "    'default_assignparam' : {'DPrt' : {'flip_prob' : 0.1}},\n",
    "    'global_assignparam'  : {'testnoise': True},\n",
    "}\n",
    "\n",
    "train, train_ID, labels, \\\n",
    "val, val_ID, val_labels, \\\n",
    "test, test_ID, test_labels, \\\n",
    "postprocess_dict = \\\n",
    "am.automunge(df_train,\n",
    "             labels_column = labels_column,\n",
    "             trainID_column = trainID_column,\n",
    "             powertransform = powertransform,\n",
    "             assigncat = assigncat,\n",
    "             noise_augment = noise_augment,\n",
    "             entropy_seeds = entropy_seeds,\n",
    "             assignparam = assignparam,\n",
    "             printstatus = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass_NArw</th>\n",
       "      <th>Pclass_DPrt</th>\n",
       "      <th>Name_NArw</th>\n",
       "      <th>Name_DPh2_DPo7</th>\n",
       "      <th>Sex_NArw</th>\n",
       "      <th>Sex_DPb2_DPbn</th>\n",
       "      <th>Age_NArw</th>\n",
       "      <th>Age_DPrt</th>\n",
       "      <th>SibSp_NArw</th>\n",
       "      <th>SibSp_DPrt</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticket_NArw</th>\n",
       "      <th>Ticket_DPhs_0_mlhs_DPod</th>\n",
       "      <th>Ticket_DPhs_1_mlhs_DPod</th>\n",
       "      <th>Ticket_DPhs_2_mlhs_DPod</th>\n",
       "      <th>Fare_NArw</th>\n",
       "      <th>Fare_DPrt</th>\n",
       "      <th>Cabin_NArw</th>\n",
       "      <th>Cabin_DPo4_DPod</th>\n",
       "      <th>Embarked_NArw</th>\n",
       "      <th>Embarked_DPo4_DPod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.132948</td>\n",
       "      <td>0</td>\n",
       "      <td>0.433644</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.061045</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>806</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019854</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>328</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.041136</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>355</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.358235</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>870</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013387</td>\n",
       "      <td>1</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>590</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.497361</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>915</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.054457</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>961</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.308872</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>921</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013761</td>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Pclass_NArw  Pclass_DPrt  Name_NArw  Name_DPh2_DPo7  Sex_NArw  \\\n",
       "25              0          1.0          0              19         0   \n",
       "1789            0          1.0          0             806         0   \n",
       "1302            0          1.0          0             355         0   \n",
       "253             0          1.0          0             590         0   \n",
       "1775            0          1.0          0             961         0   \n",
       "\n",
       "      Sex_DPb2_DPbn  Age_NArw  Age_DPrt  SibSp_NArw  SibSp_DPrt  ...  \\\n",
       "25                0         0  0.132948           0    0.433644  ...   \n",
       "1789              1         0  0.019854           0    0.375000  ...   \n",
       "1302              1         1  0.358235           0    0.000000  ...   \n",
       "253               1         0  0.497361           0    0.125000  ...   \n",
       "1775              1         0  0.308872           0    0.000000  ...   \n",
       "\n",
       "      Ticket_NArw  Ticket_DPhs_0_mlhs_DPod  Ticket_DPhs_1_mlhs_DPod  \\\n",
       "25              0                      119                        0   \n",
       "1789            0                      328                        0   \n",
       "1302            0                      870                        0   \n",
       "253             0                      915                        0   \n",
       "1775            0                      921                      236   \n",
       "\n",
       "      Ticket_DPhs_2_mlhs_DPod  Fare_NArw  Fare_DPrt  Cabin_NArw  \\\n",
       "25                          0          0   0.061045           1   \n",
       "1789                        0          0   0.041136           1   \n",
       "1302                        0          0   0.013387           1   \n",
       "253                         0          0   0.054457           1   \n",
       "1775                        0          0   0.013761           1   \n",
       "\n",
       "      Cabin_DPo4_DPod  Embarked_NArw  Embarked_DPo4_DPod  \n",
       "25                  3              0                   1  \n",
       "1789                7              0                   1  \n",
       "1302              146              0                   3  \n",
       "253                 3              0                   1  \n",
       "1775              129              0                   1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly we can prepare additional test data in postmunge(.) using the postprocess_dict returned from automunge(.), which since we set testnoise as globally activated will result in injected noise in the default traindata=False case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_seeds = [2345, 77887, 2342, 7878789]\n",
    "\n",
    "traindata = False\n",
    "\n",
    "test, test_ID, test_labels, \\\n",
    "postreports_dict = \\\n",
    "am.postmunge(postprocess_dict, \n",
    "             df_test,\n",
    "             entropy_seeds = entropy_seeds,\n",
    "             traindata=traindata,\n",
    "             printstatus=False,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass_NArw</th>\n",
       "      <th>Pclass_DPrt</th>\n",
       "      <th>Name_NArw</th>\n",
       "      <th>Name_DPh2_DPo7</th>\n",
       "      <th>Sex_NArw</th>\n",
       "      <th>Sex_DPb2_DPbn</th>\n",
       "      <th>Age_NArw</th>\n",
       "      <th>Age_DPrt</th>\n",
       "      <th>SibSp_NArw</th>\n",
       "      <th>SibSp_DPrt</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticket_NArw</th>\n",
       "      <th>Ticket_DPhs_0_mlhs_DPod</th>\n",
       "      <th>Ticket_DPhs_1_mlhs_DPod</th>\n",
       "      <th>Ticket_DPhs_2_mlhs_DPod</th>\n",
       "      <th>Fare_NArw</th>\n",
       "      <th>Fare_DPrt</th>\n",
       "      <th>Cabin_NArw</th>\n",
       "      <th>Cabin_DPo4_DPod</th>\n",
       "      <th>Embarked_NArw</th>\n",
       "      <th>Embarked_DPo4_DPod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.428248</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>739</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015282</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.122006</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>789</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013663</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018256</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>310</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.334004</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>822</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016908</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>311</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>829</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023984</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass_NArw  Pclass_DPrt  Name_NArw  Name_DPh2_DPo7  Sex_NArw  \\\n",
       "0            0          1.0          0              15         0   \n",
       "1            0          1.0          0              68         0   \n",
       "2            0          0.5          0              44         0   \n",
       "3            0          1.0          0             310         0   \n",
       "4            0          1.0          0             311         0   \n",
       "\n",
       "   Sex_DPb2_DPbn  Age_NArw  Age_DPrt  SibSp_NArw  SibSp_DPrt  ...  \\\n",
       "0              1         0  0.428248           0    0.000000  ...   \n",
       "1              0         0  1.000000           0    0.122006  ...   \n",
       "2              1         0  1.000000           0    0.000000  ...   \n",
       "3              1         0  0.334004           0    0.000000  ...   \n",
       "4              0         0  0.271174           0    0.125000  ...   \n",
       "\n",
       "   Ticket_NArw  Ticket_DPhs_0_mlhs_DPod  Ticket_DPhs_1_mlhs_DPod  \\\n",
       "0            0                      739                        0   \n",
       "1            0                      789                        0   \n",
       "2            0                       87                        0   \n",
       "3            0                      822                        0   \n",
       "4            0                      829                        0   \n",
       "\n",
       "   Ticket_DPhs_2_mlhs_DPod  Fare_NArw  Fare_DPrt  Cabin_NArw  Cabin_DPo4_DPod  \\\n",
       "0                        0          0   0.015282           1               45   \n",
       "1                        0          0   0.013663           1                3   \n",
       "2                        0          0   0.018256           1                5   \n",
       "3                        0          0   0.016908           1               45   \n",
       "4                        0          0   0.023984           1                3   \n",
       "\n",
       "   Embarked_NArw  Embarked_DPo4_DPod  \n",
       "0              0                   3  \n",
       "1              0                   1  \n",
       "2              0                   3  \n",
       "3              0                   1  \n",
       "4              0                   1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise directed at existing data pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more thing. When noise is intended for direction at an existing data pipeline, such as for incorporation of noise into test data for an inference operation on a previously trained model, there may be desire to inject noise without other edits to a dataframe. This is possible by passing the dataframe as a df_train to an automunge(.) call and assigning the various features to one of these three pass-through categories:\n",
    "\n",
    "- DPne: pass-through numeric with gaussian (or laplace) noise, comparable parameter support to DPnb\n",
    "- DPse: pass-through with swap noise (e.g. for categoric data), comparable parameter support to DPmc\n",
    "- excl: pass-through without noise\n",
    "\n",
    "Note that DPse injects swap noise by accessing an alternate row entry for a target. This type of noise may not be suitable for test data injections in a scenario where inference may be run on a test set with one or very few samples. The convention in library is that data is received in a tidy form (one column per feature and one row per observation), so ideally categoric features should be received in a single column configuration for targeting with DPse.\n",
    "\n",
    "Note that DPne will return entries as float data type, converting any non-numeric to NaN. The default noise scale for DPne (sigma=0.06 / test_sigma=0.03) is set to align with z-score normalized data. For the DPne pass-through transform, since the feature may not be z-score normalized, the scaling is adjusted by multiplication with the evaluated standard deviation of the feature as found in the training data by use of the defaulted parameter rescale_sigmas = True. This adjustment factor is derived based on the training data used to fit the postprocess_dict, and that same basis is carried through to postmunge(.). If user doesn't have access to the training data, they can fit the postprocess_dict to a representative df_test routed as the automunge(.) df_train.\n",
    "\n",
    "Here is an example of injecting noise to the Titanic's df_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = \\\n",
    "['Age', 'Fare']\n",
    "\n",
    "categoric_features = \\\n",
    "['Pclass', 'Name', 'Sex', 'SibSp', 'Parch', 'Ticket', 'Cabin', 'Embarked']\n",
    "\n",
    "passthrough_features = \\\n",
    "['PassengerId']\n",
    "\n",
    "#assign the features to one of DTne/DTse/excl\n",
    "#The DT configuration defaults to injecting noise just to test data\n",
    "assigncat = \\\n",
    "{'DTne' : numeric_features, #numeric features receiving gaussian noise\n",
    " 'DTse' : categoric_features, #categproc features receiving swap noise\n",
    " 'excl' : passthrough_features,\n",
    "}\n",
    "\n",
    "#if we want to update the noise parameters they can be applied in assignparam\n",
    "#shown here are the defaults\n",
    "assignparam = \\\n",
    "{'default_assignparam' : \n",
    "  {'DPne' : {'test_sigma' : 0.06,\n",
    "             'rescale_sigmas' : True},\n",
    "   'DTse' : {'test_flip_prob' : 0.01}}}\n",
    "\n",
    "#We'll also deactivate shuffletrain to retain order of rows\n",
    "shuffletrain = False\n",
    "\n",
    "#note that the family trees for DPne/DPse/excl do not include NArw aggregation\n",
    "#so no need to deactivate NArw_marker\n",
    "#they are also already excluded from infill based on process_dict specification\n",
    "#so no need to deactivate MLinfill\n",
    "\n",
    "#the orig_headers parameter retains original column headers without suffix appenders\n",
    "orig_headers = True\n",
    "\n",
    "#this operation will fit the postprocess_dict to the df_test\n",
    "#if the training set is accessible that could be used in its place \n",
    "train, train_ID, labels, \\\n",
    "val, val_ID, val_labels, \\\n",
    "test, test_ID, test_labels, \\\n",
    "postprocess_dict = \\\n",
    "am.automunge(df_test,\n",
    "             assigncat = assigncat,\n",
    "             assignparam = assignparam,\n",
    "             shuffletrain = shuffletrain,\n",
    "             orig_headers = orig_headers,\n",
    "             printstatus = False,\n",
    "            )\n",
    "            \n",
    "#we can then use the populated postprocess_dict to run postmunge(.)\n",
    "#which has better latency than automunge(.)\n",
    "#the entropy seeding parameters are shown with their defaults for reference\n",
    "\n",
    "test, test_ID, test_labels, \\\n",
    "postreports_dict = \\\n",
    "am.postmunge(\n",
    "  postprocess_dict, \n",
    "  df_test,\n",
    "  printstatus = False,\n",
    "  random_generator = False,\n",
    "  entropy_seeds = False,\n",
    "  sampling_dict = {},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned dataframe test can then be passed to inference. The order of columns in returned dataframe will be retained for these transforms and the orig_headers parameter retains original column headers without suffix appenders.\n",
    "\n",
    "The postmunge(.) call can then be repeated as additional inference data becomes available, and could be applied sequentially to streams of data in inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
