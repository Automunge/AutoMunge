{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automunge under automation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automunge is available now for pip install:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Automunge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or to upgrade (we currently roll out upgrades pretty frequently):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Automunge --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once installed, run this in a local session to initialize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Automunge import Automunger\n",
    "am = Automunger.AutoMunge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under automation, the automunge(.) function will: \n",
    "- normalize numeric features\n",
    "- binarize bounded categoric features\n",
    "- hash unbounded categoric features\n",
    "- encode date-time entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate, let's encode the Titanic set, a well known benchmark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#titanic set\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what the data looks like in a raw form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to designate to automunge any columns that are to be treated as labels or ID sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic set\n",
    "labels_column = 'Survived'\n",
    "trainID_column = 'PassengerId'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then pass these dataframes to the automunge(.) function for processing.\n",
    "\n",
    "Note that the function call returns 17 sets. some of which may be empty based on parameter configurations. It's an unusual convention but we find that by having one return configuration for all scenarios it keeps things simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________\n",
      "Begin Automunge processing\n",
      "\n",
      "evaluating column:  Pclass\n",
      "processing column:  Pclass\n",
      "    root category:  text\n",
      " returned columns:\n",
      "['Pclass_1.0', 'Pclass_2.0', 'Pclass_3.0']\n",
      "\n",
      "evaluating column:  Name\n",
      "processing column:  Name\n",
      "    root category:  hash\n",
      " returned columns:\n",
      "['Name_hash_0', 'Name_hash_1', 'Name_hash_2', 'Name_hash_3', 'Name_hash_4', 'Name_hash_5', 'Name_hash_6', 'Name_hash_7', 'Name_hash_8', 'Name_hash_9', 'Name_hash_10', 'Name_hash_11', 'Name_hash_12', 'Name_hash_13']\n",
      "\n",
      "evaluating column:  Sex\n",
      "processing column:  Sex\n",
      "    root category:  bnry\n",
      " returned columns:\n",
      "['Sex_bnry']\n",
      "\n",
      "evaluating column:  Age\n",
      "processing column:  Age\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['Age_nmbr']\n",
      "\n",
      "evaluating column:  SibSp\n",
      "processing column:  SibSp\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['SibSp_nmbr']\n",
      "\n",
      "evaluating column:  Parch\n",
      "processing column:  Parch\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['Parch_nmbr']\n",
      "\n",
      "evaluating column:  Ticket\n",
      "processing column:  Ticket\n",
      "    root category:  hash\n",
      " returned columns:\n",
      "['Ticket_hash_0', 'Ticket_hash_1', 'Ticket_hash_2']\n",
      "\n",
      "evaluating column:  Fare\n",
      "processing column:  Fare\n",
      "    root category:  nmbr\n",
      " returned columns:\n",
      "['Fare_nmbr']\n",
      "\n",
      "evaluating column:  Cabin\n",
      "processing column:  Cabin\n",
      "    root category:  hsh2\n",
      " returned columns:\n",
      "['Cabin_hash']\n",
      "\n",
      "evaluating column:  Embarked\n",
      "processing column:  Embarked\n",
      "    root category:  1010\n",
      " returned columns:\n",
      "['Embarked_1010_0', 'Embarked_1010_1']\n",
      "\n",
      "______\n",
      "\n",
      "evaluating label column:  Survived\n",
      "processing label column:  Survived\n",
      "    root label category:  lbbn\n",
      "\n",
      " returned columns:\n",
      "['Survived_0.0', 'Survived_1.0']\n",
      "\n",
      "______\n",
      "\n",
      "infill to column:  Sex_bnry\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Age_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  SibSp_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Parch_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Fare_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Cabin_hash\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Pclass_1.0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Pclass_2.0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Pclass_3.0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Name_hash_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Name_hash_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Name_hash_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Name_hash_3\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Name_hash_4\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Name_hash_5\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Name_hash_6\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Name_hash_7\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Name_hash_8\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Name_hash_9\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Name_hash_10\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Name_hash_11\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Name_hash_12\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Name_hash_13\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Ticket_hash_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Ticket_hash_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Ticket_hash_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Embarked_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Embarked_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "______\n",
      "\n",
      "versioning serial stamp:\n",
      "_5.56_797922035195_2021-02-03T09:07:52.958449\n",
      "\n",
      "Automunge returned ID column set: \n",
      "['PassengerId', 'Automunge_index_797922035195']\n",
      "\n",
      "Automunge returned train column set: \n",
      "['Sex_bnry', 'Age_nmbr', 'SibSp_nmbr', 'Parch_nmbr', 'Fare_nmbr', 'Cabin_hash', 'Pclass_1.0', 'Pclass_2.0', 'Pclass_3.0', 'Name_hash_0', 'Name_hash_1', 'Name_hash_2', 'Name_hash_3', 'Name_hash_4', 'Name_hash_5', 'Name_hash_6', 'Name_hash_7', 'Name_hash_8', 'Name_hash_9', 'Name_hash_10', 'Name_hash_11', 'Name_hash_12', 'Name_hash_13', 'Ticket_hash_0', 'Ticket_hash_1', 'Ticket_hash_2', 'Embarked_1010_0', 'Embarked_1010_1']\n",
      "\n",
      "Automunge returned label column set: \n",
      "['Survived_0.0', 'Survived_1.0']\n",
      "\n",
      "_______________\n",
      "Automunge Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train, trainID, labels, \\\n",
    "validation1, validationID1, validationlabels1, \\\n",
    "validation2, validationID2, validationlabels2, \\\n",
    "test, testID, testlabels, \\\n",
    "labelsencoding_dict, finalcolumns_train, finalcolumns_test, \\\n",
    "featureimportance, postprocess_dict \\\n",
    "= am.automunge(df_train,\n",
    "               labels_column = labels_column,\n",
    "               trainID_column = trainID_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned data can be accessed in the sets:\n",
    "train, trainID, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_bnry</th>\n",
       "      <th>Age_nmbr</th>\n",
       "      <th>SibSp_nmbr</th>\n",
       "      <th>Parch_nmbr</th>\n",
       "      <th>Fare_nmbr</th>\n",
       "      <th>Cabin_hash</th>\n",
       "      <th>Pclass_1.0</th>\n",
       "      <th>Pclass_2.0</th>\n",
       "      <th>Pclass_3.0</th>\n",
       "      <th>Name_hash_0</th>\n",
       "      <th>...</th>\n",
       "      <th>Name_hash_9</th>\n",
       "      <th>Name_hash_10</th>\n",
       "      <th>Name_hash_11</th>\n",
       "      <th>Name_hash_12</th>\n",
       "      <th>Name_hash_13</th>\n",
       "      <th>Ticket_hash_0</th>\n",
       "      <th>Ticket_hash_1</th>\n",
       "      <th>Ticket_hash_2</th>\n",
       "      <th>Embarked_1010_0</th>\n",
       "      <th>Embarked_1010_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>0.767199</td>\n",
       "      <td>-0.341261</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>541</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>1</td>\n",
       "      <td>0.100052</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.436762</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>369</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>857</td>\n",
       "      <td>314</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.745970</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.488580</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>315</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>221</td>\n",
       "      <td>670</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.822726</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>0.767199</td>\n",
       "      <td>0.016014</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1015</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>920</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.207437</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.421837</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>635</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>578</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sex_bnry  Age_nmbr  SibSp_nmbr  Parch_nmbr  Fare_nmbr  Cabin_hash  \\\n",
       "709         1  0.000000    0.432550    0.767199  -0.341261         175   \n",
       "439         1  0.100052   -0.474279   -0.473408  -0.436762         175   \n",
       "840         1 -0.745970   -0.474279   -0.473408  -0.488580         175   \n",
       "720         0 -1.822726   -0.474279    0.767199   0.016014         175   \n",
       "39          0 -1.207437    0.432550   -0.473408  -0.421837         175   \n",
       "\n",
       "     Pclass_1.0  Pclass_2.0  Pclass_3.0  Name_hash_0  ...  Name_hash_9  \\\n",
       "709           0           0           1          124  ...            0   \n",
       "439           0           1           0          369  ...            0   \n",
       "840           0           0           1          315  ...            0   \n",
       "720           0           1           0         1015  ...            0   \n",
       "39            0           0           1          635  ...            0   \n",
       "\n",
       "     Name_hash_10  Name_hash_11  Name_hash_12  Name_hash_13  Ticket_hash_0  \\\n",
       "709             0             0             0             0            541   \n",
       "439             0             0             0             0            857   \n",
       "840             0             0             0             0            221   \n",
       "720             0             0             0             0            920   \n",
       "39              0             0             0             0            578   \n",
       "\n",
       "     Ticket_hash_1  Ticket_hash_2  Embarked_1010_0  Embarked_1010_1  \n",
       "709              0              0                0                0  \n",
       "439            314              0                1                0  \n",
       "840            670              0                1                0  \n",
       "720              0              0                1                0  \n",
       "39               0              0                0                0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the column headers of the returned data are different, now including suffix appenders logging the applied transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any carved out ID sets are included in the trainID set as well as an aggregated set of index numbers (since the function by default shuffles training data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Automunge_index_797922035195</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>710</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>440</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>841</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>721</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Automunge_index_797922035195\n",
       "709          710                           709\n",
       "439          440                           439\n",
       "840          841                           840\n",
       "720          721                           720\n",
       "39            40                            39"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainID.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived_0.0</th>\n",
       "      <th>Survived_1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived_0.0  Survived_1.0\n",
       "709             0             1\n",
       "439             1             0\n",
       "840             1             0\n",
       "720             0             1\n",
       "39              0             1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a few more common parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few options that might come up often:\n",
    "- if we have test data available at same time as train data, we can also pass a test set\n",
    "- if we want to carve out a validation set processed on the train set basis we can designate a ratio by the valpercent1 and/or valpercent2 parameter\n",
    "- if we want to turn off printouts we can turn off with printstatus = False\n",
    "- if we want to return numpy arrays instead of dataframes can pass pandasoutput = False\n",
    "- for including with transformations a marker for entries that were subject to infill can pass NArw_marker = True\n",
    "- for auto ML derived missing data infill can apply MLinfill = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, trainID, labels, \\\n",
    "validation1, validationID1, validationlabels1, \\\n",
    "validation2, validationID2, validationlabels2, \\\n",
    "test, testID, testlabels, \\\n",
    "labelsencoding_dict, finalcolumns_train, finalcolumns_test, \\\n",
    "featureimportance, postprocess_dict \\\n",
    "= am.automunge(df_train,\n",
    "               df_test = df_test,\n",
    "               labels_column = labels_column,\n",
    "               trainID_column = trainID_column,\n",
    "               valpercent1 = 0.2, \n",
    "               printstatus = False, \n",
    "               pandasoutput = False,\n",
    "               MLinfill = True,\n",
    "               NArw_marker = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.37173158, -0.48163003, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.        ,  1.3082061 ,  0.44518235, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 1.        ,  2.4319756 , -0.48163003, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       ...,\n",
       "       [ 1.        ,  0.6714034 , -0.48163003, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 1.        , -0.28454977, -0.48163003, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 1.        , -1.9336214 ,  0.44518235, ...,  0.        ,\n",
       "         0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the test data is returned in test, testID, testlabels\n",
    "#here as a numpy array based on pandasoutput parameter\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing additional test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the various returned sets, an important one is the final object we call the postprocess_dict. Think of this as a key to processing additioanl data on the original train set basis. If you intend to productionize a model we recomend saving externally such as with the pickle library. Once we have additional data we want to process we can pass it with the postprocess_dict to the postmunge(.) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________\n",
      "Begin Postmunge processing\n",
      "\n",
      "______\n",
      "\n",
      "processing column:  Pclass\n",
      "    root category:  text\n",
      "\n",
      " returned columns:\n",
      "['Pclass_NArw', 'Pclass_1.0', 'Pclass_2.0', 'Pclass_3.0']\n",
      "\n",
      "______\n",
      "\n",
      "processing column:  Name\n",
      "    root category:  hash\n",
      "\n",
      " returned columns:\n",
      "['Name_NArw', 'Name_hash_0', 'Name_hash_1', 'Name_hash_2', 'Name_hash_3', 'Name_hash_4', 'Name_hash_5', 'Name_hash_6', 'Name_hash_7', 'Name_hash_8', 'Name_hash_9', 'Name_hash_10', 'Name_hash_11', 'Name_hash_12', 'Name_hash_13']\n",
      "\n",
      "______\n",
      "\n",
      "processing column:  Sex\n",
      "    root category:  bnry\n",
      "\n",
      " returned columns:\n",
      "['Sex_bnry', 'Sex_NArw']\n",
      "\n",
      "______\n",
      "\n",
      "processing column:  Age\n",
      "    root category:  nmbr\n",
      "\n",
      " returned columns:\n",
      "['Age_nmbr', 'Age_NArw']\n",
      "\n",
      "______\n",
      "\n",
      "processing column:  SibSp\n",
      "    root category:  nmbr\n",
      "\n",
      " returned columns:\n",
      "['SibSp_nmbr', 'SibSp_NArw']\n",
      "\n",
      "______\n",
      "\n",
      "processing column:  Parch\n",
      "    root category:  nmbr\n",
      "\n",
      " returned columns:\n",
      "['Parch_nmbr', 'Parch_NArw']\n",
      "\n",
      "______\n",
      "\n",
      "processing column:  Ticket\n",
      "    root category:  hash\n",
      "\n",
      " returned columns:\n",
      "['Ticket_NArw', 'Ticket_hash_0', 'Ticket_hash_1', 'Ticket_hash_2']\n",
      "\n",
      "______\n",
      "\n",
      "processing column:  Fare\n",
      "    root category:  nmbr\n",
      "\n",
      " returned columns:\n",
      "['Fare_nmbr', 'Fare_NArw']\n",
      "\n",
      "______\n",
      "\n",
      "processing column:  Cabin\n",
      "    root category:  1010\n",
      "\n",
      " returned columns:\n",
      "['Cabin_NArw', 'Cabin_1010_0', 'Cabin_1010_1', 'Cabin_1010_2', 'Cabin_1010_3', 'Cabin_1010_4', 'Cabin_1010_5', 'Cabin_1010_6']\n",
      "\n",
      "______\n",
      "\n",
      "processing column:  Embarked\n",
      "    root category:  1010\n",
      "\n",
      " returned columns:\n",
      "['Embarked_NArw', 'Embarked_1010_0', 'Embarked_1010_1']\n",
      "\n",
      "______\n",
      "\n",
      "infill to column:  Sex_bnry\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Age_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  SibSp_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Parch_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Fare_nmbr\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Pclass_1.0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Pclass_2.0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Pclass_3.0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Name_hash_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Name_hash_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Name_hash_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Name_hash_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Name_hash_4\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Name_hash_5\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Name_hash_6\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Name_hash_7\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Name_hash_8\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Name_hash_9\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Name_hash_10\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Name_hash_11\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Name_hash_12\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Name_hash_13\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Ticket_hash_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Ticket_hash_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Ticket_hash_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Cabin_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Cabin_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Cabin_1010_2\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Cabin_1010_3\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Cabin_1010_4\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Cabin_1010_5\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Cabin_1010_6\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Embarked_1010_0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Embarked_1010_1\n",
      "     infill type: MLinfill\n",
      "\n",
      "_______________\n",
      "Postmunge returned ID column set: \n",
      "['PassengerId', 'Automunge_index_145867262940']\n",
      "\n",
      "Postmunge returned test column set: \n",
      "['Sex_bnry', 'Age_nmbr', 'SibSp_nmbr', 'Parch_nmbr', 'Fare_nmbr', 'Pclass_NArw', 'Pclass_1.0', 'Pclass_2.0', 'Pclass_3.0', 'Name_NArw', 'Name_hash_0', 'Name_hash_1', 'Name_hash_2', 'Name_hash_3', 'Name_hash_4', 'Name_hash_5', 'Name_hash_6', 'Name_hash_7', 'Name_hash_8', 'Name_hash_9', 'Name_hash_10', 'Name_hash_11', 'Name_hash_12', 'Name_hash_13', 'Sex_NArw', 'Age_NArw', 'SibSp_NArw', 'Parch_NArw', 'Ticket_NArw', 'Ticket_hash_0', 'Ticket_hash_1', 'Ticket_hash_2', 'Fare_NArw', 'Cabin_NArw', 'Cabin_1010_0', 'Cabin_1010_1', 'Cabin_1010_2', 'Cabin_1010_3', 'Cabin_1010_4', 'Cabin_1010_5', 'Cabin_1010_6', 'Embarked_NArw', 'Embarked_1010_0', 'Embarked_1010_1']\n",
      "\n",
      "_______________\n",
      "Postmunge Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test, testID, testlabels, \\\n",
    "labelsencoding_dict, postreports_dict \\\n",
    "= am.postmunge(postprocess_dict, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_bnry</th>\n",
       "      <th>Age_nmbr</th>\n",
       "      <th>SibSp_nmbr</th>\n",
       "      <th>Parch_nmbr</th>\n",
       "      <th>Fare_nmbr</th>\n",
       "      <th>Pclass_NArw</th>\n",
       "      <th>Pclass_1.0</th>\n",
       "      <th>Pclass_2.0</th>\n",
       "      <th>Pclass_3.0</th>\n",
       "      <th>Name_NArw</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_1010_0</th>\n",
       "      <th>Cabin_1010_1</th>\n",
       "      <th>Cabin_1010_2</th>\n",
       "      <th>Cabin_1010_3</th>\n",
       "      <th>Cabin_1010_4</th>\n",
       "      <th>Cabin_1010_5</th>\n",
       "      <th>Cabin_1010_6</th>\n",
       "      <th>Embarked_NArw</th>\n",
       "      <th>Embarked_1010_0</th>\n",
       "      <th>Embarked_1010_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.371732</td>\n",
       "      <td>-0.481630</td>\n",
       "      <td>-0.493483</td>\n",
       "      <td>-0.480821</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.308206</td>\n",
       "      <td>0.445182</td>\n",
       "      <td>-0.493483</td>\n",
       "      <td>-0.496660</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2.431976</td>\n",
       "      <td>-0.481630</td>\n",
       "      <td>-0.493483</td>\n",
       "      <td>-0.445326</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.190153</td>\n",
       "      <td>-0.481630</td>\n",
       "      <td>-0.493483</td>\n",
       "      <td>-0.464904</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.564743</td>\n",
       "      <td>0.445182</td>\n",
       "      <td>0.705697</td>\n",
       "      <td>-0.395663</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex_bnry  Age_nmbr  SibSp_nmbr  Parch_nmbr  Fare_nmbr  Pclass_NArw  \\\n",
       "0         1  0.371732   -0.481630   -0.493483  -0.480821            0   \n",
       "1         0  1.308206    0.445182   -0.493483  -0.496660            0   \n",
       "2         1  2.431976   -0.481630   -0.493483  -0.445326            0   \n",
       "3         1 -0.190153   -0.481630   -0.493483  -0.464904            0   \n",
       "4         0 -0.564743    0.445182    0.705697  -0.395663            0   \n",
       "\n",
       "   Pclass_1.0  Pclass_2.0  Pclass_3.0  Name_NArw  ...  Cabin_1010_0  \\\n",
       "0           0           0           1          0  ...             0   \n",
       "1           0           0           1          0  ...             0   \n",
       "2           0           1           0          0  ...             0   \n",
       "3           0           0           1          0  ...             0   \n",
       "4           0           0           1          0  ...             0   \n",
       "\n",
       "   Cabin_1010_1  Cabin_1010_2  Cabin_1010_3  Cabin_1010_4  Cabin_1010_5  \\\n",
       "0             1             1             1             0             0   \n",
       "1             1             1             1             0             0   \n",
       "2             1             1             1             0             0   \n",
       "3             1             1             1             0             0   \n",
       "4             1             1             1             0             0   \n",
       "\n",
       "   Cabin_1010_6  Embarked_NArw  Embarked_1010_0  Embarked_1010_1  \n",
       "0             0              0                0                1  \n",
       "1             0              0                1                0  \n",
       "2             0              0                0                1  \n",
       "3             0              0                1                0  \n",
       "4             0              0                1                0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automunge has a library of transformations (documented in the read me). In general, each of these transformations is fit to properties of the train set to enable processing on a consistent basis of additional data.\n",
    "\n",
    "Each transformation in the libary has a distinct 4 character string identifier, generally aligned with the suffix appender on the returned set. \n",
    "\n",
    "We can designate our assignments in the assigncat parameter as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we designate min-max scaling to the column 'Fare'\n",
    "assigncat = {'mnmx':['Fare']}\n",
    "\n",
    "train, trainID, labels, \\\n",
    "validation1, validationID1, validationlabels1, \\\n",
    "validation2, validationID2, validationlabels2, \\\n",
    "test, testID, testlabels, \\\n",
    "labelsencoding_dict, finalcolumns_train, finalcolumns_test, \\\n",
    "featureimportance, postprocess_dict \\\n",
    "= am.automunge(df_train,\n",
    "               labels_column = labels_column,\n",
    "               trainID_column = trainID_column,\n",
    "               assigncat = assigncat,\n",
    "               printstatus = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the columns returned from a specific input column can use the column map stored in the postprocess_dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare_mnmx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>0.029758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.020495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>0.015469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>0.064412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.021942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Fare_mnmx\n",
       "709   0.029758\n",
       "439   0.020495\n",
       "840   0.015469\n",
       "720   0.064412\n",
       "39    0.021942"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[postprocess_dict['column_map']['Fare']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing data infill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noted earlier that the MLinfill parameter activates an autoML method for missing data inputation. Let's take a look at this in action. Here we'll turn on ML infill as well as markers for entries subject to infill with the NArw_marker parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, trainID, labels, \\\n",
    "validation1, validationID1, validationlabels1, \\\n",
    "validation2, validationID2, validationlabels2, \\\n",
    "test, testID, testlabels, \\\n",
    "labelsencoding_dict, finalcolumns_train, finalcolumns_test, \\\n",
    "featureimportance, postprocess_dict \\\n",
    "= am.automunge(df_train,\n",
    "               labels_column = labels_column,\n",
    "               trainID_column = trainID_column,\n",
    "               MLinfill = True,\n",
    "               NArw_marker=True,\n",
    "               printstatus = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By inspection, if appears that one of the entries in the Age column was subject to infill:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_nmbr</th>\n",
       "      <th>Age_NArw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>-1.692485</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.100052</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>-0.745970</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>-1.822726</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-1.207437</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age_nmbr  Age_NArw\n",
       "709 -1.692485         1\n",
       "439  0.100052         0\n",
       "840 -0.745970         0\n",
       "720 -1.822726         0\n",
       "39  -1.207437         0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[postprocess_dict['column_map']['Age']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears the ML infill is assuming for first row's inputation that this is a very young passenger (remember this is normalized data is reason for the negative value)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the trained models for each feature are saved in the postprocess_dict to enable a consistent inputation basis for subsequent data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML infill isn't the only inputation option. Other options like mode, adjacent cell, 0/1, mean, etc can be designated to distinct columns with the assigninfill parameter.\n",
    "\n",
    "Here we'll demonstrate applying a few different approaches to different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "assigninfill = {'MLinfill'  : ['Pclass'],\n",
    "                'adjinfill' : ['Age'],\n",
    "                'modeinfill': ['Fare']}\n",
    "\n",
    "train, trainID, labels, \\\n",
    "validation1, validationID1, validationlabels1, \\\n",
    "validation2, validationID2, validationlabels2, \\\n",
    "test, testID, testlabels, \\\n",
    "labelsencoding_dict, finalcolumns_train, finalcolumns_test, \\\n",
    "featureimportance, postprocess_dict \\\n",
    "= am.automunge(df_train,\n",
    "               labels_column = labels_column,\n",
    "               trainID_column = trainID_column,\n",
    "               assigninfill = assigninfill,\n",
    "               printstatus = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_bnry</th>\n",
       "      <th>Age_nmbr</th>\n",
       "      <th>SibSp_nmbr</th>\n",
       "      <th>Parch_nmbr</th>\n",
       "      <th>Fare_nmbr</th>\n",
       "      <th>Cabin_hash</th>\n",
       "      <th>Pclass_1.0</th>\n",
       "      <th>Pclass_2.0</th>\n",
       "      <th>Pclass_3.0</th>\n",
       "      <th>Name_hash_0</th>\n",
       "      <th>...</th>\n",
       "      <th>Name_hash_9</th>\n",
       "      <th>Name_hash_10</th>\n",
       "      <th>Name_hash_11</th>\n",
       "      <th>Name_hash_12</th>\n",
       "      <th>Name_hash_13</th>\n",
       "      <th>Ticket_hash_0</th>\n",
       "      <th>Ticket_hash_1</th>\n",
       "      <th>Ticket_hash_2</th>\n",
       "      <th>Embarked_1010_0</th>\n",
       "      <th>Embarked_1010_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.592148</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>0.767199</td>\n",
       "      <td>-0.341261</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>541</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>1</td>\n",
       "      <td>0.100052</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.436762</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>369</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>857</td>\n",
       "      <td>314</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.745970</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.488580</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>315</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>221</td>\n",
       "      <td>670</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.822726</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>0.767199</td>\n",
       "      <td>0.016014</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1015</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>920</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.207437</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.421837</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>635</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>578</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sex_bnry  Age_nmbr  SibSp_nmbr  Parch_nmbr  Fare_nmbr  Cabin_hash  \\\n",
       "709         1 -0.592148    0.432550    0.767199  -0.341261         175   \n",
       "439         1  0.100052   -0.474279   -0.473408  -0.436762         175   \n",
       "840         1 -0.745970   -0.474279   -0.473408  -0.488580         175   \n",
       "720         0 -1.822726   -0.474279    0.767199   0.016014         175   \n",
       "39          0 -1.207437    0.432550   -0.473408  -0.421837         175   \n",
       "\n",
       "     Pclass_1.0  Pclass_2.0  Pclass_3.0  Name_hash_0  ...  Name_hash_9  \\\n",
       "709           0           0           1          124  ...            0   \n",
       "439           0           1           0          369  ...            0   \n",
       "840           0           0           1          315  ...            0   \n",
       "720           0           1           0         1015  ...            0   \n",
       "39            0           0           1          635  ...            0   \n",
       "\n",
       "     Name_hash_10  Name_hash_11  Name_hash_12  Name_hash_13  Ticket_hash_0  \\\n",
       "709             0             0             0             0            541   \n",
       "439             0             0             0             0            857   \n",
       "840             0             0             0             0            221   \n",
       "720             0             0             0             0            920   \n",
       "39              0             0             0             0            578   \n",
       "\n",
       "     Ticket_hash_1  Ticket_hash_2  Embarked_1010_0  Embarked_1010_1  \n",
       "709              0              0                0                0  \n",
       "439            314              0                1                0  \n",
       "840            670              0                1                0  \n",
       "720              0              0                1                0  \n",
       "39               0              0                0                0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In closing, as an explanation, the whole point of conducting all of the transformations in a single function is that this application serves to populate a dictionary (the \"postprocess_dict\") fit to properties of the train data, capturing all of the steps and parameters of transformations, potentially including methods for ML derived missing data inputation, dimensionality reductions, and other various encodings available in the library. This returned dictionary can then be passed to the postmunge(.) function with subsequent data for fully consistent processing on the train set basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________\n",
      "Begin Postmunge processing\n",
      "\n",
      "______\n",
      "\n",
      "processing column:  Pclass\n",
      "    root category:  text\n",
      "\n",
      " returned columns:\n",
      "['Pclass_1.0', 'Pclass_2.0', 'Pclass_3.0']\n",
      "\n",
      "______\n",
      "\n",
      "processing column:  Name\n",
      "    root category:  hash\n",
      "\n",
      " returned columns:\n",
      "['Name_hash_0', 'Name_hash_1', 'Name_hash_2', 'Name_hash_3', 'Name_hash_4', 'Name_hash_5', 'Name_hash_6', 'Name_hash_7', 'Name_hash_8', 'Name_hash_9', 'Name_hash_10', 'Name_hash_11', 'Name_hash_12', 'Name_hash_13']\n",
      "\n",
      "______\n",
      "\n",
      "processing column:  Sex\n",
      "    root category:  bnry\n",
      "\n",
      " returned columns:\n",
      "['Sex_bnry']\n",
      "\n",
      "______\n",
      "\n",
      "processing column:  Age\n",
      "    root category:  nmbr\n",
      "\n",
      " returned columns:\n",
      "['Age_nmbr']\n",
      "\n",
      "______\n",
      "\n",
      "processing column:  SibSp\n",
      "    root category:  nmbr\n",
      "\n",
      " returned columns:\n",
      "['SibSp_nmbr']\n",
      "\n",
      "______\n",
      "\n",
      "processing column:  Parch\n",
      "    root category:  nmbr\n",
      "\n",
      " returned columns:\n",
      "['Parch_nmbr']\n",
      "\n",
      "______\n",
      "\n",
      "processing column:  Ticket\n",
      "    root category:  hash\n",
      "\n",
      " returned columns:\n",
      "['Ticket_hash_0', 'Ticket_hash_1', 'Ticket_hash_2']\n",
      "\n",
      "______\n",
      "\n",
      "processing column:  Fare\n",
      "    root category:  nmbr\n",
      "\n",
      " returned columns:\n",
      "['Fare_nmbr']\n",
      "\n",
      "______\n",
      "\n",
      "processing column:  Cabin\n",
      "    root category:  hsh2\n",
      "\n",
      " returned columns:\n",
      "['Cabin_hash']\n",
      "\n",
      "______\n",
      "\n",
      "processing column:  Embarked\n",
      "    root category:  1010\n",
      "\n",
      " returned columns:\n",
      "['Embarked_1010_0', 'Embarked_1010_1']\n",
      "\n",
      "______\n",
      "\n",
      "infill to column:  Sex_bnry\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Age_nmbr\n",
      "     infill type: adjinfill\n",
      "\n",
      "infill to column:  SibSp_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Parch_nmbr\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Fare_nmbr\n",
      "     infill type: modeinfill\n",
      "\n",
      "infill to column:  Cabin_hash\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Pclass_1.0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Pclass_2.0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Pclass_3.0\n",
      "     infill type: MLinfill\n",
      "\n",
      "infill to column:  Name_hash_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Name_hash_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Name_hash_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Name_hash_3\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Name_hash_4\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Name_hash_5\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Name_hash_6\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Name_hash_7\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Name_hash_8\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Name_hash_9\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Name_hash_10\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Name_hash_11\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Name_hash_12\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Name_hash_13\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Ticket_hash_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Ticket_hash_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Ticket_hash_2\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Embarked_1010_0\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "infill to column:  Embarked_1010_1\n",
      "     infill type: stdrdinfill\n",
      "\n",
      "_______________\n",
      "Postmunge returned ID column set: \n",
      "['PassengerId', 'Automunge_index_829601025164']\n",
      "\n",
      "Postmunge returned test column set: \n",
      "['Sex_bnry', 'Age_nmbr', 'SibSp_nmbr', 'Parch_nmbr', 'Fare_nmbr', 'Cabin_hash', 'Pclass_1.0', 'Pclass_2.0', 'Pclass_3.0', 'Name_hash_0', 'Name_hash_1', 'Name_hash_2', 'Name_hash_3', 'Name_hash_4', 'Name_hash_5', 'Name_hash_6', 'Name_hash_7', 'Name_hash_8', 'Name_hash_9', 'Name_hash_10', 'Name_hash_11', 'Name_hash_12', 'Name_hash_13', 'Ticket_hash_0', 'Ticket_hash_1', 'Ticket_hash_2', 'Embarked_1010_0', 'Embarked_1010_1']\n",
      "\n",
      "_______________\n",
      "Postmunge Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test, testID, testlabels, \\\n",
    "labelsencoding_dict, postreports_dict \\\n",
    "= am.postmunge(postprocess_dict, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_bnry</th>\n",
       "      <th>Age_nmbr</th>\n",
       "      <th>SibSp_nmbr</th>\n",
       "      <th>Parch_nmbr</th>\n",
       "      <th>Fare_nmbr</th>\n",
       "      <th>Cabin_hash</th>\n",
       "      <th>Pclass_1.0</th>\n",
       "      <th>Pclass_2.0</th>\n",
       "      <th>Pclass_3.0</th>\n",
       "      <th>Name_hash_0</th>\n",
       "      <th>...</th>\n",
       "      <th>Name_hash_9</th>\n",
       "      <th>Name_hash_10</th>\n",
       "      <th>Name_hash_11</th>\n",
       "      <th>Name_hash_12</th>\n",
       "      <th>Name_hash_13</th>\n",
       "      <th>Ticket_hash_0</th>\n",
       "      <th>Ticket_hash_1</th>\n",
       "      <th>Ticket_hash_2</th>\n",
       "      <th>Embarked_1010_0</th>\n",
       "      <th>Embarked_1010_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.369241</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.490508</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>276</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>423</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.330631</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.507194</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>754</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>804</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2.484298</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.453112</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>382</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>931</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.207592</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.473739</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>271</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>644</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.592148</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>0.767199</td>\n",
       "      <td>-0.400792</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>546</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex_bnry  Age_nmbr  SibSp_nmbr  Parch_nmbr  Fare_nmbr  Cabin_hash  \\\n",
       "0         1  0.369241   -0.474279   -0.473408  -0.490508         175   \n",
       "1         0  1.330631    0.432550   -0.473408  -0.507194         175   \n",
       "2         1  2.484298   -0.474279   -0.473408  -0.453112         175   \n",
       "3         1 -0.207592   -0.474279   -0.473408  -0.473739         175   \n",
       "4         0 -0.592148    0.432550    0.767199  -0.400792         175   \n",
       "\n",
       "   Pclass_1.0  Pclass_2.0  Pclass_3.0  Name_hash_0  ...  Name_hash_9  \\\n",
       "0           0           0           1          276  ...            0   \n",
       "1           0           0           1          754  ...            0   \n",
       "2           0           1           0          382  ...            0   \n",
       "3           0           0           1          271  ...            0   \n",
       "4           0           0           1          546  ...            0   \n",
       "\n",
       "   Name_hash_10  Name_hash_11  Name_hash_12  Name_hash_13  Ticket_hash_0  \\\n",
       "0             0             0             0             0            423   \n",
       "1             0             0             0             0            804   \n",
       "2             0             0             0             0            931   \n",
       "3             0             0             0             0            644   \n",
       "4             0             0             0             0             75   \n",
       "\n",
       "   Ticket_hash_1  Ticket_hash_2  Embarked_1010_0  Embarked_1010_1  \n",
       "0              0              0                0                1  \n",
       "1              0              0                1                0  \n",
       "2              0              0                0                1  \n",
       "3              0              0                1                0  \n",
       "4              0              0                1                0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
